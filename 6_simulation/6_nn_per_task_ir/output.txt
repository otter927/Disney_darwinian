[[[0.95469505 0.11293834 0.69591892 ... 0.75641778 0.9387113  0.92920223]
  [0.11810563 0.39197917 0.8328044  ... 0.67493119 0.58009367 0.71198847]
  [0.86899976 0.0645738  0.33170603 ... 0.67474951 0.20978689 0.12937382]
  ...
  [0.01290612 0.59678762 0.12892752 ... 0.33792439 0.64389323 0.12724605]
  [0.38626714 0.65874314 0.24045373 ... 0.63897246 0.89890679 0.80081144]
  [0.46941606 0.95948657 0.31401673 ... 0.26652522 0.0769238  0.39254875]]

 [[0.11269362 0.8548553  0.76849217 ... 0.90367352 0.8530622  0.73940906]
  [0.43792728 0.88743252 0.49737021 ... 0.76019003 0.80343788 0.28589605]
  [0.62430253 0.88240716 0.02465423 ... 0.50857489 0.73407697 0.08793353]
  ...
  [0.84851634 0.94659834 0.77065122 ... 0.0045265  0.76310205 0.67136947]
  [0.2158037  0.31556665 0.65691183 ... 0.39041955 0.99389424 0.32407309]
  [0.06789379 0.0322158  0.22380315 ... 0.47756295 0.88028663 0.00965239]]

 [[0.88151126 0.95712933 0.37867858 ... 0.35937573 0.74258271 0.454661  ]
  [0.13000668 0.78887512 0.1091436  ... 0.84791279 0.40205707 0.19317898]
  [0.51472011 0.70813407 0.69541064 ... 0.34861662 0.54732826 0.07204368]
  ...
  [0.07639714 0.98961322 0.68160292 ... 0.3787732  0.61721436 0.35575684]
  [0.91845457 0.35196044 0.99643916 ... 0.79728519 0.70448658 0.13100988]
  [0.86869976 0.94044462 0.54074966 ... 0.01257529 0.86158785 0.41633077]]

 [[0.23511009 0.43902861 0.23075339 ... 0.77613119 0.55225541 0.19256199]
  [0.97682583 0.9161205  0.52753963 ... 0.35214755 0.11998043 0.27028074]
  [0.38773699 0.50837393 0.8950632  ... 0.73174041 0.83330026 0.23520162]
  ...
  [0.83716493 0.63609944 0.99038924 ... 0.18403879 0.82840844 0.02565669]
  [0.209724   0.52389362 0.56133129 ... 0.03065193 0.98341914 0.25429815]
  [0.12302223 0.14528694 0.62011821 ... 0.58288312 0.71215252 0.48486234]]]
[[-1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1  1  1 -1  1  1  1 -1
  -1  1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1  1
  -1 -1  1  1 -1  1  1  1 -1 -1  1  1  1 -1  1 -1  1  1  1  1  1 -1  1  1
  -1  1  1 -1  1 -1  1 -1]
 [-1  1 -1  1 -1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1 -1  1
   1 -1  1 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1  1  1  1 -1  1 -1 -1 -1 -1  1
  -1 -1  1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1
   1 -1  1  1 -1 -1  1  1]
 [-1 -1  1  1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
  -1  1 -1  1  1 -1  1 -1 -1 -1  1  1  1  1 -1  1 -1 -1  1  1  1  1 -1 -1
   1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1  1
  -1 -1  1  1  1 -1 -1  1]
 [ 1 -1  1  1 -1  1 -1  1  1 -1 -1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1
  -1  1  1  1  1 -1 -1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1  1  1  1 -1 -1
   1  1 -1 -1 -1  1  1 -1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1 -1 -1 -1
   1  1 -1 -1  1 -1 -1  1]]
train_ds
<BatchDataset element_spec=(TensorSpec(shape=(None, 180, 80), dtype=tf.float64, name=None), TensorSpec(shape=(None, 80), dtype=tf.int64, name=None))>
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn (SimpleRNN)      (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
x_mb
tf.Tensor(
[[-1  1 -1  1 -1  1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1 -1  1
   1 -1  1 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1  1  1  1 -1  1 -1 -1 -1 -1  1
  -1 -1  1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1
   1 -1  1  1 -1 -1  1  1]
 [ 1 -1  1  1 -1  1 -1  1  1 -1 -1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1
  -1  1  1  1  1 -1 -1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1  1  1  1 -1 -1
   1  1 -1 -1 -1  1  1 -1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1 -1 -1 -1
   1  1 -1 -1  1 -1 -1  1]], shape=(2, 80), dtype=int64)
tr_loss:[1.2090328 1.3504469]
x_mb
tf.Tensor(
[[-1 -1  1  1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
  -1  1 -1  1  1 -1  1 -1 -1 -1  1  1  1  1 -1  1 -1 -1  1  1  1  1 -1 -1
   1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1  1
  -1 -1  1  1  1 -1 -1  1]
 [-1  1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1  1  1 -1  1  1  1 -1
  -1  1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1  1
  -1 -1  1  1 -1  1  1  1 -1 -1  1  1  1 -1  1 -1  1  1  1  1  1 -1  1  1
  -1  1  1 -1  1 -1  1 -1]], shape=(2, 80), dtype=int64)
tr_loss:[1.3989296 1.265873 ]
[[ 0.04271621  0.70967436  0.8489661   0.01146856 -0.99407244  0.02224227
  -0.2716934   0.6987111   0.9395603  -0.9216793   0.60748863 -0.28403518
   0.6635468   0.75912917  0.92235214 -0.8562184   0.98952484  0.29044387
   0.5538364  -0.1983303  -0.21303913 -0.9068295   0.7576592   0.4627203
  -0.7855607   0.6138367   0.84909374  0.22234029  0.4982963   0.022863
   0.76643616  0.53983927 -0.9680016  -0.9199166   0.6289547   0.2809763
  -0.9064903  -0.7911666   0.9444062   0.69673127  0.9507205  -0.381229
   0.90911686 -0.9733674  -0.7844291  -0.5433503  -0.525328    0.02573839
   0.64323217 -0.8913199  -0.09234247  0.89082307 -0.7613256  -0.8876948
   0.13443102  0.759621    0.6240738  -0.16530925 -0.2014196  -0.27191982
   0.5080119  -0.92036885  0.21456525 -0.21685438  0.9277506   0.24825488
  -0.04534803 -0.8413332  -0.06141238 -0.46220508  0.6237979  -0.27145895
  -0.6657661  -0.8751114   0.49683532  0.11620282  0.8001167  -0.92847365
  -0.5474862  -0.6252749 ]
 [ 0.48715854  0.9284712   0.6577178   0.6218911  -0.9769923   0.6914015
   0.4567217   0.80369306  0.9184579  -0.90813065  0.87347615 -0.61768484
   0.7532696   0.9660248   0.971908   -0.8000255   0.99833673  0.8925769
   0.48723418  0.57721174 -0.11623087 -0.70548505  0.29251614  0.16820782
  -0.61750513 -0.06322598  0.8905092   0.6431015  -0.17894983  0.82395464
   0.9174392   0.52272534 -0.9768877  -0.9885965   0.6079239  -0.28894973
  -0.5016659  -0.3532337   0.7809147   0.8002847   0.95071644  0.02123326
   0.9855876  -0.8427252  -0.6831891  -0.6818685  -0.57702076 -0.72413194
   0.45311216 -0.9594272   0.6479044   0.28092247 -0.9533623  -0.47296166
   0.21994564  0.5752812   0.24844702  0.34117338  0.5350683  -0.72996116
  -0.25490832 -0.96961933  0.7509655  -0.6920352   0.57164687  0.74333215
  -0.5380751  -0.68376464  0.29015258 -0.6526051   0.6111704  -0.2930435
  -0.4054438  -0.91540104  0.8594796   0.8380936   0.57230824 -0.9625917
  -0.7465495  -0.20894887]
 [ 0.6097543   0.9787435   0.7059481   0.77477604 -0.96260357 -0.22418897
   0.5765885   0.6948653   0.8596573  -0.9163366   0.76911837 -0.10841093
   0.7248795   0.9846244   0.9604073  -0.7907376   0.99882305  0.4276904
   0.39465967  0.62103105 -0.25458753 -0.7452337   0.94930935 -0.66720074
  -0.6617602   0.7164262   0.85068846  0.76341903  0.53414655  0.42662618
   0.9429257   0.20450741 -0.9601803  -0.9023509   0.5117447   0.16152447
  -0.6701227   0.13801278  0.7717948   0.26946077  0.9597526  -0.43777815
   0.769108   -0.85318595 -0.47869277 -0.6259352  -0.75399965 -0.7542864
   0.31657714 -0.7610748  -0.22968905  0.41435966 -0.5768485  -0.8197585
  -0.61309445  0.58736324 -0.5100126   0.50459063  0.02247301 -0.49827194
  -0.4046948  -0.9792169   0.29446262 -0.5465163   0.7450747   0.11182635
  -0.343436   -0.58895296  0.35510063 -0.5600583   0.71985763 -0.2885364
  -0.40807694 -0.82045287  0.3488686   0.28230605  0.48660412 -0.9456397
  -0.34084773 -0.26003453]
 [ 0.19394739  0.9647866   0.7612635   0.43304792 -0.98897654  0.6289353
   0.07070493  0.43947688  0.9691393  -0.9317195   0.8098156  -0.54034173
   0.8242513   0.8841881   0.9596797  -0.81706136  0.99779016  0.7252032
   0.887063    0.58770573 -0.06354266 -0.56428236  0.29984793  0.05722848
  -0.86679655  0.719022    0.842854    0.3380372   0.50585395  0.80668694
   0.7611517   0.6882398  -0.98347604 -0.94610244  0.83961743  0.36542848
  -0.6827251  -0.5340035   0.6038841   0.6096249   0.5958658   0.01546468
   0.83748424 -0.5191429  -0.5887873   0.10180197 -0.16853805 -0.23026837
   0.6661685  -0.8622669  -0.59812313  0.4634075  -0.7227425  -0.54115
  -0.51782703  0.7920312  -0.03953272  0.39923546 -0.19603205  0.04141979
   0.0514817  -0.9689251   0.6083114  -0.62566596  0.857854    0.6894765
  -0.57322466 -0.9141323   0.46919483 -0.76224715  0.01272109 -0.56027323
  -0.6767864  -0.9063442  -0.01115581  0.26122656  0.9334808  -0.97911584
  -0.45646837 -0.27860287]]
[[[0.50071618 0.01465658 0.40918678 ... 0.88704825 0.35902952 0.0908336 ]
  [0.26208228 0.74185983 0.53845032 ... 0.99242765 0.34011462 0.3302949 ]
  [0.92076493 0.38618376 0.69201799 ... 0.85689669 0.04809574 0.1159538 ]
  ...
  [0.62302007 0.70538803 0.88012506 ... 0.74703134 0.89235617 0.46329313]
  [0.0149     0.77593612 0.44298021 ... 0.10039089 0.04404631 0.54976431]
  [0.04452009 0.55528423 0.36364499 ... 0.1100316  0.90985735 0.64550484]]

 [[0.41893223 0.92093774 0.13361745 ... 0.39446108 0.24617739 0.28178912]
  [0.62126108 0.50280136 0.22903195 ... 0.3529354  0.52353037 0.39154907]
  [0.56551824 0.41420464 0.19424296 ... 0.76455527 0.12519286 0.35545951]
  ...
  [0.45518779 0.52722639 0.87772075 ... 0.47898206 0.25430445 0.78323883]
  [0.87842645 0.59259873 0.75890298 ... 0.89354722 0.73746289 0.72550864]
  [0.70205258 0.2518354  0.25267299 ... 0.80843177 0.5785887  0.95996484]]

 [[0.10102255 0.59249156 0.79739105 ... 0.23057974 0.53895403 0.28689323]
  [0.75422291 0.41848004 0.65191813 ... 0.9512125  0.15960842 0.91505493]
  [0.21025159 0.85856042 0.32356339 ... 0.97770601 0.10290493 0.62927689]
  ...
  [0.34559062 0.70002759 0.71899367 ... 0.26229934 0.49575893 0.41010474]
  [0.37079931 0.0847078  0.87094718 ... 0.03392024 0.27375625 0.2838185 ]
  [0.3605732  0.00382864 0.65493813 ... 0.27670119 0.20410743 0.93098734]]

 [[0.5151519  0.26432187 0.36220116 ... 0.43444594 0.2550839  0.89226166]
  [0.09967608 0.0195769  0.80824606 ... 0.51809303 0.66835155 0.98772855]
  [0.99804229 0.4827992  0.60965184 ... 0.29684043 0.01421458 0.05452968]
  ...
  [0.75099759 0.23319219 0.30047356 ... 0.08401769 0.40785038 0.8761001 ]
  [0.16483928 0.32533673 0.73918164 ... 0.3337573  0.41319765 0.13391784]
  [0.40705347 0.13900977 0.13677788 ... 0.38501939 0.08139082 0.41258626]]]
[[-1  1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1 -1  1  1  1 -1  1  1
  -1 -1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1
   1 -1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1 -1  1 -1  1  1 -1 -1  1  1  1
  -1 -1  1  1  1 -1  1 -1]
 [-1 -1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1  1  1  1 -1 -1  1 -1  1 -1  1
  -1 -1 -1  1 -1  1  1 -1  1 -1  1  1 -1 -1  1 -1  1  1  1 -1 -1 -1 -1  1
  -1 -1 -1 -1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1  1
   1  1 -1 -1  1  1 -1 -1]
 [ 1 -1 -1 -1  1  1  1  1 -1  1  1 -1  1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1
   1 -1 -1  1 -1  1  1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1  1  1 -1 -1  1
   1  1 -1  1  1 -1  1  1 -1 -1  1  1  1 -1  1  1  1  1 -1  1 -1 -1  1 -1
  -1 -1 -1  1  1  1 -1 -1]
 [ 1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1  1 -1  1  1  1 -1  1 -1  1  1
  -1 -1 -1 -1 -1  1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1  1 -1  1
   1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1
  -1  1 -1 -1  1 -1 -1  1]]
train_ds
<BatchDataset element_spec=(TensorSpec(shape=(None, 180, 80), dtype=tf.float64, name=None), TensorSpec(shape=(None, 80), dtype=tf.int64, name=None))>
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_1 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
x_mb
tf.Tensor(
[[-1  1  1 -1 -1  1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1 -1  1  1  1 -1  1  1
  -1 -1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1
   1 -1 -1 -1 -1  1  1  1  1  1 -1  1 -1  1 -1  1 -1  1  1 -1 -1  1  1  1
  -1 -1  1  1  1 -1  1 -1]
 [ 1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1  1 -1  1  1  1 -1  1 -1  1  1
  -1 -1 -1 -1 -1  1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1  1 -1  1
   1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1
  -1  1 -1 -1  1 -1 -1  1]], shape=(2, 80), dtype=int64)
tr_loss:[1.2094364 1.2839117]
x_mb
tf.Tensor(
[[-1 -1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1  1  1  1 -1 -1  1 -1  1 -1  1
  -1 -1 -1  1 -1  1  1 -1  1 -1  1  1 -1 -1  1 -1  1  1  1 -1 -1 -1 -1  1
  -1 -1 -1 -1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1  1
   1  1 -1 -1  1  1 -1 -1]
 [ 1  1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1  1 -1  1  1  1 -1  1 -1  1  1
  -1 -1 -1 -1 -1  1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1  1 -1  1
   1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1
  -1  1 -1 -1  1 -1 -1  1]], shape=(2, 80), dtype=int64)
tr_loss:[1.1308906 0.8913876]
[[ 7.06544146e-02  7.44105339e-01  3.42985421e-01 -9.80329454e-01
  -7.11330533e-01  6.91914320e-01 -9.33493674e-01 -9.01117265e-01
  -9.18306589e-01  8.93275559e-01  5.84810197e-01  5.40768385e-01
   7.05433786e-01 -4.79765981e-01  8.36055279e-01 -9.53863204e-01
   8.66578400e-01 -8.85757506e-01  2.13733703e-01 -7.03206718e-01
  -2.03535393e-01 -7.93120563e-02 -1.44061306e-02  3.48959833e-01
  -6.46185160e-01 -8.58483136e-01 -4.02031869e-01 -4.68936443e-01
   6.94445014e-01  9.62443054e-01 -2.05116630e-01  6.00303531e-01
  -5.76270759e-01  7.59591758e-02 -7.23570287e-01 -9.17200863e-01
  -7.74102211e-01 -5.25749266e-01  4.18027848e-01  3.19379091e-01
  -6.50592148e-01  7.28705525e-02  9.17924464e-01  3.40015948e-01
  -1.74837545e-01  2.93857694e-01  7.84757495e-01  1.03211381e-01
   6.38825595e-01 -7.35664964e-01 -9.00038123e-01 -4.90667939e-01
   6.00431204e-01 -5.55522382e-01  2.81304002e-01  6.78719699e-01
   8.49718392e-01  4.65772189e-02 -8.61977339e-01 -7.43926823e-01
  -6.90229177e-01  4.37570453e-01 -9.68269229e-01 -7.45104909e-01
  -8.16799819e-01 -1.30897880e-01 -1.33901879e-01 -8.51817071e-01
  -4.25196528e-01  3.39593321e-01 -1.46801323e-01  5.11135876e-01
   1.14169054e-01  9.55653548e-01 -2.47480169e-01  2.03183755e-01
   9.26403821e-01 -9.75914240e-01  7.00837016e-01 -5.43834269e-01]
 [ 6.38269901e-01 -2.38495599e-03  2.65678406e-01 -9.13125455e-01
  -4.73767549e-01  8.18405509e-01 -9.46883202e-01 -6.54091001e-01
  -9.53067005e-01  8.80908251e-01  7.06179261e-01  7.29254663e-01
   5.63862562e-01 -4.43497121e-01  8.89899433e-01 -8.88444781e-01
   5.99691093e-01 -5.02099693e-01  3.54702324e-01 -3.70767742e-01
  -1.55665040e-01  1.31516993e-01  5.05273402e-01  4.81271923e-01
  -6.41201615e-01 -8.80301058e-01 -6.32951617e-01 -8.04059625e-01
   8.79338205e-01  8.67118478e-01 -4.27978039e-01  5.47690690e-01
   8.43882270e-04 -1.72520325e-01 -6.16908669e-01 -9.44348991e-01
  -8.06529447e-02 -7.24285483e-01  4.78993475e-01  5.02323657e-02
  -4.64056134e-01  3.52061272e-01  7.54338384e-01  8.45611453e-01
  -1.50686398e-01  4.46024179e-01  6.90236330e-01  5.88054359e-01
   2.56268997e-02 -8.60016763e-01 -8.99837077e-01 -5.13451159e-01
   8.93179953e-01 -3.50666374e-01 -1.69722378e-01  8.58376682e-01
   6.64522111e-01 -3.79310161e-01 -4.52133209e-01 -4.93898600e-01
  -8.24412227e-01  2.50181556e-01 -9.44206893e-01 -9.46435392e-01
  -7.09949076e-01 -1.50121395e-02 -6.70385435e-02 -6.80994153e-01
  -4.16345358e-01  8.65495503e-01 -3.10166210e-01  1.33632094e-01
   3.64922017e-01  8.08623016e-01 -9.98713747e-02  9.10960063e-02
   9.52555597e-01 -9.65266943e-01 -4.55005467e-01 -7.12258637e-01]
 [ 2.71855474e-01  5.27932286e-01 -1.00012356e-02 -7.70283043e-01
  -5.48794568e-01  6.53018117e-01 -9.28175449e-01 -6.81027532e-01
  -8.87219965e-01  7.92399406e-01  2.66776830e-01  7.31811464e-01
   5.54163814e-01 -6.47456586e-01  9.58864033e-01 -9.72430468e-01
   7.52485454e-01 -8.06167305e-01  2.84120329e-02 -8.85417461e-01
   4.59174633e-01 -2.86673069e-01  5.49962521e-01  3.15459520e-01
   3.10950369e-01 -8.23859870e-01 -5.61423182e-01 -6.26418293e-01
   8.80466044e-01  8.28916371e-01 -6.30889595e-01 -9.41219851e-02
   6.14912391e-01  2.65180051e-01 -5.03155112e-01 -8.26185942e-01
  -1.85835272e-01 -6.63172245e-01 -4.48530555e-01 -1.11245394e-01
  -6.33751750e-01  7.23404944e-01  9.52871978e-01  8.45780432e-01
   2.42334351e-01  1.33577064e-01  9.27735269e-01 -3.66315037e-01
   2.21378073e-01 -7.27291286e-01 -7.75881648e-01  1.38520941e-01
   6.33628666e-01 -6.29253447e-01 -6.40838981e-01  6.05668068e-01
   8.45484376e-01 -6.99642003e-01 -8.69823813e-01 -8.66471410e-01
  -7.23939538e-01  6.52085781e-01 -8.66135120e-01 -9.32162285e-01
  -8.56552422e-01 -2.99756557e-01  6.29671812e-01 -6.25318825e-01
  -5.50587535e-01  7.12029815e-01 -4.07805182e-02  3.16266000e-01
   2.22663745e-01  6.27145708e-01  3.17159742e-01  3.23209107e-01
   9.73375499e-01 -7.35530496e-01  4.09138381e-01 -3.28197360e-01]
 [ 3.09248269e-01  9.49493051e-01  1.77960142e-01 -9.11686063e-01
  -7.97001898e-01  6.37095749e-01 -1.36546507e-01 -9.15178597e-01
  -8.12341690e-01  2.59599686e-01 -6.63525641e-01  8.86315882e-01
   5.48463464e-01 -6.08671904e-01  9.16920185e-01 -8.77433062e-01
   9.46411669e-01 -7.31307685e-01  4.08350617e-01 -6.70485377e-01
  -3.30601305e-01 -3.93895388e-01  1.03740595e-01  3.90997291e-01
  -7.97095418e-01 -6.80876851e-01 -5.78255594e-01 -5.89159369e-01
   5.66937149e-01  8.97357643e-01 -9.56409574e-01 -4.44516867e-01
   6.03117704e-01 -2.48417519e-02 -3.33826214e-01 -4.83034283e-01
  -5.26405156e-01 -5.64494193e-01 -7.45145798e-01  8.57855499e-01
   2.40605362e-02 -4.91575837e-01  8.99771810e-01  3.42860490e-01
   6.10216916e-01 -2.57286638e-01  6.48677051e-01  7.55708575e-01
   3.93690854e-01 -6.23301148e-01 -9.36923265e-01  4.62596655e-01
   8.82644653e-01 -4.43452537e-01  2.72568792e-01  8.25375497e-01
   5.01914740e-01 -5.40615141e-01 -4.97767240e-01 -8.78887117e-01
  -8.90042782e-01  2.05275342e-01 -4.62014198e-01 -8.73798132e-01
  -8.01401317e-01 -5.78535676e-01  3.56079787e-01 -5.87739229e-01
  -6.47686362e-01  7.46843278e-01 -6.20129883e-01  4.13264155e-01
  -5.96145153e-01  9.50569212e-01  2.57078055e-02 -2.46404022e-01
   9.36944544e-01 -9.41310763e-01 -2.80118376e-01 -2.89438158e-01]]
[[[0.36014043 0.60168681 0.55362263 ... 0.44532641 0.13354067 0.55478911]
  [0.77049213 0.83240067 0.95488099 ... 0.5230821  0.43297392 0.68957195]
  [0.55214608 0.22711035 0.32615355 ... 0.34406645 0.33271566 0.80778744]
  ...
  [0.82654678 0.88062188 0.94460992 ... 0.64765265 0.91846993 0.13440805]
  [0.91620544 0.08436945 0.5877004  ... 0.12779343 0.36543218 0.1768363 ]
  [0.98693888 0.96740842 0.3077956  ... 0.54556502 0.04509254 0.17443499]]

 [[0.83312074 0.60776106 0.78344792 ... 0.65338626 0.28725681 0.01430753]
  [0.34954024 0.33792939 0.83349624 ... 0.31020556 0.78906785 0.87482052]
  [0.6278175  0.61626289 0.73521004 ... 0.08346142 0.64806029 0.10161856]
  ...
  [0.41614619 0.58413836 0.6145451  ... 0.38827175 0.60836621 0.62262522]
  [0.38083619 0.76522282 0.38270855 ... 0.53522106 0.24376047 0.97983874]
  [0.72616677 0.781829   0.55615489 ... 0.99009783 0.9113679  0.35853687]]

 [[0.8550071  0.50856851 0.11107392 ... 0.45990368 0.08493239 0.38061348]
  [0.18965039 0.7297816  0.33315038 ... 0.03201148 0.51737814 0.76160473]
  [0.60259893 0.97798085 0.31581902 ... 0.1963547  0.87193221 0.20461185]
  ...
  [0.69870151 0.07028232 0.95991805 ... 0.61568559 0.70031064 0.30380424]
  [0.18446019 0.11857728 0.95966373 ... 0.75394227 0.49765193 0.81099813]
  [0.58945244 0.67781685 0.92098698 ... 0.4517357  0.29505763 0.10081558]]

 [[0.91278119 0.66874264 0.7421482  ... 0.21139146 0.62723961 0.01509407]
  [0.7811357  0.08130327 0.11045036 ... 0.34526928 0.61484006 0.26210351]
  [0.00884025 0.5394508  0.95808955 ... 0.85304645 0.43814454 0.7215082 ]
  ...
  [0.14377001 0.73716155 0.19781043 ... 0.65854859 0.96292103 0.55571725]
  [0.54251406 0.75049409 0.20185337 ... 0.61661863 0.96288388 0.57953026]
  [0.17199243 0.67541274 0.17784902 ... 0.05972674 0.34999472 0.24019101]]]
[[-1 -1 -1  1  1  1 -1  1  1 -1  1  1 -1 -1 -1  1 -1  1  1  1  1  1 -1  1
  -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1  1  1  1 -1  1
   1  1 -1  1  1  1  1 -1  1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1  1 -1 -1  1
  -1  1  1  1  1  1 -1 -1]
 [-1 -1 -1  1  1  1 -1  1 -1 -1  1 -1  1  1  1  1  1  1  1 -1 -1  1  1 -1
   1 -1  1 -1 -1  1  1  1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1  1  1 -1 -1
   1  1  1 -1  1  1 -1 -1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1 -1 -1
  -1  1  1  1 -1  1  1 -1]
 [ 1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1  1  1  1  1 -1  1 -1 -1 -1 -1  1  1
   1 -1  1 -1 -1  1 -1 -1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1 -1 -1 -1  1
   1  1  1  1 -1  1  1 -1  1 -1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1  1  1  1
   1  1  1  1 -1  1 -1 -1]
 [ 1 -1  1  1  1 -1  1  1  1 -1  1  1 -1 -1 -1  1  1  1  1 -1 -1 -1  1  1
   1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1 -1  1  1 -1 -1  1 -1  1 -1  1 -1 -1
   1 -1 -1  1 -1 -1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1
  -1 -1  1 -1  1  1 -1 -1]]
train_ds
<BatchDataset element_spec=(TensorSpec(shape=(None, 180, 80), dtype=tf.float64, name=None), TensorSpec(shape=(None, 80), dtype=tf.int64, name=None))>
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_2 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
x_mb
tf.Tensor(
[[ 1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1  1  1  1  1 -1  1 -1 -1 -1 -1  1  1
   1 -1  1 -1 -1  1 -1 -1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1 -1 -1 -1  1
   1  1  1  1 -1  1  1 -1  1 -1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1  1  1  1
   1  1  1  1 -1  1 -1 -1]
 [ 1 -1  1  1  1 -1  1  1  1 -1  1  1 -1 -1 -1  1  1  1  1 -1 -1 -1  1  1
   1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1 -1  1  1 -1 -1  1 -1  1 -1  1 -1 -1
   1 -1 -1  1 -1 -1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1
  -1 -1  1 -1  1  1 -1 -1]], shape=(2, 80), dtype=int64)
tr_loss:[1.5171839 1.4202664]
x_mb
tf.Tensor(
[[ 1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1  1  1  1  1 -1  1 -1 -1 -1 -1  1  1
   1 -1  1 -1 -1  1 -1 -1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1 -1 -1 -1  1
   1  1  1  1 -1  1  1 -1  1 -1 -1 -1 -1  1  1 -1  1 -1 -1 -1  1  1  1  1
   1  1  1  1 -1  1 -1 -1]
 [-1 -1 -1  1  1  1 -1  1 -1 -1  1 -1  1  1  1  1  1  1  1 -1 -1  1  1 -1
   1 -1  1 -1 -1  1  1  1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1  1  1 -1 -1
   1  1  1 -1  1  1 -1 -1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1 -1 -1
  -1  1  1  1 -1  1  1 -1]], shape=(2, 80), dtype=int64)
tr_loss:[0.8249179 1.1724204]
[[-7.23382413e-01 -3.59670281e-01  6.20515086e-03 -8.15971076e-01
  -8.78672540e-01 -8.87831807e-01 -5.96513748e-01  1.03926331e-01
  -5.84436715e-01 -5.10123730e-01  5.27320266e-01  3.98826420e-01
   5.23049712e-01  3.02969456e-01 -4.58886653e-01 -5.24415374e-01
   6.70081377e-01  7.81073093e-01  8.44838977e-01 -7.34305620e-01
  -7.91616976e-01 -8.44525278e-01  2.24705026e-01  1.22497156e-01
   8.17165732e-01 -9.59786057e-01  7.00820386e-01 -2.56985158e-01
  -7.12929964e-01  7.91215539e-01 -6.56286180e-02 -9.36490476e-01
  -8.11651289e-01 -7.23021328e-01 -5.55253327e-02 -8.69651079e-01
  -7.63563871e-01 -7.54921436e-01 -6.54185712e-01  2.30082259e-01
  -8.77708614e-01 -1.78649023e-01 -5.95637739e-01  2.77270041e-02
  -7.45574892e-01 -8.91091526e-01 -5.41999936e-01 -7.58957386e-01
   3.01028103e-01  3.39760892e-02  7.78609395e-01 -1.51633956e-02
  -4.42043155e-01 -8.53194445e-02 -5.50325394e-01 -8.24686944e-01
   4.85321194e-01 -1.81820258e-01 -3.25326830e-01 -4.82876956e-01
   3.89294833e-01  8.19975495e-01  2.23553210e-01  2.82930225e-01
  -2.33333915e-01  3.99346113e-01  5.18837512e-01  8.57214868e-01
   3.26495677e-01  4.13656235e-05 -5.88860512e-01  3.10903639e-01
   6.78895295e-01 -4.11929905e-01  9.38849330e-01  8.71330142e-01
  -2.64838934e-01  4.44304198e-01 -7.82635033e-01  5.82767904e-01]
 [-4.20167953e-01 -3.62953633e-01 -3.32275957e-01 -7.54299223e-01
  -8.49915624e-01 -4.61869568e-01 -4.60723817e-01  7.61191070e-01
  -5.08632123e-01  1.84828356e-01  6.95957780e-01  6.75590158e-01
  -2.21529081e-02  7.18190849e-01 -3.96319896e-01 -7.61632979e-01
   8.53671014e-01  8.12105358e-01  8.23758185e-01 -5.74851871e-01
  -9.34038401e-01 -7.43972361e-01  5.04259109e-01 -9.21167359e-02
   7.71066666e-01 -8.19051445e-01  6.40002847e-01 -3.60517681e-01
  -5.64258516e-01  8.66109729e-01 -2.05677494e-01 -9.26128507e-01
  -8.24524760e-01  1.53051391e-01 -4.14368547e-02 -4.71461505e-01
  -9.25602555e-01 -2.63475329e-01 -4.40389812e-01  1.20097093e-01
  -6.20796382e-01 -4.14096713e-01 -7.73265481e-01 -1.45007996e-02
  -3.72986764e-01 -8.61873925e-01 -1.09866612e-01 -6.39336824e-01
   6.93038940e-01 -7.51554012e-01  9.29929554e-01 -6.55463159e-01
  -1.37330964e-01  3.06705505e-01 -4.93934751e-01 -7.11920738e-01
   9.01821673e-01 -6.67344928e-01  2.53577065e-02 -4.30861682e-01
   6.14301741e-01  4.03703183e-01  2.89330661e-01  5.70288837e-01
  -8.28773305e-02  1.05857842e-01  8.10341477e-01  2.94457749e-02
   4.57725823e-01 -6.97275028e-02 -3.32943499e-01  5.53146422e-01
   3.80763352e-01 -2.08725929e-01  9.26377714e-01  5.46683311e-01
  -4.01443362e-01 -9.62042902e-03 -7.32703924e-01  1.42145097e-01]
 [ 1.19814657e-01 -4.46615189e-01 -4.72341180e-01 -8.93393993e-01
  -7.88616598e-01 -8.21642101e-01 -8.52895856e-01  8.08069944e-01
  -4.95459765e-01 -5.50379992e-01  8.87833476e-01  6.71216249e-01
   5.86341500e-01  6.30469203e-01 -5.30765891e-01 -9.04653549e-01
   7.70471632e-01  8.26711655e-01 -4.52904761e-01 -8.89567971e-01
  -9.40549493e-01 -7.32411802e-01  7.03145444e-01  7.21149147e-02
   8.03090513e-01 -8.55042815e-01  6.12827182e-01 -1.16791122e-01
  -8.85707021e-01  6.17438078e-01 -7.52207637e-01 -9.58599269e-01
  -7.11812198e-01  6.26852989e-01  6.57646656e-01 -3.43437552e-01
  -7.31474996e-01 -8.52976620e-01 -8.37806165e-01  2.95411013e-02
  -7.55671740e-01  2.21573934e-03 -8.75668108e-01  3.04081440e-01
  -8.43957424e-01 -8.62074912e-01 -5.99754453e-01 -7.69737840e-01
   7.02743471e-01 -3.84044766e-01  8.90226543e-01  1.98101565e-01
  -6.33173108e-01  6.41337156e-01 -3.42708975e-02 -7.29597628e-01
   9.04310465e-01 -8.69985342e-01  5.88903949e-02  4.52998906e-01
   3.68454843e-03  2.04891056e-01  4.23575610e-01 -6.22587912e-02
   2.70873398e-01  1.25044405e-01  6.39075279e-01 -3.50687541e-02
   5.43658912e-01  4.23716515e-01  3.06208879e-01  7.02717960e-01
   4.19399828e-01  4.50363278e-01  9.53267038e-01  8.44700634e-01
  -2.95209140e-01  7.01676965e-01 -5.65775514e-01 -1.00428924e-01]
 [-2.78157264e-01 -1.09106034e-01 -2.51914173e-01 -7.89474666e-01
  -2.85093635e-01 -7.18940496e-01 -4.74208087e-01  8.96276593e-01
  -7.95951664e-01  2.86335722e-02  8.36241245e-01  7.92120636e-01
   7.99975038e-01  6.38194203e-01 -6.92408979e-01 -2.50845820e-01
   9.01458859e-01  8.72453094e-01  8.77368391e-01 -6.33806229e-01
  -3.89125884e-01 -8.58776808e-01  7.98994362e-01 -8.41107816e-02
   8.76477659e-01 -9.06635880e-01  6.78828955e-01  4.15460020e-01
  -5.59057388e-03  8.45608473e-01 -8.40353429e-01 -9.04269993e-01
  -9.13954675e-01 -2.51649559e-01 -1.08566977e-01 -8.07960927e-01
  -9.12720263e-01 -8.69987011e-01 -7.40983844e-01 -9.91396159e-02
  -8.47156882e-01  2.59254217e-01 -9.45991576e-01 -4.70842659e-01
  -9.41717565e-01 -6.75628245e-01 -5.62634468e-01 -9.00893927e-01
   7.79188871e-01 -7.22360313e-01  8.93624544e-01 -2.05273345e-01
  -6.94899023e-01 -2.73642857e-02 -8.07636559e-01 -9.30857658e-01
   5.79331458e-01 -5.69467008e-01 -4.31101978e-01 -7.51137495e-01
   5.17788887e-01  1.58293411e-01  4.63098854e-01  3.95764075e-02
  -2.31632322e-01  6.28407896e-01  7.10936248e-01  8.95438433e-01
   5.51711202e-01  3.16899456e-02 -7.91293800e-01 -2.26626232e-01
   6.12709939e-01 -1.64552465e-01  9.13157582e-01  2.75248736e-01
  -3.42053473e-01  3.20481598e-01 -8.36832702e-01  1.12891316e-01]]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 0 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(14400,)
learning_input.shape[1]
1
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(6, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 6 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(7, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 7 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(8, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 8 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(9, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 9 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(10, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 10 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(11, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 11 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(12, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 12 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(13, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 13 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(14, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 14 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(15, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 15 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(16, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 16 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(17, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 17 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(18, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 18 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(19, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 19 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(20, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 20 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(21, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 21 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(22, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 22 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(23, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 23 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(24, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 24 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(25, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 25 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(26, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 26 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(27, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 27 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(28, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 28 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(29, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 29 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(30, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 30 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(31, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 31 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(32, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 32 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(33, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 33 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(34, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 34 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(35, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 35 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(36, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 36 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(37, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 37 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(38, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 38 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(39, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 39 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(40, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 40 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(41, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 41 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(42, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 42 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(43, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 43 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(44, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 44 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(45, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 45 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(46, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 46 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(47, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 47 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(48, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 48 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(49, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 49 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(50, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 50 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(51, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 51 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(52, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 52 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(53, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 53 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(54, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 54 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(55, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 55 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(56, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 56 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(57, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 57 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(58, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 58 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(59, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 59 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(60, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 60 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(61, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 61 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(62, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 62 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(63, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 63 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(64, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 64 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(65, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 65 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(66, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 66 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(67, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 67 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(68, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 68 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(69, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 69 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(70, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 70 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(71, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 71 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(72, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 72 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(73, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 73 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(74, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 74 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(75, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 75 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(76, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 76 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(77, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 77 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(78, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 78 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(79, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 79 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(80, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 80 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(81, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 81 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(82, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 82 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(83, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 83 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(84, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 84 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(85, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 85 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(86, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 86 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(87, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 87 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(88, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 88 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(89, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 89 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(90, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 90 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(91, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 91 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(92, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 92 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(93, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 93 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(94, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 94 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(95, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 95 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(96, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 96 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(97, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 97 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(98, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 98 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(99, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 99 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(100, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-0
text_input.shape
(100, 14400)
learning_input_tmp.shape
(100, 180, 80)
learning_input.shape
(100, 180, 80)
learning_output_tmp.shape
(100, 80)
learning_output.shape
(100, 80)
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_3 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.7413046  0.5471171  0.7391432  0.7616501  0.5761911  0.7940089
 0.70655084 0.5425969  0.67386854 0.57035196 0.68682075 0.56495535
 0.6205818  0.5842945  0.7929444  0.5701885  0.7086996  0.69190353
 0.67015517 0.64002734 0.55561095 0.4497265  0.5484408  0.58219993
 0.7329877  0.51608306 0.733      0.5633682  0.55022156 0.595998
 0.6628377  0.516008   0.57156646 0.7399451  0.6120588  0.7251868
 0.6343689  0.84252894 0.7133337  0.6793687  0.6259166  0.59543115
 0.5326017  0.50756377 0.6178778  0.5695809  0.58804494 0.6655049
 0.4994958  0.7736536 ]
tr_loss:[0.7703506  0.54856527 0.616829   0.44381237 0.66653615 0.6532111
 0.67358685 0.7149078  0.63746315 0.588305   0.5081884  0.5829444
 0.6443932  0.56096554 0.5004102  0.735675   0.67625827 0.5272741
 0.9330069  0.69601697 0.90978545 0.55668193 0.65677536 0.6922635
 0.61327446 0.51280767 0.53381145 0.5494633  0.54260665 0.539118
 0.6724167  0.7131277  0.6423289  0.53357965 0.5349869  0.7560241
 0.73337847 0.61291003 0.60613203 0.6425049  0.5819522  0.4456377
 0.6499034  0.64696443 0.6414581  0.46033382 0.5079796  0.636775
 0.4797865  0.5856756 ]
tr_loss:[0.44266033 0.45564285 0.5804537  0.4527362  0.6870057  0.5252371
 0.59496945 0.5116681  0.33940792 0.6407774  0.6901533  0.326701
 0.5247812  0.5482966  0.4214425  0.37702438 0.5461211  0.38835612
 0.56376106 0.57739156 0.42776996 0.3513783  0.556858   0.48231068
 0.5852159  0.43550807 0.5563267  0.52682334 0.48300058 0.6418175
 0.5594855  0.39723077 0.3646709  0.45038262 0.3640312  0.5452225
 0.6936537  0.56622875 0.44984847 0.5666586  0.36268345 0.37996426
 0.4365119  0.39741582 0.42261276 0.5627178  0.47032404 0.5388548
 0.48157138 0.46937543]
tr_loss:[0.5718108  0.39676008 0.26586515 0.41649705 0.50655353 0.5606428
 0.36272353 0.4495983  0.42749172 0.4574085  0.46219796 0.43554792
 0.44168463 0.40573645 0.40564504 0.4607211  0.38348353 0.3954925
 0.42577228 0.44920748 0.5191312  0.5827699  0.52158177 0.3681646
 0.43930522 0.4647483  0.45257387 0.44465932 0.39449582 0.48653364
 0.46513695 0.45007783 0.59306353 0.33332163 0.55939597 0.39640117
 0.48053652 0.4282816  0.5085678  0.5704883  0.50622606 0.39238653
 0.44850454 0.40401903 0.3735265  0.56390953 0.52217984 0.3902184
 0.5335783  0.4359652 ]
text_input.shape
(100, 14400)
learning_input_tmp.shape
(100, 180, 80)
learning_input.shape
(100, 180, 80)
learning_output_tmp.shape
(100, 80)
learning_output.shape
(100, 80)
Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_4 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.7176712  0.6220516  0.6951267  0.8816202  0.73827994 0.70596933
 0.504288   0.55114925 0.6042482  0.5930436  0.6384621  0.79123425
 0.62232363 0.48042935 0.6277588  0.7502346  0.6944305  0.58324665
 0.596497   0.62307394 0.68397653 0.6459371  0.8396193  0.6777089
 0.5247587  0.5883261  0.594594   0.56874573 0.7397961  0.7015223
 0.69571066 0.5533497  0.6493555  0.57584596 0.5574714  0.59276515
 0.658366   0.6235439  0.58444965 0.60920024 0.5919169  0.6409235
 0.60068095 0.71158504 0.86258566 0.6569874  0.6665213  0.6919452
 0.4711326  0.9088858 ]
tr_loss:[0.51351863 0.46631774 0.42380023 0.7380225  0.62553126 0.6739383
 0.52096254 0.69210416 0.5229658  0.5982455  0.6149224  0.6454912
 0.61532533 0.73415184 0.6257828  0.6151923  0.52713716 0.54964954
 0.7328819  0.7401141  0.45471603 0.6289487  0.6685213  0.5881712
 0.57794946 0.54263103 0.69883996 0.61350566 0.49444017 0.56224
 0.59420395 0.7425214  0.5531715  0.49146423 0.5827343  0.47849026
 0.7693348  0.6539489  0.49499482 0.6819388  0.613441   0.4993382
 0.6394762  0.6513298  0.5742943  0.51840216 0.54054534 0.48334116
 0.5308796  0.6803605 ]
tr_loss:[0.51402855 0.41076058 0.6384536  0.36616293 0.5630678  0.44345608
 0.37859693 0.3209514  0.38644814 0.6385628  0.5809026  0.48565227
 0.42447186 0.5230611  0.5894777  0.47693062 0.47069016 0.47070512
 0.52354765 0.50357467 0.5385343  0.49659187 0.41820565 0.4463481
 0.45272237 0.4674047  0.41728678 0.55885524 0.53609496 0.48012227
 0.38693067 0.4826396  0.41361126 0.60191447 0.5551586  0.5472375
 0.56039476 0.636495   0.5836671  0.55482996 0.4312252  0.4749879
 0.41520405 0.38524944 0.4407584  0.39053726 0.47705087 0.600588
 0.40849608 0.508755  ]
tr_loss:[0.61613023 0.5141673  0.4281941  0.5493684  0.39548054 0.3677029
 0.42496008 0.47973856 0.34516823 0.4402917  0.5172633  0.41697615
 0.4166812  0.3735016  0.43517023 0.5144488  0.44532385 0.5901005
 0.44363347 0.4620224  0.33376035 0.43657795 0.42174834 0.46792737
 0.40227157 0.4342657  0.52799404 0.39116538 0.57920873 0.28163582
 0.6047629  0.49810448 0.49053708 0.46601725 0.356136   0.46241322
 0.34829375 0.36375207 0.6314347  0.41096354 0.54092467 0.47557044
 0.6219147  0.4260831  0.5192982  0.40616488 0.48193425 0.4452265
 0.5443365  0.5977249 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 100 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(101, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 101 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(102, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 102 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(103, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 103 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(104, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 104 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(105, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 105 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(106, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 106 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(107, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 107 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(108, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 108 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(109, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 109 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(110, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 110 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(111, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 111 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(112, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 112 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(113, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 113 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(114, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 114 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(115, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 115 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(116, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 116 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(117, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 117 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(118, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 118 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(119, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 119 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(120, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 120 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(121, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 121 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(122, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 122 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(123, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 123 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(124, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 124 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(125, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 125 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(126, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 126 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(127, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 127 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(128, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 128 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(129, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 129 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(130, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 130 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(131, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 131 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(132, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 132 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(133, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 133 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(134, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 134 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(135, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 135 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(136, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 136 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(137, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 137 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(138, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 138 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(139, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 139 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(140, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 140 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(141, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 141 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(142, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 142 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(143, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 143 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(144, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 144 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(145, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 145 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(146, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 146 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(147, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 147 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(148, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 148 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(149, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 149 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(150, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 150 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(151, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 151 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(152, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 152 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(153, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 153 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(154, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 154 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(155, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 155 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(156, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 156 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(157, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 157 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(158, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 158 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(159, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 159 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(160, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 160 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(161, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 161 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(162, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 162 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(163, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 163 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(164, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 164 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(165, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 165 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(166, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 166 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(167, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 167 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(168, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 168 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(169, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 169 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(170, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 170 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(171, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 171 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(172, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 172 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(173, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 173 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(174, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 174 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(175, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 175 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(176, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 176 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(177, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 177 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(178, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 178 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(179, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 179 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(180, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 180 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(181, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 181 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(182, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 182 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(183, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 183 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(184, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 184 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(185, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 185 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(186, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 186 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(187, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 187 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(188, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 188 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(189, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 189 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(190, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 190 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(191, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 191 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(192, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 192 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(193, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 193 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(194, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 194 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(195, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 195 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(196, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 196 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(197, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 197 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(198, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 198 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(199, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 199 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(200, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-100
text_input.shape
(200, 14400)
learning_input_tmp.shape
(200, 180, 80)
learning_input.shape
(200, 180, 80)
learning_output_tmp.shape
(200, 80)
learning_output.shape
(200, 80)
Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_5 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.7546135  0.601319   0.7969134  0.5251138  0.5449675  0.6662047
 0.58374584 0.6318222  0.5759634  0.75736964 0.6138706  0.5394851
 0.50445473 0.60855216 0.44159713 0.7717911  0.5051235  0.60644704
 0.60669816 0.71193445 0.5210216  0.63652    0.5980808  0.619778
 0.7314614  0.6347935  0.58091086 0.6858838  0.5346025  0.62939763
 0.71160245 0.59654737 0.5947166  0.58269185 0.5628022  0.5043482
 0.6440221  0.77894485 0.6072453  0.7529003  0.62456584 0.49769384
 0.64842206 0.6529993  0.8459326  0.49182948 0.7330904  0.6172555
 0.66422635 0.558605  ]
tr_loss:[0.5392114  0.6521508  0.7000114  0.7064575  0.5526818  0.5578629
 0.733595   0.73867923 0.59126174 0.60611737 0.58001626 0.643348
 0.5429182  0.6179728  0.6081942  0.566648   0.6304115  0.62735605
 0.62703705 0.5927001  0.71947944 0.6650642  0.5391612  0.67113715
 0.50927955 0.5246406  0.7123651  0.6791659  0.5859159  0.5513873
 0.6457186  0.6449904  0.8184515  0.5226207  0.5083774  0.58098906
 0.67872995 0.58833206 0.86427414 0.7431985  0.51945496 0.5482291
 0.6586773  0.68166506 0.64688295 0.6057416  0.61891    0.620032
 0.5841875  0.71095383]
tr_loss:[0.54419744 0.76260203 0.51402396 0.6257454  0.56557095 0.79371464
 0.59420455 0.76220906 0.6738658  0.60677034 0.5995711  0.686312
 0.62835985 0.509147   0.4217046  0.4938407  0.50752133 0.39877468
 0.43235198 0.51537716 0.5190147  0.46208686 0.5383188  0.7139451
 0.6415225  0.52564    0.5324869  0.6100862  0.554334   0.6696577
 0.5409428  0.56962955 0.6679994  0.6240634  0.5293776  0.4871962
 0.5279368  0.5708307  0.52563983 0.4670865  0.64471376 0.7215504
 0.62584525 0.5632008  0.7012276  0.6471319  0.60291916 0.51133645
 0.6473998  0.64016163]
tr_loss:[0.5661144  0.61519814 0.64807236 0.6552573  0.53741616 0.5874343
 0.6156871  0.5034253  0.47806674 0.7079567  0.47849464 0.52405655
 0.59842634 0.609471   0.61003834 0.6118679  0.7148223  0.4106707
 0.38555747 0.7142587  0.58340615 0.63887787 0.67001224 0.5570078
 0.5851067  0.64569044 0.6275319  0.6571253  0.5515747  0.5627618
 0.6424009  0.5118349  0.5882844  0.49967748 0.55787617 0.4851356
 0.56420153 0.48365563 0.5780185  0.49136877 0.58874786 0.56118757
 0.6792275  0.55419904 0.6250197  0.5908812  0.6027209  0.6077072
 0.6141739  0.64805305]
tr_loss:[0.33809477 0.57444316 0.37392363 0.40851727 0.34524444 0.50089663
 0.60202897 0.5508758  0.42243427 0.33369404 0.4941948  0.28976366
 0.38705084 0.52338046 0.35291004 0.30949816 0.34004197 0.4946348
 0.44948825 0.4148528  0.43593758 0.5178777  0.5609704  0.33123812
 0.36863437 0.42974052 0.3905949  0.58782524 0.49146396 0.5921025
 0.48854533 0.4589532  0.38909277 0.55159795 0.5303517  0.39363995
 0.58688146 0.524198   0.5530602  0.39690715 0.5511111  0.6110817
 0.5286201  0.5692138  0.3837127  0.39809424 0.47049952 0.46350256
 0.432981   0.509712  ]
tr_loss:[0.5460561  0.510149   0.36430222 0.30906233 0.49309748 0.46864262
 0.4373793  0.42845935 0.41571084 0.40682507 0.4984211  0.47433442
 0.41703662 0.3478139  0.40355158 0.48547736 0.3909607  0.50474215
 0.43081665 0.4789187  0.39941952 0.30748817 0.45706654 0.47697997
 0.47252226 0.3666256  0.58338654 0.39700767 0.3409948  0.6347542
 0.49096727 0.47548157 0.512332   0.47879076 0.4468828  0.50827336
 0.4566141  0.3799161  0.52671105 0.45643395 0.33409846 0.38900936
 0.31366363 0.46510315 0.43990898 0.5028422  0.6241232  0.4103485
 0.39637473 0.46615297]
tr_loss:[0.3549272  0.4573234  0.39689717 0.40086251 0.4505256  0.41028637
 0.4551874  0.5126539  0.30362445 0.51435494 0.37961817 0.44555083
 0.57207596 0.3378946  0.38659492 0.45630527 0.43052936 0.42981434
 0.3877279  0.4028565  0.41027147 0.4524227  0.30376428 0.4572803
 0.301998   0.54992425 0.5078007  0.39492136 0.5061418  0.53994167
 0.5117918  0.52850413 0.3761088  0.49381194 0.41069084 0.42784128
 0.38306266 0.3766703  0.49952573 0.3358427  0.46907824 0.29348862
 0.5129075  0.52662504 0.4746282  0.34033448 0.4110628  0.32162312
 0.6491188  0.49227667]
tr_loss:[0.46519217 0.41116962 0.39156818 0.3457585  0.5467771  0.33533016
 0.3259155  0.3308874  0.5783023  0.37718105 0.3070356  0.4653638
 0.29968995 0.35043606 0.5290928  0.39795083 0.36895984 0.47058478
 0.45781246 0.3928952  0.34720936 0.37081185 0.4210972  0.37766752
 0.30831298 0.34060678 0.41607016 0.42321745 0.41173983 0.38633406
 0.5224088  0.48890457 0.44641447 0.4609964  0.36089525 0.33483213
 0.49207908 0.46841115 0.36203626 0.40096197 0.34040886 0.41820264
 0.44371948 0.46772593 0.27511507 0.39827675 0.4331004  0.31160027
 0.38860387 0.503019  ]
text_input.shape
(200, 14400)
learning_input_tmp.shape
(200, 180, 80)
learning_input.shape
(200, 180, 80)
learning_output_tmp.shape
(200, 80)
learning_output.shape
(200, 80)
Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_6 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.5980054  0.5913359  0.62618244 0.8390053  0.47572717 0.5286554
 0.8458417  0.5178431  0.6671897  0.6571211  0.6530197  0.5090194
 0.52953845 0.48295373 0.5819667  0.6209208  0.5725927  0.48303857
 0.49498692 0.54223967 0.70577776 0.626672   0.6973567  0.69212645
 0.61364573 0.4341905  0.46443835 0.71926373 0.6271615  0.526778
 0.5944773  0.67034435 0.5247592  0.70644695 0.6820958  0.46296406
 0.63809097 0.5830998  0.51842135 0.69013226 0.55240375 0.7915353
 0.4086093  0.625785   0.6323813  0.57888234 0.6571976  0.82213384
 0.49505633 0.6143839 ]
tr_loss:[0.6991874  0.47390833 0.720116   0.6076353  0.4118843  0.52683306
 0.7573436  0.661296   0.6658395  0.5474108  0.8168808  0.68467575
 0.6468285  0.439022   0.54564106 0.6562117  0.5674782  0.63728034
 0.5121429  0.5869327  0.6328567  0.5837668  0.58620775 0.6861416
 0.48912668 0.68265504 0.63989973 0.5277849  0.69853765 0.82154655
 0.7763027  0.6086632  0.53614277 0.42837802 0.6468623  0.64989483
 0.50427216 0.5719822  0.44853482 0.6148711  0.6085397  0.80684584
 0.39960736 0.5245622  0.64223665 0.68114316 0.6365522  0.65385115
 0.5188015  0.577552  ]
tr_loss:[0.5388368  0.54227436 0.62720644 0.5195757  0.46042585 0.67708635
 0.7112169  0.6641814  0.6112714  0.68356895 0.54317415 0.5643155
 0.5214463  0.6141741  0.4946557  0.6062957  0.59610736 0.5406581
 0.7090439  0.66472065 0.5391606  0.49251184 0.52248985 0.5662878
 0.541433   0.4952039  0.6068055  0.5508987  0.5428357  0.5060421
 0.64308536 0.6371023  0.5164861  0.43243504 0.43911466 0.5515233
 0.5568072  0.80109847 0.6101121  0.50923526 0.63918805 0.4682722
 0.5487214  0.54660636 0.5470805  0.5958909  0.6015252  0.6239115
 0.58830243 0.5869023 ]
tr_loss:[0.51584893 0.5598989  0.49911243 0.5755345  0.70190334 0.5229038
 0.6595672  0.48882985 0.6573049  0.5047568  0.6339838  0.65611136
 0.43379164 0.6446713  0.68045616 0.66548616 0.52289474 0.66284364
 0.60304594 0.6180656  0.46864137 0.5231068  0.4734768  0.55456096
 0.595352   0.5732082  0.53890723 0.5447623  0.6010729  0.53011376
 0.4494211  0.4208618  0.5419395  0.49475035 0.50642186 0.57551336
 0.47994035 0.77422667 0.7013429  0.63333446 0.5072197  0.59164375
 0.5931796  0.5932061  0.553315   0.7117113  0.52911025 0.63509357
 0.5586475  0.6252693 ]
tr_loss:[0.41861573 0.60021764 0.24981876 0.44729534 0.37119502 0.42308497
 0.5808125  0.43174037 0.5310815  0.43296137 0.49212378 0.3913509
 0.4306081  0.5418297  0.48066598 0.5332008  0.5159839  0.6170591
 0.5067023  0.43868294 0.37850323 0.24137846 0.44318992 0.45584393
 0.4629983  0.4881596  0.37224156 0.4728492  0.3951026  0.41344708
 0.36610818 0.41021758 0.27484283 0.5373406  0.51772326 0.40796334
 0.41346797 0.51287067 0.45585203 0.45456696 0.41629815 0.5085758
 0.4746934  0.5425475  0.46600834 0.52732074 0.3692085  0.59650207
 0.38663912 0.51402175]
tr_loss:[0.36105222 0.5409597  0.39584    0.5377971  0.37792864 0.4065916
 0.48583335 0.47519985 0.33243436 0.55685234 0.32011753 0.4248652
 0.33802098 0.46675855 0.4514494  0.28329214 0.3391329  0.446498
 0.37608752 0.41184822 0.40308666 0.47448    0.26395756 0.50032777
 0.45256615 0.36315924 0.40205914 0.5763691  0.49351445 0.40287513
 0.37177148 0.43004924 0.46364045 0.5497851  0.38936228 0.31253237
 0.32270226 0.32345238 0.44692793 0.48258907 0.47128028 0.36089864
 0.39304048 0.37185806 0.34083802 0.42954677 0.4988591  0.44260216
 0.30015093 0.39379042]
tr_loss:[0.26299155 0.45145592 0.4403225  0.384691   0.41045222 0.43995968
 0.37744173 0.3702004  0.331218   0.398175   0.42699665 0.5198539
 0.3673728  0.3851946  0.4087162  0.3987934  0.47696686 0.3664587
 0.31973198 0.45931992 0.32735148 0.42238194 0.53200144 0.3652532
 0.5366111  0.35816318 0.38478044 0.49354702 0.39914867 0.57027465
 0.5549402  0.45592934 0.4285698  0.44949016 0.31279817 0.38750082
 0.48022002 0.48949975 0.32286677 0.5588333  0.5080765  0.58351904
 0.49644393 0.39633965 0.32768726 0.41241655 0.43394685 0.55909
 0.38783187 0.4916319 ]
tr_loss:[0.439917   0.40949827 0.39624366 0.5572649  0.47674775 0.3591908
 0.33873326 0.3689025  0.4518159  0.3700353  0.411465   0.4952591
 0.4426051  0.3039682  0.4208088  0.38246503 0.49814454 0.43434197
 0.46418133 0.40625644 0.46496335 0.36923164 0.4185624  0.4235936
 0.2942334  0.35231417 0.47446197 0.3853403  0.36936545 0.44120032
 0.29166168 0.53500974 0.33783796 0.3526934  0.4717102  0.4607308
 0.41126585 0.51543015 0.3424402  0.46719307 0.39578268 0.31259704
 0.35004133 0.37195104 0.53858936 0.33741143 0.5583671  0.51068795
 0.52056396 0.41901088]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 200 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(201, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 201 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(202, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 202 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(203, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 203 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(204, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 204 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(205, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 205 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(206, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 206 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(207, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 207 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(208, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 208 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(209, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 209 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(210, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 210 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(211, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 211 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(212, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 212 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(213, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 213 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(214, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 214 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(215, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 215 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(216, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 216 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(217, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 217 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(218, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 218 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(219, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 219 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(220, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 220 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(221, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 221 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(222, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 222 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(223, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 223 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(224, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 224 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(225, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 225 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(226, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 226 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(227, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 227 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(228, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 228 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(229, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 229 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(230, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 230 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(231, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 231 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(232, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 232 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(233, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 233 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(234, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 234 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(235, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 235 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(236, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 236 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(237, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 237 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(238, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 238 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(239, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 239 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(240, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 240 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(241, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 241 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(242, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 242 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(243, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 243 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(244, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 244 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(245, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 245 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(246, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 246 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(247, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 247 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(248, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 248 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(249, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 249 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(250, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 250 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(251, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 251 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(252, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 252 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(253, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 253 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(254, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 254 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(255, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 255 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(256, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 256 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(257, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 257 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(258, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 258 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(259, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 259 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(260, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 260 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(261, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 261 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(262, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 262 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(263, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 263 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(264, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 264 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(265, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 265 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(266, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 266 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(267, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 267 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(268, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 268 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(269, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 269 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(270, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 270 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(271, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 271 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(272, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 272 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(273, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 273 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(274, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 274 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(275, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 275 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(276, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 276 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(277, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 277 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(278, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 278 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(279, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 279 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(280, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 280 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(281, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 281 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(282, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 282 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(283, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 283 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(284, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 284 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(285, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 285 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(286, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 286 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(287, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 287 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(288, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 288 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(289, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 289 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(290, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 290 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(291, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 291 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(292, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 292 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(293, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 293 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(294, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 294 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(295, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 295 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(296, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 296 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(297, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 297 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(298, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 298 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(299, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 299 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(300, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-200
text_input.shape
(300, 14400)
learning_input_tmp.shape
(300, 180, 80)
learning_input.shape
(300, 180, 80)
learning_output_tmp.shape
(300, 80)
learning_output.shape
(300, 80)
Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_7 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.60512966 0.6059185  0.5572284  0.5699258  0.6036334  0.47170216
 0.5452208  0.62614983 0.49026972 0.6272384  0.6836004  0.61066365
 0.67669106 0.5951785  0.5360287  0.47753114 0.51473266 0.46676797
 0.7744626  0.52943486 0.5749514  0.65114164 0.53101575 0.594645
 0.66852295 0.6304142  0.45664805 0.7480061  0.66789603 0.54996365
 0.5552319  0.59401625 0.4576994  0.62478095 0.72145677 0.57382464
 0.85882264 0.61097366 0.601427   0.6332911  0.67659456 0.75387496
 0.62669533 0.6637666  0.49472922 0.67877716 0.483884   0.48266086
 0.4782847  0.6320581 ]
tr_loss:[0.42200762 0.6406652  0.55036974 0.53416026 0.40853825 0.689365
 0.7319805  0.7536147  0.48102808 0.5990386  0.550382   0.6655493
 0.6201371  0.6439773  0.6091857  0.6137581  0.5542811  0.63232005
 0.5212236  0.54278994 0.5779543  0.6267644  0.653156   0.5335949
 0.464887   0.6281209  0.6669779  0.49288234 0.84279823 0.60285485
 0.54961723 0.43205658 0.5946013  0.58503264 0.57505554 0.6464385
 0.54220045 0.6727623  0.48453408 0.71844757 0.6728988  0.44095713
 0.72024506 0.5668031  0.46388245 0.61774147 0.577281   0.5940838
 0.55046827 0.63996005]
tr_loss:[0.56234056 0.54890317 0.6186763  0.41981715 0.5762588  0.606217
 0.629419   0.5517298  0.58768564 0.67309904 0.69367    0.4257895
 0.5792457  0.58341056 0.49713382 0.60036564 0.5505079  0.60079813
 0.51066625 0.66498584 0.5350884  0.77776814 0.7169195  0.44175643
 0.51420087 0.55993825 0.5117283  0.6284679  0.6766829  0.6717449
 0.49076977 0.500725   0.5549997  0.47303414 0.55668306 0.44838303
 0.605929   0.6173401  0.6924608  0.5993455  0.4246522  0.6062678
 0.5536329  0.6151633  0.6285485  0.5633796  0.57452977 0.48979783
 0.63827646 0.54042053]
tr_loss:[0.56131315 0.6390724  0.44223347 0.54980165 0.5602604  0.5941564
 0.43598872 0.56314254 0.51466334 0.55287206 0.4996572  0.47516948
 0.48697585 0.61980295 0.5006212  0.58292186 0.8017062  0.5128232
 0.50681686 0.39038002 0.4602944  0.48885384 0.5170991  0.55219424
 0.47766504 0.5327193  0.76793146 0.6488966  0.4771967  0.67162406
 0.5076896  0.54304355 0.5475341  0.5105338  0.36485595 0.4340457
 0.59248865 0.40267783 0.5377299  0.45908436 0.61893654 0.64528054
 0.5692278  0.4469831  0.46640673 0.39865646 0.52461135 0.41291428
 0.5113654  0.46290034]
tr_loss:[0.501581   0.42745894 0.48037845 0.456968   0.5449885  0.49076614
 0.47815585 0.47335324 0.54028016 0.53092337 0.37226668 0.5421804
 0.57293737 0.5210064  0.5428197  0.59273225 0.6556376  0.60953814
 0.5493506  0.47003728 0.55491245 0.43527666 0.4239482  0.5748131
 0.5738257  0.4805266  0.45463914 0.58875805 0.49682242 0.5082941
 0.5669651  0.56286573 0.5370775  0.39503497 0.50875926 0.44264752
 0.5887663  0.4930009  0.41407508 0.42015713 0.46449074 0.46904334
 0.4705221  0.46752653 0.5766817  0.5596123  0.37805003 0.58728653
 0.48810148 0.56018054]
tr_loss:[0.5838154  0.46153012 0.7099663  0.46534842 0.4681046  0.42499328
 0.5698875  0.40254164 0.62700367 0.38073626 0.5009798  0.56932753
 0.59547347 0.64785755 0.5532125  0.6332115  0.5197786  0.4469912
 0.42949075 0.5680147  0.5174688  0.5092863  0.5563399  0.45461893
 0.4902545  0.6603381  0.44074255 0.5389577  0.5985706  0.44887227
 0.2896264  0.6564952  0.58367515 0.45261917 0.42260513 0.4620452
 0.65584266 0.5023736  0.5100006  0.5327449  0.511573   0.593336
 0.53070354 0.67353487 0.58199006 0.35521087 0.4960731  0.6020383
 0.43802938 0.40943328]
tr_loss:[0.3596197  0.40298423 0.4512806  0.4365608  0.3789657  0.3345365
 0.41176224 0.27614966 0.427137   0.46403146 0.47544652 0.4438166
 0.51520026 0.40166354 0.47081432 0.41593042 0.41138926 0.31889865
 0.36185414 0.3760212  0.26900202 0.41913167 0.32627192 0.39727664
 0.3807116  0.42944604 0.38737756 0.3997767  0.49596286 0.35075125
 0.43742973 0.3477104  0.43127576 0.36956614 0.50795126 0.4750413
 0.4339679  0.49380416 0.465765   0.5313483  0.5698725  0.3601512
 0.37413937 0.48530102 0.39479053 0.3565019  0.5116133  0.52749306
 0.40577063 0.3029166 ]
tr_loss:[0.44185066 0.3879056  0.36256328 0.39301804 0.3718553  0.29206067
 0.3810231  0.28169727 0.35139552 0.30900067 0.32371104 0.38033664
 0.5228019  0.36213502 0.34844914 0.44221276 0.39631552 0.4089455
 0.42547536 0.36140066 0.38271338 0.3716771  0.48675227 0.30485135
 0.41888863 0.4306224  0.28645635 0.4778188  0.33165258 0.37599307
 0.4067412  0.36759576 0.32370842 0.3409322  0.37736273 0.32132816
 0.4155063  0.4983925  0.40103474 0.32463855 0.32816324 0.37672853
 0.31260306 0.3975883  0.33662802 0.3787659  0.35174054 0.4216736
 0.37722582 0.5502927 ]
tr_loss:[0.38629293 0.39247042 0.31202516 0.40894595 0.35488233 0.38835078
 0.49689722 0.42145056 0.34373    0.30615506 0.43228045 0.32939172
 0.41164866 0.3755557  0.4684084  0.37112248 0.28698498 0.28830895
 0.38845903 0.351689   0.3272186  0.42089385 0.29926246 0.28391367
 0.42708644 0.38189024 0.39638957 0.31826717 0.35174948 0.43004346
 0.40847287 0.39277735 0.50719464 0.48571882 0.46569586 0.45016026
 0.5087169  0.39861888 0.551202   0.46326318 0.4294881  0.48533887
 0.2634569  0.35231823 0.23659873 0.34996644 0.33270365 0.38278198
 0.33800668 0.3749193 ]
tr_loss:[0.41281778 0.33934203 0.22216758 0.24287562 0.3194446  0.4270114
 0.43733716 0.42913038 0.37270212 0.41799957 0.38419217 0.3152198
 0.40835962 0.255401   0.27155495 0.27001876 0.28313503 0.3924071
 0.35499758 0.4514145  0.43343908 0.36659414 0.45329565 0.29570702
 0.40009555 0.27013996 0.35012904 0.31856698 0.3736097  0.52545226
 0.3183507  0.3116591  0.34450728 0.37994346 0.27042773 0.3176313
 0.43001157 0.3367249  0.38622373 0.31353387 0.42713898 0.27265376
 0.3608244  0.28544736 0.45561275 0.30779338 0.29978764 0.32894567
 0.3414825  0.4468853 ]
tr_loss:[0.4116791  0.34811175 0.3797714  0.39104906 0.32382065 0.2863657
 0.42297012 0.35990518 0.24122624 0.4103284  0.39255872 0.4127845
 0.4512728  0.3101376  0.40093046 0.36513788 0.39149854 0.34307137
 0.35715002 0.3686627  0.41513586 0.4009901  0.36713475 0.2859261
 0.3968848  0.37819472 0.48663577 0.34042385 0.40808448 0.3311483
 0.32918623 0.2239007  0.29644284 0.447962   0.2760538  0.34559926
 0.3726178  0.51931053 0.27765286 0.31091145 0.5076218  0.3649098
 0.5021069  0.28763732 0.4597664  0.41555953 0.37103462 0.36785826
 0.3535095  0.33274135]
tr_loss:[0.33648595 0.3988958  0.3432723  0.35025573 0.31837076 0.31795484
 0.3761701  0.2856063  0.35145584 0.3531544  0.34821272 0.333252
 0.4296754  0.30360383 0.38666624 0.32996482 0.32859927 0.40540868
 0.3008555  0.3353486  0.31778017 0.3807488  0.3157763  0.3795179
 0.44328898 0.3825886  0.43683377 0.45508155 0.28297395 0.35636684
 0.34227806 0.42301297 0.37217045 0.38971767 0.26342025 0.24749418
 0.36753002 0.30187553 0.3649785  0.24222466 0.29584494 0.42272314
 0.32992578 0.38613176 0.30650836 0.44353718 0.25029406 0.2637866
 0.46129102 0.45136577]
text_input.shape
(300, 14400)
learning_input_tmp.shape
(300, 180, 80)
learning_input.shape
(300, 180, 80)
learning_output_tmp.shape
(300, 80)
learning_output.shape
(300, 80)
Model: "sequential_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_8 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.5175963  0.70555484 0.5382436  0.7126119  0.5655122  0.566539
 0.7567456  0.6808051  0.62776077 0.5597278  0.49059826 0.5314687
 0.65999633 0.723981   0.68026996 0.5589961  0.74193037 0.41320068
 0.5160452  0.5589895  0.579285   0.63362074 0.46216926 0.48376054
 0.6485895  0.58571464 0.5996225  0.6490615  0.64119804 0.50212204
 0.5876424  0.57634586 0.5110589  0.5682178  0.60780275 0.54589784
 0.44429788 0.52658904 0.6208365  0.69009155 0.56816167 0.590319
 0.5589291  0.52113867 0.59626865 0.52102095 0.6273595  0.51706445
 0.43495718 0.5225963 ]
tr_loss:[0.6653414  0.6423828  0.6070611  0.49387184 0.633875   0.6155791
 0.5448734  0.44801778 0.47799954 0.46053666 0.62302184 0.5847098
 0.64921856 0.6745297  0.6426201  0.5126413  0.6098689  0.6556606
 0.56004226 0.5499593  0.66876376 0.594347   0.60030425 0.5939685
 0.610902   0.72500426 0.70822257 0.6730793  0.6100513  0.46287313
 0.5549647  0.52004707 0.6892311  0.54608405 0.41353774 0.38094145
 0.55405796 0.5090231  0.5733449  0.5804924  0.5772055  0.60299414
 0.6167345  0.68451536 0.43879557 0.5632762  0.49094647 0.59760636
 0.68846524 0.66591626]
tr_loss:[0.44771928 0.5304259  0.48530093 0.71790075 0.49115333 0.586352
 0.54668224 0.56824905 0.56090176 0.5650456  0.4541398  0.5280983
 0.51495874 0.69675934 0.5406934  0.59092027 0.4503637  0.564005
 0.50723344 0.52397305 0.49524385 0.6200616  0.494248   0.63991165
 0.6599421  0.5971652  0.541071   0.5482591  0.5970868  0.6245272
 0.5425526  0.52454615 0.6571678  0.41566658 0.6326722  0.30087262
 0.874879   0.5469762  0.61678207 0.54389477 0.47118768 0.6476644
 0.4908681  0.5610773  0.44802076 0.436045   0.51143086 0.4541706
 0.55574816 0.47977757]
tr_loss:[0.664235   0.6441671  0.5695977  0.47376513 0.6184328  0.49562845
 0.6211294  0.3907736  0.49341106 0.49621367 0.48448434 0.5407018
 0.3638677  0.43433434 0.439686   0.5915686  0.5964335  0.48445868
 0.5788353  0.4137269  0.4659132  0.6094817  0.4890318  0.39797598
 0.4912738  0.47195593 0.4021538  0.50732183 0.45174813 0.45281467
 0.59595937 0.55235755 0.6777226  0.6221328  0.4771181  0.52076626
 0.55914897 0.49679622 0.40613395 0.62869036 0.6942984  0.40029183
 0.5408236  0.53176177 0.5458728  0.42418995 0.5619899  0.6516787
 0.58594084 0.61997235]
tr_loss:[0.46710712 0.47585267 0.6007541  0.4739085  0.41735497 0.7190116
 0.64444906 0.5000434  0.5261567  0.6505959  0.65299433 0.47833356
 0.59745896 0.66474134 0.64748734 0.5454451  0.52484596 0.4865869
 0.58799756 0.39067376 0.512164   0.6106221  0.53695166 0.40115422
 0.55735046 0.55013335 0.45313787 0.54908943 0.5911754  0.39492375
 0.5412178  0.5022718  0.4381876  0.50573385 0.44574824 0.47292185
 0.49880266 0.40376425 0.37046927 0.58574057 0.5535348  0.43995112
 0.44271892 0.48216304 0.46373838 0.5434473  0.41570872 0.46907598
 0.5232603  0.56386274]
tr_loss:[0.42431465 0.5446393  0.48225874 0.5473534  0.53843534 0.37389764
 0.39086977 0.48926458 0.45934325 0.37918133 0.57048184 0.664227
 0.5573828  0.48572788 0.6146566  0.46847534 0.488618   0.3761519
 0.41766205 0.56501305 0.48464578 0.49589032 0.4057154  0.6503552
 0.47009295 0.41401058 0.38408786 0.51550597 0.4221354  0.48393774
 0.43201074 0.5734307  0.62490666 0.40403694 0.43615952 0.42067137
 0.42385578 0.51495314 0.55540055 0.38803166 0.53920156 0.5819624
 0.54726756 0.52231055 0.65738237 0.4942561  0.51556146 0.5355443
 0.62002546 0.43747908]
tr_loss:[0.48816353 0.381213   0.43198904 0.5539095  0.3577456  0.46699494
 0.47851545 0.30454668 0.34235138 0.30840367 0.4906165  0.41594043
 0.3946727  0.45527434 0.4258477  0.39682356 0.39501005 0.36832288
 0.3606178  0.415368   0.40106815 0.46198702 0.2728508  0.47473556
 0.61263925 0.42817003 0.43662325 0.58267546 0.38918978 0.5297524
 0.41780528 0.38766336 0.42822948 0.36045843 0.5130967  0.32324535
 0.3631516  0.4646986  0.31184712 0.30854154 0.3808275  0.32650343
 0.4509674  0.52517384 0.25111085 0.35702148 0.39691237 0.5424515
 0.5170116  0.34896055]
tr_loss:[0.53019255 0.34813774 0.29274136 0.44295207 0.52217454 0.5545305
 0.4807766  0.42873412 0.3442443  0.30435222 0.31558904 0.3253848
 0.4340621  0.457884   0.27635685 0.47391596 0.46699595 0.3912025
 0.42820612 0.41815504 0.34844053 0.38477802 0.32536834 0.3742527
 0.3124381  0.43642455 0.45797697 0.3620967  0.3940074  0.31432754
 0.42768258 0.32415062 0.4251731  0.39662293 0.40332255 0.32676664
 0.25468922 0.3140239  0.30515426 0.46642485 0.42756158 0.4294383
 0.3875965  0.43036994 0.27770802 0.3752745  0.35440233 0.41190606
 0.41634908 0.2511651 ]
tr_loss:[0.36010948 0.2714641  0.3344553  0.4355103  0.44510904 0.27165794
 0.43390846 0.37342814 0.33798727 0.41886005 0.46366492 0.24032569
 0.4169495  0.3318453  0.31520975 0.5275806  0.4898563  0.2889196
 0.31968436 0.27327186 0.31930643 0.45317087 0.36258477 0.3381945
 0.50088966 0.38239294 0.3229545  0.33879656 0.46386504 0.47652674
 0.4158445  0.35208908 0.40527496 0.35795116 0.40653047 0.37456375
 0.3434046  0.4933498  0.34194887 0.5381063  0.30175248 0.3076616
 0.41872674 0.39133963 0.42322922 0.31598142 0.362719   0.3956515
 0.42100096 0.27191368]
tr_loss:[0.45237702 0.33931696 0.31411427 0.32863364 0.3404181  0.33837935
 0.338891   0.32714006 0.37678158 0.35866874 0.36632973 0.3499542
 0.36918217 0.3890981  0.3481999  0.56694776 0.32544437 0.5696007
 0.43830925 0.36871108 0.45405644 0.5069664  0.30336413 0.33823535
 0.3121267  0.2362937  0.4151876  0.32168773 0.4130845  0.32132214
 0.38407364 0.293761   0.38541391 0.44300562 0.34222168 0.3650381
 0.3790517  0.2847374  0.32576892 0.22316459 0.4707798  0.31741714
 0.38431853 0.383508   0.38393593 0.32715645 0.28973684 0.28846022
 0.3013033  0.35382858]
tr_loss:[0.23092632 0.32419544 0.2674812  0.29852414 0.30593196 0.26178026
 0.36415902 0.3640825  0.40619707 0.293305   0.2644637  0.29331723
 0.31284058 0.3537302  0.2863674  0.24966387 0.30031547 0.3685572
 0.32121438 0.37992066 0.3379416  0.3556954  0.38008478 0.3346047
 0.37202328 0.30224457 0.3542841  0.42487478 0.28211293 0.37993497
 0.39897674 0.2831447  0.3003598  0.40882844 0.39384696 0.38691482
 0.34959382 0.2769842  0.3140396  0.37770385 0.28672218 0.1890039
 0.3498757  0.33454782 0.31905496 0.41414946 0.3103552  0.3325928
 0.29993445 0.30531254]
tr_loss:[0.32222465 0.34100828 0.35760802 0.3300383  0.46626616 0.2316736
 0.28354287 0.33234033 0.31253827 0.3887816  0.35862446 0.34970063
 0.32509136 0.44145933 0.3481403  0.3933898  0.39893302 0.4206895
 0.29898554 0.41400442 0.2726667  0.22509651 0.3256623  0.34973183
 0.26203188 0.32286745 0.32055297 0.43436775 0.32271633 0.375517
 0.4050234  0.28612265 0.32657576 0.4218467  0.35086107 0.39917466
 0.34221846 0.3624108  0.46763617 0.37590775 0.46042618 0.37520677
 0.38806483 0.366648   0.38236415 0.34507275 0.33195013 0.35164985
 0.339548   0.3437581 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 300 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(301, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 301 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(302, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 302 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(303, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 303 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(304, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 304 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(305, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 305 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(306, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 306 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(307, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 307 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(308, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 308 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(309, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 309 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(310, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 310 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(311, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 311 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(312, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 312 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(313, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 313 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(314, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 314 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(315, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 315 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(316, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 316 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(317, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 317 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(318, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 318 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(319, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 319 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(320, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 320 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(321, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 321 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(322, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 322 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(323, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 323 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(324, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 324 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(325, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 325 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(326, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 326 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(327, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 327 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(328, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 328 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(329, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 329 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(330, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 330 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(331, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 331 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(332, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 332 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(333, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 333 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(334, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 334 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(335, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 335 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(336, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 336 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(337, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 337 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(338, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 338 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(339, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 339 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(340, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 340 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(341, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 341 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(342, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 342 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(343, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 343 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(344, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 344 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(345, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 345 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(346, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 346 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(347, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 347 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(348, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 348 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(349, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 349 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(350, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 350 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(351, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 351 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(352, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 352 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(353, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 353 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(354, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 354 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(355, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 355 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(356, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 356 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(357, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 357 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(358, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 358 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(359, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 359 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(360, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 360 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(361, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 361 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(362, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 362 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(363, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 363 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(364, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 364 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(365, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 365 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(366, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 366 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(367, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 367 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(368, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 368 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(369, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 369 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(370, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 370 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(371, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 371 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(372, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 372 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(373, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 373 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(374, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 374 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(375, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 375 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(376, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 376 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(377, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 377 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(378, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 378 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(379, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 379 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(380, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 380 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(381, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 381 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(382, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 382 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(383, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 383 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(384, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 384 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(385, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 385 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(386, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 386 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(387, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 387 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(388, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 388 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(389, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 389 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(390, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 390 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(391, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 391 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(392, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 392 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(393, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 393 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(394, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 394 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(395, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 395 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(396, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 396 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(397, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 397 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(398, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 398 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(399, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 399 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(400, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-300
text_input.shape
(400, 14400)
learning_input_tmp.shape
(400, 180, 80)
learning_input.shape
(400, 180, 80)
learning_output_tmp.shape
(400, 80)
learning_output.shape
(400, 80)
Model: "sequential_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_9 (SimpleRNN)    (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.6983661  0.46411046 0.51565915 0.65217876 0.6835317  0.34086165
 0.5639061  0.42496198 0.63779217 0.38437262 0.6008172  0.71999043
 0.71723735 0.43123025 0.5245093  0.62996966 0.45443177 0.5043224
 0.48042804 0.6076391  0.5178171  0.6617567  0.5073508  0.63515246
 0.38939923 0.7181395  0.797222   0.60097253 0.62063754 0.5446748
 0.7942286  0.86995316 0.47556582 0.43120202 0.4666667  0.5877182
 0.6255697  0.6811791  0.67894506 0.52416867 0.5103439  0.7080552
 0.59924114 0.5851699  0.59641737 0.5737503  0.6234988  0.6544856
 0.5077011  0.67508316]
tr_loss:[0.60316676 0.5675157  0.4078208  0.67941207 0.6239999  0.4882676
 0.46486968 0.45851773 0.45275593 0.511876   0.47576267 0.58692324
 0.6438762  0.5821206  0.60644734 0.6993948  0.5999584  0.50275457
 0.5135833  0.62785804 0.53279686 0.59023964 0.55555123 0.58642757
 0.59755975 0.4678977  0.6964694  0.45491314 0.46108732 0.3815995
 0.6005293  0.7299007  0.707852   0.3997602  0.40520138 0.5274471
 0.5552844  0.44582286 0.53099155 0.4943761  0.6337823  0.52626437
 0.6321316  0.4949779  0.6195469  0.49115235 0.5075176  0.4990371
 0.61563104 0.57986146]
tr_loss:[0.51525253 0.80412924 0.5002645  0.47573584 0.80800724 0.4054994
 0.48674616 0.4138388  0.53236026 0.6201061  0.4209598  0.37264645
 0.4343049  0.520167   0.40526724 0.25531182 0.56306714 0.60847914
 0.3466192  0.46277326 0.6077406  0.6681925  0.4376585  0.49674731
 0.39609465 0.57454383 0.39667544 0.47943753 0.37271047 0.5874657
 0.5567681  0.38024825 0.37392202 0.4814778  0.4438743  0.5239053
 0.6758105  0.5126065  0.43927318 0.36186618 0.31869906 0.6202704
 0.36661333 0.5718577  0.6320332  0.5462179  0.5715724  0.4373272
 0.73776424 0.4948407 ]
tr_loss:[0.69869053 0.5390469  0.3538348  0.56673926 0.5013894  0.4489972
 0.5028093  0.47370157 0.55032575 0.5273526  0.6207551  0.47465533
 0.4968854  0.64627886 0.4556325  0.439066   0.3930629  0.51009303
 0.61360204 0.51593095 0.5840832  0.45338297 0.49135786 0.6141873
 0.63267356 0.35362533 0.5860381  0.5954358  0.5280154  0.5358829
 0.45250672 0.5427572  0.6523134  0.4921034  0.5275143  0.30910844
 0.48273334 0.50264186 0.47863588 0.32995814 0.6130811  0.41584927
 0.5331613  0.5400179  0.39480013 0.57703143 0.58409786 0.5246692
 0.54524356 0.43961748]
tr_loss:[0.4438563  0.39882421 0.4938712  0.6235196  0.629542   0.43518835
 0.55215466 0.36733288 0.3934335  0.69114023 0.5121467  0.5794175
 0.7319864  0.44404054 0.4031927  0.37162107 0.40739888 0.50643283
 0.6213871  0.52895284 0.528859   0.41822544 0.5882176  0.6607746
 0.4230345  0.5313168  0.47401413 0.43847093 0.35840577 0.39985514
 0.5653504  0.34184447 0.41292357 0.6138536  0.68792343 0.41768894
 0.4705634  0.55281395 0.4832949  0.7680982  0.5948084  0.5287121
 0.585227   0.5538505  0.6445228  0.44775862 0.5436538  0.5086045
 0.5050424  0.53008556]
tr_loss:[0.4189705  0.31896567 0.59422004 0.40715504 0.35395277 0.35577512
 0.44548655 0.43907303 0.46196303 0.44677478 0.49850416 0.47860202
 0.5657142  0.57731706 0.3728302  0.37761778 0.4616807  0.45132026
 0.42460975 0.39170247 0.3052626  0.6098052  0.58403957 0.43707266
 0.30733198 0.37990904 0.32932082 0.49348742 0.3777242  0.46976876
 0.25629455 0.45660383 0.3667757  0.37567264 0.66311526 0.36925554
 0.36795563 0.6965624  0.5961671  0.57993805 0.3823746  0.4828299
 0.4995803  0.32384032 0.57283765 0.4158236  0.5437539  0.48724213
 0.55096924 0.4637807 ]
tr_loss:[0.5451948  0.4564372  0.38012877 0.5402266  0.33975288 0.31363052
 0.46309695 0.3053607  0.53982717 0.5005811  0.2926224  0.3266545
 0.4993702  0.41768223 0.37981656 0.39388704 0.59960854 0.45946693
 0.587423   0.4919463  0.5915556  0.5534135  0.36792016 0.53583115
 0.5311884  0.43417096 0.38961226 0.38835442 0.59694445 0.31082717
 0.67974734 0.37025082 0.5940256  0.30076423 0.46420544 0.43429637
 0.28746447 0.54546964 0.27548376 0.29138947 0.545345   0.39888558
 0.5284602  0.4591135  0.5802782  0.4272152  0.48888478 0.509606
 0.44780684 0.49822116]
tr_loss:[0.5461504  0.34375733 0.40865907 0.45068902 0.5052764  0.5028058
 0.55978537 0.4231917  0.31424767 0.46905965 0.64952475 0.48032933
 0.25013047 0.4317092  0.2913019  0.47345775 0.3234642  0.32610583
 0.48091155 0.35620874 0.42192927 0.25325495 0.33076787 0.5572693
 0.526885   0.36681244 0.37059084 0.3691329  0.3260851  0.55682623
 0.288891   0.3325538  0.61523336 0.34182087 0.4073721  0.45627022
 0.44068733 0.5174898  0.63852274 0.41971937 0.45458493 0.30070463
 0.26092255 0.369645   0.4494844  0.6459041  0.58271563 0.44799072
 0.4430352  0.39489257]
tr_loss:[0.32438198 0.19703104 0.34980288 0.3062922  0.5672293  0.46055683
 0.32380491 0.284323   0.22179155 0.46267653 0.2282416  0.5429311
 0.3666903  0.4771754  0.39484873 0.1908854  0.32719436 0.23853374
 0.3213265  0.39073083 0.2800463  0.34214097 0.23618837 0.48232394
 0.5336238  0.44706708 0.3832633  0.32802558 0.41241112 0.596361
 0.20863745 0.26307848 0.3700332  0.27716988 0.38396278 0.3454474
 0.37211967 0.42815948 0.3710076  0.44183397 0.28970698 0.36819896
 0.36184806 0.39981186 0.35217685 0.26731429 0.44342858 0.33712342
 0.24674773 0.2392551 ]
tr_loss:[0.31491774 0.39579868 0.40884113 0.39498496 0.38627797 0.27280897
 0.5477579  0.22862878 0.32874078 0.17442842 0.23971438 0.35112974
 0.19695012 0.3415963  0.42881155 0.28097948 0.16143717 0.25380325
 0.4928893  0.34950587 0.35113057 0.49616498 0.36744028 0.42988652
 0.4876643  0.26551747 0.28205174 0.39295954 0.34065646 0.5660975
 0.43749872 0.26102862 0.4757328  0.38383323 0.37088412 0.36814296
 0.2725057  0.23640385 0.36918086 0.42812762 0.40558785 0.3301291
 0.3835705  0.2968172  0.41296306 0.3351999  0.37657732 0.33401433
 0.24636777 0.39203313]
tr_loss:[0.30890113 0.32588768 0.17286262 0.4237507  0.31445575 0.34822083
 0.20792408 0.29593688 0.29477376 0.32588452 0.38961792 0.20579657
 0.4102138  0.40172425 0.45830026 0.31389052 0.46311155 0.27367517
 0.31549686 0.33789414 0.34935623 0.31060553 0.22531919 0.2766068
 0.3701736  0.34280786 0.1792694  0.4608554  0.3256904  0.4173704
 0.4515589  0.30470917 0.35668284 0.37903547 0.27989468 0.28708273
 0.3298356  0.31583133 0.35336095 0.2731622  0.476029   0.3999842
 0.33541504 0.33258596 0.14579245 0.41225028 0.1962674  0.36262947
 0.34046012 0.27972704]
tr_loss:[0.27295262 0.39367968 0.4115445  0.27287608 0.20242754 0.38450035
 0.33011657 0.41855603 0.3416957  0.34073246 0.31483465 0.26443902
 0.27965334 0.32770523 0.28969425 0.43307552 0.38251665 0.32825586
 0.27307072 0.32713008 0.18953092 0.3481609  0.28214025 0.2449563
 0.2511834  0.18116798 0.30351305 0.30827585 0.27750093 0.19540147
 0.2535166  0.28330928 0.2980247  0.29553166 0.30669722 0.3007168
 0.33657366 0.32975554 0.4834469  0.2536579  0.36066008 0.30630326
 0.39371732 0.45235682 0.20689812 0.37862143 0.34595782 0.26008862
 0.28767824 0.32935998]
tr_loss:[0.25614095 0.25995907 0.42549247 0.37985533 0.30333018 0.18125503
 0.2946859  0.16453138 0.17827031 0.34255219 0.35123786 0.3290754
 0.42753953 0.2499182  0.29557252 0.13710104 0.37296423 0.21394496
 0.3110147  0.44092265 0.21875343 0.4924117  0.35630247 0.25072607
 0.3329988  0.4077868  0.22828197 0.32774737 0.34746155 0.29180205
 0.38416567 0.39213297 0.30174565 0.24860363 0.3457385  0.4241125
 0.34246483 0.26043466 0.23587577 0.36826053 0.2270529  0.34582773
 0.34625143 0.20032966 0.33306447 0.20345955 0.38586646 0.20644231
 0.27295083 0.40743843]
tr_loss:[0.2866262  0.35543257 0.46444306 0.4236452  0.43293944 0.30917484
 0.2745664  0.39154387 0.33232412 0.3109632  0.4338607  0.32361117
 0.36641294 0.29303372 0.33785406 0.18166688 0.29303232 0.29124397
 0.2810005  0.24424663 0.391584   0.41279942 0.37456146 0.34706694
 0.40167674 0.23679276 0.3034134  0.3252039  0.4378379  0.22476093
 0.26741427 0.2420158  0.4414533  0.35229275 0.2885037  0.31140965
 0.24474998 0.29736668 0.3453404  0.26598325 0.3916764  0.10435808
 0.34849498 0.13863754 0.29345772 0.23280707 0.23419194 0.13134268
 0.36761498 0.34506655]
tr_loss:[0.37787598 0.21039887 0.22973363 0.32086796 0.3361438  0.21258609
 0.2395803  0.35938728 0.3414352  0.34608993 0.32157835 0.3658537
 0.42941576 0.37032315 0.21243525 0.18987243 0.23638025 0.36197716
 0.34964594 0.22464332 0.11090956 0.3239872  0.34198943 0.2827704
 0.282561   0.29788837 0.2532849  0.2929713  0.3950277  0.27420193
 0.38306862 0.3850548  0.17823212 0.2203031  0.26296428 0.21989305
 0.31749925 0.23100428 0.34113294 0.35704634 0.25208288 0.38774508
 0.2561735  0.32595286 0.1932964  0.41152936 0.144039   0.30935377
 0.3429071  0.28413025]
tr_loss:[0.3047164  0.20088992 0.32887316 0.41132385 0.30916968 0.25969157
 0.27428183 0.2054561  0.29320323 0.30376035 0.2900471  0.30072945
 0.32852468 0.35940903 0.28669387 0.23875785 0.353921   0.21015438
 0.35019293 0.4506503  0.32544643 0.32556194 0.39682308 0.18694505
 0.37700766 0.38993615 0.34863234 0.20656674 0.26633862 0.3836406
 0.28703925 0.22159465 0.39683202 0.19481419 0.16237946 0.37667027
 0.3768012  0.30189005 0.22128458 0.385399   0.34792563 0.33115065
 0.15657361 0.30138788 0.3108092  0.2064441  0.21114531 0.29749507
 0.15894756 0.31256437]
text_input.shape
(400, 14400)
learning_input_tmp.shape
(400, 180, 80)
learning_input.shape
(400, 180, 80)
learning_output_tmp.shape
(400, 80)
learning_output.shape
(400, 80)
Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_10 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.68133533 0.49852514 0.6681272  0.34733564 0.66120857 0.6106558
 0.27199712 0.6103989  0.50529814 0.6473573  0.6131328  0.5857748
 0.4292744  0.48704964 0.39194185 0.4999054  0.54438835 0.6344738
 0.5124621  0.50090456 0.3751648  0.5085157  0.5012844  0.5717191
 0.46963724 0.6177581  0.6769677  0.5579909  0.51561666 0.40621033
 0.39741373 0.4211871  0.65740675 0.46378765 0.606603   0.5444816
 0.5763361  0.634362   0.59098494 0.6223506  0.3932943  0.6169287
 0.6491667  0.55615455 0.5179413  0.45441055 0.4802692  0.56119716
 0.44268718 0.6875857 ]
tr_loss:[0.4867742  0.525699   0.37167025 0.69919086 0.68143713 0.68174314
 0.3508746  0.571417   0.5556539  0.62929803 0.49869078 0.4293924
 0.52784956 0.6435076  0.7501863  0.43122092 0.56797105 0.7014821
 0.4682588  0.51650906 0.5898793  0.50520885 0.6047783  0.51736355
 0.61877126 0.35026753 0.53711975 0.4444278  0.44507828 0.5999732
 0.46087584 0.6098059  0.55737364 0.52173376 0.5509206  0.5361533
 0.7729018  0.68221885 0.3873765  0.49111968 0.4259858  0.54794914
 0.45019037 0.59196526 0.4268462  0.6972379  0.58125156 0.4727199
 0.45430914 0.57358724]
tr_loss:[0.58774674 0.52055043 0.47227734 0.45867172 0.43954378 0.50999695
 0.47595245 0.3400126  0.515103   0.59305626 0.43785495 0.55080354
 0.6032645  0.57213324 0.60775244 0.4987901  0.49888867 0.47834677
 0.6983751  0.35623103 0.51330143 0.5110543  0.4053194  0.36260372
 0.63915193 0.58000976 0.43473497 0.6611402  0.74935967 0.56510967
 0.51968604 0.5140998  0.68573654 0.36209416 0.5894791  0.52609074
 0.51003057 0.56973445 0.4573391  0.44938907 0.42503947 0.4227454
 0.5036222  0.31332725 0.74319494 0.583834   0.5851858  0.33399987
 0.49643803 0.31055808]
tr_loss:[0.5472814  0.46586865 0.5176856  0.61324924 0.5446309  0.51058674
 0.59706676 0.5440631  0.63459164 0.54967594 0.53897935 0.561635
 0.33794418 0.5030266  0.72801924 0.32345206 0.43152595 0.48601913
 0.7206734  0.4126791  0.50757474 0.3914144  0.26561266 0.6671264
 0.41731519 0.70659244 0.6352318  0.49706116 0.5093478  0.47166616
 0.49598083 0.50791377 0.5407101  0.5857013  0.4893404  0.5585768
 0.44009584 0.551398   0.4864645  0.37341106 0.67712957 0.73648596
 0.45349866 0.53345656 0.5099165  0.31376082 0.51608115 0.304516
 0.47798365 0.36175123]
tr_loss:[0.3355877  0.3608348  0.37797156 0.48077425 0.55710256 0.46826324
 0.38993698 0.37629038 0.4512179  0.5133965  0.5128185  0.4001587
 0.5555278  0.5723864  0.6899532  0.32041335 0.58116454 0.5229054
 0.5493755  0.38618106 0.4660986  0.47701544 0.40244666 0.32027403
 0.5139328  0.6563592  0.35263476 0.61155367 0.63179064 0.6976005
 0.4072481  0.6795012  0.485643   0.6510892  0.47151127 0.2894785
 0.6710236  0.3047492  0.46683082 0.51875365 0.5633352  0.7171209
 0.5799185  0.4074699  0.51002216 0.6890374  0.46335143 0.6036499
 0.56496227 0.54134995]
tr_loss:[0.37876612 0.56270075 0.54430485 0.60339874 0.55194455 0.50682956
 0.59155655 0.39808342 0.32812706 0.38037452 0.42093533 0.61046124
 0.469589   0.476751   0.64030945 0.5249685  0.5576588  0.527021
 0.61108637 0.44126877 0.5910373  0.40620017 0.505482   0.3119995
 0.48679847 0.5555686  0.6088526  0.39161438 0.374852   0.59778506
 0.5672788  0.5846689  0.6668314  0.1669656  0.51455134 0.4129859
 0.47138986 0.5042052  0.44372827 0.46079627 0.3866857  0.36843637
 0.35007492 0.41999617 0.39309987 0.358953   0.6575761  0.37593454
 0.3129777  0.43961707]
tr_loss:[0.3831244  0.3719831  0.39193696 0.38707376 0.35013217 0.43208385
 0.4911626  0.47203597 0.5980569  0.40940228 0.29161    0.47690487
 0.3835134  0.59140855 0.49360055 0.36524087 0.5644156  0.46379775
 0.4422818  0.5748487  0.594807   0.46270156 0.4236568  0.43667254
 0.37923574 0.43810987 0.73217165 0.49684516 0.45580387 0.5240904
 0.5086095  0.50250614 0.453935   0.3458213  0.2143056  0.38863823
 0.5122841  0.37643152 0.6240221  0.34347668 0.31007612 0.54403037
 0.2985733  0.40122166 0.50584877 0.4877855  0.3025523  0.39602366
 0.36176157 0.44680128]
tr_loss:[0.4538783  0.5652328  0.32645336 0.667905   0.3172728  0.5289273
 0.4630889  0.45377168 0.40661365 0.48385882 0.51720655 0.46840844
 0.5433984  0.35546356 0.5341169  0.37985888 0.48564023 0.43545684
 0.27841312 0.45570046 0.42295828 0.33434725 0.3867173  0.45690432
 0.262834   0.4078992  0.4327681  0.40942407 0.29839128 0.4857421
 0.32574558 0.38260055 0.28925952 0.44372615 0.27550563 0.45190245
 0.5234992  0.5233027  0.30707717 0.36548543 0.48415607 0.51883525
 0.34939376 0.46846437 0.52954423 0.57615817 0.5483221  0.31727418
 0.4403903  0.5039253 ]
tr_loss:[0.30294505 0.5450373  0.50892395 0.3288786  0.28899178 0.45135355
 0.22634526 0.36345726 0.31475446 0.4650213  0.45278692 0.43391842
 0.33998293 0.37507015 0.532197   0.42026544 0.42709512 0.38391715
 0.26201642 0.35008836 0.3253591  0.37908167 0.4530576  0.24474308
 0.2389329  0.4304169  0.3962911  0.3746516  0.38154402 0.33231694
 0.4268496  0.40633607 0.26119387 0.33350554 0.27329832 0.5257208
 0.3880691  0.30249792 0.28332156 0.35631937 0.4553009  0.27638236
 0.39985022 0.44217667 0.35816145 0.5369979  0.3114308  0.34747016
 0.3430436  0.3532452 ]
tr_loss:[0.29737085 0.3794135  0.29327765 0.32737318 0.245228   0.43901667
 0.40936717 0.42485318 0.44981176 0.23183334 0.41891932 0.1596556
 0.24851358 0.36937237 0.29698253 0.35886237 0.42271763 0.37452942
 0.46232072 0.27887893 0.42482883 0.2446104  0.3199072  0.3944071
 0.40086132 0.32478467 0.26181856 0.35132313 0.49159068 0.4289015
 0.23370023 0.33987775 0.29199725 0.40574867 0.22896457 0.31464648
 0.47414866 0.39064294 0.28254935 0.49506706 0.30062056 0.32074413
 0.28293347 0.21213499 0.18604776 0.4071843  0.23598595 0.4406396
 0.42349976 0.2864278 ]
tr_loss:[0.38610917 0.30621034 0.197478   0.33182916 0.35266894 0.28078622
 0.18002343 0.20812276 0.40127665 0.3279518  0.33642316 0.39599982
 0.47470158 0.3511036  0.33386162 0.34460956 0.29843187 0.29483116
 0.32897592 0.48690858 0.34981546 0.36839825 0.34161004 0.3130212
 0.4013218  0.3666646  0.45743245 0.2104358  0.28130308 0.26026255
 0.38427058 0.41018873 0.38608772 0.21258771 0.32355797 0.24523206
 0.322172   0.2140687  0.38247848 0.42890778 0.19597659 0.38027593
 0.31658354 0.36056814 0.31211743 0.31779957 0.40798074 0.2804224
 0.21151249 0.18456438]
tr_loss:[0.28872266 0.33651972 0.3911655  0.2876869  0.26675424 0.2422264
 0.20673363 0.44591674 0.32033148 0.3027772  0.40075094 0.24965486
 0.3798221  0.24079219 0.4603613  0.21995091 0.22553119 0.3330379
 0.21090432 0.21216616 0.30607262 0.3415013  0.41268998 0.3917602
 0.27749327 0.32977042 0.31172204 0.4673602  0.19534832 0.24971774
 0.1551927  0.1970476  0.37354735 0.31898576 0.35715201 0.3521924
 0.38290462 0.28190055 0.2655299  0.36077628 0.30727345 0.16773689
 0.30685064 0.3954699  0.35634392 0.36319116 0.29039177 0.42535368
 0.2728548  0.23964527]
tr_loss:[0.32250196 0.32403198 0.4380392  0.2967634  0.3434233  0.39225322
 0.3351032  0.41434154 0.1744127  0.17634274 0.26257658 0.3393458
 0.21820512 0.2894375  0.31586725 0.31295443 0.32230932 0.31017488
 0.2297987  0.2583619  0.2613648  0.2924686  0.3392098  0.27220383
 0.35260108 0.3073635  0.2118012  0.3379469  0.29922542 0.27079868
 0.24885377 0.2205657  0.4045704  0.35684642 0.341758   0.28092632
 0.26278508 0.29489025 0.29879674 0.2740344  0.5045551  0.35949832
 0.17344661 0.25800094 0.26530662 0.329175   0.15699074 0.30172625
 0.29246965 0.33108893]
tr_loss:[0.3609092  0.3917965  0.20563021 0.35995644 0.21711941 0.27632552
 0.31553388 0.41335455 0.24101023 0.3406639  0.24768543 0.45120516
 0.40482435 0.27995205 0.21761715 0.22269344 0.332822   0.23676431
 0.43521222 0.2369112  0.26786962 0.21709292 0.23532763 0.32953677
 0.24492292 0.24389362 0.23568258 0.13805072 0.47591996 0.19962817
 0.31601304 0.35408452 0.3446292  0.36310798 0.39583898 0.36406356
 0.27108967 0.3750581  0.47527274 0.39343166 0.28262967 0.2886297
 0.25941378 0.17093214 0.20676899 0.44243973 0.45083657 0.12347826
 0.24484706 0.414397  ]
tr_loss:[0.25049353 0.36180347 0.3212592  0.25259584 0.31291455 0.31693283
 0.31741667 0.31648645 0.26641962 0.25721303 0.33070204 0.35589173
 0.30212384 0.1909405  0.31518525 0.22923863 0.26364526 0.25532138
 0.21885224 0.19139923 0.21492286 0.3759292  0.2013804  0.38971797
 0.26681763 0.22470263 0.21230082 0.18343471 0.47798052 0.33483496
 0.3426426  0.23866053 0.4168991  0.35136908 0.39618883 0.35019398
 0.1622622  0.41632915 0.18758935 0.13055578 0.29124263 0.30343962
 0.3445373  0.207751   0.34522533 0.272957   0.28023177 0.18168335
 0.25477248 0.38599795]
tr_loss:[0.27138585 0.27421576 0.27977204 0.37739232 0.29558688 0.36778888
 0.2994606  0.28156132 0.21341929 0.3258837  0.35716742 0.47137475
 0.29560888 0.34755337 0.351363   0.29061398 0.40398416 0.4372116
 0.25276032 0.35067162 0.28631195 0.27235094 0.2196916  0.33304316
 0.35454148 0.31677514 0.18727268 0.2917362  0.24497588 0.26110718
 0.35135525 0.3770917  0.21038279 0.2854699  0.1953597  0.15540768
 0.30217528 0.3313492  0.27771825 0.33086807 0.29237613 0.2717567
 0.33368668 0.24177809 0.31525713 0.40992475 0.2928536  0.39951843
 0.18969485 0.35759538]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 400 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(401, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 401 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(402, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 402 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(403, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 403 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(404, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 404 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(405, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 405 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(406, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 406 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(407, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 407 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(408, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 408 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(409, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 409 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(410, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 410 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(411, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 411 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(412, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 412 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(413, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 413 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(414, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 414 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(415, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 415 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(416, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 416 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(417, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 417 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(418, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 418 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(419, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 419 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(420, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 420 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(421, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 421 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(422, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 422 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(423, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 423 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(424, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 424 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(425, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 425 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(426, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 426 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(427, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 427 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(428, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 428 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(429, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 429 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(430, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 430 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(431, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 431 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(432, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 432 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(433, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 433 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(434, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 434 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(435, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 435 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(436, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 436 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(437, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 437 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(438, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 438 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(439, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 439 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(440, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 440 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(441, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 441 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(442, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 442 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(443, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 443 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(444, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 444 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(445, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 445 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(446, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 446 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(447, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 447 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(448, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 448 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(449, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 449 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(450, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 450 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(451, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 451 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(452, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 452 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(453, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 453 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(454, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 454 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(455, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 455 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(456, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 456 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(457, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 457 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(458, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 458 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(459, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 459 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(460, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 460 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(461, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 461 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(462, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 462 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(463, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 463 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(464, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 464 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(465, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 465 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(466, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 466 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(467, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 467 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(468, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 468 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(469, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 469 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(470, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 470 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(471, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 471 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(472, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 472 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(473, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 473 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(474, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 474 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(475, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 475 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(476, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 476 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(477, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 477 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(478, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 478 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(479, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 479 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(480, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 480 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(481, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 481 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(482, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 482 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(483, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 483 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(484, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 484 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(485, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 485 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(486, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 486 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(487, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 487 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(488, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 488 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(489, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 489 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(490, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 490 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(491, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 491 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(492, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 492 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(493, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 493 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(494, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 494 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(495, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 495 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(496, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 496 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(497, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 497 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(498, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 498 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(499, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 499 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(500, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-400
text_input.shape
(500, 14400)
learning_input_tmp.shape
(500, 180, 80)
learning_input.shape
(500, 180, 80)
learning_output_tmp.shape
(500, 80)
learning_output.shape
(500, 80)
Model: "sequential_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_11 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.5830027  0.7005585  0.39993876 0.5826911  0.5732781  0.5774315
 0.6962511  0.59309477 0.57701385 0.50876606 0.4192585  0.42966574
 0.7894172  0.57747424 0.53681344 0.6125743  0.59188807 0.5396182
 0.5909629  0.6416957  0.38550273 0.50722414 0.44961968 0.460388
 0.5157635  0.41650176 0.44558868 0.47310653 0.480695   0.65781754
 0.5509613  0.5818001  0.6050436  0.5315153  0.56811935 0.5464972
 0.65336365 0.49066353 0.5793397  0.6096188  0.5168254  0.5139528
 0.53180945 0.5093468  0.45065528 0.71096796 0.46935743 0.48497233
 0.48731202 0.5671276 ]
tr_loss:[0.5826287  0.5558055  0.5331087  0.5109514  0.41312522 0.5769357
 0.7393017  0.3728381  0.49721903 0.65665686 0.5151188  0.52390623
 0.6143533  0.47816268 0.35139585 0.5527071  0.561718   0.77287424
 0.6425773  0.46377072 0.50724775 0.55559117 0.36216193 0.63367146
 0.41455793 0.5322374  0.63252175 0.50254744 0.516871   0.57026786
 0.5182792  0.5082947  0.44700298 0.5484551  0.62508327 0.50872576
 0.42195615 0.6797246  0.49037337 0.5913347  0.5125996  0.5644509
 0.6445974  0.44318342 0.39737588 0.54452753 0.55182445 0.676398
 0.34627157 0.6189896 ]
tr_loss:[0.3476048  0.3178705  0.35449585 0.6114278  0.45856276 0.45460424
 0.6212574  0.64082366 0.35303205 0.59243256 0.50529796 0.60569894
 0.43231553 0.543344   0.6195072  0.47952047 0.66304797 0.43613607
 0.5081186  0.63256055 0.5862683  0.39095646 0.69384277 0.35541168
 0.35128993 0.47150525 0.4124362  0.390318   0.60159236 0.5085894
 0.538741   0.46219063 0.34209353 0.4436697  0.36023226 0.6371962
 0.6014029  0.558304   0.56139714 0.645758   0.5057601  0.3491681
 0.5772233  0.35409966 0.35998145 0.45535955 0.47217408 0.5204271
 0.6139572  0.6043345 ]
tr_loss:[0.44356817 0.36623764 0.5364877  0.5238231  0.5315225  0.33513245
 0.33116466 0.49884933 0.3581861  0.441192   0.31962833 0.39826906
 0.53805166 0.32722545 0.5058242  0.36952776 0.32719427 0.54383904
 0.599545   0.6091033  0.30576533 0.3674074  0.50583    0.46890467
 0.45247373 0.32116422 0.5228052  0.29656833 0.29848424 0.29819113
 0.5455761  0.47702655 0.5039571  0.4263143  0.29927954 0.5651547
 0.42532888 0.46024102 0.4113596  0.5557236  0.6385455  0.51518023
 0.6207075  0.51211107 0.32503492 0.56088936 0.5182489  0.33280236
 0.65689504 0.5219745 ]
tr_loss:[0.27475125 0.20066395 0.19766243 0.5307008  0.51920575 0.4450205
 0.77261275 0.6902642  0.47290078 0.1985636  0.46243173 0.5090097
 0.41487974 0.5331661  0.32398143 0.40783748 0.62259036 0.56744987
 0.5616829  0.61775076 0.43975067 0.35056686 0.5740245  0.5169492
 0.3397747  0.42160922 0.38448995 0.40068746 0.46801576 0.30028751
 0.4476263  0.5385413  0.37588716 0.31613535 0.55558336 0.26023385
 0.4455635  0.66709626 0.18651775 0.4425881  0.4583252  0.51143616
 0.6394722  0.50305855 0.18833569 0.57593    0.3429909  0.5453721
 0.18752496 0.5738599 ]
tr_loss:[0.1692507  0.4114992  0.7059206  0.26820114 0.3433103  0.58622766
 0.54592717 0.400386   0.491803   0.5422101  0.53653497 0.31380922
 0.588766   0.5751052  0.4798215  0.5397827  0.6564104  0.34885037
 0.15335831 0.51661986 0.70096093 0.46444422 0.43949547 0.14975959
 0.6808422  0.15582894 0.5302695  0.52660215 0.37458596 0.47734728
 0.13602264 0.38639507 0.5325657  0.42695045 0.42539412 0.13953546
 0.15048286 0.76631224 0.49726677 0.15290317 0.21144387 0.39039797
 0.32286263 0.14764737 0.4199957  0.31526577 0.1375277  0.53143823
 0.44517833 0.6503437 ]
tr_loss:[0.65816724 0.21638091 0.49258098 0.45209217 0.09925781 0.10432317
 0.5354885  0.3939448  0.09790593 0.576079   0.6270839  0.5482526
 0.53272545 0.4432021  0.40181145 0.28602287 0.47121096 0.573359
 0.5334216  0.51371956 0.5973233  0.37009963 0.21197172 0.5623807
 0.41279402 0.09771261 0.09855632 0.41282225 0.5308191  0.3163763
 0.0976901  0.10472801 0.32375914 0.50469816 0.10170572 0.4108718
 0.10658242 0.5478207  0.35883516 0.41712683 0.15791228 0.5309147
 0.5444125  0.72104245 0.38467154 0.2691442  0.55885756 0.6001257
 0.09691981 0.41475385]
tr_loss:[0.26088786 0.319667   0.46420866 0.54633534 0.41978985 0.55151266
 0.5609914  0.46355373 0.503753   0.08317457 0.07904269 0.13478586
 0.49149936 0.36599928 0.31360942 0.6066058  0.5902127  0.2834726
 0.4495902  0.5242465  0.36862555 0.53309107 0.47331405 0.6115209
 0.5178706  0.4484132  0.11657639 0.08168016 0.5307422  0.5158988
 0.3516798  0.37804282 0.41548777 0.45953894 0.46163923 0.38218865
 0.08026768 0.0805674  0.53016925 0.45803294 0.5983953  0.5548322
 0.40232044 0.61014    0.5490108  0.59281003 0.525946   0.5849129
 0.5540973  0.57661045]
tr_loss:[0.3643623  0.50270206 0.4842266  0.3181058  0.40100008 0.07080775
 0.44980097 0.47368374 0.54032624 0.51782393 0.59598047 0.067058
 0.30687788 0.414929   0.30078995 0.12160878 0.45707482 0.57059175
 0.44033784 0.0687383  0.30882826 0.25297096 0.6589531  0.52254134
 0.36553344 0.4196868  0.2925749  0.2728838  0.1012557  0.07147796
 0.06792741 0.52553445 0.06753192 0.39242563 0.43405706 0.52856463
 0.47987682 0.39245194 0.27793837 0.53589934 0.48315296 0.6214169
 0.4415234  0.5198389  0.66118    0.27595744 0.09135724 0.06676207
 0.06746197 0.5160759 ]
tr_loss:[0.49679846 0.05544454 0.44503507 0.05535265 0.525424   0.05566495
 0.43373793 0.07838999 0.4221116  0.5357907  0.5721775  0.5439202
 0.05702169 0.44616356 0.29807934 0.5137491  0.595365   0.05506505
 0.05463894 0.05982492 0.53693765 0.5939743  0.34250662 0.495313
 0.45471096 0.05904553 0.31811684 0.05812561 0.4128592  0.5041349
 0.44406018 0.05802801 0.4648548  0.46197873 0.0581044  0.05472041
 0.5433645  0.50736296 0.6973048  0.51932895 0.48956776 0.60702884
 0.5337781  0.50860125 0.41786727 0.377837   0.46624374 0.6160677
 0.5615984  0.4253304 ]
tr_loss:[0.32097977 0.50659794 0.30798298 0.47628564 0.33234602 0.23693338
 0.34118277 0.04974635 0.38309345 0.0475141  0.3103914  0.47547144
 0.04987099 0.6463567  0.492138   0.2506402  0.56387335 0.52498835
 0.3407383  0.4683579  0.26771507 0.41140634 0.04951867 0.40770832
 0.04784905 0.323363   0.34685606 0.4398474  0.04798371 0.22694635
 0.37383953 0.32540977 0.40441146 0.24454424 0.3348145  0.4058202
 0.33521608 0.46779394 0.4182195  0.37738228 0.40405685 0.28967723
 0.26448148 0.48489666 0.39900213 0.43895015 0.34865418 0.29664302
 0.04838578 0.34657723]
tr_loss:[0.31090283 0.4083047  0.4403428  0.34645835 0.15940383 0.3977407
 0.09417135 0.284056   0.04541042 0.04726043 0.23600492 0.4591466
 0.22898383 0.28974363 0.35147402 0.0456256  0.3004299  0.3694888
 0.47452965 0.04744507 0.34553224 0.30717272 0.23223095 0.34937105
 0.37282866 0.4722742  0.37327105 0.33708692 0.04539365 0.29259664
 0.51063335 0.28589067 0.36428794 0.32027537 0.43081078 0.31386885
 0.33373648 0.40406933 0.20428257 0.21273911 0.46743584 0.24306092
 0.17124148 0.27845973 0.29320684 0.25660682 0.04534192 0.32930413
 0.48334438 0.28804153]
tr_loss:[0.32300478 0.2860032  0.0399434  0.4118169  0.40192205 0.43360776
 0.29991078 0.4585052  0.4126071  0.03850321 0.39266533 0.4522509
 0.4409637  0.03825383 0.0438198  0.28567782 0.22840741 0.312953
 0.04727625 0.41289386 0.38360518 0.04234231 0.06274803 0.5210808
 0.33389792 0.3626637  0.05295809 0.10822611 0.31601954 0.37699562
 0.38322383 0.04354159 0.39635453 0.30319566 0.44485182 0.03899142
 0.43170673 0.34597573 0.2632555  0.33078545 0.21378508 0.04325627
 0.3579846  0.24404807 0.03974513 0.38543588 0.0439535  0.38481045
 0.03954729 0.37485087]
tr_loss:[0.3211181  0.39186415 0.42952627 0.2907403  0.2858952  0.2519456
 0.03486834 0.26578492 0.21622142 0.34774846 0.038592   0.03945382
 0.31902152 0.35934132 0.4165949  0.4012247  0.3468287  0.32112664
 0.29949346 0.40802002 0.42493397 0.03908397 0.04709389 0.03577402
 0.37841278 0.34064466 0.21074028 0.19233118 0.27815586 0.30810648
 0.20769414 0.46863884 0.41441292 0.29303503 0.36686817 0.4577527
 0.38575685 0.37674966 0.25828767 0.40570825 0.3719923  0.22596519
 0.35268608 0.34057152 0.2105597  0.03841182 0.04100772 0.45342922
 0.3720819  0.41371125]
tr_loss:[0.38520855 0.33631188 0.35413635 0.34316647 0.27364343 0.4019638
 0.51587915 0.31038785 0.34489807 0.10263095 0.30995488 0.03451474
 0.03762793 0.37488222 0.40362626 0.30012858 0.45175734 0.03836253
 0.29089323 0.03839324 0.3680099  0.48229137 0.28246066 0.19271879
 0.4335648  0.04686663 0.28007954 0.40586996 0.03667586 0.3702981
 0.2924183  0.2624516  0.08831079 0.2557395  0.11306039 0.3118871
 0.37136632 0.47153026 0.30034542 0.38884228 0.37447032 0.03703409
 0.2663104  0.36295587 0.50965613 0.43009692 0.03477187 0.35652366
 0.4018286  0.3252655 ]
tr_loss:[0.34694573 0.2785649  0.0386271  0.25592393 0.2243953  0.506811
 0.03760262 0.41258293 0.03764854 0.19341533 0.03808379 0.04580776
 0.21783796 0.1566426  0.2538914  0.3710659  0.26774248 0.33034497
 0.05863615 0.2956102  0.41056213 0.31674266 0.03774881 0.31941494
 0.40403804 0.3023756  0.29620272 0.2870373  0.03832044 0.42372203
 0.29425368 0.03844679 0.2418048  0.45281965 0.25129855 0.37958875
 0.26661998 0.03780756 0.43821627 0.32893983 0.28869858 0.3950812
 0.13370451 0.4579977  0.14558919 0.33203182 0.4708499  0.30143213
 0.03852946 0.30754685]
tr_loss:[0.38611856 0.3402551  0.28976712 0.37946856 0.03687139 0.22954528
 0.28320122 0.26298887 0.2638394  0.27790084 0.29503673 0.38471594
 0.36473963 0.27448374 0.03682622 0.26041406 0.39280367 0.22583504
 0.34608212 0.03750342 0.20327206 0.21275158 0.0465812  0.3617053
 0.25499386 0.24065766 0.3821578  0.03675413 0.36819786 0.40616083
 0.4607226  0.36410528 0.38545522 0.1205761  0.33072233 0.2834111
 0.1159025  0.27010888 0.36580458 0.3436615  0.32332867 0.59403485
 0.2747643  0.03715599 0.32365063 0.49674645 0.03720589 0.31114674
 0.2804993  0.3475471 ]
tr_loss:[0.38593742 0.32519192 0.30865383 0.08600514 0.03234825 0.27875865
 0.44173306 0.3508901  0.31398982 0.2388092  0.22868338 0.03214296
 0.03223853 0.03177502 0.19250916 0.39522225 0.16895185 0.3928078
 0.27879506 0.3984865  0.30212927 0.34447795 0.42154282 0.23247504
 0.14155853 0.3570384  0.03771181 0.24219342 0.29485124 0.24722166
 0.03246235 0.03313194 0.27090698 0.262036   0.33478767 0.18332523
 0.46285114 0.40757543 0.43573913 0.34202862 0.39041692 0.34566036
 0.36159554 0.35273802 0.27020964 0.30514878 0.35508928 0.2863621
 0.36144447 0.37112206]
tr_loss:[0.02851092 0.08594041 0.38338187 0.02751354 0.14676423 0.19786344
 0.02597785 0.02694845 0.39533347 0.02774789 0.34473482 0.02712235
 0.36908668 0.39869404 0.38916248 0.23862195 0.3425343  0.20024708
 0.26546878 0.30265665 0.29548344 0.02758482 0.37789762 0.21063492
 0.47981477 0.24947362 0.26365525 0.36896145 0.3874196  0.37541878
 0.13752224 0.2494338  0.37080008 0.38193226 0.2572756  0.02606652
 0.32124946 0.02687719 0.23762174 0.34568316 0.30664438 0.44265914
 0.02592443 0.45727628 0.3249566  0.35549435 0.23400338 0.02767856
 0.41565552 0.09697183]
tr_loss:[0.35596317 0.32928005 0.2686659  0.2516953  0.29348978 0.3580133
 0.4114464  0.2679666  0.36782914 0.22953327 0.39747348 0.18806031
 0.43464375 0.02272853 0.24176183 0.33681262 0.38119027 0.35891235
 0.02241317 0.19940381 0.02380931 0.22276787 0.0234653  0.02321444
 0.29861608 0.21547501 0.3284456  0.02596684 0.02222474 0.26933515
 0.22139557 0.29669124 0.22167139 0.39069766 0.2539661  0.09012926
 0.02231726 0.32788694 0.3608604  0.31689233 0.31963423 0.14684127
 0.21860635 0.3573663  0.20011477 0.17876457 0.29531622 0.34429532
 0.26672173 0.43826455]
text_input.shape
(500, 14400)
learning_input_tmp.shape
(500, 180, 80)
learning_input.shape
(500, 180, 80)
learning_output_tmp.shape
(500, 80)
learning_output.shape
(500, 80)
Model: "sequential_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_12 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.56084055 0.6282744  0.34660292 0.6619693  0.7055146  0.616519
 0.5053555  0.5970851  0.56175435 0.42750555 0.5040677  0.50102913
 0.5750495  0.5931579  0.39024997 0.5995046  0.3592441  0.5901123
 0.4094751  0.5675543  0.47614703 0.5960004  0.8440725  0.68310744
 0.5702628  0.68971896 0.61482966 0.54990697 0.5349448  0.65396947
 0.6366539  0.75327826 0.6148135  0.65474683 0.5515715  0.5778147
 0.53672624 0.5471498  0.4776774  0.5604352  0.53611994 0.41732064
 0.56566983 0.6971631  0.6055189  0.6179843  0.62250245 0.56136614
 0.48657107 0.5973449 ]
tr_loss:[0.5568973  0.5838829  0.39770222 0.45815974 0.52871096 0.37034565
 0.606642   0.3571725  0.40328574 0.50243384 0.46528134 0.7177469
 0.35005182 0.3550059  0.6537573  0.5351027  0.5006887  0.54886544
 0.45663816 0.43864536 0.34944242 0.47513503 0.7446051  0.5341522
 0.56685036 0.71672094 0.5015416  0.5200325  0.45952624 0.6519762
 0.48683494 0.4858369  0.39001885 0.5660325  0.51407605 0.65421176
 0.5489253  0.5530761  0.53270406 0.35616878 0.71718955 0.65820456
 0.5721952  0.44815144 0.51444227 0.49561796 0.35714182 0.47905707
 0.36527207 0.37318745]
tr_loss:[0.5517524  0.43539128 0.54191655 0.35671043 0.41773337 0.5871369
 0.66241825 0.26348916 0.46571034 0.5391487  0.69985735 0.5171832
 0.26744226 0.271362   0.31533125 0.2675939  0.635883   0.66803247
 0.5610827  0.64739645 0.3905138  0.40284356 0.67114055 0.47217807
 0.26441354 0.42977348 0.46488675 0.3538467  0.638749   0.6364874
 0.6247873  0.44274467 0.56430984 0.5417102  0.44602585 0.3439172
 0.26371852 0.26526302 0.42442083 0.2886618  0.30251843 0.61264884
 0.55952215 0.5758838  0.50553876 0.4629756  0.6590296  0.59395695
 0.27431965 0.77392447]
tr_loss:[0.5817455  0.60981715 0.6400789  0.5293547  0.1707014  0.47345248
 0.56967723 0.59739816 0.45451552 0.4373583  0.7131258  0.39842322
 0.6358374  0.61885846 0.35017616 0.3398288  0.17407236 0.4296461
 0.59914714 0.5282842  0.4730689  0.40470856 0.4057046  0.6328269
 0.5685954  0.51725715 0.34361058 0.48635903 0.30673942 0.17391442
 0.36018977 0.1722918  0.59356767 0.6265152  0.20857923 0.3999765
 0.7527971  0.17312123 0.64014024 0.6009297  0.54075897 0.5589495
 0.4623168  0.6612872  0.42008168 0.4874156  0.49055743 0.5177983
 0.5702702  0.17144662]
tr_loss:[0.5879882  0.723539   0.5539629  0.49828285 0.5837437  0.4284018
 0.42036557 0.34069383 0.47187757 0.5786763  0.6423696  0.4463707
 0.5980061  0.61322105 0.13596329 0.6326386  0.477372   0.53595984
 0.62202626 0.4443848  0.25473064 0.46516576 0.57607347 0.3753229
 0.37492436 0.5239609  0.14836554 0.46591625 0.5519999  0.28524548
 0.13490616 0.13160035 0.54327613 0.5776576  0.30877513 0.3302071
 0.53703624 0.4846363  0.1483865  0.5287279  0.13878867 0.13639133
 0.13352719 0.4672163  0.49282855 0.511018   0.3792066  0.45917258
 0.21611783 0.5238975 ]
tr_loss:[0.61679983 0.10998151 0.35390562 0.46027416 0.43063864 0.33579
 0.6391728  0.54402244 0.56672055 0.10695937 0.52269363 0.6468745
 0.40037808 0.10196523 0.10788834 0.10964976 0.42690343 0.38082457
 0.48614216 0.38769564 0.7160822  0.36617574 0.5142386  0.5103699
 0.7131696  0.37950057 0.5278893  0.54957265 0.10403723 0.40105587
 0.5953933  0.4664955  0.1067334  0.24058452 0.5537133  0.28736156
 0.47063532 0.5414901  0.5057249  0.50282115 0.5691264  0.39234358
 0.10272994 0.52087444 0.11128803 0.30890486 0.10311586 0.48388386
 0.53381366 0.44010726]
tr_loss:[0.5418362  0.08583535 0.31847817 0.52207834 0.48835954 0.58295774
 0.48394006 0.5034927  0.08278896 0.22275586 0.30161566 0.08114208
 0.3811417  0.41026968 0.49206552 0.08577043 0.524077   0.34512895
 0.08492352 0.65796834 0.46947175 0.3937505  0.31997177 0.47582054
 0.43395433 0.5699199  0.5092422  0.47728056 0.6085984  0.35081142
 0.0809684  0.08033065 0.07945146 0.08230443 0.44068408 0.6027726
 0.0829827  0.62968403 0.37816802 0.18475926 0.1797509  0.2289212
 0.07927018 0.4684797  0.3274108  0.0799827  0.6370859  0.3286155
 0.49210367 0.51759636]
tr_loss:[0.5047234  0.5279979  0.43298435 0.6385354  0.07212728 0.48373532
 0.08679078 0.57469636 0.61161447 0.34616154 0.4442505  0.6050576
 0.43860722 0.07225201 0.5356655  0.0719543  0.3932616  0.68124294
 0.43812937 0.5113996  0.37780333 0.36841863 0.45052713 0.36470777
 0.48612022 0.53701735 0.07205211 0.34964758 0.52884597 0.4844628
 0.07237069 0.316353   0.19190638 0.07207306 0.07265972 0.419132
 0.42031088 0.39909983 0.5442685  0.36364445 0.53120387 0.7256744
 0.0718015  0.39271185 0.45631972 0.38230568 0.4630271  0.6655108
 0.62568367 0.6421822 ]
tr_loss:[0.31421256 0.33979148 0.58004177 0.47603664 0.3877619  0.302427
 0.39242473 0.55409276 0.61963    0.35880837 0.53207874 0.35421753
 0.55579007 0.5257047  0.4789234  0.51880974 0.44154605 0.38948628
 0.5131996  0.36108822 0.5696766  0.4867293  0.6029129  0.3331433
 0.28235972 0.06381704 0.5611216  0.5007266  0.34319538 0.6180396
 0.4070405  0.44322234 0.5968707  0.44934607 0.7083357  0.45533735
 0.44815725 0.5301995  0.0624129  0.56694096 0.32562572 0.43098822
 0.3140747  0.06008595 0.42802134 0.56017524 0.32207593 0.5097578
 0.06179844 0.49870244]
tr_loss:[0.05662585 0.5695105  0.3916474  0.32068545 0.05632992 0.29126224
 0.05693289 0.23153786 0.05726063 0.0572274  0.0554636  0.05591507
 0.56921756 0.54043686 0.24166413 0.5180804  0.56313723 0.45836335
 0.45631248 0.5288145  0.6015729  0.05691049 0.48290366 0.5952633
 0.182273   0.49126157 0.05611805 0.6426065  0.4504097  0.40963173
 0.49632853 0.05693747 0.35028547 0.562628   0.52707684 0.4636197
 0.3749968  0.41269296 0.4777791  0.28065854 0.05577198 0.5167199
 0.28448582 0.31706065 0.5367669  0.26605964 0.55514914 0.29820147
 0.3533704  0.05720385]
tr_loss:[0.04546048 0.24725246 0.29156768 0.4649679  0.34251896 0.40804926
 0.21872573 0.44306675 0.19965728 0.37756795 0.5281066  0.40753824
 0.3677768  0.46089286 0.27957422 0.51320964 0.2783338  0.3030262
 0.32807234 0.4129176  0.5510244  0.41364574 0.04636987 0.21839419
 0.3115221  0.31627017 0.04664568 0.04561014 0.38755804 0.04664951
 0.29392877 0.3459404  0.30868065 0.3038408  0.04582968 0.3335789
 0.5068281  0.43006763 0.40809956 0.35561395 0.3610316  0.3912552
 0.3555268  0.1161809  0.37960127 0.3711223  0.04757751 0.1910512
 0.33329663 0.5587083 ]
tr_loss:[0.04153883 0.2504758  0.3141068  0.2153883  0.3222561  0.39431924
 0.36833477 0.32671952 0.04367395 0.374338   0.42127085 0.37574038
 0.04094667 0.04154078 0.3179461  0.24932785 0.3600968  0.4999389
 0.26614517 0.47778147 0.39220145 0.46414232 0.5388125  0.29293436
 0.26160222 0.36943257 0.21185398 0.38701302 0.42232117 0.24455039
 0.5310644  0.38194513 0.41680413 0.4150916  0.413405   0.10174654
 0.28660625 0.42108184 0.38011983 0.5084179  0.04055053 0.37641507
 0.42542976 0.28300613 0.29217845 0.3625665  0.04029164 0.14521478
 0.4333977  0.40127736]
tr_loss:[0.5314809  0.44339857 0.04391729 0.36897153 0.35046554 0.43653908
 0.03496717 0.2655711  0.39480472 0.31875968 0.37692207 0.21724875
 0.38765293 0.34434372 0.40477338 0.2987164  0.32323366 0.32267135
 0.35215682 0.25584197 0.23580316 0.37639752 0.27767494 0.34732112
 0.41265622 0.2509891  0.3457761  0.03383772 0.35819662 0.43847352
 0.38952523 0.37311393 0.3627678  0.24769187 0.23867169 0.4601899
 0.43826085 0.26981074 0.46194726 0.3761395  0.37777996 0.03347979
 0.3933731  0.3621138  0.43723089 0.23789611 0.26206255 0.03415392
 0.40638828 0.33649325]
tr_loss:[0.32290414 0.03446255 0.36206883 0.27734002 0.40502125 0.37691313
 0.2612117  0.39717823 0.2954285  0.35566586 0.33441985 0.38882288
 0.337781   0.36080962 0.23416924 0.47669372 0.34625533 0.4229684
 0.03421042 0.33612114 0.33336037 0.28999066 0.34913465 0.2816624
 0.18860419 0.29758257 0.2224272  0.46598607 0.4715612  0.40737048
 0.29025847 0.32658404 0.20628612 0.36125317 0.3519761  0.525478
 0.368802   0.11175072 0.14226906 0.25769013 0.03661582 0.26390782
 0.3995466  0.39072448 0.44831306 0.10262743 0.3187707  0.26301372
 0.24366859 0.36527777]
tr_loss:[0.54803735 0.04576467 0.37124604 0.03991515 0.3634293  0.04423184
 0.30975407 0.44036302 0.36647207 0.26984447 0.324507   0.3593854
 0.41567403 0.4078227  0.230027   0.04064916 0.27720764 0.498207
 0.41576892 0.2084724  0.14508423 0.2983411  0.3597227  0.26304966
 0.1811969  0.04368722 0.18176015 0.30088884 0.29227415 0.27282476
 0.30693132 0.04390611 0.38236484 0.04357193 0.39980048 0.34889418
 0.04276105 0.3684265  0.04003881 0.2773363  0.46609324 0.04060045
 0.2668869  0.31693548 0.23149829 0.2723605  0.04538188 0.35208294
 0.0637759  0.36217976]
tr_loss:[0.400465   0.04452105 0.04515461 0.4757077  0.48923826 0.31849128
 0.03960951 0.24276909 0.04294784 0.04250639 0.23842672 0.42152208
 0.31852865 0.13271001 0.32656795 0.3559771  0.40553397 0.20119958
 0.30339187 0.41930023 0.04042064 0.35574073 0.38979864 0.35410333
 0.32163057 0.36487454 0.38434872 0.04424108 0.20109543 0.11143706
 0.20764264 0.42853817 0.4907631  0.21087933 0.05744302 0.04279844
 0.40171367 0.29172277 0.4018901  0.22660446 0.38135758 0.03970751
 0.40599376 0.04368307 0.40848732 0.27054906 0.19010256 0.03935771
 0.41902542 0.35625857]
tr_loss:[0.22030243 0.3160773  0.2780422  0.26078004 0.03050893 0.30333376
 0.36288017 0.38082236 0.38783684 0.31231102 0.03015541 0.13712151
 0.16894506 0.19733913 0.32287356 0.02940813 0.43948203 0.03383488
 0.03217595 0.33504707 0.35875374 0.29985917 0.34767094 0.03131393
 0.33512196 0.43406492 0.2766382  0.28671786 0.3437175  0.41555852
 0.2810542  0.35978612 0.45580322 0.23905234 0.29967403 0.37511414
 0.3264616  0.04925922 0.03457093 0.03175833 0.41847286 0.24502122
 0.30578476 0.30650637 0.29262978 0.2659778  0.06113162 0.1660622
 0.20572014 0.2901701 ]
tr_loss:[0.3691778  0.28412557 0.28617954 0.02350421 0.2128605  0.3004784
 0.40531096 0.36659765 0.2003243  0.34122822 0.2774987  0.2658484
 0.07149404 0.34613195 0.05533641 0.46337122 0.0264941  0.10477094
 0.02518829 0.02284993 0.32125577 0.40393582 0.02346116 0.34388494
 0.3755687  0.29726964 0.45828867 0.3472642  0.02550294 0.42387503
 0.2978542  0.3490255  0.02378579 0.16068555 0.37950805 0.02373407
 0.02538248 0.3458901  0.39603466 0.02539614 0.0269054  0.163722
 0.3243704  0.2869965  0.25424647 0.3356378  0.02865731 0.29354006
 0.4175374  0.02762791]
tr_loss:[0.292737   0.15666021 0.32893673 0.02050481 0.16428813 0.44592673
 0.37305695 0.24678183 0.4679075  0.02530454 0.25551093 0.22672275
 0.40241933 0.29510516 0.3327375  0.27941227 0.34077495 0.02056094
 0.3432688  0.26126933 0.26589888 0.26003683 0.3592233  0.32920828
 0.34261495 0.26237902 0.3873753  0.02313089 0.33557767 0.02301065
 0.02357031 0.36245176 0.02368167 0.19452818 0.38918608 0.23177305
 0.43147716 0.25021535 0.31499377 0.346953   0.11788726 0.21961601
 0.3638076  0.27940005 0.42691344 0.02120827 0.42376065 0.34319615
 0.22275214 0.31045732]
tr_loss:[0.35993338 0.29923224 0.02888008 0.2655324  0.35611528 0.31938693
 0.22999759 0.39468592 0.12981682 0.02843788 0.09395166 0.1826988
 0.20788726 0.28535068 0.3546561  0.0258517  0.35926983 0.3962373
 0.32141018 0.34318802 0.13788883 0.02886945 0.4218553  0.37475958
 0.28688383 0.23965879 0.25175172 0.02314699 0.23630771 0.25067192
 0.02552224 0.02416014 0.42406005 0.02343373 0.18804821 0.29343018
 0.19119677 0.3856657  0.37634882 0.02768919 0.14736724 0.40701103
 0.29926968 0.3561601  0.02469247 0.2542544  0.10463981 0.24216752
 0.20596096 0.44517606]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 500 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(501, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 501 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(502, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 502 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(503, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 503 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(504, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 504 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(505, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 505 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(506, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 506 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(507, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 507 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(508, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 508 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(509, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 509 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(510, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 510 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(511, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 511 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(512, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 512 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(513, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 513 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(514, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 514 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(515, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 515 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(516, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 516 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(517, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 517 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(518, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 518 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(519, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 519 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(520, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 520 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(521, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 521 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(522, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 522 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(523, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 523 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(524, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 524 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(525, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 525 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(526, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 526 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(527, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 527 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(528, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 528 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(529, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 529 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(530, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 530 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(531, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 531 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(532, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 532 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(533, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 533 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(534, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 534 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(535, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 535 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(536, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 536 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(537, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 537 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(538, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 538 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(539, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 539 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(540, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 540 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(541, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 541 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(542, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 542 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(543, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 543 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(544, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 544 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(545, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 545 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(546, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 546 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(547, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 547 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(548, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 548 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(549, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 549 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(550, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 550 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(551, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 551 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(552, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 552 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(553, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 553 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(554, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 554 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(555, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 555 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(556, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 556 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(557, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 557 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(558, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 558 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(559, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 559 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(560, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 560 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(561, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 561 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(562, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 562 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(563, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 563 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(564, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 564 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(565, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 565 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(566, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 566 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(567, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 567 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(568, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 568 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(569, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 569 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(570, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 570 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(571, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 571 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(572, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 572 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(573, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 573 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(574, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 574 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(575, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 575 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(576, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 576 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(577, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 577 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(578, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 578 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(579, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 579 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(580, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 580 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(581, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 581 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(582, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 582 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(583, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 583 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(584, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 584 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(585, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 585 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(586, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 586 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(587, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 587 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(588, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 588 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(589, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 589 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(590, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 590 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(591, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 591 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(592, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 592 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(593, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 593 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(594, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 594 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(595, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 595 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(596, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 596 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(597, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 597 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(598, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 598 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(599, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 599 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(600, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-500
text_input.shape
(600, 14400)
learning_input_tmp.shape
(600, 180, 80)
learning_input.shape
(600, 180, 80)
learning_output_tmp.shape
(600, 80)
learning_output.shape
(600, 80)
Model: "sequential_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_13 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.717802   0.56790847 0.50757086 0.8640193  0.5377168  0.60399973
 0.79965365 0.5989729  0.48671108 0.8340886  0.39571112 0.6165472
 0.5333266  0.5171919  0.66265076 0.56724626 0.3884583  0.847263
 0.53767836 0.56632406 0.53629816 0.36412376 0.52590895 0.5116947
 0.68611753 0.83603346 0.70437783 0.52813095 0.7866389  0.5622201
 0.43855596 0.8439108  0.39378962 0.5374137  0.55475855 0.4550221
 0.6213299  0.6556796  0.55698526 0.5386292  0.53580546 0.831701
 0.8250176  0.49189728 0.46790552 0.55952466 0.59747803 0.6678561
 0.84629613 0.49849826]
tr_loss:[0.6167113  0.5075467  0.37482244 0.58442944 0.68258315 0.48673683
 0.45708466 0.5007863  0.7020513  0.47629967 0.45791006 0.58927274
 0.5346591  0.54937667 0.5409776  0.3681887  0.49220696 0.5305387
 0.41715327 0.5262602  0.5040533  0.60195637 0.5828563  0.5018217
 0.50455904 0.5793827  0.53708935 0.36720985 0.52216136 0.6311806
 0.41696388 0.33824807 0.37530094 0.478093   0.34334368 0.4943468
 0.40670604 0.59229916 0.56860733 0.50424147 0.4896666  0.6650972
 0.3737709  0.64162433 0.31283924 0.34204483 0.59479314 0.5585973
 0.49159765 0.58672667]
tr_loss:[0.30512774 0.34237942 0.28173023 0.30913115 0.5314557  0.730994
 0.7993125  0.2872095  0.2770015  0.65931726 0.27047092 0.5632278
 0.4915701  0.30261546 0.3473603  0.44807643 0.4621214  0.28169495
 0.58235    0.28856778 0.6273363  0.3010711  0.63153106 0.34922296
 0.58240104 0.27973047 0.6991816  0.27844137 0.5775355  0.60910887
 0.6119998  0.30943325 0.30928966 0.66713    0.56723434 0.31434983
 0.5890869  0.40637034 0.5246112  0.5940652  0.26874962 0.3047041
 0.7416673  0.46961913 0.43390378 0.4841296  0.41843152 0.513445
 0.28156605 0.55949086]
tr_loss:[0.24691164 0.32167655 0.3705875  0.2290334  0.6630896  0.6712035
 0.62699366 0.51014215 0.39226374 0.467799   0.16234228 0.42622375
 0.37663975 0.605948   0.47265476 0.45769233 0.221661   0.5927521
 0.46852213 0.6459619  0.18050817 0.17485085 0.40813965 0.16944711
 0.46909967 0.42777467 0.21638091 0.17195776 0.54345894 0.8669531
 0.17119817 0.34896252 0.545763   0.17275874 0.61375743 0.5514084
 0.3185831  0.38858038 0.4706645  0.47354993 0.51551557 0.17203204
 0.6469998  0.34465012 0.5125667  0.17455664 0.3875342  0.1725526
 0.62800586 0.17109723]
tr_loss:[0.3180511  0.36419225 0.47125244 0.55956626 0.10396449 0.2505219
 0.54879034 0.12166157 0.38105756 0.58634675 0.10394509 0.639647
 0.11753447 0.10521142 0.55682653 0.1472274  0.57238185 0.3437704
 0.10036068 0.49144983 0.1099788  0.36060292 0.47444534 0.6508245
 0.43289098 0.5579853  0.14621791 0.4954234  0.46669474 0.35582918
 0.12110247 0.4593215  0.45583105 0.58797944 0.47951564 0.4725526
 0.14113195 0.63264525 0.41953516 0.5484276  0.688208   0.1191197
 0.5031346  0.11498501 0.4442242  0.3491157  0.61107403 0.41734344
 0.51678187 0.357841  ]
tr_loss:[0.13402523 0.5342489  0.6030702  0.09141047 0.33001742 0.17396739
 0.4676559  0.11737011 0.08708085 0.50761235 0.13545036 0.10568597
 0.39314786 0.12548412 0.47310668 0.39240164 0.5247503  0.6252549
 0.48095384 0.10259932 0.10492698 0.4658765  0.10354314 0.50483215
 0.7051633  0.10843632 0.483389   0.13193575 0.08660279 0.57571477
 0.13560912 0.24442193 0.55639374 0.5997719  0.58673626 0.35668704
 0.13568206 0.12692502 0.6008915  0.09325471 0.40958434 0.13078153
 0.13012485 0.08943687 0.12977578 0.5108353  0.58050096 0.08829451
 0.64231    0.08728597]
tr_loss:[0.08604213 0.5407614  0.4502409  0.07937609 0.41153803 0.51021415
 0.5087943  0.48813385 0.43536267 0.09888209 0.48018318 0.5400666
 0.08733805 0.65637714 0.55572623 0.61321425 0.42202172 0.4783992
 0.5618708  0.3492816  0.5828179  0.54598504 0.5651808  0.0854207
 0.57841426 0.08340051 0.08712171 0.08133627 0.08126976 0.5445148
 0.28751516 0.09161232 0.29242578 0.08189936 0.529665   0.08511066
 0.60495716 0.58472645 0.51757365 0.5458409  0.43231946 0.08228229
 0.49988556 0.26628202 0.59348893 0.45657024 0.54461366 0.0797777
 0.33580345 0.33026066]
tr_loss:[0.40436664 0.45967674 0.08222039 0.49220222 0.69569796 0.3723933
 0.08129206 0.3105452  0.54523057 0.7155528  0.41352472 0.06966889
 0.36724597 0.7036264  0.41195172 0.5272655  0.5884712  0.4514594
 0.3184999  0.6908604  0.08330522 0.3913374  0.49117804 0.25128192
 0.07504395 0.3315006  0.41367668 0.53032357 0.07603522 0.58958113
 0.07437384 0.08318152 0.4117233  0.06963975 0.07518969 0.08185706
 0.07454473 0.46315923 0.62692595 0.07631705 0.30447826 0.5658117
 0.08417298 0.43700832 0.53131807 0.07144427 0.08025874 0.07374674
 0.5986704  0.34102696]
tr_loss:[0.06949965 0.43305063 0.6816643  0.06689235 0.6478465  0.29410952
 0.7511295  0.41072473 0.06246691 0.50780267 0.30767077 0.41232672
 0.38089624 0.06731538 0.65359867 0.06965774 0.47434193 0.52009857
 0.58519363 0.07628529 0.06197096 0.06806417 0.33293715 0.5356153
 0.18066487 0.38571513 0.47353917 0.43311542 0.06629639 0.53990763
 0.06798009 0.06451339 0.3409937  0.07052922 0.06770454 0.5459086
 0.3915125  0.2333082  0.06615736 0.4542121  0.7433461  0.06049962
 0.56871665 0.34117484 0.06818215 0.06734536 0.5131997  0.70994174
 0.36455116 0.07220318]
tr_loss:[0.45726854 0.60066366 0.61752456 0.13600847 0.2816537  0.09062193
 0.06523406 0.0676953  0.3284298  0.05626817 0.29558215 0.07843304
 0.5161022  0.40239325 0.59160805 0.06199648 0.07072438 0.6113083
 0.05695771 0.3803915  0.44243327 0.06161165 0.26263654 0.5236771
 0.22836384 0.49568883 0.46742606 0.67976046 0.3883174  0.05621141
 0.37959722 0.36066428 0.06630437 0.47577864 0.6178661  0.06740539
 0.55907565 0.38627115 0.5315949  0.35081273 0.43177152 0.24715838
 0.45425653 0.06087756 0.08372317 0.05693563 0.52861613 0.4584411
 0.524339   0.57953966]
tr_loss:[0.5356207  0.5424204  0.0613909  0.06556671 0.5179032  0.41488808
 0.5393626  0.06299122 0.05783387 0.60994226 0.7132343  0.54285574
 0.39387217 0.1292983  0.31851852 0.05192924 0.48870367 0.04983499
 0.27615744 0.36242208 0.4031106  0.05023225 0.50339234 0.05991327
 0.62275875 0.05008592 0.09398068 0.67699385 0.49698195 0.54638404
 0.44109064 0.06176803 0.5210618  0.53800076 0.39416105 0.05005296
 0.0535579  0.5398863  0.40495753 0.38360542 0.25107378 0.4655525
 0.49279204 0.44755095 0.40919465 0.06157578 0.32959613 0.5397192
 0.54403555 0.502535  ]
tr_loss:[0.04331956 0.14610112 0.4953637  0.5149496  0.39870834 0.5243906
 0.5970747  0.3205809  0.06012833 0.51362073 0.4339549  0.34167704
 0.04306752 0.4820486  0.04326399 0.06149033 0.5271278  0.31397378
 0.16817924 0.05471129 0.35641542 0.4213782  0.27646518 0.5083367
 0.36537555 0.4713592  0.06478118 0.42256737 0.4744254  0.4632369
 0.55077744 0.06410582 0.4493637  0.3654905  0.50934744 0.04511454
 0.39113066 0.04408967 0.39662895 0.0958549  0.44702768 0.5263413
 0.5650613  0.31194    0.40960813 0.39238396 0.43527365 0.5178205
 0.5009326  0.50532335]
tr_loss:[0.40560412 0.43497005 0.3027592  0.03996087 0.40001783 0.45442337
 0.08291683 0.22191048 0.39986292 0.05362666 0.12185538 0.34497207
 0.05724982 0.44967565 0.06808092 0.33753812 0.5158103  0.24001145
 0.35463876 0.06636865 0.0435419  0.37796235 0.06605311 0.22832938
 0.5290923  0.21029551 0.06901457 0.52271783 0.06789808 0.2541874
 0.32560688 0.43909532 0.34879893 0.42480963 0.52145797 0.43877727
 0.39666206 0.405277   0.4562579  0.06818468 0.06921014 0.20450771
 0.2933525  0.06113136 0.06665577 0.04490195 0.29529047 0.27019563
 0.39896077 0.0402824 ]
tr_loss:[0.3511237  0.06348643 0.06196587 0.2626503  0.06189258 0.43097156
 0.37187663 0.03612    0.4428143  0.0362182  0.18543535 0.23328936
 0.06298618 0.47278196 0.03716066 0.03580572 0.0378885  0.33997908
 0.47013253 0.03622416 0.08883218 0.31746542 0.19238725 0.19222203
 0.4886368  0.34509933 0.3213901  0.06111422 0.33091268 0.26705766
 0.3193667  0.3936983  0.27275664 0.31392962 0.06479365 0.03634702
 0.03800543 0.3503085  0.3593332  0.06963199 0.03582982 0.22956946
 0.3724807  0.21541925 0.2892141  0.38983455 0.56521726 0.2965644
 0.4601472  0.44916955]
tr_loss:[0.37544814 0.33466706 0.05509507 0.34070858 0.45820513 0.4720579
 0.43076062 0.35897493 0.0348409  0.34478718 0.24252896 0.51788884
 0.42001063 0.05321453 0.24458885 0.05343746 0.22697568 0.24491258
 0.41802543 0.38945508 0.41455895 0.35115275 0.27087668 0.42372712
 0.0537703  0.33456108 0.03632803 0.03641555 0.5048765  0.26074046
 0.28847367 0.35900372 0.44840518 0.6406081  0.48524198 0.38808075
 0.28047913 0.34221378 0.34785438 0.49019337 0.3277051  0.44318455
 0.0571972  0.0560106  0.05669368 0.3719073  0.05553969 0.40190846
 0.39533776 0.49402365]
tr_loss:[0.03269028 0.24405146 0.3425405  0.42024088 0.06869064 0.2697736
 0.3908119  0.45048895 0.2833017  0.40757293 0.05239599 0.39433992
 0.41509476 0.25536212 0.03687294 0.03451276 0.28056148 0.29781625
 0.03329761 0.05136138 0.05042426 0.03555487 0.32845086 0.05338237
 0.31634203 0.5267101  0.30165827 0.5730408  0.38688934 0.36274952
 0.3683414  0.32221    0.03436629 0.2584649  0.24126077 0.03444294
 0.45247817 0.34012952 0.35657012 0.35193697 0.31340605 0.46715698
 0.47564363 0.18071151 0.45839548 0.24283127 0.2573765  0.41204327
 0.2672672  0.3594524 ]
tr_loss:[0.31505814 0.36515465 0.3223701  0.36059612 0.3318101  0.02944957
 0.23710704 0.37308994 0.02969406 0.4440629  0.23555708 0.35201043
 0.3269872  0.42788363 0.44622755 0.3198458  0.41696268 0.02913125
 0.44878083 0.37019086 0.03062974 0.06762439 0.02898309 0.2879855
 0.04359636 0.37804502 0.5204757  0.44932047 0.03145225 0.4577741
 0.3226571  0.04200158 0.2860629  0.2777227  0.41432413 0.3095067
 0.03169892 0.18481469 0.03464845 0.36587963 0.04823827 0.2396247
 0.39470035 0.4106813  0.04733717 0.37828717 0.37882763 0.32355773
 0.042121   0.2756764 ]
tr_loss:[0.03904239 0.3263256  0.44844264 0.3079695  0.03791986 0.35955065
 0.25555047 0.2638472  0.44958013 0.37262863 0.3483331  0.5205945
 0.22951455 0.04288305 0.29370612 0.35466734 0.02667192 0.02707382
 0.40717548 0.0246063  0.39486152 0.1770017  0.12920065 0.31188947
 0.04131383 0.3724882  0.5149516  0.35319102 0.03782291 0.18280692
 0.43918476 0.33489543 0.40925542 0.03852469 0.3460308  0.03679445
 0.0265848  0.31868538 0.03657939 0.2987245  0.3231721  0.04182811
 0.27646858 0.2183074  0.24278478 0.47605616 0.43835148 0.31617862
 0.2622313  0.41760784]
tr_loss:[0.42071396 0.2860943  0.03815592 0.28430787 0.03149119 0.39536482
 0.0275598  0.41309547 0.02743822 0.33179587 0.43486062 0.21898358
 0.3784505  0.02347854 0.43596998 0.411213   0.02568224 0.02716024
 0.26690778 0.5225356  0.02580293 0.02380103 0.40301102 0.03660641
 0.37095338 0.03197647 0.4690114  0.2910575  0.0232806  0.41420358
 0.0272392  0.02786258 0.24246636 0.43138474 0.36219674 0.02777131
 0.36495095 0.02354755 0.33804065 0.5062116  0.02801943 0.37214231
 0.26670033 0.07389925 0.42441773 0.36525542 0.2453916  0.37584227
 0.30165446 0.31385756]
tr_loss:[0.33517224 0.030721   0.04051347 0.2366631  0.02096825 0.25726786
 0.33829683 0.02317754 0.02996657 0.38011256 0.34276167 0.03244963
 0.31245843 0.02066699 0.24701448 0.02650655 0.35737842 0.02407249
 0.02259576 0.3041454  0.09238734 0.03108745 0.02149982 0.03117543
 0.02574225 0.48945054 0.02063912 0.0213807  0.37622926 0.03044908
 0.38250262 0.16630447 0.3635283  0.33384824 0.39830408 0.03376427
 0.3885408  0.3196127  0.40046826 0.02647615 0.3580387  0.03232937
 0.0309667  0.3617303  0.38957033 0.30619702 0.30039486 0.29700202
 0.03056288 0.3341417 ]
tr_loss:[0.35324758 0.03599826 0.01903097 0.352527   0.37528625 0.03276885
 0.4814051  0.01646045 0.02673077 0.02782767 0.45322084 0.298243
 0.4934515  0.15042016 0.23384187 0.02889351 0.40735215 0.02114502
 0.02707249 0.3890509  0.31207955 0.03469327 0.01522032 0.01507834
 0.01705246 0.11468985 0.03088675 0.29684806 0.34082693 0.27142122
 0.41949385 0.02049735 0.3256415  0.34305984 0.30276707 0.25862157
 0.02753625 0.02496688 0.3511797  0.01720454 0.026466   0.4939417
 0.2348958  0.02864727 0.23606035 0.01583107 0.4254779  0.02769758
 0.26276982 0.02852082]
tr_loss:[0.35657278 0.34373912 0.3542469  0.02307476 0.0235039  0.02343528
 0.5294386  0.1005111  0.36647722 0.2771822  0.22115946 0.3698173
 0.21231797 0.35062402 0.02286236 0.35922045 0.12920776 0.4572808
 0.35975933 0.01472645 0.02379368 0.01684949 0.01354548 0.23452504
 0.01304697 0.3782518  0.32987756 0.01745585 0.01906461 0.29965585
 0.24039702 0.24920633 0.37070808 0.3006094  0.03058843 0.0180718
 0.01903145 0.0171799  0.35237175 0.34956867 0.23997669 0.37405694
 0.43635243 0.3184036  0.3039537  0.33079615 0.02334055 0.43329564
 0.01576092 0.0183902 ]
tr_loss:[0.20530716 0.3576209  0.02158357 0.2384613  0.35960832 0.02190048
 0.27026662 0.46358386 0.30562717 0.2626261  0.33712044 0.38487345
 0.01946755 0.39658955 0.01972457 0.21101756 0.3857301  0.50360984
 0.31768426 0.32357937 0.02192298 0.02125876 0.33253556 0.26646727
 0.32599264 0.26470643 0.02464466 0.02093773 0.30835342 0.37103653
 0.26877818 0.41787162 0.18664205 0.40250963 0.30424464 0.0240522
 0.19364317 0.37826324 0.02273508 0.35179073 0.01345437 0.0974409
 0.02285244 0.36160192 0.3068985  0.27056915 0.2833589  0.22661987
 0.17174372 0.30929354]
tr_loss:[0.20166564 0.1799252  0.09930639 0.02292795 0.02316033 0.2358826
 0.3236029  0.02156251 0.314275   0.02032141 0.32692283 0.02182166
 0.02671604 0.28223473 0.29964027 0.27560025 0.195146   0.02254278
 0.27236885 0.3341454  0.250008   0.25162953 0.14481151 0.25838155
 0.25284246 0.327962   0.02219993 0.23348539 0.13865325 0.3251119
 0.5113808  0.28045496 0.2389824  0.4499371  0.02112865 0.28894863
 0.02307207 0.01642744 0.38766527 0.16599222 0.26908797 0.02185411
 0.02441655 0.35305047 0.3512213  0.38694492 0.27214256 0.13735761
 0.3534869  0.01973222]
text_input.shape
(600, 14400)
learning_input_tmp.shape
(600, 180, 80)
learning_input.shape
(600, 180, 80)
learning_output_tmp.shape
(600, 80)
learning_output.shape
(600, 80)
Model: "sequential_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_14 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.59385437 0.68763626 0.5985542  0.5846826  0.58651006 0.6847291
 0.5991565  0.43424162 0.38929707 0.73149115 0.69359    0.6114023
 0.505491   0.4668618  0.5448192  0.61021554 0.45075297 0.46758795
 0.41016588 0.5604292  0.5177789  0.46633023 0.64152193 0.57130563
 0.56067437 0.5931777  0.43066993 0.43552536 0.68614316 0.43639582
 0.5711805  0.44495708 0.62211466 0.6629421  0.60154617 0.59097064
 0.44618708 0.74630237 0.5178626  0.69167864 0.622702   0.5378499
 0.5772443  0.63427925 0.508626   0.6946951  0.6868454  0.56969184
 0.5977588  0.6021586 ]
tr_loss:[0.58676636 0.44191885 0.58543414 0.5763944  0.3962476  0.3939625
 0.74976236 0.6267549  0.40196759 0.44867247 0.5707017  0.42241374
 0.751875   0.553369   0.53871965 0.5157474  0.5895273  0.3614083
 0.5002292  0.51991194 0.53153956 0.45253602 0.5997453  0.57508546
 0.44663516 0.368048   0.52005655 0.49011493 0.69906723 0.581534
 0.53739107 0.5293624  0.5137177  0.43429127 0.5641071  0.5283021
 0.5406746  0.5578308  0.3620041  0.63753986 0.5381464  0.49676293
 0.5867599  0.4406701  0.5142182  0.5581765  0.5506857  0.37135988
 0.5168693  0.39690343]
tr_loss:[0.25176704 0.25092486 0.5910004  0.2518273  0.322254   0.3452775
 0.3861128  0.5886194  0.2531935  0.25067607 0.3219451  0.72459126
 0.63032436 0.49887553 0.5300151  0.33761346 0.82833195 0.37400755
 0.6445508  0.2522303  0.2450592  0.4100286  0.5310785  0.5084256
 0.25196895 0.3284643  0.28569967 0.25308818 0.51690197 0.25311852
 0.5519923  0.4270486  0.25146276 0.48508748 0.43981344 0.50324446
 0.7080294  0.3372612  0.3225884  0.56023777 0.24993508 0.2508771
 0.7753094  0.5728677  0.54335594 0.37982625 0.4650938  0.44494122
 0.69025975 0.25126976]
tr_loss:[0.54197127 0.4407714  0.59489334 0.45438623 0.35323822 0.2021235
 0.5332899  0.44656292 0.6145304  0.37906146 0.46789175 0.2435977
 0.68936217 0.20448315 0.54008    0.55571157 0.24334042 0.664408
 0.5627224  0.38270417 0.3810801  0.21054871 0.42644516 0.20824066
 0.3717978  0.42097297 0.2506048  0.24446937 0.43382996 0.5925704
 0.6650588  0.60302764 0.5666019  0.24322024 0.56925386 0.24274564
 0.20007043 0.24425265 0.31762654 0.63722545 0.5963663  0.5928858
 0.5714079  0.41516453 0.593888   0.9748182  0.41644794 0.50074255
 0.2149814  0.3375375 ]
tr_loss:[0.5022211  0.50464666 0.72305924 0.37000105 0.42495894 0.17928445
 0.45409375 0.46798143 0.40534726 0.2784037  0.17863369 0.4697698
 0.5630212  0.54753655 0.56840694 0.15548053 0.6133119  0.16794263
 0.3387472  0.16840252 0.1566677  0.4605639  0.4402872  0.49542302
 0.44677192 0.60014707 0.57823265 0.45646125 0.16703504 0.1695598
 0.35972452 0.4132635  0.1795189  0.4401845  0.5223076  0.62901616
 0.5627872  0.16939647 0.48828238 0.5540128  0.3979479  0.17645624
 0.7350557  0.59752    0.16679935 0.6681036  0.36359236 0.48882785
 0.70440626 0.49025804]
tr_loss:[0.6684074  0.46481505 0.57483613 0.13253282 0.125827   0.1177239
 0.11282821 0.45363092 0.5465072  0.47077265 0.4023346  0.5494113
 0.3653643  0.47785217 0.5596554  0.13881417 0.22152252 0.40731654
 0.63463223 0.37546095 0.5666262  0.6258377  0.5192369  0.40803355
 0.12324526 0.2558389  0.43366522 0.11184242 0.18426646 0.60590553
 0.5888095  0.44508582 0.39914337 0.55758154 0.1322904  0.5350479
 0.12691171 0.4360706  0.45906964 0.2715184  0.5229518  0.58714354
 0.6738931  0.68367136 0.42605057 0.2649215  0.5786887  0.4397704
 0.12191357 0.55050594]
tr_loss:[0.48293534 0.6173173  0.11211351 0.46309614 0.62717545 0.08989004
 0.5609435  0.09921881 0.37924972 0.11269832 0.45912442 0.67593944
 0.09037552 0.54066753 0.5624725  0.09074743 0.35022599 0.38935366
 0.5694783  0.11144572 0.10091976 0.60784787 0.40317503 0.5909554
 0.63522834 0.09096733 0.39851254 0.5260844  0.1014806  0.5149805
 0.1095105  0.60708207 0.4782215  0.4865028  0.10455109 0.35233974
 0.3702858  0.10410829 0.5074803  0.09785793 0.3669753  0.39966065
 0.47657496 0.10452089 0.46060848 0.42885607 0.10795826 0.53939706
 0.5752274  0.33393183]
tr_loss:[0.08564734 0.09332429 0.4705289  0.10164323 0.11068659 0.36784345
 0.08594858 0.31755257 0.36634114 0.4883429  0.45488986 0.09417073
 0.11347876 0.36865082 0.1115829  0.18047002 0.44797152 0.1130749
 0.10484955 0.4515625  0.10955198 0.09909628 0.10782621 0.52911866
 0.55480987 0.10643562 0.10526409 0.33887213 0.07872098 0.11251221
 0.31433758 0.31917724 0.07984562 0.08249615 0.08224903 0.11290739
 0.398647   0.4320344  0.0769815  0.09591714 0.561398   0.09486301
 0.5166567  0.11575811 0.5127982  0.41278714 0.33882084 0.14769413
 0.35449642 0.5146388 ]
tr_loss:[0.10210879 0.70846474 0.07809903 0.34094182 0.08286019 0.4917573
 0.42538399 0.07351645 0.5146171  0.08384677 0.63411754 0.08026471
 0.07931726 0.38623357 0.56396836 0.515736   0.55539745 0.48692313
 0.43829507 0.42015934 0.4504558  0.3808835  0.31176236 0.47520447
 0.0808869  0.35273656 0.6302961  0.555587   0.08451723 0.08394651
 0.5555294  0.08065756 0.59160376 0.0789835  0.07010134 0.37656122
 0.63067394 0.569992   0.6051181  0.07948343 0.47376376 0.0849088
 0.07383547 0.34128937 0.07125091 0.5127161  0.09982326 0.4478244
 0.08187325 0.07941806]
tr_loss:[0.51120675 0.40562838 0.08562776 0.5717543  0.5872761  0.54027617
 0.5709009  0.2888667  0.47196048 0.07428367 0.40137106 0.47412935
 0.50328517 0.51786494 0.07994247 0.08424082 0.35198814 0.09222554
 0.49912792 0.4926559  0.08531959 0.19975892 0.57027835 0.43387756
 0.3212916  0.3455016  0.4674899  0.36044708 0.6056024  0.10313974
 0.07060604 0.2819344  0.07723273 0.61751056 0.08682692 0.0923641
 0.596855   0.07197201 0.5480733  0.5022629  0.6431233  0.5813896
 0.5629817  0.08386749 0.36966503 0.2765565  0.08431816 0.07104145
 0.08859642 0.07396512]
tr_loss:[0.07763743 0.0782568  0.0796338  0.38950852 0.5228578  0.47157568
 0.30415785 0.49774343 0.07741248 0.16707598 0.07449183 0.310805
 0.50781554 0.50469625 0.6132015  0.45547748 0.5923871  0.1492098
 0.5558549  0.07922341 0.07001673 0.43657637 0.321819   0.07888874
 0.51096123 0.07794391 0.35443965 0.08011426 0.47804895 0.53158414
 0.5326084  0.07821903 0.08194778 0.08068168 0.14597818 0.07308026
 0.40561    0.08157636 0.48581782 0.155486   0.43920168 0.6330127
 0.4528923  0.07959104 0.07286718 0.46461964 0.40400544 0.5693
 0.08177331 0.42949215]
tr_loss:[0.51607275 0.46394897 0.31982723 0.43294007 0.5183856  0.05810357
 0.43948942 0.05951116 0.3488779  0.46016112 0.4403318  0.4305417
 0.4408494  0.44106126 0.4072155  0.22898102 0.07388151 0.38317293
 0.3797723  0.3955959  0.30304548 0.33472344 0.4848505  0.0587864
 0.0597478  0.38437635 0.552637   0.47350645 0.06311196 0.22292176
 0.41485652 0.4126976  0.06091422 0.52245206 0.32029104 0.39481464
 0.49657327 0.06138659 0.06349529 0.4709859  0.06186543 0.0621021
 0.59562445 0.46775547 0.42858848 0.06554577 0.36135942 0.37484327
 0.47936907 0.42841825]
tr_loss:[0.06276609 0.3246892  0.3810532  0.3665465  0.4721343  0.25710496
 0.4207387  0.2743546  0.26091105 0.06296445 0.41273326 0.20093949
 0.05987879 0.45252305 0.4206539  0.30786768 0.43779907 0.28604394
 0.06192553 0.06286045 0.44411308 0.2316637  0.06116109 0.3268909
 0.04753384 0.4118289  0.20155469 0.05133506 0.06269415 0.18041432
 0.281658   0.34938726 0.4088219  0.36519727 0.5336608  0.34810144
 0.27458328 0.05845594 0.05699856 0.27423176 0.04888407 0.06291528
 0.39095432 0.06693798 0.06634314 0.3733763  0.5194081  0.50758487
 0.05725008 0.46274883]
tr_loss:[0.05559755 0.3311065  0.05485287 0.05300958 0.05091083 0.06870584
 0.40764132 0.2492652  0.37204218 0.3957356  0.40687424 0.29496294
 0.4913803  0.77367544 0.44431224 0.3726515  0.4490377  0.3882739
 0.5337603  0.09812093 0.41652426 0.34913793 0.0509882  0.4908002
 0.26576766 0.05518348 0.38893598 0.3735686  0.42569762 0.05442805
 0.3478685  0.43332776 0.35196218 0.23914258 0.05079767 0.05581255
 0.05565532 0.05260443 0.38646802 0.39465174 0.32107633 0.17026962
 0.44889158 0.38108325 0.13087709 0.32089537 0.49820742 0.05002781
 0.05287503 0.38861644]
tr_loss:[0.44207516 0.3149988  0.33512923 0.4471454  0.3279937  0.50532466
 0.34232742 0.05007384 0.04511206 0.4149619  0.4035203  0.3798027
 0.12789738 0.05159922 0.38030034 0.11439168 0.3082628  0.3211759
 0.39588803 0.16453333 0.4125649  0.32344943 0.420865   0.47617978
 0.2672957  0.38456488 0.3959384  0.40379745 0.46325445 0.04354011
 0.4010686  0.27461392 0.26799065 0.04338633 0.04870909 0.32476383
 0.45608464 0.3563196  0.04483489 0.04755832 0.38287082 0.35196978
 0.36522222 0.34627932 0.04681685 0.46946716 0.397439   0.12928209
 0.43940407 0.265122  ]
tr_loss:[0.49753165 0.5563873  0.22302327 0.39042792 0.04459929 0.21425895
 0.49172512 0.25492722 0.047679   0.16650501 0.04577419 0.33153453
 0.03954393 0.04056232 0.3708805  0.5439207  0.30652708 0.2807061
 0.04059094 0.27196974 0.41694275 0.4116934  0.04667478 0.06639972
 0.4742776  0.44072175 0.04818854 0.04109957 0.32447034 0.2842241
 0.25293332 0.22799158 0.345222   0.04838018 0.36871523 0.22868848
 0.49803728 0.2670063  0.04770392 0.04475144 0.4659005  0.36443257
 0.04768563 0.4857505  0.05271654 0.04074436 0.51259226 0.35874856
 0.04637732 0.36079592]
tr_loss:[0.37710497 0.04334811 0.29944983 0.04260238 0.24252048 0.04040541
 0.29867285 0.36660558 0.3528586  0.2885469  0.4109746  0.2751872
 0.03550753 0.04191754 0.04124842 0.321174   0.04223693 0.21262681
 0.38922703 0.06185206 0.03570307 0.39996904 0.3022701  0.03577746
 0.22286627 0.35928053 0.5031735  0.26585376 0.04321329 0.42290503
 0.04311061 0.30109304 0.06053837 0.04330764 0.3187085  0.23795561
 0.46345043 0.37707743 0.0428514  0.03614922 0.21603835 0.35969692
 0.36161163 0.2590949  0.38802424 0.51179075 0.0423523  0.05137748
 0.03605541 0.3162219 ]
tr_loss:[0.42196417 0.38581476 0.34202522 0.37635794 0.3437128  0.03742323
 0.28132838 0.34462085 0.47588286 0.03749958 0.04016517 0.40703505
 0.1716285  0.40599647 0.27720776 0.03202916 0.29785424 0.2301127
 0.0377359  0.24983005 0.03183604 0.43302575 0.03119922 0.031305
 0.30234498 0.3874601  0.21481141 0.03198896 0.04290507 0.3738826
 0.28330642 0.29685932 0.45182475 0.2790225  0.0312498  0.42051736
 0.35679865 0.03830629 0.33561736 0.03809384 0.23662086 0.12516749
 0.03917415 0.4585716  0.49808016 0.28895056 0.33245853 0.03127532
 0.38349995 0.40072465]
tr_loss:[0.3683314  0.31386495 0.02995982 0.27868542 0.02999687 0.04462723
 0.1197443  0.31461662 0.23588257 0.42706418 0.28419495 0.3384506
 0.04494118 0.0403977  0.19926226 0.02984014 0.03743591 0.29268643
 0.2305294  0.376583   0.38730502 0.27579072 0.3465291  0.33895525
 0.31583282 0.0298157  0.3526224  0.32784906 0.3824198  0.3211893
 0.46290892 0.03615656 0.26115564 0.28008398 0.24426922 0.03003243
 0.3789974  0.22376601 0.23720269 0.20325474 0.03876863 0.2627492
 0.02956287 0.26741517 0.27050486 0.34260845 0.27596045 0.42095488
 0.03818902 0.18843338]
tr_loss:[0.03858022 0.32892966 0.2869489  0.03873531 0.36505923 0.41205883
 0.03845458 0.27734017 0.03862312 0.34155017 0.20989457 0.03649059
 0.38112158 0.21298055 0.40466198 0.0367357  0.03876461 0.3593245
 0.31688985 0.02728968 0.03743621 0.03771999 0.02737819 0.02680192
 0.38541952 0.03611452 0.33946007 0.21915416 0.23230724 0.36335674
 0.03808106 0.03809157 0.03340937 0.31026772 0.21270707 0.35124308
 0.24291106 0.21859339 0.02953584 0.30623674 0.34983683 0.04021698
 0.32880172 0.30356032 0.02636026 0.27611285 0.02882669 0.2745154
 0.02673402 0.45291463]
tr_loss:[0.02431648 0.32503554 0.28190604 0.03221112 0.38192266 0.333961
 0.03284841 0.28464797 0.03180126 0.0314467  0.29814276 0.1969575
 0.24778101 0.29970065 0.37554437 0.0243351  0.03300945 0.0356162
 0.30910334 0.0235035  0.03154435 0.30480796 0.03437813 0.18297078
 0.02315532 0.30060235 0.3386678  0.257053   0.037126   0.36228392
 0.02429696 0.31149372 0.2919333  0.0244669  0.03438704 0.3908867
 0.4340809  0.18964934 0.36134776 0.27463007 0.2530561  0.02321346
 0.53488964 0.28416094 0.27060986 0.02342649 0.3542264  0.30513996
 0.02427655 0.3460593 ]
tr_loss:[0.21754003 0.0302823  0.02839928 0.29966098 0.3801408  0.32677937
 0.21839137 0.32809997 0.34839684 0.02929216 0.23346886 0.35514182
 0.16397938 0.43799692 0.23835945 0.3284026  0.28078777 0.3323245
 0.3820932  0.24827214 0.4483858  0.29566255 0.324184   0.28756166
 0.21405455 0.02176978 0.47090554 0.24655437 0.05727189 0.39440647
 0.02178846 0.02127711 0.02109727 0.3841642  0.3771661  0.29270792
 0.02188408 0.02975628 0.02962915 0.17708452 0.02870557 0.35120025
 0.3577352  0.03694513 0.39540428 0.20866013 0.021232   0.3466421
 0.24196868 0.02176485]
tr_loss:[0.28976738 0.02068365 0.19552821 0.02172102 0.02591367 0.02075281
 0.09316139 0.21366549 0.24889445 0.22855115 0.02695943 0.34234416
 0.29111463 0.09523122 0.17321305 0.3738757  0.2320729  0.0415131
 0.02199693 0.02422535 0.03177878 0.43840018 0.3109043  0.3573239
 0.17913719 0.330679   0.02710784 0.37519407 0.2746175  0.20794182
 0.4070019  0.3456629  0.18929422 0.0423535  0.32255778 0.02065559
 0.41450182 0.11444998 0.20744315 0.21691695 0.28635377 0.36075306
 0.02138562 0.39065167 0.03683906 0.0242008  0.1024766  0.46579257
 0.2390207  0.2747162 ]
tr_loss:[0.27463013 0.20864901 0.34137008 0.33257732 0.23980828 0.34824222
 0.2851367  0.02676779 0.42704645 0.4647387  0.20594454 0.31059137
 0.03287612 0.32254    0.0238797  0.16352198 0.2812241  0.4127192
 0.09463325 0.02084801 0.27890745 0.33755556 0.02199337 0.02027705
 0.3415629  0.22500582 0.39362526 0.33191383 0.41715574 0.35334346
 0.32720512 0.3945529  0.35747242 0.02086741 0.02033686 0.39069706
 0.02148213 0.02613072 0.33813667 0.01850826 0.3080324  0.02482153
 0.02576314 0.2804403  0.38425034 0.46513295 0.27837557 0.02226689
 0.2772065  0.25701398]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 600 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(601, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 601 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(602, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 602 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(603, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 603 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(604, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 604 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(605, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 605 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(606, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 606 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(607, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 607 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(608, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 608 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(609, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 609 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(610, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 610 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(611, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 611 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(612, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 612 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(613, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 613 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(614, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 614 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(615, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 615 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(616, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 616 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(617, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 617 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(618, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 618 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(619, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 619 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(620, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 620 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(621, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 621 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(622, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 622 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(623, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 623 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(624, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 624 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(625, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 625 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(626, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 626 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(627, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 627 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(628, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 628 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(629, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 629 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(630, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 630 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(631, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 631 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(632, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 632 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(633, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 633 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(634, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 634 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(635, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 635 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(636, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 636 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(637, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 637 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(638, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 638 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(639, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 639 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(640, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 640 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(641, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 641 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(642, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 642 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(643, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 643 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(644, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 644 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(645, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 645 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(646, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 646 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(647, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 647 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(648, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 648 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(649, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 649 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(650, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 650 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(651, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 651 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(652, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 652 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(653, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 653 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(654, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 654 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(655, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 655 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(656, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 656 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(657, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 657 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(658, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 658 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(659, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 659 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(660, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 660 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(661, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 661 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(662, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 662 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(663, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 663 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(664, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 664 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(665, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 665 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(666, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 666 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(667, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 667 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(668, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 668 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(669, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 669 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(670, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 670 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(671, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 671 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(672, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 672 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(673, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 673 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(674, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 674 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(675, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 675 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(676, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 676 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(677, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 677 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(678, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 678 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(679, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 679 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(680, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 680 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(681, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 681 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(682, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 682 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(683, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 683 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(684, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 684 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(685, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 685 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(686, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 686 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(687, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 687 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(688, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 688 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(689, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 689 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(690, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 690 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(691, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 691 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(692, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 692 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(693, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 693 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(694, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 694 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(695, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 695 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(696, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 696 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(697, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 697 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(698, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 698 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(699, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 699 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(700, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-600
text_input.shape
(700, 14400)
learning_input_tmp.shape
(700, 180, 80)
learning_input.shape
(700, 180, 80)
learning_output_tmp.shape
(700, 80)
learning_output.shape
(700, 80)
Model: "sequential_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_15 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.46512097 0.5221299  0.6490025  0.6629354  0.76478964 0.75753766
 0.5262959  0.4201064  0.7570324  0.44248122 0.5116338  0.85667866
 0.5046092  0.5079135  0.45977268 0.691424   0.51237047 0.522179
 0.7340882  0.85783994 0.5052559  0.88169765 0.47396842 0.3274059
 0.5045152  0.57196224 0.5625621  0.80407476 0.44390336 0.80219305
 0.50102884 0.50114524 0.51754814 0.5126131  0.48299813 0.60045385
 0.6089148  0.3897015  0.5330306  0.45281872 0.867235   0.58650786
 0.40223417 0.72620136 0.6230813  0.8558008  0.8015337  0.82799435
 0.47739783 0.68069637]
tr_loss:[0.36789203 0.675436   0.5567691  0.4929819  0.3584307  0.616851
 0.6043433  0.5240585  0.5019153  0.50514585 0.4978736  0.38707146
 0.497801   0.3731936  0.5288825  0.4656878  0.53879136 0.78966486
 0.6269391  0.500898   0.47876358 0.31775603 0.61638033 0.36694512
 0.5104141  0.420652   0.5560548  0.531814   0.38671666 0.62730044
 0.37604338 0.47910374 0.59942424 0.4634653  0.6190008  0.35898772
 0.46603775 0.6109525  0.6618858  0.3651074  0.51588285 0.47346163
 0.6597713  0.58317864 0.6656178  0.46639395 0.4438328  0.58412474
 0.57616484 0.46790165]
tr_loss:[0.29321885 0.32968095 0.56449604 0.28919366 0.5288131  0.30180353
 0.651235   0.33278996 0.4754879  0.43286484 0.32844412 0.59908175
 0.29730132 0.33438593 0.28630495 0.51289487 0.4036192  0.3002345
 0.29386044 0.5335263  0.6310373  0.3431211  0.5851437  0.29977438
 0.2957767  0.33142194 0.3701582  0.287703   0.32764858 0.43257537
 0.3710616  0.5852779  0.3253966  0.37283844 0.64597356 0.32287693
 0.2862611  0.43327737 0.35002947 0.6348944  0.5253449  0.7012143
 0.33844924 0.31296363 0.29224926 0.589964   0.43500835 0.30140394
 0.28731048 0.32278228]
tr_loss:[0.71449935 0.5880778  0.6933736  0.18949337 0.4459866  0.46939802
 0.20303154 0.44168782 0.19220617 0.19377334 0.4012928  0.47125274
 0.18106245 0.61991405 0.5603715  0.55829465 0.22035536 0.17671888
 0.591293   0.43025914 0.6095965  0.19433725 0.62060684 0.637292
 0.49538383 0.19396093 0.35084748 0.19044921 0.26709643 0.51962936
 0.18949087 0.5881217  0.1710517  0.4043004  0.8630791  0.17799982
 0.4118193  0.42804545 0.70570964 0.17815185 0.6382735  0.17604141
 0.18373826 0.19763389 0.53379434 0.17677805 0.47263995 0.5236522
 0.25828823 0.17731312]
tr_loss:[0.13916633 0.32260612 0.50013757 0.5417806  0.46305647 0.16409358
 0.14875945 0.45528477 0.12996797 0.6594283  0.48025998 0.59828156
 0.14950517 0.62312114 0.4870572  0.647011   0.5160614  0.6048732
 0.16899717 0.14867021 0.65877086 0.14112243 0.13031335 0.13027108
 0.3685074  0.55891293 0.45471048 0.12656508 0.13013072 0.14394099
 0.68826646 0.6909145  0.5292259  0.17101708 0.4552679  0.15192732
 0.1422656  0.49422294 0.3924145  0.53196084 0.5117749  0.58693725
 0.14683864 0.13522294 0.5451546  0.7151122  0.32236162 0.6026809
 0.13109626 0.56988513]
tr_loss:[0.11487482 0.11453553 0.6051143  0.09659843 0.37090844 0.35572886
 0.09859625 0.60522854 0.13291171 0.6361553  0.13943447 0.12661096
 0.11885627 0.10776961 0.10719321 0.38108978 0.09930574 0.13381569
 0.13726704 0.57889855 0.13841455 0.5707925  0.23897195 0.42668766
 0.12246853 0.68338794 0.4385275  0.5946545  0.58677876 0.40019274
 0.3594207  0.35054043 0.587166   0.6310003  0.48873097 0.10637949
 0.09817787 0.40447235 0.61599857 0.09696858 0.12228967 0.5422236
 0.09828221 0.5023479  0.5159801  0.6342207  0.11167681 0.6199644
 0.11178404 0.72730684]
tr_loss:[0.42935723 0.08241007 0.61653125 0.11041012 0.5333371  0.11830416
 0.08218201 0.0960488  0.2490896  0.5251362  0.24853072 0.5409442
 0.38078967 0.09839571 0.5049497  0.6847989  0.58386743 0.54920816
 0.56313473 0.48486558 0.11511306 0.48216742 0.61701554 0.10574023
 0.60439646 0.6308503  0.5180658  0.09989591 0.48361653 0.555277
 0.12509426 0.1085417  0.11523898 0.34217912 0.51722443 0.3517591
 0.39275545 0.1060461  0.12524465 0.34912404 0.54869545 0.34960327
 0.5769044  0.12799665 0.47906238 0.09912415 0.66866064 0.5980402
 0.12524107 0.34806648]
tr_loss:[0.06223401 0.09596009 0.08013041 0.5767379  0.53204143 0.55671763
 0.69774413 0.4584976  0.71031904 0.08852129 0.43762317 0.09229331
 0.36242405 0.06048224 0.08610314 0.19134691 0.50121295 0.06385877
 0.09595957 0.09753421 0.27491012 0.47914892 0.09429882 0.32815143
 0.08775401 0.38250488 0.0980674  0.6801863  0.4510042  0.09680424
 0.33118513 0.07563375 0.09492838 0.58001673 0.35555965 0.38555145
 0.081834   0.4493517  0.06307949 0.520774   0.46129268 0.4479865
 0.6058308  0.43916112 0.29190508 0.4220987  0.08772503 0.39671826
 0.5976024  0.47291636]
tr_loss:[0.05249103 0.5652251  0.04217107 0.0382944  0.08015645 0.08061253
 0.06602456 0.5534374  0.61755455 0.04155308 0.47782454 0.08537294
 0.46683592 0.04974399 0.05644245 0.49008495 0.45686784 0.06246725
 0.04301214 0.04174755 0.59241176 0.09077624 0.34849426 0.08937991
 0.6011272  0.54050076 0.44683227 0.37604266 0.35178804 0.03997331
 0.04063599 0.0667272  0.64502025 0.04769797 0.5896633  0.5749631
 0.06310467 0.04244932 0.07983132 0.16530052 0.5070218  0.4033014
 0.11026604 0.21076627 0.6206312  0.5028154  0.04134371 0.5374881
 0.42389488 0.04238449]
tr_loss:[0.0416373  0.5091702  0.50416684 0.06091956 0.19279924 0.5655899
 0.03857832 0.06363994 0.49527472 0.49237823 0.0905297  0.25654274
 0.09865127 0.5543686  0.04837622 0.48928833 0.45450455 0.6158246
 0.09956477 0.49852103 0.08474953 0.62174594 0.5715973  0.54222566
 0.43282324 0.3529645  0.03645606 0.0896946  0.51082176 0.5066658
 0.567404   0.09064852 0.28189152 0.7220906  0.43679777 0.03703519
 0.2811407  0.3072685  0.5618578  0.35584694 0.05862338 0.54359424
 0.06873243 0.39114922 0.3091118  0.49640864 0.39772606 0.33232844
 0.36871475 0.058681  ]
tr_loss:[0.48780093 0.06696711 0.4573989  0.09326845 0.37143552 0.0906754
 0.08785786 0.04431728 0.09603465 0.6327064  0.04957796 0.08909634
 0.13733426 0.45635286 0.08673298 0.49901944 0.0468566  0.09536454
 0.05098429 0.03680003 0.545975   0.04052696 0.5561     0.13518569
 0.43812028 0.3373798  0.0417427  0.4815317  0.36843002 0.44057828
 0.3757798  0.1517705  0.09450059 0.42858297 0.4601345  0.45747414
 0.44900355 0.67585385 0.04234366 0.0473181  0.45013374 0.48844394
 0.36250228 0.04122042 0.23315224 0.0868789  0.36114353 0.03846826
 0.04605874 0.49618158]
tr_loss:[0.3180012  0.06827892 0.03959539 0.5495175  0.4490847  0.03916749
 0.43349203 0.0650811  0.49167234 0.03815011 0.57272905 0.04096853
 0.04091441 0.49920493 0.48383266 0.46700057 0.54043067 0.07092541
 0.649557   0.03831315 0.0782341  0.51680005 0.04799324 0.08065094
 0.04016913 0.0809476  0.03863873 0.03459307 0.50720036 0.34058136
 0.32119238 0.64333266 0.05186474 0.03945112 0.53414834 0.08372383
 0.08474939 0.0701928  0.56576455 0.4630457  0.3475044  0.53431064
 0.33953232 0.05179317 0.6357212  0.68078023 0.08413935 0.4179612
 0.03871524 0.08205988]
tr_loss:[0.03944812 0.43277898 0.354364   0.3455424  0.03902632 0.03962861
 0.06688201 0.5120681  0.5101553  0.3448688  0.4501621  0.6417283
 0.03987433 0.03907397 0.06504846 0.07375665 0.40696985 0.03914626
 0.36974987 0.30005446 0.07245173 0.04041279 0.41084662 0.03671776
 0.38344115 0.07391795 0.36594105 0.35026446 0.07147429 0.06664085
 0.22768478 0.5592294  0.55508274 0.074573   0.06764244 0.34882182
 0.04469199 0.3583191  0.6408702  0.06634311 0.28517246 0.07681483
 0.06537743 0.5924417  0.58536136 0.29863396 0.07495964 0.54058254
 0.5641534  0.34666082]
tr_loss:[0.45806885 0.04094125 0.619663   0.06811202 0.546203   0.06797126
 0.4921422  0.44752914 0.377079   0.06814551 0.61219704 0.43512058
 0.48519292 0.40815744 0.04071447 0.23123796 0.07067684 0.04000058
 0.06280501 0.1482366  0.52444965 0.54959786 0.44783133 0.05185263
 0.07109285 0.33087683 0.061478   0.05785703 0.30380067 0.50905263
 0.37231237 0.03982406 0.5242306  0.2951247  0.05008161 0.5282819
 0.04048954 0.4289054  0.5692344  0.06978016 0.36937767 0.32321796
 0.0404207  0.06751688 0.47351283 0.03982943 0.5416495  0.5975443
 0.06865074 0.05886922]
tr_loss:[0.03532304 0.40441972 0.4091634  0.37557337 0.38172856 0.03963486
 0.05596416 0.05773125 0.05887719 0.1900151  0.03875897 0.0629695
 0.3779447  0.03634486 0.05603369 0.36340392 0.06320965 0.04928246
 0.46337444 0.04573693 0.5706581  0.05673056 0.28510195 0.06622866
 0.06175158 0.26205125 0.04433818 0.04236462 0.24738781 0.32309785
 0.29265195 0.4083302  0.04251525 0.33758357 0.19844925 0.08124504
 0.0352336  0.3537882  0.0539929  0.25140777 0.50277466 0.34171748
 0.36660042 0.04544106 0.0629063  0.4166214  0.04383435 0.35287786
 0.06211577 0.26295504]
tr_loss:[0.06112305 0.4120368  0.42882052 0.0344509  0.04394585 0.37910387
 0.40858942 0.04208472 0.03458055 0.29260978 0.03684335 0.21638496
 0.04386968 0.04971366 0.36435473 0.03654464 0.0582472  0.38247487
 0.04395473 0.05488551 0.29526666 0.26827532 0.45305648 0.49178284
 0.5554346  0.04830772 0.31165084 0.04224823 0.37745208 0.3133033
 0.25888714 0.19902603 0.480233   0.35065278 0.05894344 0.35651144
 0.59351003 0.04830172 0.28211427 0.03552029 0.4799367  0.30427903
 0.0404994  0.39560735 0.05040572 0.42338476 0.04894128 0.04876845
 0.04834072 0.2548791 ]
tr_loss:[0.49598044 0.41591597 0.46150747 0.35602197 0.3392499  0.43702778
 0.27153644 0.09122039 0.04481775 0.04015786 0.42875844 0.38689926
 0.2683789  0.03804593 0.04065143 0.04056547 0.04948265 0.54897904
 0.06257287 0.28323275 0.5007469  0.34741083 0.32556742 0.36980233
 0.5111371  0.23724599 0.29281378 0.03629815 0.05546003 0.4449009
 0.50252295 0.35388085 0.0625447  0.04206082 0.35962826 0.29909915
 0.40373087 0.03941481 0.37303147 0.37858048 0.05009461 0.03569918
 0.53711176 0.39032978 0.5068699  0.4316802  0.33303362 0.03999023
 0.24984837 0.36645928]
tr_loss:[0.04984577 0.04175843 0.1573461  0.3833672  0.37544456 0.46591908
 0.039235   0.30206078 0.41379052 0.24176459 0.1495199  0.03795061
 0.4665026  0.04327674 0.0380673  0.44723767 0.04328283 0.04962885
 0.44391555 0.03064756 0.04394475 0.25334683 0.2651934  0.4117073
 0.34645253 0.15615341 0.04608257 0.38950136 0.34342834 0.41624555
 0.29003087 0.03810214 0.06211509 0.03786164 0.34078735 0.0449478
 0.12941441 0.4421483  0.04694687 0.1904844  0.4062849  0.03739662
 0.03246049 0.3128338  0.37023133 0.4332614  0.0600736  0.30111757
 0.3716742  0.25852567]
tr_loss:[0.04575758 0.41892838 0.44091645 0.34709734 0.04651546 0.05469557
 0.30332103 0.363957   0.45045918 0.026026   0.34329778 0.4251124
 0.4987546  0.23996635 0.21862273 0.027306   0.3835774  0.04701768
 0.46255264 0.3650662  0.5009083  0.05421183 0.02699442 0.0240202
 0.0447155  0.22555833 0.02256705 0.31644624 0.3026254  0.4853897
 0.04142468 0.41139135 0.05308707 0.02245521 0.34686792 0.02833444
 0.34798768 0.33661708 0.03853323 0.04630479 0.03421021 0.38388434
 0.29639772 0.04406614 0.05295889 0.38830143 0.22966425 0.03967968
 0.04239022 0.44303852]
tr_loss:[0.3089601  0.28611127 0.04153223 0.22670293 0.37001967 0.36595535
 0.34390402 0.03444258 0.18586966 0.3312237  0.21298723 0.0314239
 0.03869401 0.02226833 0.17897551 0.03844815 0.27294526 0.46753827
 0.04658447 0.2906125  0.03961796 0.03908217 0.04587419 0.03415124
 0.0248064  0.3551361  0.45219415 0.37998244 0.41905466 0.04687325
 0.25351453 0.4341186  0.03978225 0.10551895 0.37329656 0.48110995
 0.32666746 0.03983976 0.02641726 0.0282295  0.30160204 0.3295167
 0.45476198 0.3379206  0.0249777  0.47456774 0.48160726 0.04131817
 0.29427463 0.04281527]
tr_loss:[0.46226215 0.03610144 0.37384492 0.4444171  0.29768997 0.03793535
 0.03397457 0.22568183 0.03978978 0.27678728 0.396285   0.02603772
 0.03922617 0.28893837 0.3236645  0.28070885 0.3152612  0.4179243
 0.3086638  0.37051266 0.30037042 0.39827046 0.03948564 0.25907
 0.03482684 0.35779852 0.35369024 0.03805341 0.49102718 0.17744505
 0.4591461  0.03957815 0.4197002  0.18040745 0.20384474 0.03847927
 0.03940284 0.3098344  0.23413607 0.3604757  0.02632183 0.49237117
 0.03729058 0.03853198 0.02612968 0.37448055 0.2746915  0.02181643
 0.38472152 0.03197145]
tr_loss:[0.02297864 0.02907997 0.32165226 0.23147973 0.02310951 0.3753646
 0.40194002 0.3461972  0.03473649 0.03422065 0.02647566 0.29491588
 0.35715732 0.04718999 0.05364561 0.02427551 0.35787183 0.02451763
 0.35890678 0.03413926 0.28794587 0.03509835 0.03468347 0.03654643
 0.44443375 0.23236075 0.3972662  0.2451622  0.03121285 0.03032977
 0.03480365 0.04022761 0.04092806 0.03463299 0.3640937  0.10657762
 0.33172974 0.03438437 0.03957082 0.02342846 0.40319118 0.37831417
 0.02685642 0.4262113  0.03684655 0.03478726 0.29274386 0.35181108
 0.29330263 0.29161876]
tr_loss:[0.1582413  0.02981271 0.02688907 0.48104078 0.0414838  0.03179176
 0.02510552 0.02768443 0.03687216 0.04365814 0.2636939  0.4775835
 0.43088573 0.02399833 0.2761658  0.39688784 0.03414737 0.38695586
 0.22599924 0.10076074 0.27369323 0.28463927 0.39033276 0.45952353
 0.02551088 0.03417857 0.25400835 0.34869772 0.44571814 0.04321403
 0.4048945  0.03616505 0.37920085 0.18818276 0.43780097 0.24703977
 0.03842661 0.33097187 0.42887133 0.25891927 0.02860971 0.23729208
 0.0246827  0.14324482 0.03107649 0.27663696 0.11661442 0.0248244
 0.36488265 0.50390685]
tr_loss:[0.43751985 0.39179617 0.33304596 0.02258508 0.3894424  0.39281827
 0.04383201 0.02376701 0.35623738 0.23462161 0.02262997 0.33823156
 0.3733817  0.31139326 0.2225235  0.07913659 0.03278344 0.34464312
 0.18702161 0.03161789 0.3035111  0.03452277 0.32827407 0.03241844
 0.27041882 0.22142163 0.30677372 0.2060807  0.31645083 0.29349405
 0.31996232 0.02251652 0.02232471 0.024629   0.34290558 0.32112283
 0.03230618 0.0334314  0.02189362 0.03769785 0.2801926  0.03315907
 0.31722528 0.4774355  0.36129102 0.3612239  0.03197499 0.23034577
 0.29982933 0.32153416]
tr_loss:[0.01986804 0.35786843 0.01993443 0.02935029 0.43841666 0.02010086
 0.2438322  0.29889306 0.2531193  0.18266375 0.01980993 0.02004956
 0.02917172 0.02967618 0.02832097 0.03050927 0.10358932 0.02996207
 0.299455   0.03489258 0.2424831  0.34884173 0.02012237 0.38690004
 0.3253076  0.03716096 0.2770999  0.02934093 0.03492827 0.25182724
 0.20666616 0.2938691  0.1328905  0.37805948 0.13200912 0.02954206
 0.02053507 0.24231084 0.23895895 0.02917573 0.29647774 0.30354157
 0.3014578  0.20103931 0.4392151  0.27768892 0.02915129 0.27768162
 0.02026052 0.03153821]
tr_loss:[0.35892245 0.24975815 0.34565607 0.03018713 0.02770883 0.19726977
 0.01722674 0.01855552 0.26752812 0.0222117  0.32890075 0.14131728
 0.03330745 0.01720617 0.4791193  0.02832289 0.49422273 0.03300423
 0.01858901 0.0329747  0.02875959 0.02753113 0.29444575 0.02737277
 0.3213552  0.01792299 0.36413798 0.39982098 0.3043491  0.17748733
 0.27132162 0.02676852 0.35213232 0.2991209  0.02858326 0.0310469
 0.02758257 0.03709517 0.19897424 0.03319553 0.3104381  0.35095274
 0.02864287 0.02809695 0.02834282 0.40075654 0.19854932 0.41278633
 0.02264277 0.02709635]
tr_loss:[0.2970323  0.25164336 0.25101477 0.359482   0.3486657  0.02789089
 0.31924558 0.02657906 0.28033134 0.03355489 0.02716196 0.323793
 0.01460522 0.2980314  0.284795   0.02945951 0.35819924 0.01476214
 0.34184885 0.33094707 0.01503102 0.01797312 0.22410302 0.39201096
 0.2697223  0.01401378 0.0265885  0.37746304 0.21346533 0.2614562
 0.14939955 0.02764601 0.27833182 0.3587708  0.34437352 0.21534196
 0.28612018 0.36652666 0.02662001 0.3960518  0.26160035 0.02450229
 0.02440857 0.26858598 0.38261205 0.20725241 0.03346054 0.31624258
 0.30142885 0.02684912]
tr_loss:[0.204071   0.01492496 0.31460968 0.02394251 0.03975997 0.29327297
 0.31850666 0.02467509 0.01837866 0.0322713  0.22007379 0.11682118
 0.32663736 0.02645307 0.40599555 0.3584575  0.02479058 0.39246494
 0.03209794 0.35508552 0.03402137 0.30085427 0.31458884 0.4398435
 0.02002291 0.21346541 0.08204801 0.39743605 0.44565946 0.3234136
 0.02206653 0.01407832 0.22935088 0.43128148 0.21559839 0.40078783
 0.01400636 0.44819623 0.03257712 0.01507403 0.27827853 0.01434648
 0.27380556 0.34376934 0.35418358 0.2745697  0.3562916  0.29993692
 0.0273627  0.03272215]
text_input.shape
(700, 14400)
learning_input_tmp.shape
(700, 180, 80)
learning_input.shape
(700, 180, 80)
learning_output_tmp.shape
(700, 80)
learning_output.shape
(700, 80)
Model: "sequential_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_16 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.4850564  0.70629084 0.5466126  0.72923493 0.47966298 0.5296079
 0.8946638  0.80639493 0.47647887 0.81707704 0.75895613 0.8736515
 0.49050942 0.53163624 0.43525428 0.66757214 0.6014056  0.489911
 0.6544449  0.55222094 0.5916841  0.44786492 0.66100156 0.89319146
 0.46259728 0.580966   0.817623   0.88258743 0.67463386 0.8924681
 0.49051982 0.7919427  0.8957016  0.47055236 0.5926627  0.6493929
 0.750082   0.46718234 0.5053465  0.53130585 0.7683883  0.35857964
 0.4625699  0.48155564 0.8187498  0.7069003  0.4289113  0.36631924
 0.51825035 0.6959786 ]
tr_loss:[0.46719852 0.5800913  0.65191317 0.41637745 0.5165647  0.4729907
 0.34440598 0.45919505 0.6156742  0.5820526  0.51815915 0.54007274
 0.45791405 0.5302681  0.4583474  0.72565264 0.5434656  0.52059925
 0.550326   0.483488   0.33575317 0.40474162 0.45514798 0.35970682
 0.5815124  0.44220343 0.45293093 0.5782981  0.3377682  0.33321708
 0.4466083  0.6365741  0.5352734  0.7284667  0.4555691  0.54238546
 0.5253964  0.49841183 0.53754836 0.43811283 0.83403176 0.36546844
 0.4225176  0.45727402 0.5628361  0.6591585  0.39334756 0.53265965
 0.7369281  0.35713258]
tr_loss:[0.45423937 0.33300012 0.54342186 0.2807642  0.33622795 0.44021195
 0.4543476  0.59204733 0.22627239 0.5797038  0.30115062 0.51277125
 0.25923547 0.44361505 0.76364994 0.45539626 0.505386   0.41950172
 0.5795039  0.31912762 0.7631706  0.45576078 0.63154113 0.378944
 0.32187095 0.30672184 0.6197672  0.33477    0.3302282  0.21314082
 0.4385817  0.62795675 0.30683774 0.7262477  0.27965495 0.34825206
 0.663792   0.7336146  0.5871202  0.538894   0.7112149  0.60058177
 0.20516796 0.27896053 0.33016604 0.2032698  0.20658624 0.6369994
 0.37644967 0.6859913 ]
tr_loss:[0.22349735 0.6409073  0.594004   0.25749403 0.2090623  0.35421473
 0.33902547 0.5629374  0.18302485 0.77540195 0.2188851  0.478059
 0.12463582 0.25843555 0.13799131 0.49607104 0.4805254  0.3252057
 0.6788951  0.12484167 0.3903789  0.3495978  0.5698191  0.58320636
 0.21025296 0.18407717 0.45486313 0.510079   0.5117572  0.5180317
 0.22040772 0.13558662 0.6633571  0.5499407  0.33720252 0.14765446
 0.18528442 0.5972821  0.231105   0.5271242  0.22047298 0.4478175
 0.22403212 0.18414523 0.5891391  0.21705198 0.40032476 0.18759009
 0.5351615  0.6983349 ]
tr_loss:[0.38683265 0.5060762  0.15140206 0.13031767 0.59553385 0.12425762
 0.12641117 0.10335648 0.436246   0.35695547 0.6638789  0.32645044
 0.08425518 0.49470663 0.6105238  0.38651818 0.6130503  0.12973936
 0.40133682 0.08613051 0.12195637 0.12159233 0.13798063 0.13183454
 0.6205888  0.1320332  0.51642317 0.12378068 0.5000402  0.13056965
 0.12035508 0.11999909 0.47125268 0.10005672 0.12112391 0.5788337
 0.09821546 0.08878584 0.41163737 0.5928254  0.49208498 0.15000811
 0.49791622 0.41932994 0.67354196 0.31794265 0.08653301 0.37660128
 0.14408539 0.14298755]
tr_loss:[0.11115209 0.68021595 0.08689287 0.11228631 0.7010199  0.4116814
 0.39889225 0.10496306 0.5533942  0.10822713 0.08514015 0.11149178
 0.11891428 0.47153935 0.59765255 0.11544862 0.2920247  0.3469217
 0.0921036  0.08846245 0.08725574 0.08463548 0.53476655 0.08978607
 0.3471858  0.55268335 0.090491   0.25951663 0.5940447  0.6731677
 0.08766179 0.11027069 0.0881547  0.08964398 0.0878417  0.30349
 0.6141571  0.6537183  0.6836803  0.07675803 0.08763205 0.08441162
 0.4724865  0.09007277 0.11347453 0.5789206  0.56570977 0.5721972
 0.5548704  0.4236568 ]
tr_loss:[0.0960926  0.06513112 0.42461124 0.08615611 0.55770856 0.08419696
 0.41210443 0.08194109 0.48729214 0.72386026 0.4140432  0.44824886
 0.06807175 0.53161275 0.6248251  0.07459762 0.7586981  0.42280644
 0.36793256 0.0655028  0.32789403 0.16000107 0.5681547  0.71344143
 0.07373796 0.06882614 0.06723012 0.07230724 0.06674562 0.5115472
 0.65118754 0.35222834 0.0852195  0.4327333  0.3623853  0.07052173
 0.60576475 0.0896562  0.08620224 0.5321783  0.08846051 0.57370436
 0.09224536 0.08623767 0.41334796 0.5981452  0.08640824 0.06787161
 0.08148873 0.5462361 ]
tr_loss:[0.27523148 0.04909446 0.38610712 0.5320237  0.38304722 0.20242438
 0.6716876  0.09041484 0.5188064  0.2815116  0.05776316 0.47810787
 0.41589546 0.5751189  0.7627053  0.48075527 0.09207049 0.5216219
 0.06483729 0.44965935 0.4304617  0.5444773  0.50038517 0.38256532
 0.37390527 0.51867163 0.05982996 0.5147234  0.63754416 0.09172937
 0.67132694 0.28739738 0.48220626 0.10397089 0.06651498 0.05659246
 0.06181341 0.08751132 0.4613592  0.06700379 0.05476826 0.5607934
 0.59586936 0.47177735 0.06365112 0.07386776 0.0476933  0.06436925
 0.58451    0.52773285]
tr_loss:[0.09389021 0.04574658 0.47527605 0.46590084 0.09384189 0.06170939
 0.41172153 0.05209392 0.55985993 0.3081529  0.08986516 0.04296626
 0.61630666 0.0599792  0.48305815 0.04307289 0.06044837 0.08979864
 0.61960554 0.09136862 0.0580355  0.04293109 0.52426946 0.2751871
 0.5433678  0.5262065  0.4704277  0.5637854  0.5265147  0.63561857
 0.4082202  0.47830358 0.35830578 0.58012956 0.4447481  0.09240534
 0.04482123 0.4138445  0.09499614 0.10490177 0.4651347  0.5367447
 0.39019567 0.48568687 0.50635767 0.6299499  0.6423677  0.71208566
 0.3705093  0.09489895]
tr_loss:[0.60599774 0.04724992 0.27603382 0.6033184  0.09485276 0.5156935
 0.34321862 0.08241321 0.05031902 0.44412822 0.04764896 0.45850697
 0.6004708  0.09190918 0.42347288 0.5952145  0.7144184  0.16513489
 0.08207911 0.44658738 0.06297499 0.07616054 0.07507947 0.54956806
 0.5714787  0.06733718 0.6738771  0.5460252  0.43145514 0.5562316
 0.5382506  0.57310057 0.68874055 0.46509776 0.09367617 0.54695475
 0.04826029 0.5059697  0.09534284 0.06704418 0.3335883  0.04863334
 0.09426944 0.09616176 0.04663891 0.05496823 0.5896889  0.04706506
 0.44832325 0.16021597]
tr_loss:[0.3769597  0.35044116 0.5138043  0.2854157  0.09598275 0.28789663
 0.40418786 0.05875212 0.56662345 0.05320647 0.48383084 0.09277216
 0.40266165 0.5242241  0.09443476 0.65276384 0.06453925 0.68290126
 0.32373634 0.07983713 0.06667048 0.46833426 0.5667338  0.5597007
 0.45160943 0.05867839 0.06653264 0.0454345  0.09344523 0.04772104
 0.46769732 0.09378931 0.59401196 0.51727355 0.5092584  0.42488012
 0.04424675 0.5623743  0.33906683 0.34721217 0.45900464 0.5298751
 0.5599559  0.32549793 0.4274748  0.38769618 0.06047095 0.43344584
 0.5069747  0.06218614]
tr_loss:[0.5770892  0.45264953 0.38148618 0.09242801 0.35417098 0.06233816
 0.358218   0.18736072 0.39598584 0.05769688 0.09197401 0.09071239
 0.3432638  0.32141876 0.05828243 0.51402485 0.41337562 0.54256475
 0.04821729 0.6065334  0.43975425 0.09150702 0.4832142  0.05815075
 0.03780302 0.4371891  0.03499392 0.16240826 0.03704165 0.05679097
 0.49054986 0.44401845 0.03428771 0.05903848 0.5702172  0.5045775
 0.06153755 0.32490692 0.06512904 0.03417738 0.05914024 0.03646697
 0.4194731  0.05004426 0.0349488  0.36380363 0.0551683  0.46166706
 0.288248   0.03768561]
tr_loss:[0.08672682 0.08595031 0.04403831 0.04851476 0.4080761  0.31232315
 0.49584597 0.53555244 0.64574015 0.08570056 0.5036281  0.45444164
 0.33899465 0.3933124  0.5677546  0.5916403  0.12397339 0.4093713
 0.02495095 0.028093   0.36193222 0.08553241 0.02717403 0.5946668
 0.08708189 0.4304472  0.08756958 0.04607963 0.46024713 0.08525106
 0.02398189 0.12836272 0.28249463 0.04913013 0.04506613 0.02481066
 0.08756111 0.4165124  0.5333437  0.18475208 0.58945936 0.5551983
 0.46787483 0.5926324  0.5121769  0.08789611 0.5621062  0.33405966
 0.38672152 0.02872554]
tr_loss:[0.03043    0.33081785 0.07900551 0.02974173 0.0283436  0.28346628
 0.08028452 0.5017836  0.5231785  0.43752974 0.08306651 0.37882155
 0.10683306 0.08012863 0.33129844 0.36971933 0.6193943  0.5079482
 0.3056179  0.65151006 0.26071423 0.08383989 0.4467106  0.08063825
 0.02576637 0.45344526 0.0563862  0.53898233 0.3960361  0.54204917
 0.33625323 0.20934474 0.02531161 0.458908   0.11341469 0.04418523
 0.41515762 0.5443557  0.04590488 0.03024399 0.2823268  0.5041046
 0.08360654 0.5368241  0.05265391 0.42511636 0.35418114 0.2963079
 0.02922839 0.5117176 ]
tr_loss:[0.5182601  0.3543077  0.04248726 0.2944414  0.07443764 0.42965937
 0.04591823 0.18471803 0.48018065 0.02912292 0.21284255 0.57928646
 0.20744212 0.37316704 0.02788877 0.05105839 0.38435215 0.29960582
 0.3629715  0.02811803 0.32121533 0.05891498 0.28227732 0.21738324
 0.59037197 0.35931218 0.40295848 0.43238887 0.46723548 0.6295799
 0.04292222 0.37778968 0.34984    0.37617666 0.4392416  0.38379306
 0.07298354 0.3743897  0.26792505 0.41802388 0.03863973 0.04181809
 0.46830267 0.35040376 0.02828641 0.61385643 0.04806448 0.23462024
 0.3403008  0.15794575]
tr_loss:[0.0273067  0.180849   0.02948536 0.0300775  0.03813475 0.54056656
 0.35707858 0.224405   0.3942609  0.05062984 0.3155747  0.36831993
 0.0684973  0.05016149 0.44420975 0.30015436 0.02768888 0.4669705
 0.05407415 0.3081604  0.34159875 0.05629404 0.0302911  0.02967623
 0.33531895 0.14107722 0.32059056 0.02721881 0.04110152 0.05855637
 0.40369788 0.3633341  0.44014144 0.45528907 0.20525494 0.24191305
 0.07280661 0.34418577 0.5067438  0.32379317 0.02858519 0.42647582
 0.5495819  0.55347    0.07030064 0.02984419 0.37871033 0.0354986
 0.07294364 0.04152011]
tr_loss:[0.02423579 0.28576857 0.5457292  0.4884909  0.04778705 0.049683
 0.5738259  0.28087813 0.04235018 0.04426831 0.46276465 0.03290328
 0.02648612 0.35850507 0.2249374  0.38655934 0.35135737 0.06830442
 0.46599334 0.12100367 0.36047593 0.2822906  0.33118692 0.5241857
 0.45536846 0.3608963  0.05343419 0.39639336 0.04950187 0.02268327
 0.3047666  0.02522222 0.04690758 0.45793048 0.06464432 0.23647591
 0.4962573  0.04388103 0.36073345 0.04669128 0.06814741 0.05535903
 0.06716117 0.13125661 0.40657192 0.22122487 0.04953433 0.40971717
 0.4306922  0.20017958]
tr_loss:[0.327802   0.06352123 0.06546183 0.41377306 0.02504644 0.2439493
 0.338406   0.04368732 0.45805663 0.06469812 0.02846354 0.43357936
 0.45927048 0.02885086 0.06689933 0.06611207 0.46301088 0.02875283
 0.02924401 0.2686138  0.3835331  0.22268221 0.08055084 0.0266163
 0.03272582 0.5591514  0.06244508 0.4841577  0.0413929  0.37491027
 0.06459294 0.5473253  0.0261612  0.37921125 0.48181325 0.06703329
 0.42310125 0.29600334 0.3914197  0.05225303 0.33042252 0.03623096
 0.05240481 0.26200595 0.02918828 0.42199928 0.41856915 0.34611878
 0.37192765 0.37396997]
tr_loss:[0.04767424 0.2529851  0.37122336 0.04687127 0.02393083 0.05857714
 0.33772495 0.05436204 0.23831888 0.04342521 0.02381987 0.2190868
 0.27376896 0.14702848 0.05828031 0.30653262 0.315004   0.36305135
 0.05451725 0.35206798 0.4340087  0.3156116  0.05716553 0.13631484
 0.25645086 0.24505734 0.44160932 0.34111887 0.40384072 0.04475435
 0.44370055 0.05463614 0.29677266 0.02498893 0.03410464 0.04913138
 0.44363743 0.29320574 0.36835688 0.45653945 0.02375602 0.02352088
 0.38680202 0.49395967 0.33883128 0.04175071 0.21163729 0.05450087
 0.27838483 0.25264415]
tr_loss:[0.04917211 0.42439312 0.02190032 0.3287272  0.46109563 0.26763573
 0.3563879  0.29730695 0.25190058 0.02099219 0.3308054  0.03857242
 0.32779709 0.39728636 0.02094337 0.04419825 0.2633016  0.33569247
 0.05171771 0.02050094 0.36144245 0.02027937 0.02124419 0.31043667
 0.04580846 0.04908669 0.37431413 0.04461683 0.35750157 0.052396
 0.38592303 0.5027982  0.03685725 0.28708255 0.40096617 0.24725318
 0.05005072 0.27823773 0.0422309  0.32756865 0.05242003 0.20937428
 0.05134315 0.4131236  0.05385514 0.44399223 0.2322968  0.1057776
 0.37116843 0.34295076]
tr_loss:[0.02082865 0.04891069 0.31268087 0.0473549  0.23822327 0.02880063
 0.44448695 0.04773303 0.04810087 0.04665496 0.20490618 0.22461545
 0.506254   0.02130681 0.04453179 0.04699848 0.04450868 0.03724713
 0.0209705  0.02140384 0.04523296 0.4198429  0.02049677 0.04627173
 0.2591553  0.26992202 0.0360386  0.51756656 0.04815768 0.04491495
 0.2619614  0.35216704 0.42651194 0.02325317 0.35464478 0.45946503
 0.31402296 0.02876215 0.40437812 0.34271905 0.03716962 0.04737055
 0.22691333 0.04503835 0.47318769 0.02109387 0.04612971 0.1637675
 0.34469572 0.37743026]
tr_loss:[0.46077156 0.3408671  0.0411294  0.5206099  0.02238575 0.2861762
 0.45416626 0.04178082 0.27817187 0.02363383 0.3524956  0.33717495
 0.37128627 0.2856852  0.04670339 0.04749636 0.34769887 0.23838846
 0.04118068 0.04196082 0.04326844 0.38732234 0.02243212 0.34804448
 0.0234539  0.02604404 0.417904   0.2647919  0.34249672 0.21817318
 0.28240532 0.04362268 0.37505254 0.2546846  0.48024994 0.279325
 0.02527599 0.04286479 0.04043242 0.04707905 0.34548125 0.40265426
 0.48611158 0.03913683 0.03954279 0.04868813 0.03035923 0.27938977
 0.03634701 0.4082405 ]
tr_loss:[0.24375704 0.43701243 0.49632406 0.20147559 0.04301263 0.02997981
 0.37442607 0.26763332 0.09754314 0.24009168 0.0378165  0.02132809
 0.02962197 0.02680375 0.24922805 0.03139963 0.35665312 0.03812753
 0.31031886 0.3149172  0.30192834 0.30845717 0.03909489 0.3745748
 0.27076596 0.02060151 0.266396   0.07511319 0.3990415  0.43045893
 0.3927659  0.4476726  0.35775703 0.16722313 0.04121789 0.25706732
 0.31223178 0.03909544 0.0366989  0.2624978  0.3251326  0.45563856
 0.3520177  0.42483583 0.42526823 0.30623585 0.37457138 0.19115436
 0.44817844 0.42652878]
tr_loss:[0.2689299  0.28151736 0.2704247  0.39900258 0.3048378  0.4195486
 0.01954986 0.40526086 0.40127164 0.2745809  0.02132918 0.25364235
 0.33592337 0.02204556 0.33130115 0.21978179 0.01971812 0.03999708
 0.32097027 0.34346145 0.18266036 0.32331032 0.36673975 0.03784958
 0.2008713  0.02398761 0.02761944 0.11647384 0.334735   0.01954088
 0.23164979 0.42046037 0.3427558  0.31661987 0.35290915 0.13197108
 0.02168965 0.04440471 0.22091103 0.0274564  0.38013297 0.04592156
 0.02136738 0.4259438  0.04262399 0.3850285  0.1998192  0.04820354
 0.03626923 0.02704272]
tr_loss:[0.3040246  0.3074205  0.2705249  0.03717885 0.02177635 0.02776589
 0.03080496 0.03779968 0.0187034  0.01815923 0.07833557 0.03729966
 0.35204068 0.02366369 0.03754869 0.44160882 0.01895372 0.03863351
 0.2987957  0.02775161 0.26487738 0.24250436 0.01875404 0.24606462
 0.18432708 0.03763207 0.26077253 0.019668   0.02377324 0.17326811
 0.20751922 0.34239292 0.35921568 0.15500912 0.11964054 0.03531431
 0.01988399 0.02972537 0.04543314 0.02433227 0.266845   0.31267887
 0.262731   0.41541392 0.20605361 0.03165757 0.26846212 0.22735712
 0.04163614 0.4190188 ]
tr_loss:[0.02714863 0.02109018 0.3327558  0.03607054 0.03473699 0.02958792
 0.37277836 0.03444963 0.03153839 0.02911107 0.38124728 0.13656536
 0.36157602 0.01672716 0.02021227 0.25489795 0.22611503 0.0324662
 0.36345777 0.34914586 0.33966464 0.01570253 0.20552988 0.01625272
 0.01555567 0.35990936 0.3745969  0.03450617 0.01577071 0.0351267
 0.42024535 0.01663621 0.03476251 0.01669337 0.24262325 0.42986664
 0.50187385 0.39350814 0.10002991 0.37315243 0.0312505  0.3932816
 0.01635149 0.23585348 0.32390338 0.0311346  0.21235831 0.277008
 0.0223742  0.01838368]
tr_loss:[0.03289009 0.34460527 0.02921364 0.01281461 0.02297965 0.29088458
 0.4200329  0.32758516 0.22838327 0.38141197 0.24495998 0.02176314
 0.47146788 0.19505689 0.35959324 0.38035488 0.40753645 0.30494037
 0.34809902 0.03617178 0.384283   0.31101432 0.4014241  0.13455816
 0.03209825 0.25193858 0.19084339 0.2154398  0.02508644 0.3466348
 0.3918763  0.02343863 0.3644579  0.01343744 0.02337412 0.45436877
 0.01532157 0.42719203 0.3108127  0.01402596 0.31992754 0.0303915
 0.02288474 0.3759772  0.38337332 0.35783955 0.02999752 0.24086313
 0.3098279  0.03018168]
tr_loss:[0.40885526 0.02762227 0.3410831  0.37280315 0.02877164 0.02353463
 0.32179028 0.02826377 0.34512007 0.3040854  0.38598832 0.335295
 0.03285635 0.35048026 0.41201383 0.02898316 0.3821965  0.38335198
 0.22886257 0.02646155 0.36312813 0.02912768 0.18897355 0.02751912
 0.03061699 0.31563288 0.32687742 0.30383658 0.3537771  0.02831184
 0.3700163  0.02314534 0.28775793 0.3442009  0.02671296 0.01899171
 0.4271926  0.03116562 0.03375756 0.3838324  0.01201316 0.21839842
 0.28732294 0.324383   0.2501238  0.03329593 0.02839043 0.0250175
 0.24391904 0.03679337]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 700 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(701, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 701 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(702, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 702 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(703, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 703 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(704, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 704 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(705, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 705 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(706, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 706 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(707, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 707 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(708, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 708 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(709, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 709 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(710, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 710 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(711, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 711 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(712, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 712 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(713, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 713 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(714, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 714 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(715, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 715 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(716, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 716 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(717, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 717 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(718, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 718 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(719, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 719 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(720, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 720 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(721, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 721 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(722, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 722 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(723, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 723 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(724, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 724 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(725, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 725 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(726, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 726 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(727, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 727 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(728, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 728 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(729, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 729 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(730, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 730 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(731, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 731 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(732, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 732 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(733, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 733 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(734, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 734 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(735, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 735 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(736, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 736 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(737, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 737 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(738, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 738 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(739, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 739 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(740, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 740 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(741, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 741 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(742, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 742 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(743, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 743 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(744, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 744 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(745, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 745 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(746, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 746 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(747, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 747 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(748, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 748 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(749, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 749 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(750, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 750 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(751, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 751 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(752, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 752 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(753, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 753 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(754, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 754 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(755, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 755 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(756, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 756 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(757, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 757 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(758, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 758 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(759, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 759 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(760, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 760 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(761, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 761 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(762, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 762 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(763, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 763 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(764, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 764 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(765, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 765 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(766, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 766 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(767, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 767 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(768, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 768 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(769, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 769 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(770, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 770 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(771, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 771 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(772, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 772 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(773, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 773 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(774, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 774 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(775, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 775 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(776, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 776 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(777, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 777 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(778, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 778 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(779, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 779 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(780, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 780 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(781, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 781 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(782, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 782 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(783, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 783 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(784, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 784 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(785, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 785 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(786, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 786 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(787, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 787 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(788, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 788 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(789, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 789 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(790, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 790 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(791, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 791 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(792, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 792 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(793, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 793 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(794, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 794 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(795, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 795 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(796, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 796 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(797, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 797 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(798, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 798 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(799, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 799 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(800, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-700
text_input.shape
(800, 14400)
learning_input_tmp.shape
(800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(800, 80)
learning_output.shape
(750, 80)
Model: "sequential_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_17 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.71784675 0.5187365  0.79419345 0.72121876 0.6395196  0.729298
 0.6560067  0.5700556  0.7457919  0.56071466 0.3043607  0.49971128
 0.7901491  0.46967596 0.78658974 0.62234986 0.7291405  0.7273224
 0.6672536  0.7178809  0.5141742  0.69874823 0.43396863 0.74367684
 0.60806763 0.79234725 0.5744958  0.4663349  0.69226635 0.62304544
 0.7243753  0.814415   0.4975891  0.58250076 0.7587833  0.6438569
 0.3922813  0.6642362  0.39062914 0.7902106  0.6431719  0.7617978
 0.61418355 0.5120234  0.516891   0.7779853  0.5235871  0.53839624
 0.5538894  0.80449736]
tr_loss:[0.5416365  0.5151907  0.5752842  0.7546301  0.37595534 0.41082364
 0.6180692  0.5404748  0.575359   0.64597195 0.52288735 0.5903257
 0.35977325 0.35750246 0.50190544 0.5574557  0.5240335  0.5710009
 0.3909237  0.3589623  0.50413465 0.44373688 0.5753536  0.50980914
 0.68847835 0.51993656 0.5245417  0.3423557  0.5214734  0.5102403
 0.5556444  0.51265925 0.4955329  0.61611634 0.37066302 0.56253034
 0.50933915 0.57590413 0.5629727  0.41320878 0.36956343 0.3365298
 0.61909974 0.55409974 0.6416019  0.42004928 0.35784915 0.43940789
 0.5012936  0.60246783]
tr_loss:[0.5480839  0.66986257 0.43773547 0.51524085 0.40627462 0.40240473
 0.33253235 0.39870137 0.61236835 0.52132565 0.44170752 0.5100709
 0.8131831  0.58175373 0.43345395 0.4486839  0.61922413 0.3137749
 0.42959    0.405612   0.41399574 0.40486556 0.51009214 0.29682922
 0.4394799  0.4659342  0.29031038 0.29878867 0.40462646 0.6549462
 0.5360297  0.2778267  0.46280822 0.55535924 0.81973064 0.4095164
 0.40332532 0.33841348 0.43586993 0.46538335 0.37457246 0.47773057
 0.48158902 0.34258622 0.5314132  0.48231918 0.39877856 0.2819574
 0.39341047 0.58846974]
tr_loss:[0.52399164 0.58825666 0.23081121 0.21311712 0.20865016 0.5736205
 0.29880875 0.2876503  0.48618802 0.23412618 0.3069026  0.24265437
 0.23331055 0.20981634 0.46937665 0.30184335 0.5208383  0.3025721
 0.43988952 0.2775932  0.23332667 0.23335603 0.3025275  0.2965363
 0.63625973 0.48943463 0.29675427 0.29766148 0.23419385 0.22155066
 0.39456114 0.2526067  0.30736825 0.2960458  0.6654309  0.22422838
 0.23467517 0.5490527  0.68403804 0.30592537 0.21008945 0.21731368
 0.23171356 0.28067714 0.5846655  0.29829878 0.64143664 0.4465762
 0.70337135 0.23613659]
tr_loss:[0.18403119 0.5728866  0.21582916 0.18820432 0.53419906 0.19406906
 0.23324683 0.6718781  0.18247679 0.5259242  0.22400627 0.2145547
 0.2162447  0.20529687 0.46601287 0.18065858 0.2214509  0.5627591
 0.48320955 0.19541338 0.19301362 0.44965482 0.40849385 0.44277516
 0.1924508  0.18166304 0.41614407 0.1885432  0.19926548 0.22013958
 0.375078   0.2175184  0.1807327  0.2364312  0.22822046 0.18123972
 0.20514087 0.31635466 0.18761927 0.46861047 0.18891421 0.20565537
 0.4737135  0.6745687  0.19393714 0.18498604 0.21989839 0.35097623
 0.68410015 0.46714228]
tr_loss:[0.14427826 0.14188647 0.16394532 0.33594722 0.47584534 0.17539369
 0.6035411  0.4238122  0.16431603 0.13904245 0.5872525  0.37562287
 0.1560597  0.16170782 0.51044387 0.14063093 0.14866018 0.18864462
 0.5415267  0.16326205 0.39818114 0.6349403  0.13803227 0.54810286
 0.52309126 0.4816954  0.14846578 0.38360047 0.14914672 0.30399328
 0.66286707 0.15101418 0.4224659  0.4508236  0.13643551 0.50989664
 0.1720753  0.15800473 0.46871275 0.17650393 0.5955732  0.17564143
 0.46886247 0.1599118  0.37834397 0.14809181 0.47548047 0.68546176
 0.1410885  0.17228715]
tr_loss:[0.43792638 0.12662593 0.4435831  0.13286115 0.4309705  0.42618933
 0.45178366 0.16726442 0.12489025 0.69295675 0.12682721 0.13180177
 0.12295158 0.33970052 0.13586895 0.60156    0.10144262 0.13613743
 0.49279767 0.72770894 0.52684075 0.2825448  0.5959757  0.32418838
 0.60280645 0.13439201 0.42251387 0.11094487 0.11924847 0.10205963
 0.5698718  0.13004713 0.47052926 0.10255597 0.4721281  0.6223879
 0.13771872 0.46387154 0.13795166 0.10404352 0.13311343 0.5807404
 0.38564342 0.34032255 0.5887948  0.4344488  0.14471073 0.11093505
 0.40750012 0.12751016]
tr_loss:[0.1122872  0.11205951 0.10506842 0.30165443 0.36324278 0.12310103
 0.49888164 0.35937563 0.38793737 0.10804056 0.6488081  0.43981534
 0.10091479 0.5255435  0.10840075 0.38479057 0.08841568 0.43629226
 0.12488586 0.4165636  0.09909671 0.14096388 0.40701675 0.2471128
 0.5989543  0.09122816 0.09095338 0.55982304 0.10913177 0.53853637
 0.479364   0.6471776  0.32561067 0.40780193 0.11893287 0.08805665
 0.52338445 0.53606933 0.09000225 0.12367193 0.11765336 0.0911317
 0.53360736 0.10468278 0.4378918  0.10792367 0.0990961  0.11872859
 0.557251   0.42376965]
tr_loss:[0.0910687  0.11613087 0.4627894  0.11246596 0.53690374 0.5093371
 0.08991295 0.08959746 0.08252013 0.6479529  0.5276462  0.08433242
 0.16209705 0.08794843 0.0856997  0.08343439 0.4069832  0.42621413
 0.10640068 0.49416733 0.09799372 0.44053292 0.3213557  0.10587543
 0.08157289 0.09004377 0.09161685 0.20340732 0.42075634 0.59041435
 0.08363199 0.10545976 0.38914445 0.54139423 0.45120662 0.08938458
 0.11254878 0.38448185 0.11585417 0.5488137  0.0953465  0.58209336
 0.08192226 0.08947198 0.08340118 0.10416685 0.10160477 0.20916295
 0.46473303 0.10515281]
tr_loss:[0.06541616 0.45454723 0.10821922 0.49613577 0.52224576 0.506812
 0.4331459  0.07722944 0.49468604 0.37392336 0.10657599 0.07114683
 0.07335196 0.10645306 0.07683362 0.08415224 0.07760533 0.08813892
 0.5086382  0.48400623 0.06460054 0.06342886 0.52797335 0.28666574
 0.42500123 0.109728   0.423565   0.32439643 0.06305976 0.65782356
 0.56215805 0.07434414 0.53063136 0.09778198 0.09857941 0.08206158
 0.10571325 0.42377815 0.5068639  0.44785166 0.10564401 0.33160067
 0.10637446 0.6289536  0.09795769 0.45170555 0.41302568 0.46836844
 0.36809406 0.09209621]
tr_loss:[0.27043155 0.4356541  0.07206305 0.6288996  0.38871783 0.5349803
 0.46240917 0.34478799 0.06472732 0.5382667  0.05821748 0.37211967
 0.05351125 0.09271567 0.06960773 0.40538675 0.10667096 0.52887595
 0.44889784 0.05491688 0.4920774  0.0856701  0.47060642 0.08795836
 0.10174213 0.5845766  0.6368658  0.0603848  0.42931923 0.10261586
 0.45191592 0.6143016  0.3003275  0.0679358  0.08784316 0.5960451
 0.36613804 0.44284153 0.12052315 0.08958305 0.06447518 0.05108981
 0.08820765 0.20455325 0.06055889 0.08751698 0.6768578  0.62619203
 0.10363797 0.5456796 ]
tr_loss:[0.09988388 0.08453701 0.44468507 0.06327602 0.46507472 0.07985006
 0.5578559  0.08394951 0.43554965 0.07905412 0.56949794 0.5349932
 0.43938693 0.05473746 0.04325392 0.05030927 0.4255177  0.07383449
 0.64251435 0.4684109  0.06982572 0.4622069  0.41397494 0.46549577
 0.4308493  0.06068573 0.04825937 0.04466164 0.40517077 0.10095215
 0.10335406 0.07659639 0.4287179  0.54031336 0.17408943 0.10267866
 0.05519302 0.4697585  0.04878709 0.0505457  0.07638553 0.4644931
 0.08335947 0.10284241 0.10416012 0.43288922 0.5287237  0.39260966
 0.07658643 0.05019135]
tr_loss:[0.1121463  0.45860642 0.45008445 0.0518995  0.43432826 0.48605418
 0.5115765  0.05544608 0.41575432 0.62817395 0.37687835 0.4740056
 0.46754608 0.45707655 0.04397677 0.3441514  0.47425526 0.27748093
 0.08739255 0.6034233  0.08056978 0.5653006  0.06307419 0.04825082
 0.04000618 0.07418551 0.33998156 0.3223261  0.0452336  0.27860704
 0.65211976 0.04775111 0.6492475  0.0394884  0.1006787  0.03932243
 0.06290083 0.508289   0.20820153 0.04479487 0.09627019 0.30994081
 0.05500744 0.07989516 0.55016696 0.48622078 0.5392459  0.3099286
 0.03975655 0.53859663]
tr_loss:[0.24163136 0.09667595 0.3323618  0.4633499  0.05717057 0.5440691
 0.34437045 0.28257522 0.05618651 0.3380304  0.09885912 0.60735863
 0.5433091  0.0998721  0.5194885  0.42760068 0.06668888 0.07154379
 0.59166735 0.6401877  0.08861507 0.57590944 0.38515753 0.06811382
 0.04234736 0.05391031 0.10078301 0.4103667  0.7376756  0.52879775
 0.4798886  0.5481213  0.41049546 0.46958295 0.05509151 0.31451735
 0.09663747 0.49435225 0.09875015 0.08553793 0.06645747 0.17792042
 0.08957165 0.3136379  0.40474406 0.0614704  0.6489404  0.07911756
 0.44969282 0.6659381 ]
tr_loss:[0.06656119 0.47569865 0.45581397 0.4274539  0.06125788 0.16862808
 0.06564602 0.08400764 0.05748811 0.44586578 0.4242161  0.48093826
 0.06037655 0.17418823 0.07149248 0.7631179  0.45215106 0.05599491
 0.04191366 0.05331761 0.5294326  0.48083812 0.5399819  0.4513393
 0.26590133 0.0961701  0.08347305 0.09674901 0.05840433 0.05462646
 0.06448235 0.06510887 0.60858226 0.505686   0.09729324 0.05811192
 0.63363373 0.06062134 0.05886557 0.06111331 0.40034324 0.386382
 0.0971416  0.04442076 0.05825995 0.44143423 0.08546978 0.05350382
 0.06077502 0.06564626]
tr_loss:[0.42600384 0.11054518 0.10407235 0.08998314 0.0677809  0.41874152
 0.06720243 0.05715631 0.2880331  0.42576534 0.42004046 0.0948806
 0.09295841 0.45947522 0.06003461 0.04337449 0.621095   0.3715734
 0.04469224 0.07231434 0.05391721 0.3431322  0.05169694 0.09815396
 0.22489348 0.05667763 0.05438547 0.35051256 0.4028945  0.4178686
 0.08360701 0.04394932 0.44141516 0.05682883 0.40668947 0.33675402
 0.41736203 0.05628385 0.335329   0.4295661  0.04397282 0.19361597
 0.06828286 0.45219478 0.05270857 0.38554022 0.28419536 0.08470052
 0.08560748 0.04509938]
tr_loss:[0.16005656 0.07635258 0.0852505  0.06561403 0.37449372 0.0723011
 0.49024767 0.434375   0.05635771 0.41427675 0.10319712 0.45868737
 0.3673624  0.05369445 0.37894392 0.05555098 0.08734337 0.44732594
 0.357469   0.29605097 0.3894933  0.55480105 0.3939043  0.08322328
 0.34856337 0.04305122 0.40618086 0.05234967 0.40432233 0.43201542
 0.49536887 0.4313426  0.45299396 0.08848216 0.49463835 0.05811488
 0.05189275 0.42700797 0.31865597 0.08800428 0.48922348 0.05381263
 0.40462437 0.05374108 0.07014407 0.30313367 0.4848259  0.05932164
 0.45411405 0.0845507 ]
tr_loss:[0.04681963 0.26731586 0.42905912 0.50956964 0.20233378 0.5519941
 0.08183716 0.37855548 0.51763767 0.58870506 0.54860955 0.08265401
 0.23233113 0.051233   0.07980372 0.3564833  0.08207745 0.04056162
 0.04767019 0.38584277 0.0475117  0.39847    0.05506293 0.08128307
 0.4732255  0.04270399 0.43315634 0.06466164 0.43248233 0.34430307
 0.3859002  0.29901314 0.49355155 0.04325435 0.05095775 0.26238889
 0.42205605 0.24374855 0.04862009 0.3273174  0.34830636 0.04690461
 0.04940535 0.44892138 0.46764207 0.0435482  0.04893631 0.04203219
 0.04001565 0.25124198]
tr_loss:[0.0671014  0.05078082 0.32740122 0.4245851  0.07435103 0.04642274
 0.03866566 0.05109341 0.05077279 0.062346   0.14145991 0.42674488
 0.2943093  0.0432838  0.05617357 0.06524827 0.4677024  0.03458583
 0.07625669 0.04531467 0.39812446 0.05994706 0.05806143 0.07439576
 0.6795088  0.03807809 0.07668628 0.18126278 0.26972547 0.05942308
 0.07329764 0.04615611 0.05077972 0.3246429  0.0627911  0.40361342
 0.05880566 0.48646665 0.22949469 0.35662112 0.13364354 0.37673247
 0.271386   0.30029756 0.04349678 0.4393506  0.05102435 0.46671015
 0.23785129 0.3393777 ]
tr_loss:[0.0402863  0.38787246 0.27654642 0.38425642 0.03810924 0.04581922
 0.03725915 0.06061913 0.38385487 0.05011514 0.36922714 0.40864676
 0.0762717  0.38317207 0.03980475 0.39300027 0.05533806 0.04006333
 0.2812291  0.27278265 0.5417207  0.1610296  0.04333758 0.04040215
 0.384664   0.03730277 0.14892443 0.52653474 0.5375177  0.3025891
 0.03926649 0.14236295 0.06747636 0.48311502 0.3104713  0.39165485
 0.06929158 0.03744721 0.34957135 0.4280901  0.51765835 0.04443486
 0.04014953 0.03757159 0.4257161  0.02792399 0.39176348 0.0531692
 0.37674552 0.3616668 ]
tr_loss:[0.43077707 0.44877544 0.04525094 0.38628808 0.07041142 0.03571532
 0.27015895 0.44048434 0.03575521 0.0305265  0.02894797 0.05619725
 0.03902334 0.24909827 0.37981683 0.2897103  0.02849545 0.34849063
 0.35802427 0.37082377 0.06375031 0.06376809 0.05787893 0.22361584
 0.02964903 0.4184739  0.03011942 0.14647833 0.0347443  0.03661748
 0.3143263  0.02817737 0.11986406 0.4002347  0.06903979 0.03429896
 0.45827323 0.02917266 0.3463291  0.49879837 0.04351413 0.06868345
 0.04489525 0.3831733  0.0309078  0.05488191 0.05893362 0.3954063
 0.06837075 0.2375836 ]
tr_loss:[0.30963105 0.0338062  0.45013857 0.03155188 0.06231606 0.02342412
 0.06216174 0.05808088 0.52624816 0.04452779 0.03392506 0.49726957
 0.4697818  0.2598176  0.03428676 0.0253156  0.03470472 0.06145216
 0.0630772  0.30766025 0.0636692  0.41927558 0.3102738  0.3001361
 0.02445984 0.02162779 0.24356008 0.09636866 0.22233292 0.02310614
 0.17104514 0.40974814 0.0344284  0.04175464 0.4072283  0.44666338
 0.03316637 0.465899   0.03347079 0.04139683 0.05449759 0.31295413
 0.04889037 0.03418415 0.31604356 0.21445446 0.05362501 0.29802328
 0.05139518 0.05363441]
tr_loss:[0.02107693 0.04733679 0.42152977 0.45430145 0.03130241 0.0549639
 0.27058235 0.12131504 0.02000935 0.01979648 0.04620948 0.4433292
 0.05356266 0.05538839 0.02876625 0.0229777  0.29776692 0.51194686
 0.03837501 0.0560225  0.05518428 0.0284695  0.5477554  0.05325974
 0.04761813 0.36648917 0.01850899 0.3601997  0.40258756 0.30466932
 0.3282787  0.3786867  0.4265132  0.02868904 0.05313182 0.45996347
 0.04357326 0.5306624  0.4678358  0.04598319 0.527279   0.22752824
 0.45174375 0.05279226 0.02234039 0.28864795 0.28365308 0.0288721
 0.03239747 0.32602948]
tr_loss:[0.05411255 0.05286171 0.05455092 0.3569259  0.02018248 0.45055428
 0.03034528 0.03105684 0.02437325 0.13566877 0.05298467 0.027674
 0.02695589 0.34846145 0.03076878 0.05166198 0.28860578 0.04035906
 0.05304557 0.32564265 0.03184491 0.02989692 0.31076345 0.36107865
 0.02974328 0.42177352 0.02670244 0.03230753 0.37841615 0.02997855
 0.31346384 0.02462306 0.22470012 0.44816995 0.2811311  0.04063549
 0.28290352 0.40876684 0.0422131  0.3335106  0.05141364 0.3101973
 0.01925688 0.03140511 0.3225022  0.04551197 0.05286528 0.3040623
 0.05161972 0.22757068]
tr_loss:[0.4118957  0.04327513 0.0485841  0.36673728 0.04462006 0.0209016
 0.46192488 0.04450681 0.33957332 0.0454201  0.02121718 0.05559854
 0.03778519 0.43947124 0.05423362 0.02599726 0.55297005 0.2600905
 0.42258888 0.04397542 0.03779418 0.38826126 0.30965716 0.37434635
 0.05304793 0.05436577 0.02162212 0.02402995 0.02136176 0.2047199
 0.26770768 0.05663966 0.439492   0.38097873 0.4812997  0.3597505
 0.05169255 0.34044057 0.31396347 0.03385621 0.05189551 0.0502787
 0.47557935 0.30187377 0.03732378 0.4771022  0.04647617 0.32260457
 0.23126307 0.04352624]
tr_loss:[0.28690895 0.22638783 0.39738694 0.0263808  0.05769617 0.31410286
 0.02608818 0.02905959 0.16579647 0.37318364 0.04986016 0.05282766
 0.03073739 0.40327635 0.09356628 0.28468508 0.0235775  0.40947518
 0.03089065 0.0407143  0.03901414 0.05465434 0.02611554 0.05263165
 0.27249786 0.02206343 0.03041259 0.07762881 0.4062541  0.05065785
 0.02716637 0.11280467 0.05224656 0.05559234 0.03391304 0.0543352
 0.03513826 0.03424739 0.39494097 0.36165753 0.0267338  0.03345094
 0.02533798 0.3191632  0.0370867  0.36381873 0.26667085 0.05612519
 0.34105057 0.39271626]
tr_loss:[0.3438639  0.42885858 0.03651392 0.02049352 0.30904645 0.24025588
 0.28782454 0.23641166 0.2933673  0.25567254 0.02021531 0.04842148
 0.02879471 0.03439008 0.35972166 0.02593486 0.3558017  0.32193694
 0.26783928 0.04865611 0.33552855 0.05333124 0.4726581  0.05006403
 0.04967533 0.55495226 0.26524323 0.04843395 0.02010464 0.02008108
 0.36766243 0.3326512  0.04629911 0.0253484  0.40885472 0.02573668
 0.3934104  0.40435806 0.26030594 0.05158772 0.0496124  0.46745506
 0.04185987 0.02941642 0.05081408 0.03451596 0.16866156 0.04143868
 0.03028214 0.44018817]
tr_loss:[0.25867712 0.53869265 0.27691847 0.0290015  0.38053924 0.30758983
 0.02975159 0.04777729 0.3264776  0.03653261 0.20737644 0.4037363
 0.5778835  0.4861618  0.04735851 0.02580388 0.46290198 0.04723329
 0.2905762  0.3074105  0.23233378 0.03091504 0.046847   0.4036304
 0.22793922 0.04706762 0.05013495 0.02572451 0.03221096 0.04085821
 0.26487187 0.04930249 0.01880363 0.23592623 0.02463008 0.18752773
 0.04694883 0.45926046 0.04133245 0.0486489  0.26698145 0.3274545
 0.04801241 0.01802707 0.02183378 0.02604233 0.4642271  0.04777714
 0.04774472 0.04360654]
tr_loss:[0.41489044 0.02783298 0.04105471 0.4151078  0.03029438 0.37341696
 0.3125024  0.03266441 0.05131479 0.043737   0.04263028 0.23457853
 0.02088698 0.01758494 0.04106151 0.392204   0.04843353 0.2848081
 0.39215928 0.01804911 0.02437331 0.03827024 0.39964962 0.22625366
 0.03643438 0.03973597 0.02855803 0.15989904 0.3032085  0.32836825
 0.02451365 0.4167137  0.32145196 0.04562102 0.30759913 0.34699216
 0.4156881  0.2917982  0.01750809 0.34021506 0.03954643 0.28446704
 0.04020727 0.04366932 0.27815926 0.3592053  0.21853456 0.3119996
 0.02497341 0.04209065]
tr_loss:[0.3246072  0.03291456 0.0179589  0.02738003 0.29720408 0.38127804
 0.32702225 0.01896446 0.26588184 0.02062581 0.41384292 0.04361108
 0.49689427 0.34703517 0.24324691 0.3173822  0.04981642 0.03652
 0.30193225 0.0908995  0.03946244 0.3207191  0.36727238 0.03996659
 0.03930518 0.02385841 0.01894457 0.02461161 0.0423619  0.38518184
 0.03709621 0.05190804 0.20670727 0.04904389 0.28911915 0.02839102
 0.20137756 0.25377485 0.30357766 0.27772993 0.02374816 0.04101488
 0.33265448 0.03945661 0.3919749  0.04000086 0.01881596 0.28931302
 0.17308328 0.2677886 ]
text_input.shape
(800, 14400)
learning_input_tmp.shape
(800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(800, 80)
learning_output.shape
(750, 80)
Model: "sequential_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_18 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.44203654 0.6369179  0.44001406 0.42989525 0.6355857  0.6414502
 0.5084239  0.6720735  0.4404695  0.6439459  0.6723512  0.66138494
 0.5230117  0.45332956 0.67313933 0.41812572 0.6541767  0.4302779
 0.42815614 0.40729737 0.70655864 0.3651587  0.6752136  0.5338456
 0.46791467 0.5925967  0.6411166  0.64885515 0.64727515 0.7088006
 0.6417739  0.6833585  0.64643186 0.56049824 0.39599594 0.6191119
 0.60039186 0.61158574 0.6483256  0.6067565  0.6477151  0.6096549
 0.6620697  0.5654357  0.64833176 0.7061669  0.6293818  0.7020543
 0.39504766 0.51836425]
tr_loss:[0.50096446 0.7662128  0.2811605  0.37317523 0.45870084 0.4553896
 0.45787388 0.299541   0.5034696  0.6234918  0.40518245 0.45324078
 0.3060083  0.48515025 0.72222203 0.39136186 0.40475744 0.5440516
 0.43330544 0.31206626 0.40637523 0.6311886  0.28166872 0.3088437
 0.29678234 0.577041   0.37187248 0.45150933 0.38441908 0.4510162
 0.40350017 0.40762272 0.38205367 0.45343655 0.6313627  0.639158
 0.4037388  0.5876309  0.37196308 0.30841064 0.4030603  0.37977064
 0.54286444 0.53577757 0.3809144  0.60842144 0.4470048  0.652119
 0.62618864 0.4377663 ]
tr_loss:[0.25997585 0.51140994 0.32534617 0.44539747 0.21696374 0.3304652
 0.297855   0.4646411  0.52699673 0.44849643 0.6213265  0.5800766
 0.46577802 0.27084994 0.29670018 0.29401094 0.7589946  0.54838353
 0.49812078 0.21896358 0.26499182 0.36150664 0.27406716 0.72410583
 0.28167763 0.5473581  0.21024796 0.32742602 0.5632173  0.35153776
 0.48225683 0.33210507 0.2677551  0.54782534 0.4167269  0.2739892
 0.53887594 0.282275   0.43846932 0.4808914  0.55885065 0.50118434
 0.53343076 0.2935132  0.29553333 0.39761958 0.5174974  0.4100194
 0.34703723 0.24010539]
tr_loss:[0.5455359  0.5989288  0.5316485  0.2015479  0.16728576 0.18647072
 0.17457247 0.17818753 0.21045597 0.18729267 0.16634646 0.48273295
 0.17650597 0.1771607  0.18023507 0.5258318  0.41505918 0.18367274
 0.23874867 0.2454916  0.5347936  0.43188095 0.43633872 0.20982532
 0.47988182 0.1850912  0.2294373  0.4215598  0.18433356 0.5422887
 0.20852824 0.18271291 0.51675683 0.6635532  0.39379025 0.1752695
 0.22175555 0.5563803  0.18920977 0.2192336  0.21098664 0.5047616
 0.66489613 0.21457848 0.18132415 0.21127963 0.18517557 0.23019023
 0.4623367  0.19320452]
tr_loss:[0.5095142  0.65221703 0.5156938  0.5864409  0.54220116 0.12689538
 0.5500187  0.18360406 0.12804988 0.4718687  0.6395081  0.12812793
 0.16124792 0.46043253 0.12632275 0.1313614  0.13715209 0.10121264
 0.45271388 0.14978476 0.52245706 0.14190516 0.22288518 0.12655494
 0.5270201  0.1356279  0.15625736 0.65486526 0.3224193  0.10349735
 0.62671036 0.6154567  0.7243444  0.6506561  0.12225485 0.13881029
 0.29846713 0.10175487 0.12561205 0.15369019 0.14222895 0.10017936
 0.368869   0.68356264 0.1384778  0.43520975 0.5630335  0.50232565
 0.44201785 0.12889904]
tr_loss:[0.1039172  0.49208298 0.13861422 0.13165864 0.58316356 0.5376638
 0.58921343 0.1064461  0.09982885 0.55103815 0.40202412 0.4234779
 0.11364446 0.624478   0.09739371 0.33641836 0.47656885 0.09533121
 0.53738225 0.50493205 0.4969965  0.10178133 0.3427109  0.3620585
 0.42552727 0.09738939 0.10410614 0.45526856 0.55906296 0.5758983
 0.66026825 0.10543263 0.08040525 0.6816292  0.1387556  0.09750748
 0.49238023 0.46512967 0.09732714 0.33138186 0.10325348 0.4526504
 0.5490856  0.08917146 0.08227338 0.11100085 0.09786923 0.10400636
 0.42011184 0.13401215]
tr_loss:[0.10891783 0.09658603 0.3284523  0.08195198 0.30238163 0.5724515
 0.5570391  0.07891277 0.4881378  0.55092543 0.10317081 0.08215924
 0.11604643 0.46431953 0.46817255 0.56527865 0.26038316 0.07629518
 0.1111654  0.0685686  0.53177667 0.43815365 0.0941685  0.08492587
 0.61272776 0.08225714 0.0826475  0.07387302 0.09399803 0.09387144
 0.55738276 0.47314304 0.06677362 0.5847079  0.537439   0.37780145
 0.37597814 0.06799876 0.09703615 0.08192291 0.07974439 0.08330299
 0.5886725  0.07880484 0.08467431 0.09493663 0.48481256 0.55218595
 0.59388196 0.41485175]
tr_loss:[0.5996357  0.57496405 0.6594229  0.1047288  0.08665818 0.4345687
 0.08832179 0.06981172 0.62919676 0.07201741 0.09869112 0.07208542
 0.6202362  0.5123922  0.5842979  0.52401525 0.0720651  0.41859454
 0.29509702 0.07465614 0.56964403 0.07269315 0.09992377 0.07409649
 0.2061294  0.30912662 0.34923372 0.55689555 0.5533503  0.07224947
 0.07408814 0.58236474 0.38732424 0.5413062  0.38464123 0.42588997
 0.08995067 0.5264934  0.0781128  0.21315937 0.36277568 0.5537754
 0.08840892 0.4484399  0.09134135 0.07218256 0.08839743 0.10064969
 0.09263401 0.46473303]
tr_loss:[0.4062654  0.0663387  0.5313638  0.40763587 0.46888646 0.05977027
 0.39094064 0.05550801 0.38296777 0.09473368 0.66734064 0.46209425
 0.08081719 0.2893029  0.52551115 0.08049024 0.08089894 0.29182965
 0.59882677 0.49049038 0.37849402 0.38393623 0.4625825  0.07456378
 0.42650613 0.5261678  0.06475768 0.06451972 0.0787579  0.07276478
 0.07993313 0.05886627 0.07968463 0.6835852  0.0878043  0.47619477
 0.4567484  0.34326684 0.54849416 0.33173856 0.49751943 0.08154353
 0.07666624 0.19456895 0.47073975 0.0670617  0.42559546 0.07865846
 0.17763166 0.07149968]
tr_loss:[0.3359893  0.34777004 0.08096834 0.05951735 0.08358043 0.06972512
 0.06157193 0.05495417 0.07887806 0.07999577 0.07909088 0.07833139
 0.66487324 0.06253176 0.063361   0.39013767 0.46362758 0.07970452
 0.5006193  0.08080414 0.4913833  0.07303015 0.08312636 0.39452538
 0.4467907  0.44584903 0.06554229 0.27380258 0.07928547 0.43292332
 0.45755428 0.05248905 0.17087981 0.06832518 0.47695404 0.07941012
 0.49009743 0.09151661 0.47632313 0.07867382 0.07801618 0.05040045
 0.08249609 0.5224104  0.06347109 0.05313104 0.3711005  0.64484066
 0.05094914 0.06364539]
tr_loss:[0.05964736 0.04929823 0.45375022 0.5472231  0.08727773 0.0514145
 0.51467043 0.31087926 0.05904134 0.32915384 0.06060045 0.32816398
 0.44780105 0.0650322  0.059526   0.10146247 0.04402205 0.06039848
 0.4163774  0.04793566 0.34006262 0.05512118 0.5431989  0.49077684
 0.38371217 0.05771641 0.471359   0.07013647 0.07763046 0.49091357
 0.35495642 0.527968   0.59868133 0.09170388 0.57016915 0.2526788
 0.08210421 0.48350126 0.05953658 0.34391552 0.38883913 0.08099724
 0.08211527 0.06004    0.06436329 0.56578386 0.60061586 0.0903555
 0.09179153 0.47169486]
tr_loss:[0.05653834 0.05633742 0.09157141 0.52100307 0.5803308  0.05487959
 0.46309692 0.04603454 0.08330492 0.08811619 0.05118977 0.16454223
 0.52707785 0.09243789 0.4844368  0.08310242 0.57487565 0.05517746
 0.05375098 0.49507436 0.06010505 0.0811025  0.04864242 0.0786757
 0.5484648  0.48544306 0.05487578 0.04636316 0.06442989 0.18859212
 0.06251158 0.21658234 0.06957177 0.3794535  0.05500588 0.05496987
 0.0797933  0.05624929 0.4222412  0.05497031 0.50213194 0.08282606
 0.3447293  0.44098797 0.52326965 0.65440875 0.5942265  0.562983
 0.07162036 0.4537863 ]
tr_loss:[0.08061944 0.07032063 0.0527084  0.08164803 0.08465736 0.23751059
 0.08174704 0.08199622 0.08054177 0.05676704 0.47450846 0.05037885
 0.08217561 0.5080333  0.30496    0.6066939  0.04883789 0.07681837
 0.4592785  0.0481674  0.29277045 0.5039748  0.6047516  0.04869921
 0.06397965 0.43497688 0.41641837 0.05975088 0.04666733 0.0502945
 0.50986886 0.31208402 0.05434038 0.04710672 0.08108489 0.04144387
 0.5648613  0.36309224 0.04041745 0.61519897 0.06175489 0.12553975
 0.0750752  0.4260202  0.07436757 0.5559195  0.6303829  0.38997918
 0.04781023 0.08282447]
tr_loss:[0.38018948 0.46779442 0.4077917  0.42494172 0.677618   0.45178947
 0.07455884 0.04619375 0.07515737 0.62434065 0.32939228 0.48311782
 0.29335666 0.07487869 0.07638828 0.58563316 0.0567194  0.04899403
 0.49574375 0.04203711 0.46102533 0.04059611 0.3922686  0.03886508
 0.03704119 0.3688373  0.04667195 0.04732002 0.4458844  0.04237407
 0.05871096 0.5557808  0.3561465  0.05350064 0.23640664 0.49611837
 0.05863668 0.03980272 0.46757698 0.62461907 0.04790283 0.06571943
 0.47059956 0.46235976 0.03926955 0.53650653 0.04683585 0.58617413
 0.18791406 0.36742568]
tr_loss:[0.42343205 0.3499036  0.03805721 0.38639295 0.03989406 0.04233618
 0.07085209 0.06562277 0.06903422 0.21859615 0.44541654 0.04354339
 0.42719454 0.37062654 0.49846092 0.04395261 0.11091783 0.04230721
 0.03118467 0.03325889 0.04575179 0.0409791  0.05877556 0.41253883
 0.04024614 0.04376631 0.03179555 0.04358458 0.45949927 0.04316028
 0.07070336 0.05591636 0.4880107  0.41700983 0.06673799 0.55796576
 0.49732226 0.40146655 0.45523053 0.0431126  0.49729174 0.04437746
 0.04425403 0.5386945  0.25868613 0.07031437 0.06132696 0.2702004
 0.10722198 0.47254914]
tr_loss:[0.03810462 0.3440993  0.41001216 0.06536607 0.06494174 0.3935627
 0.5233763  0.06484486 0.04959868 0.05112352 0.03629587 0.39844194
 0.51517665 0.06612699 0.06289311 0.03872528 0.40511307 0.0383418
 0.13640077 0.47694463 0.35763675 0.38139352 0.03679895 0.3606161
 0.39189485 0.38628048 0.0460123  0.03662264 0.04611866 0.06050621
 0.03739534 0.03868799 0.04533981 0.04158593 0.03896052 0.3883857
 0.37516874 0.49425817 0.40570775 0.36896896 0.03632034 0.41887626
 0.39230648 0.34714133 0.47322494 0.04076272 0.3527152  0.3711742
 0.04693595 0.04000293]
tr_loss:[0.23449865 0.3509651  0.05727699 0.3209587  0.48720425 0.07682908
 0.0411938  0.32525355 0.40069324 0.05258512 0.03173025 0.39570135
 0.43339962 0.05745029 0.03856712 0.50635254 0.05918552 0.33339077
 0.02999168 0.03375065 0.51145625 0.03248446 0.35020718 0.03102635
 0.52013934 0.45574504 0.03025873 0.25978464 0.05737469 0.36775026
 0.04216903 0.03458975 0.03389493 0.03802579 0.05739073 0.17363939
 0.05754398 0.29533118 0.3460906  0.31046477 0.05966432 0.02884434
 0.02944919 0.0341344  0.03457367 0.3778364  0.15607402 0.4908293
 0.29580283 0.03459756]
tr_loss:[0.41661304 0.05424033 0.03500737 0.02789427 0.05540514 0.03398707
 0.39966533 0.37959644 0.05532328 0.19645485 0.0311325  0.22293487
 0.0561807  0.05404883 0.39718696 0.26874056 0.04078943 0.47758275
 0.14436622 0.03253823 0.06831191 0.35414788 0.05427325 0.05048896
 0.05397341 0.03626836 0.03296848 0.3339104  0.02967961 0.18217798
 0.24848075 0.02702638 0.424275   0.44563022 0.3122646  0.35027274
 0.04340071 0.5090041  0.04411851 0.30684122 0.03187553 0.05546337
 0.3863243  0.0556402  0.04413644 0.28240183 0.03133388 0.03455022
 0.42965063 0.03371947]
tr_loss:[0.35990375 0.03865507 0.03500639 0.4321703  0.3642165  0.03726432
 0.46733373 0.41657573 0.24082069 0.02903438 0.02611332 0.04898693
 0.03249052 0.04728315 0.42574295 0.04952159 0.03850148 0.38157496
 0.04177054 0.2932054  0.03564786 0.43842483 0.03919904 0.0439967
 0.05086185 0.0381902  0.02610674 0.24598646 0.30258185 0.40407395
 0.31373486 0.05204951 0.03529357 0.03107687 0.33768314 0.04908829
 0.02835979 0.2165812  0.34467882 0.02704468 0.03424929 0.51440036
 0.22922853 0.40106314 0.04672632 0.33187944 0.03150843 0.15737662
 0.29422984 0.48710173]
tr_loss:[0.0464543  0.02909388 0.3450927  0.02764929 0.04753292 0.04668848
 0.1608136  0.04639589 0.41607088 0.3700984  0.2938799  0.04549668
 0.48385215 0.0296558  0.04910434 0.03932989 0.3048467  0.03342969
 0.04618869 0.29880098 0.38857514 0.027736   0.04613532 0.4637142
 0.02927632 0.05201841 0.03685649 0.03506454 0.41490498 0.3868204
 0.30067334 0.04099485 0.03630927 0.35619324 0.0462749  0.32678396
 0.3652096  0.38845313 0.490848   0.4122638  0.02710592 0.03977783
 0.39849705 0.03404832 0.47258496 0.41143695 0.3880518  0.03659922
 0.26288885 0.36140904]
tr_loss:[0.02757249 0.02708457 0.13940716 0.30477256 0.37575346 0.03686368
 0.38448006 0.02636096 0.38638502 0.0487797  0.33476067 0.30277818
 0.35626742 0.04289936 0.4027005  0.40958267 0.52852666 0.03687033
 0.04489106 0.3331952  0.20147815 0.03988278 0.34399813 0.03040715
 0.02537651 0.48985186 0.30298346 0.04442517 0.31223527 0.03720688
 0.03475309 0.03697539 0.42000094 0.31570747 0.31630838 0.26343638
 0.03331382 0.04347106 0.37800798 0.3983994  0.03301073 0.21084146
 0.04275821 0.37426823 0.04357692 0.30081517 0.04322637 0.25816855
 0.03366984 0.04264775]
tr_loss:[0.02777947 0.02374011 0.35081202 0.3418098  0.02971739 0.03761783
 0.02752804 0.0306509  0.46050137 0.41802353 0.02634913 0.04047938
 0.03678245 0.3467153  0.35710827 0.03183138 0.04179756 0.03029708
 0.3145021  0.02463349 0.03625144 0.4956476  0.32355958 0.04120577
 0.02694041 0.04205972 0.02483633 0.04144388 0.26364523 0.02369982
 0.02473422 0.03806355 0.02870361 0.38475055 0.02963137 0.25716862
 0.42120808 0.04072621 0.03747595 0.21721916 0.04152306 0.04140101
 0.04190214 0.3109425  0.03378985 0.03103967 0.38652238 0.06210651
 0.41068858 0.03201769]
tr_loss:[0.24064763 0.16563901 0.37221998 0.5442862  0.29944837 0.03670808
 0.0247323  0.02894335 0.02418582 0.2459329  0.02929241 0.27736595
 0.41318816 0.3041603  0.20520076 0.34124035 0.02431259 0.4398547
 0.10912099 0.03903516 0.03462001 0.3368403  0.4868484  0.3440951
 0.3315383  0.3477376  0.20909591 0.35432985 0.38071802 0.45467216
 0.03781001 0.30925876 0.04263217 0.38651994 0.1943745  0.02678339
 0.03795636 0.03210352 0.41480738 0.0396227  0.02884349 0.03721772
 0.2328124  0.02411778 0.34510446 0.31246573 0.03090241 0.40750027
 0.493394   0.03958812]
tr_loss:[0.02150593 0.5011846  0.1483979  0.3402385  0.03377386 0.02514257
 0.02202319 0.5187259  0.30038846 0.3860895  0.02452379 0.32712492
 0.03399661 0.387601   0.42285648 0.45986757 0.30752164 0.03876982
 0.02574981 0.03160121 0.0279674  0.02620802 0.42540973 0.03606197
 0.03839749 0.36328706 0.03764396 0.07544594 0.04760189 0.04967021
 0.368104   0.02619072 0.34633407 0.03485958 0.02122514 0.03057458
 0.27938524 0.03654068 0.32141072 0.02273387 0.02245167 0.31976873
 0.22087789 0.03899905 0.02409089 0.02350549 0.02574572 0.33020383
 0.3271644  0.3772058 ]
tr_loss:[0.03706026 0.31424132 0.03450686 0.02259895 0.29843703 0.02431594
 0.02368109 0.3091485  0.03066592 0.03115289 0.03877484 0.03281862
 0.16942269 0.22256693 0.2508009  0.39745492 0.02363005 0.03422602
 0.3612682  0.28728256 0.5171844  0.35224646 0.02235109 0.02260626
 0.0220476  0.02289879 0.37174565 0.414622   0.2949399  0.3565051
 0.02493961 0.23240963 0.39535093 0.25184354 0.5027709  0.35383955
 0.03645905 0.02411546 0.34210244 0.35486344 0.03331428 0.02997955
 0.3081314  0.02741758 0.4168349  0.02264862 0.41019565 0.03689194
 0.02262263 0.02279448]
tr_loss:[0.0241468  0.32392263 0.0348833  0.25644058 0.32899892 0.32709354
 0.38062653 0.02103475 0.40363923 0.20136829 0.03448945 0.29670933
 0.52199864 0.02182256 0.0598563  0.03907127 0.02441971 0.03030657
 0.33735895 0.44116813 0.03388695 0.2931535  0.02971755 0.1608418
 0.03313127 0.36473578 0.02333174 0.25834805 0.03031312 0.2645068
 0.4245615  0.02362499 0.02423338 0.02208393 0.26808518 0.02937124
 0.2960625  0.32561937 0.02328575 0.21283035 0.03759135 0.39102614
 0.03231519 0.02440043 0.03096857 0.03458565 0.03555888 0.02367813
 0.26888654 0.19459125]
tr_loss:[0.02997252 0.02191008 0.4161633  0.04336385 0.02199295 0.24484165
 0.01777291 0.24304447 0.03177275 0.14581217 0.36402106 0.20932774
 0.35509032 0.02204088 0.02432924 0.03826796 0.42614603 0.2472591
 0.42037907 0.02861733 0.02757484 0.30692083 0.0162587  0.35967025
 0.37022644 0.37407207 0.21915226 0.03205768 0.3780551  0.01734383
 0.44320232 0.38302374 0.02287709 0.40385526 0.26606575 0.0326346
 0.0324259  0.03727099 0.02855164 0.34012792 0.3735786  0.03737262
 0.37436712 0.33720455 0.3732616  0.26797143 0.03135102 0.4215153
 0.304331   0.35394955]
tr_loss:[0.01654195 0.37024146 0.23075327 0.43640494 0.31463328 0.2925694
 0.34070173 0.03510813 0.02165859 0.28724915 0.0283716  0.03011776
 0.0283383  0.02193576 0.02964011 0.34542328 0.4001422  0.02905531
 0.34347928 0.24427238 0.3718955  0.25505477 0.03922658 0.3834374
 0.03404184 0.02116223 0.39480463 0.41639107 0.35491675 0.2322652
 0.02298518 0.03279087 0.03505731 0.3542768  0.029324   0.02637763
 0.0247122  0.0278522  0.422762   0.04120341 0.16478412 0.03389378
 0.01905023 0.27043393 0.0321855  0.01584296 0.20583908 0.03538812
 0.367722   0.02923791]
tr_loss:[0.02342385 0.01922655 0.02486488 0.03343659 0.3193704  0.02705773
 0.01733271 0.11620031 0.03111634 0.16116357 0.4240945  0.02062779
 0.31175497 0.2634318  0.02065226 0.2066041  0.02509035 0.38841003
 0.2828281  0.3649951  0.5046852  0.01990682 0.02620019 0.19471177
 0.25396022 0.01682708 0.26605433 0.01567302 0.38580325 0.02487029
 0.02711954 0.03089668 0.3666924  0.02066559 0.01674736 0.30558133
 0.03076149 0.2897427  0.0222631  0.02716793 0.23642841 0.02512004
 0.03088549 0.04560559 0.21748522 0.33827567 0.02921142 0.2693054
 0.35052222 0.30273086]
tr_loss:[0.02632423 0.02682148 0.14250147 0.30798826 0.01843074 0.34317568
 0.02713817 0.02857023 0.37733248 0.0206857  0.01970872 0.26931775
 0.01898093 0.24675211 0.01928198 0.03030065 0.03008491 0.01426168
 0.28324825 0.48443514 0.30374688 0.34138197 0.35189334 0.01496684
 0.02129665 0.0282881  0.02111968 0.37440962 0.01425709 0.03449438
 0.03096446 0.31476775 0.03492682 0.02107913 0.02016596 0.2973815
 0.02814591 0.01915404 0.22650199 0.32124954 0.02791989 0.37702614
 0.03038547 0.02138409 0.02148177 0.13493593 0.33299762 0.4765299
 0.03450394 0.02275426]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 800 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(801, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 801 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(802, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 802 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(803, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 803 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(804, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 804 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(805, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 805 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(806, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 806 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(807, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 807 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(808, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 808 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(809, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 809 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(810, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 810 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(811, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 811 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(812, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 812 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(813, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 813 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(814, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 814 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(815, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 815 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(816, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 816 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(817, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 817 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(818, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 818 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(819, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 819 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(820, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 820 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(821, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 821 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(822, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 822 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(823, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 823 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(824, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 824 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(825, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 825 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(826, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 826 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(827, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 827 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(828, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 828 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(829, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 829 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(830, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 830 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(831, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 831 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(832, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 832 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(833, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 833 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(834, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 834 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(835, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 835 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(836, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 836 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(837, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 837 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(838, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 838 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(839, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 839 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(840, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 840 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(841, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 841 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(842, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 842 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(843, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 843 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(844, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 844 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(845, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 845 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(846, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 846 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(847, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 847 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(848, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 848 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(849, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 849 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(850, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 850 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(851, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 851 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(852, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 852 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(853, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 853 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(854, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 854 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(855, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 855 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(856, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 856 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(857, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 857 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(858, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 858 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(859, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 859 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(860, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 860 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(861, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 861 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(862, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 862 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(863, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 863 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(864, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 864 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(865, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 865 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(866, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 866 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(867, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 867 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(868, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 868 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(869, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 869 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(870, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 870 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(871, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 871 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(872, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 872 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(873, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 873 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(874, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 874 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(875, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 875 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(876, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 876 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(877, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 877 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(878, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 878 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(879, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 879 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(880, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 880 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(881, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 881 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(882, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 882 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(883, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 883 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(884, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 884 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(885, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 885 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(886, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 886 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(887, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 887 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(888, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 888 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(889, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 889 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(890, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 890 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(891, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 891 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(892, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 892 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(893, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 893 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(894, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 894 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(895, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 895 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(896, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 896 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(897, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 897 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(898, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 898 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(899, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 899 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(900, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-800
text_input.shape
(900, 14400)
learning_input_tmp.shape
(900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(900, 80)
learning_output.shape
(750, 80)
Model: "sequential_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_19 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.63168985 0.8602091  0.48148736 0.78138363 0.83776474 0.448618
 0.4396285  0.6524992  0.31496787 0.43165207 0.452285   0.45594186
 0.7171556  0.4304573  0.6770606  0.47320002 0.80593073 0.794291
 0.7501049  0.47437868 0.42524624 0.45853934 0.43414325 0.79775876
 0.4167057  0.75183856 0.4517952  0.7501855  0.8013094  0.44480067
 0.7573355  0.8602091  0.7453824  0.75651854 0.75618804 0.5256001
 0.4693961  0.7264659  0.5918978  0.44285136 0.86282    0.44563037
 0.5565906  0.6471533  0.611454   0.37652388 0.41613    0.7335718
 0.5462888  0.52717763]
tr_loss:[0.28405127 0.31979913 0.40558672 0.34946126 0.3053308  0.5658719
 0.28333148 0.29075098 0.42760172 0.32257482 0.39553225 0.29129347
 0.4168803  0.37683234 0.39081275 0.5930809  0.37443772 0.30814895
 0.28547448 0.45005625 0.38693362 0.3937807  0.5109599  0.37939665
 0.30549008 0.36758858 0.39337784 0.28142193 0.4870593  0.35538357
 0.37587234 0.3549756  0.7278502  0.35763302 0.4176209  0.35375896
 0.30669394 0.27615336 0.30924553 0.32631493 0.53320634 0.42493987
 0.3101071  0.36952764 0.6361208  0.35317087 0.31385592 0.37516907
 0.3788292  0.6758022 ]
tr_loss:[0.30324483 0.52750444 0.40574917 0.4340493  0.22911315 0.2863529
 0.29327536 0.25901312 0.463363   0.23148158 0.25851917 0.41419655
 0.24094541 0.5896913  0.4798487  0.5136278  0.23295231 0.28408802
 0.4600523  0.28795284 0.74247384 0.32140845 0.3222395  0.25985783
 0.27292007 0.51306534 0.2730541  0.28077587 0.2699429  0.2538391
 0.29727057 0.49914098 0.5462556  0.40703058 0.27970606 0.26489818
 0.2952488  0.27226081 0.25985748 0.28842947 0.41523772 0.23067054
 0.281979   0.40838343 0.47564334 0.25099224 0.29670277 0.26228857
 0.2753779  0.3180778 ]
tr_loss:[0.1449068  0.26666555 0.21626358 0.6060674  0.26055878 0.3639899
 0.22835581 0.23919097 0.24820742 0.5484191  0.15596436 0.14907913
 0.44592467 0.26586193 0.49934396 0.14687154 0.2651777  0.46416664
 0.18301277 0.14492361 0.24855916 0.5041281  0.18183355 0.19393642
 0.1853068  0.3930673  0.1454669  0.18188107 0.6700331  0.20434996
 0.1453875  0.17798707 0.42217463 0.44119525 0.17925684 0.5923874
 0.2516431  0.5079645  0.14623448 0.26143092 0.41641927 0.5450503
 0.169      0.46260077 0.29192173 0.24304044 0.14508155 0.5309887
 0.18196774 0.44314224]
tr_loss:[0.13759808 0.14420013 0.13152018 0.17913048 0.16570625 0.21625867
 0.15312818 0.15472667 0.1301072  0.14463925 0.47927046 0.21462421
 0.17423138 0.22841232 0.14438209 0.13262889 0.14379123 0.14765337
 0.14768459 0.17232622 0.20232978 0.14753632 0.22060537 0.13262884
 0.17755322 0.18120566 0.46022335 0.4937566  0.5554665  0.32536966
 0.13117436 0.34534732 0.55742174 0.51455563 0.13128844 0.17351755
 0.21016853 0.14453505 0.5707251  0.14871952 0.6224433  0.17252782
 0.1874573  0.12691464 0.20675051 0.48809165 0.21917272 0.6693016
 0.16472867 0.13138404]
tr_loss:[0.1277682  0.13167797 0.4080197  0.14445269 0.6167705  0.56297296
 0.08188153 0.4578514  0.12670657 0.1811047  0.19236405 0.09595826
 0.19831344 0.46691483 0.4153858  0.4847424  0.28687555 0.38750938
 0.17696235 0.09623431 0.09305123 0.38614622 0.497152   0.5030195
 0.09159864 0.10465131 0.624606   0.09398855 0.18666378 0.5450977
 0.10154356 0.585333   0.1402241  0.45413408 0.11495362 0.1401648
 0.13115427 0.14459905 0.1032269  0.17713384 0.13968213 0.19695805
 0.47159594 0.08825704 0.1309258  0.48091832 0.08188163 0.6391132
 0.46890545 0.5295098 ]
tr_loss:[0.57918537 0.11589701 0.4017558  0.10215757 0.09319291 0.3648944
 0.07211097 0.45135194 0.09987523 0.53518265 0.09593747 0.5504864
 0.08710746 0.15382572 0.089249   0.07771794 0.08185279 0.13034719
 0.47722283 0.56113946 0.10513406 0.06518456 0.2955978  0.09263763
 0.08046931 0.12021889 0.09942362 0.07771804 0.5493965  0.10208955
 0.5850613  0.08941079 0.07771802 0.36032295 0.09429117 0.3637089
 0.5953901  0.11278608 0.5156442  0.09840912 0.3923901  0.07289643
 0.11168931 0.09204006 0.36669272 0.07042932 0.4154316  0.077718
 0.55905616 0.10125095]
tr_loss:[0.10597859 0.08319048 0.08827504 0.13440979 0.1054133  0.4026522
 0.13797191 0.07306521 0.13463631 0.1400317  0.47666734 0.06684543
 0.08288156 0.08833836 0.6083473  0.29359728 0.2815398  0.70395213
 0.04900104 0.10014927 0.09803455 0.11165235 0.06119959 0.06688896
 0.1411223  0.06119967 0.59195596 0.0884606  0.07765368 0.04900485
 0.39099056 0.10582598 0.09422123 0.34965903 0.19226892 0.41594887
 0.0783549  0.5305022  0.06120034 0.05474649 0.07894077 0.503765
 0.321836   0.3212896  0.0721908  0.42244047 0.11051204 0.07222424
 0.08083011 0.06701173]
tr_loss:[0.5723435  0.4943111  0.5783844  0.08736466 0.44873038 0.0485875
 0.07949676 0.07699224 0.10240731 0.4711461  0.2951371  0.07667719
 0.57632804 0.4553094  0.3717131  0.11791182 0.05879519 0.11629287
 0.07448077 0.521021   0.05639257 0.08653039 0.37936878 0.09514759
 0.09263749 0.4737681  0.06181863 0.06174778 0.6165182  0.455015
 0.07711015 0.11917837 0.0918953  0.0648495  0.4155244  0.3070233
 0.07989359 0.36849695 0.07986363 0.06504241 0.11515131 0.05971624
 0.06504251 0.06144161 0.6298993  0.06083816 0.3258278  0.14508942
 0.07444912 0.6268331 ]
tr_loss:[0.05968122 0.06321688 0.05968124 0.06335086 0.0850896  0.11009574
 0.10887084 0.07999729 0.10864303 0.65359336 0.11129274 0.34796605
 0.07289835 0.05991036 0.29594177 0.38121045 0.10815042 0.06343447
 0.51772916 0.35978228 0.05453897 0.1066435  0.07621278 0.10982871
 0.3958438  0.10693619 0.07027193 0.06372704 0.08740278 0.10678124
 0.05773331 0.05770795 0.06158654 0.06340811 0.48696947 0.39630508
 0.49223548 0.06184813 0.08142684 0.09656439 0.45234013 0.0682686
 0.47957507 0.06545532 0.10934138 0.47731358 0.08398723 0.5911604
 0.06285499 0.06066725]
tr_loss:[0.4433753  0.4213272  0.41547245 0.05513353 0.4415841  0.06104453
 0.09617873 0.12651697 0.15501584 0.09608661 0.64894295 0.08203699
 0.4905212  0.60351324 0.23430292 0.09624327 0.07863941 0.22898039
 0.04657419 0.40027887 0.0572102  0.04842098 0.05750247 0.44184572
 0.08001653 0.5621289  0.05516624 0.07977276 0.05951131 0.09913565
 0.34521982 0.51839125 0.50478286 0.5494196  0.05206047 0.10356522
 0.08547402 0.56525743 0.07156488 0.41208434 0.50851315 0.05494963
 0.49852628 0.04657414 0.07990671 0.04826918 0.47229463 0.04657919
 0.09940916 0.08239795]
tr_loss:[0.07451721 0.5895325  0.3123911  0.07639682 0.06113572 0.06087744
 0.06592025 0.28707504 0.36685404 0.08096991 0.07593556 0.07444093
 0.05939256 0.06600361 0.42288676 0.07589763 0.623314   0.42914253
 0.46824455 0.41826743 0.08181961 0.07210267 0.1015136  0.06333612
 0.06886959 0.43216872 0.0856027  0.07437249 0.0786882  0.05884928
 0.45550817 0.08010737 0.09184919 0.099548   0.05888189 0.06583284
 0.07594895 0.06333609 0.10086431 0.06630023 0.55898505 0.06042324
 0.09945634 0.07831721 0.06262797 0.06906112 0.07889865 0.3532704
 0.04515768 0.05911063]
tr_loss:[0.05476775 0.07432064 0.09408669 0.05976285 0.09655343 0.05532334
 0.05690889 0.51596063 0.5110256  0.0586661  0.43321696 0.05954885
 0.0492493  0.04145011 0.47285885 0.08646858 0.04627764 0.05476774
 0.27511084 0.4034316  0.06531006 0.05646272 0.05875238 0.48071694
 0.05337223 0.47116232 0.35719168 0.05476773 0.08810803 0.5298846
 0.40941063 0.04627766 0.5241207  0.05934365 0.09445615 0.44986358
 0.0681681  0.10275145 0.05937543 0.05937446 0.6047851  0.5455409
 0.05151344 0.43520802 0.06979376 0.05266346 0.05961978 0.08913945
 0.04922906 0.05788948]
tr_loss:[0.469867   0.29534808 0.06469774 0.5002485  0.06026609 0.05298759
 0.05158464 0.05306404 0.3870216  0.05998399 0.06309342 0.05474918
 0.3585251  0.08957419 0.05483013 0.08888127 0.27222407 0.04903692
 0.32249302 0.06773709 0.0686565  0.37144178 0.05648177 0.08302099
 0.05343268 0.05677604 0.04983846 0.04188522 0.32495508 0.06318836
 0.4704167  0.02806204 0.0587451  0.08924621 0.05637097 0.41372362
 0.31289878 0.49028593 0.36564913 0.0365714  0.40925807 0.04760341
 0.05123005 0.5677912  0.09109597 0.05140875 0.35787314 0.05191156
 0.03832537 0.04755403]
tr_loss:[0.06247417 0.03672157 0.06086727 0.32271162 0.04943453 0.518792
 0.5810605  0.04472906 0.03602376 0.46902472 0.08091537 0.08057664
 0.52721137 0.04615241 0.03603386 0.05754092 0.638388   0.03121657
 0.45860004 0.0594353  0.07002302 0.0391443  0.4469909  0.33465877
 0.04112516 0.03954129 0.08270624 0.2657649  0.08212824 0.13459837
 0.58045506 0.04182812 0.03121469 0.0824395  0.04575136 0.6263108
 0.56663734 0.03843676 0.04757953 0.08223048 0.31561118 0.04259425
 0.5520811  0.22949108 0.06649402 0.04122468 0.08061973 0.38089883
 0.300207   0.46040553]
tr_loss:[0.40384015 0.47851983 0.36998376 0.0306259  0.03032083 0.5372545
 0.03339775 0.42735577 0.03547832 0.07591051 0.07577582 0.04056818
 0.44303364 0.44373283 0.0774671  0.14436145 0.34947592 0.04806444
 0.04246967 0.03093627 0.05914591 0.03871691 0.3657019  0.02837036
 0.35037905 0.07844909 0.40888745 0.05147166 0.0545551  0.048093
 0.03787755 0.05547157 0.07742929 0.03421532 0.3842972  0.02838215
 0.32665914 0.56192887 0.34533542 0.41520542 0.03032359 0.03780739
 0.04242426 0.5539857  0.02602512 0.47201768 0.03429789 0.07795627
 0.06005653 0.03668898]
tr_loss:[0.0614355  0.04537787 0.0524434  0.06800212 0.0537364  0.06968463
 0.03019547 0.03822549 0.03636612 0.26689926 0.02879399 0.47090864
 0.04246135 0.04441601 0.33294287 0.4506401  0.44867772 0.29663175
 0.34112296 0.49985638 0.04057423 0.04519499 0.03019463 0.05334383
 0.40935344 0.32867876 0.42527074 0.30764565 0.0650221  0.02394234
 0.4869164  0.02858976 0.02394258 0.03246321 0.2807854  0.04556062
 0.06825331 0.34213606 0.04496441 0.04582541 0.06641088 0.23582478
 0.02843936 0.02843937 0.06299848 0.06804141 0.06946453 0.05331651
 0.05109773 0.20775136]
tr_loss:[0.3000224  0.03685929 0.48575324 0.4542881  0.46848035 0.03849979
 0.0407529  0.0607326  0.04709259 0.03741107 0.06263174 0.03900553
 0.05411574 0.06573589 0.03432726 0.03877874 0.42221794 0.25826463
 0.38105974 0.34082526 0.04522922 0.0368483  0.39350358 0.3921362
 0.02506482 0.25290483 0.0455577  0.04230345 0.4698619  0.0613685
 0.3063836  0.37154806 0.04773232 0.06192864 0.16646855 0.22660542
 0.02881421 0.03775296 0.13043368 0.02506481 0.03719779 0.03419516
 0.06217124 0.452514   0.40222058 0.06609815 0.46607837 0.04776948
 0.06250988 0.02561326]
tr_loss:[0.03435945 0.02506107 0.03256603 0.09763048 0.32958597 0.03394309
 0.04022707 0.576023   0.03525723 0.03605368 0.03448837 0.28191194
 0.0365399  0.03255126 0.04168026 0.02394311 0.05465019 0.03548443
 0.06160818 0.02398967 0.03321841 0.47756806 0.03918236 0.03421303
 0.43984318 0.03347026 0.03925684 0.33671802 0.03546948 0.04447211
 0.03207504 0.04153515 0.0521541  0.05444384 0.03353303 0.03267102
 0.05379122 0.0337723  0.41302425 0.03408932 0.04600224 0.3850323
 0.0497739  0.31043077 0.05354736 0.05343152 0.08901477 0.46515268
 0.05477505 0.03375066]
tr_loss:[0.03086244 0.02761735 0.52429485 0.03832898 0.20926838 0.46764922
 0.32112804 0.42510948 0.41702098 0.02634713 0.37711352 0.48440534
 0.03583091 0.40119487 0.02526447 0.41876134 0.02909211 0.03596368
 0.05063332 0.02921842 0.0508752  0.0607973  0.02920684 0.03538527
 0.02761728 0.35457176 0.42877656 0.36525115 0.23360868 0.32160106
 0.02942432 0.041625   0.0281006  0.05092246 0.04312887 0.03221739
 0.0280078  0.50093514 0.04500679 0.48860198 0.03225674 0.04729339
 0.05016278 0.21533684 0.04836354 0.05189228 0.03685208 0.44229078
 0.05102791 0.02579164]
tr_loss:[0.0489509  0.03500292 0.0414534  0.425399   0.4009614  0.03576747
 0.03464705 0.19585933 0.27732575 0.0418887  0.03556304 0.40200415
 0.03464747 0.39639062 0.5116116  0.3773817  0.03569584 0.03297658
 0.04876789 0.30844417 0.03363148 0.5273801  0.43500727 0.03150441
 0.02829458 0.04815323 0.05039436 0.04663561 0.43567866 0.05330237
 0.04762718 0.14679554 0.03446975 0.32097715 0.24392048 0.03431338
 0.04090343 0.05032699 0.03464698 0.22376657 0.29734948 0.03469751
 0.44648677 0.03031986 0.2685234  0.02636098 0.3676532  0.03441212
 0.04873611 0.29534358]
tr_loss:[0.04471678 0.04266291 0.02760723 0.03116218 0.02889696 0.02978512
 0.02914957 0.02968648 0.25144038 0.03127179 0.04682348 0.30101663
 0.23865736 0.32459158 0.26270133 0.43289346 0.02897879 0.03157764
 0.42250785 0.48820573 0.28614134 0.0439101  0.04329262 0.34979972
 0.02254095 0.03147588 0.0422376  0.02995005 0.49214202 0.03127177
 0.0221647  0.19843504 0.03003529 0.03216555 0.39923018 0.03109577
 0.05058651 0.04334024 0.04804492 0.02216142 0.0294704  0.2597457
 0.04447284 0.0345272  0.03144298 0.03153669 0.02899658 0.32667544
 0.45983115 0.0369649 ]
tr_loss:[0.02599305 0.02493535 0.02933159 0.28913936 0.04281918 0.24335352
 0.03893423 0.04012939 0.04043138 0.02695591 0.04028196 0.34035587
 0.03952194 0.04188031 0.02789925 0.19692972 0.03032067 0.03019315
 0.02464905 0.32592934 0.27188    0.030072   0.02493532 0.37084135
 0.1061074  0.03065852 0.04084982 0.04634522 0.36519274 0.02916361
 0.36198664 0.05020009 0.02832879 0.03209833 0.03687228 0.03035316
 0.30060077 0.0546173  0.34539568 0.02893957 0.3380871  0.03007197
 0.02901336 0.4859004  0.02415349 0.04071635 0.0534896  0.03893048
 0.03859613 0.05493826]
tr_loss:[0.02680618 0.03072898 0.02319774 0.0258803  0.0397206  0.04671701
 0.25342336 0.04018815 0.02703864 0.02832387 0.03371541 0.42742118
 0.03996495 0.0403992  0.04435572 0.04098953 0.05321411 0.31817693
 0.33019653 0.04040473 0.02850201 0.05302233 0.02304683 0.02188809
 0.2446225  0.02495535 0.37281874 0.3547016  0.2758141  0.04344515
 0.04187034 0.04023218 0.16708699 0.04023692 0.02572376 0.04014589
 0.02061741 0.03169847 0.05100179 0.39342314 0.47617418 0.03253153
 0.04587234 0.03159325 0.21690921 0.3626781  0.0297828  0.40037662
 0.2924889  0.02318838]
tr_loss:[0.02996604 0.0320018  0.03072488 0.31895638 0.0406029  0.03907206
 0.33234462 0.0211573  0.0224628  0.02737788 0.02729209 0.3127218
 0.30046526 0.03862546 0.03806136 0.03753595 0.02938813 0.31846604
 0.14299175 0.03349091 0.03378175 0.02280744 0.40113822 0.02701815
 0.3656618  0.20067856 0.4394606  0.38574278 0.30938476 0.01868154
 0.02593793 0.02633593 0.03519775 0.02543143 0.03957445 0.3424496
 0.05776697 0.02551071 0.04614169 0.02586801 0.33488345 0.03152304
 0.31459397 0.19352092 0.40093836 0.03119051 0.02615247 0.35848126
 0.36051387 0.27637488]
tr_loss:[0.02886577 0.02123832 0.03038773 0.0215964  0.3557437  0.03473231
 0.03287073 0.3358915  0.02553267 0.02982358 0.3117382  0.34831753
 0.23636532 0.01623213 0.0320685  0.30827647 0.02547711 0.03667217
 0.01849861 0.02074129 0.01849026 0.02553267 0.01909643 0.03435474
 0.35749897 0.02598481 0.0356278  0.02684357 0.01862071 0.01987127
 0.0273202  0.03489583 0.02179448 0.02163817 0.427123   0.20586307
 0.28087586 0.01667477 0.01990977 0.02066678 0.03851365 0.01667477
 0.02206776 0.4280128  0.01950309 0.01791476 0.42462295 0.39532894
 0.018615   0.0212519 ]
tr_loss:[0.33462754 0.34349895 0.02262126 0.40603143 0.02143271 0.3171208
 0.19858606 0.32582176 0.03278761 0.484389   0.28177115 0.04189448
 0.41304708 0.3496388  0.02686204 0.48868817 0.28767315 0.29538232
 0.09413503 0.38469565 0.04107758 0.02217526 0.021944   0.4013351
 0.10318172 0.29255646 0.03252269 0.01816037 0.03195492 0.39017624
 0.39275816 0.3322944  0.02003937 0.0387861  0.4409485  0.02726324
 0.03342016 0.03264686 0.2893513  0.03635236 0.04509562 0.03370065
 0.40479916 0.03133477 0.02966366 0.39022517 0.03461775 0.3319673
 0.4194409  0.3684136 ]
tr_loss:[0.02191318 0.03515937 0.03647177 0.02512192 0.01688594 0.2912115
 0.03827209 0.03987661 0.40133685 0.02732507 0.34338683 0.34713838
 0.24927716 0.03581714 0.38702732 0.01690872 0.03929051 0.03736724
 0.02003495 0.2991944  0.03540868 0.02267468 0.35832316 0.38538003
 0.04045198 0.03259951 0.476967   0.01648628 0.0289492  0.0189012
 0.57848513 0.36133233 0.29758295 0.03614729 0.34748438 0.03541642
 0.02173397 0.24587803 0.40946132 0.36660266 0.02788423 0.0169087
 0.02732505 0.36664754 0.2795688  0.03586976 0.20802346 0.01689055
 0.02102198 0.01703521]
tr_loss:[0.03738472 0.17178884 0.01328872 0.01666279 0.31875318 0.0193669
 0.09243295 0.03594252 0.0261928  0.03371558 0.24250142 0.01521161
 0.26862258 0.02892645 0.19998303 0.01601337 0.01710898 0.03567712
 0.01331464 0.01857988 0.02533158 0.42705655 0.03585858 0.04938466
 0.0198986  0.03988671 0.40156937 0.0268175  0.02881297 0.03532086
 0.03966212 0.39617714 0.30868405 0.01451056 0.21939011 0.27193457
 0.02673686 0.01511012 0.0159549  0.0153121  0.51030576 0.02038763
 0.03449907 0.03883453 0.0168773  0.04222827 0.01412307 0.01407047
 0.01936691 0.0172791 ]
tr_loss:[0.0374892  0.18698151 0.01584872 0.09409895 0.28751794 0.03802301
 0.02710697 0.02425966 0.033854   0.03268148 0.01811142 0.01579712
 0.01595063 0.43363795 0.23147216 0.03737221 0.3117094  0.01884039
 0.01515725 0.01482041 0.33182162 0.01660403 0.08708303 0.40585193
 0.01584871 0.20811567 0.25983316 0.01881671 0.23108561 0.54017055
 0.03855135 0.01843424 0.02513216 0.26863074 0.01618955 0.01879294
 0.01731152 0.0314253  0.03230572 0.03855775 0.03461967 0.5548241
 0.01801557 0.3152623  0.0332685  0.03628294 0.03448383 0.32408905
 0.0158268  0.31711063]
text_input.shape
(900, 14400)
learning_input_tmp.shape
(900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(900, 80)
learning_output.shape
(750, 80)
Model: "sequential_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_20 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.55593777 0.3937746  0.66332257 0.7895657  0.78523195 0.49062365
 0.62044466 0.61362565 0.5241121  0.6745505  0.79767406 0.6775211
 0.6072653  0.7056428  0.64026725 0.6074662  0.6102049  0.61212844
 0.45883417 0.6735466  0.67470676 0.5065739  0.79767406 0.58657724
 0.5279086  0.6929837  0.7109064  0.49626046 0.49403912 0.40208745
 0.70055115 0.57021147 0.6547817  0.6774883  0.42217875 0.47164804
 0.485552   0.46202517 0.518809   0.49234754 0.7142709  0.5305107
 0.5376811  0.60244024 0.64609575 0.6775948  0.64221436 0.698211
 0.5923912  0.48914146]
tr_loss:[0.585938   0.6662022  0.5136986  0.43361306 0.5134532  0.35196385
 0.50196856 0.660598   0.5101224  0.568684   0.6626217  0.56268245
 0.57446307 0.571586   0.53300446 0.5332409  0.6920028  0.56005204
 0.5612531  0.66049063 0.5201729  0.5688965  0.38577238 0.51267636
 0.4959895  0.5542835  0.49637327 0.510933   0.55585545 0.4997023
 0.3914762  0.6747258  0.56630385 0.5165993  0.47822618 0.5154481
 0.592625   0.45894775 0.6839032  0.42054063 0.6604915  0.45773697
 0.4983057  0.52278966 0.50616974 0.4505898  0.56155235 0.51780003
 0.55483186 0.6661967 ]
tr_loss:[0.3956713  0.34015176 0.44380522 0.34515247 0.4130369  0.34087843
 0.35854802 0.27234977 0.5552478  0.34704718 0.27675483 0.42071384
 0.26877713 0.40722817 0.27060166 0.32233626 0.40523028 0.53564394
 0.41835865 0.2722265  0.26502234 0.26114482 0.4329916  0.31070668
 0.40240937 0.4328249  0.47228384 0.47568798 0.27757186 0.4679162
 0.3465456  0.317131   0.37693152 0.34520966 0.52536833 0.31376973
 0.4038888  0.34873673 0.26189438 0.38233924 0.6440211  0.31866598
 0.31548697 0.31158003 0.50711834 0.34187016 0.3444186  0.5775671
 0.46836334 0.4814852 ]
tr_loss:[0.20135288 0.24912651 0.1893143  0.23584762 0.613415   0.29630616
 0.470887   0.5064802  0.29444346 0.49450034 0.47476482 0.26576012
 0.2657601  0.42668515 0.2232109  0.27492785 0.26441306 0.19036949
 0.23763399 0.36085066 0.23426393 0.26283297 0.48932084 0.5658778
 0.18813372 0.23185806 0.2237736  0.22942853 0.33315188 0.19858947
 0.6633873  0.27533537 0.23240128 0.26601347 0.53124666 0.24578352
 0.51109684 0.3571791  0.2616186  0.20043655 0.22823742 0.25397596
 0.24089289 0.27104914 0.26850897 0.43431425 0.23084489 0.2534346
 0.5003797  0.19661002]
tr_loss:[0.5361225  0.19846983 0.62318933 0.38923016 0.1617066  0.19301663
 0.19675305 0.1762423  0.1703259  0.20237422 0.39453447 0.16124418
 0.17557785 0.42086345 0.42704964 0.1908378  0.17914782 0.37816364
 0.35288614 0.52230746 0.16479976 0.2102298  0.17428872 0.15516114
 0.20859924 0.1706172  0.33820483 0.16979396 0.17118333 0.17494895
 0.16337284 0.5024396  0.37831053 0.6360899  0.54713416 0.1758224
 0.16865101 0.42100048 0.16379523 0.15632871 0.18885878 0.5079915
 0.40538988 0.37554246 0.60390335 0.18885878 0.1895206  0.15218225
 0.56125134 0.5817253 ]
tr_loss:[0.4777549  0.6029024  0.3931802  0.32622215 0.49241394 0.13214192
 0.6440402  0.15548444 0.14887886 0.13234302 0.16971084 0.12800895
 0.1583602  0.6499422  0.15787593 0.13175479 0.36600822 0.1459094
 0.14856644 0.1536437  0.13179715 0.13739891 0.14585981 0.15300235
 0.13762239 0.15117714 0.1457617  0.13501596 0.14101118 0.15038761
 0.14203164 0.14134362 0.161304   0.16741507 0.14575748 0.12347901
 0.1241091  0.12253845 0.58583957 0.52871484 0.12464027 0.12872846
 0.14134361 0.42313156 0.15296929 0.12963335 0.12338068 0.12790006
 0.1228449  0.19586085]
tr_loss:[0.13131547 0.46355748 0.14233068 0.11651713 0.10946608 0.13214491
 0.54212487 0.5221992  0.2447846  0.13132153 0.12333877 0.11599332
 0.11443283 0.13493606 0.51600736 0.12470058 0.13147677 0.1291194
 0.6763109  0.15139934 0.13461031 0.11370532 0.14488973 0.5906178
 0.13511582 0.13217813 0.46919307 0.3853176  0.10641818 0.56917244
 0.396157   0.48401585 0.2667113  0.5171878  0.37917808 0.11326833
 0.14201482 0.11969505 0.13290656 0.4655099  0.12696585 0.12603912
 0.1173631  0.27661952 0.13131554 0.14733753 0.1322386  0.13493586
 0.11883309 0.1135605 ]
tr_loss:[0.11847657 0.11628175 0.3439166  0.10670908 0.23263915 0.3006549
 0.11789279 0.10341022 0.09271775 0.36084136 0.1104667  0.40450007
 0.11032798 0.6415852  0.6141795  0.09271771 0.42698678 0.5662252
 0.11304197 0.09258173 0.10400341 0.5593128  0.46431127 0.11877052
 0.11622868 0.31933022 0.12006031 0.11936168 0.55353606 0.38161644
 0.09628977 0.1076262  0.6212878  0.10441569 0.11621413 0.6419535
 0.10076781 0.32636875 0.10706095 0.3427731  0.120188   0.10698607
 0.11373023 0.38367885 0.35439134 0.5866151  0.11205127 0.11063508
 0.11320386 0.6071292 ]
tr_loss:[0.42044955 0.09710298 0.6101497  0.5718691  0.11317313 0.08000366
 0.07701407 0.07292438 0.08761511 0.11132667 0.60862225 0.10507973
 0.08334647 0.0747601  0.48116142 0.11250873 0.07737327 0.10288221
 0.07120802 0.07792078 0.07989503 0.07637674 0.07553853 0.10776073
 0.44366235 0.08018965 0.10038481 0.07612008 0.15880923 0.07491163
 0.39037958 0.09008399 0.07742818 0.48417586 0.0801015  0.3089164
 0.45391312 0.08444691 0.07435799 0.48572406 0.10684228 0.07449049
 0.08448248 0.07291958 0.10848282 0.07944261 0.06738049 0.06618951
 0.08926837 0.07751198]
tr_loss:[0.23304729 0.06974256 0.06953991 0.07637987 0.10827006 0.07671852
 0.06041204 0.08055682 0.10852084 0.07793668 0.50297517 0.07119359
 0.4343571  0.05387067 0.08214311 0.4254952  0.07421935 0.36902332
 0.05387137 0.07383746 0.51816094 0.4794976  0.05256964 0.06187279
 0.10859223 0.07065047 0.12300877 0.5305382  0.07002067 0.10746899
 0.08919235 0.0807512  0.06973995 0.33351725 0.57729715 0.07022443
 0.07584806 0.05387071 0.05969411 0.06894027 0.07279377 0.0669978
 0.07378834 0.07480198 0.06492294 0.59145224 0.7166253  0.39821345
 0.07400765 0.36344963]
tr_loss:[0.06383166 0.05595332 0.50010335 0.06813413 0.05331354 0.07883602
 0.06687918 0.06687709 0.39968315 0.07235155 0.0639504  0.39337498
 0.10665616 0.09021035 0.05519264 0.44911903 0.05401652 0.06580846
 0.06449715 0.38671106 0.46779624 0.07613308 0.08989106 0.08302882
 0.09640449 0.4306778  0.05331347 0.31766707 0.06013596 0.06419064
 0.05414093 0.09309545 0.10371981 0.39781648 0.62212646 0.481428
 0.09920792 0.09331302 0.08013658 0.3471369  0.06383002 0.06883859
 0.05401647 0.09119813 0.32733685 0.06766839 0.06502612 0.05700942
 0.10546513 0.07074179]
tr_loss:[0.08305997 0.0762224  0.49687153 0.1772548  0.06149275 0.5054844
 0.09254308 0.06721152 0.05676712 0.52968395 0.33677027 0.09230974
 0.34990978 0.08545172 0.5322606  0.05926687 0.5364065  0.48493415
 0.05783505 0.06533504 0.42831975 0.48258987 0.33969447 0.06239138
 0.34473103 0.10019374 0.06405393 0.09937008 0.55510265 0.06522785
 0.0948349  0.38498405 0.425673   0.09138282 0.45414954 0.42276326
 0.3984418  0.06177809 0.45864868 0.09942134 0.06058542 0.05000168
 0.06696242 0.09980061 0.05055513 0.06621505 0.08975686 0.06056888
 0.0933241  0.3227307 ]
tr_loss:[0.49059838 0.5428866  0.48631924 0.08835356 0.06213974 0.05641552
 0.37385875 0.06412923 0.5263162  0.08769266 0.06337496 0.05828174
 0.07321264 0.09348448 0.3707422  0.05639349 0.05569975 0.4267777
 0.53222644 0.09224306 0.46377477 0.54100597 0.09225367 0.06564225
 0.06950724 0.14356093 0.06072088 0.4530661  0.08498216 0.06670301
 0.3373931  0.04554131 0.5951003  0.34854206 0.05911919 0.39046544
 0.08961257 0.06319688 0.07028862 0.07367562 0.07378361 0.12373789
 0.08175252 0.06251452 0.05802929 0.06210415 0.09453388 0.06001824
 0.6369799  0.05308729]
tr_loss:[0.05434464 0.04457068 0.56527656 0.06116631 0.3014048  0.5336984
 0.06248321 0.44529194 0.32756504 0.32470745 0.08309976 0.05344323
 0.07877835 0.05632993 0.04263314 0.04995421 0.04613964 0.22985244
 0.08546463 0.4341918  0.5153572  0.05437367 0.05108426 0.07807936
 0.08259239 0.05794754 0.08171538 0.07818922 0.08581875 0.63819444
 0.07767132 0.35425407 0.48896176 0.1340049  0.05389302 0.05553757
 0.0843211  0.41678563 0.2518267  0.05724923 0.08616199 0.6213061
 0.60638225 0.06141802 0.38178897 0.04893946 0.04381728 0.40239915
 0.34508598 0.44914293]
tr_loss:[0.0771507  0.2850118  0.07386509 0.06574877 0.05328725 0.07094462
 0.04769359 0.07672233 0.06159506 0.45302087 0.6645229  0.05094172
 0.5800586  0.27376252 0.24493647 0.43453065 0.05093389 0.03362441
 0.03458702 0.06248422 0.03362442 0.05073279 0.2880319  0.04556987
 0.6083203  0.06500109 0.06433581 0.50616586 0.04640456 0.06513183
 0.5662802  0.03996336 0.48144007 0.03362108 0.03362438 0.03952465
 0.46794215 0.03362439 0.5688431  0.03952532 0.5332761  0.35183412
 0.07884748 0.04068683 0.07972132 0.04959174 0.06419984 0.2624658
 0.08589782 0.05332748]
tr_loss:[0.03960841 0.5332477  0.052309   0.06983246 0.05146732 0.40436807
 0.29839423 0.32494655 0.05261947 0.44947958 0.07287093 0.0523826
 0.0330703  0.07309344 0.07865084 0.26654032 0.43343145 0.04786216
 0.07358987 0.41911477 0.07646364 0.29864693 0.05276554 0.06978227
 0.3762148  0.07354314 0.5078202  0.38257465 0.21934478 0.27578783
 0.05891658 0.15885553 0.2945428  0.07556821 0.07738539 0.06501569
 0.03655215 0.43439808 0.3965662  0.03655236 0.07027467 0.05145333
 0.07404792 0.0478269  0.4603334  0.0391535  0.0405601  0.03705854
 0.05363256 0.04056071]
tr_loss:[0.02915531 0.04267358 0.29989758 0.0300638  0.07009889 0.35215396
 0.07536626 0.05625055 0.05603707 0.03235168 0.04164357 0.05140164
 0.06637706 0.2798423  0.5369938  0.3534123  0.09380204 0.0337546
 0.03861738 0.05329532 0.33898777 0.32036144 0.15640011 0.04140462
 0.0537141  0.38738093 0.06793155 0.03375302 0.04993196 0.4428749
 0.29293782 0.17859241 0.3742629  0.06607799 0.04136109 0.06955168
 0.28728104 0.12863247 0.04762169 0.3174413  0.04109461 0.29612762
 0.06738535 0.05374216 0.04188665 0.44415933 0.04183232 0.37651086
 0.05363363 0.03006379]
tr_loss:[0.30779457 0.03818067 0.26479912 0.04323215 0.0382571  0.5652959
 0.4005757  0.0481897  0.0424846  0.03673198 0.30515906 0.03756367
 0.03910041 0.06374741 0.03975337 0.26228604 0.43023214 0.4820525
 0.05684064 0.02425371 0.05069591 0.03814017 0.35647058 0.04459341
 0.06372352 0.06303708 0.28029925 0.38343874 0.06696971 0.0379374
 0.06368278 0.06611939 0.5343944  0.05240098 0.38111523 0.04725819
 0.06384951 0.42769566 0.04514139 0.2329082  0.35585237 0.28564543
 0.02451689 0.23770985 0.04264505 0.03681316 0.06761473 0.03839221
 0.04314367 0.05003333]
tr_loss:[0.37948877 0.0248488  0.06323979 0.03051651 0.06003147 0.45788354
 0.4781081  0.04677648 0.06436443 0.06070548 0.06021234 0.02925341
 0.03690196 0.5068364  0.34463966 0.03047748 0.03229923 0.07117779
 0.41551828 0.46725303 0.06005881 0.04728029 0.05489969 0.40530562
 0.4175141  0.0419163  0.44063225 0.04258737 0.06233366 0.0633582
 0.49454182 0.29044974 0.03040513 0.06274473 0.3306803  0.24202041
 0.04060691 0.42019472 0.358812   0.04646742 0.48759428 0.40126562
 0.04131076 0.06577498 0.33249244 0.33505315 0.03326144 0.43929535
 0.06025533 0.02390968]
tr_loss:[0.05834249 0.41231698 0.03121887 0.29335192 0.04800826 0.3472007
 0.36718565 0.26457024 0.03078712 0.05974256 0.0364309  0.06083871
 0.3252926  0.03658824 0.02653274 0.05596783 0.04478926 0.05145242
 0.05713899 0.06153129 0.05904789 0.02754416 0.03345835 0.05845705
 0.07711121 0.05406513 0.0383816  0.03188463 0.0602136  0.05995605
 0.03595082 0.06515834 0.0674961  0.03153332 0.04478923 0.0382353
 0.05629405 0.4866155  0.05284381 0.36816636 0.39669108 0.33314157
 0.24445562 0.30836588 0.03085667 0.04613006 0.422815   0.04085832
 0.02664034 0.32953638]
tr_loss:[0.05555116 0.02966061 0.4850753  0.4197926  0.2934574  0.21574369
 0.05789115 0.05180039 0.04289492 0.35219145 0.04448744 0.0289601
 0.29112586 0.05783712 0.04344609 0.01987851 0.27179334 0.04918484
 0.01987598 0.03178665 0.5121519  0.5590909  0.29874557 0.0300051
 0.0285552  0.05980403 0.3136146  0.03143285 0.0578618  0.5795
 0.20776252 0.03186079 0.03224706 0.06146682 0.02816871 0.04926743
 0.3968234  0.03978126 0.19131188 0.04075537 0.3751854  0.05825353
 0.34096336 0.24775925 0.23111275 0.03823101 0.02608421 0.02856638
 0.30921802 0.03499463]
tr_loss:[0.03584296 0.29706305 0.03001952 0.0555904  0.03416253 0.05035287
 0.03482335 0.38065013 0.0293153  0.03304871 0.0555589  0.05444128
 0.04674893 0.05505919 0.34151503 0.03792026 0.3234221  0.3512526
 0.03314174 0.03446537 0.05351428 0.05186238 0.0358699  0.30747
 0.04646661 0.04668153 0.20893665 0.2592916  0.18176843 0.05052545
 0.33365315 0.01978935 0.02224727 0.03042403 0.04132819 0.02732119
 0.02903162 0.0316843  0.04369309 0.05982307 0.34488907 0.01978936
 0.03336426 0.02495285 0.0322957  0.05412967 0.3988152  0.44881958
 0.02620671 0.31585115]
tr_loss:[0.01919824 0.05042196 0.12370574 0.38280135 0.04171955 0.02600548
 0.11028443 0.05226519 0.02652715 0.01940467 0.05115692 0.05159292
 0.5355016  0.3630312  0.40260902 0.25478023 0.05451548 0.02622315
 0.28453112 0.02523139 0.03237405 0.03088802 0.05432431 0.50897926
 0.30667862 0.02485066 0.31234366 0.02485067 0.527495   0.05058419
 0.02721277 0.42597467 0.32505253 0.39798766 0.44447786 0.04287592
 0.03062963 0.3711314  0.02496303 0.02848839 0.02936254 0.02314247
 0.17463517 0.03521186 0.40856656 0.2236216  0.04429192 0.04933046
 0.48719135 0.33449546]
tr_loss:[0.34949335 0.23925671 0.0286408  0.04351483 0.03057981 0.04686129
 0.04743424 0.43479475 0.03278067 0.02671288 0.20774403 0.4730002
 0.27580684 0.02652691 0.44786763 0.04655526 0.19848868 0.4031542
 0.3325838  0.34851316 0.0330389  0.04800615 0.02632731 0.02741417
 0.02517531 0.02444903 0.04521952 0.04558777 0.04850085 0.33723146
 0.04226203 0.06015425 0.0264746  0.46112442 0.04814431 0.03349852
 0.03879011 0.03899158 0.02328904 0.2327536  0.36894825 0.03123924
 0.48272553 0.03283425 0.23673424 0.0269945  0.30316672 0.02612806
 0.28118354 0.02727089]
tr_loss:[0.03084005 0.04361219 0.10434116 0.05455523 0.04499684 0.04867054
 0.05054398 0.20408769 0.21556048 0.02506845 0.02415941 0.46551952
 0.05504159 0.02209431 0.50609225 0.2855811  0.04813183 0.02594507
 0.04461928 0.02293425 0.02594506 0.03168088 0.29135442 0.05147473
 0.0295128  0.02833309 0.02920172 0.05374935 0.02437399 0.02960349
 0.05117559 0.04459486 0.03435611 0.0457991  0.22680314 0.43313384
 0.03169171 0.02427409 0.40005025 0.05235053 0.4627966  0.3708329
 0.35373858 0.05241309 0.0246193  0.02417666 0.0470508  0.04680122
 0.04444253 0.19877644]
tr_loss:[0.0212217  0.04533254 0.02452093 0.02781836 0.0469429  0.02048199
 0.04237118 0.024742   0.02202859 0.023612   0.03579307 0.27602562
 0.21639499 0.041936   0.02324944 0.32890424 0.02816999 0.01984697
 0.02746689 0.22463016 0.02361374 0.02117376 0.3173101  0.34206408
 0.02581303 0.30723354 0.02787043 0.02147501 0.4330247  0.59796363
 0.02134612 0.3515747  0.0431755  0.023612   0.04184613 0.24052027
 0.02119076 0.02730338 0.4787856  0.02886649 0.3493372  0.29118854
 0.3695396  0.02624405 0.23452778 0.02198879 0.02048227 0.02758438
 0.02331921 0.02437469]
tr_loss:[0.3695728  0.02147825 0.31481427 0.06831817 0.02300399 0.025301
 0.12839203 0.02673095 0.35348648 0.24495968 0.267942   0.02517636
 0.02699631 0.03406541 0.35389885 0.02673097 0.02114665 0.03946499
 0.3660895  0.03816547 0.04372098 0.43668562 0.3464455  0.02325599
 0.03840466 0.0442906  0.04625519 0.04301128 0.2727699  0.02094804
 0.02008051 0.02673095 0.40752172 0.35745054 0.42424336 0.37610105
 0.04212026 0.49588567 0.01636226 0.01628793 0.02632826 0.01797369
 0.03905765 0.38466796 0.0224603  0.02445728 0.01739277 0.01903784
 0.4429256  0.01885834]
tr_loss:[0.22045155 0.0460541  0.02414512 0.01974207 0.03700097 0.14616463
 0.03523617 0.01502468 0.0340751  0.01857961 0.02057149 0.03935648
 0.02502919 0.03898963 0.01487708 0.39026666 0.0181642  0.02526067
 0.39870402 0.01636644 0.0209866  0.4183576  0.01487421 0.48436445
 0.03567535 0.03957776 0.04860478 0.02210579 0.03465592 0.25452554
 0.50079143 0.04023247 0.03484457 0.01497211 0.03477706 0.02004563
 0.01848507 0.27254933 0.03938947 0.01956689 0.01851613 0.30379924
 0.29344472 0.33503717 0.01862661 0.03958712 0.1842726  0.02103059
 0.01636646 0.35430813]
tr_loss:[0.01790936 0.01238116 0.03414232 0.03951909 0.03404827 0.034337
 0.03391159 0.02373098 0.02071234 0.39862245 0.39220992 0.10638289
 0.01423517 0.3301856  0.4015294  0.4518613  0.44179344 0.02022775
 0.02220771 0.02232089 0.035163   0.03158791 0.02684687 0.03190787
 0.02174333 0.03573222 0.01533464 0.02126715 0.22107825 0.3716318
 0.03492721 0.01926787 0.39373893 0.36927348 0.0123811  0.03442057
 0.26349527 0.20189333 0.02768713 0.42484817 0.23221001 0.02392102
 0.03711243 0.02118057 0.02684679 0.02191081 0.02432083 0.31199512
 0.01887382 0.03053957]
tr_loss:[0.5305656  0.02209783 0.01359612 0.02095252 0.03668197 0.01205707
 0.01927298 0.3004226  0.03418374 0.03371649 0.0234351  0.03701675
 0.01169038 0.23471732 0.21995981 0.01931752 0.01101316 0.31021598
 0.33445746 0.01309655 0.19046304 0.02970681 0.02288277 0.01359612
 0.30640906 0.03272902 0.41519386 0.39708012 0.36536533 0.01450411
 0.03609861 0.41167846 0.35492554 0.285603   0.03372199 0.0130963
 0.35465333 0.03356246 0.03404724 0.02323855 0.20755935 0.02370672
 0.25606647 0.28691846 0.16542192 0.02395188 0.03893981 0.02037723
 0.02015907 0.08635865]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 900 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(901, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 901 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(902, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 902 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(903, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 903 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(904, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 904 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(905, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 905 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(906, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 906 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(907, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 907 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(908, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 908 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(909, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 909 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(910, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 910 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(911, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 911 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(912, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 912 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(913, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 913 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(914, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 914 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(915, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 915 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(916, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 916 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(917, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 917 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(918, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 918 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(919, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 919 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(920, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 920 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(921, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 921 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(922, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 922 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(923, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 923 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(924, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 924 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(925, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 925 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(926, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 926 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(927, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 927 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(928, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 928 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(929, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 929 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(930, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 930 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(931, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 931 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(932, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 932 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(933, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 933 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(934, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 934 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(935, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 935 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(936, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 936 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(937, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 937 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(938, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 938 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(939, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 939 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(940, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 940 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(941, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 941 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(942, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 942 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(943, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 943 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(944, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 944 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(945, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 945 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(946, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 946 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(947, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 947 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(948, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 948 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(949, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 949 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(950, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 950 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(951, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 951 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(952, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 952 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(953, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 953 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(954, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 954 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(955, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 955 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(956, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 956 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(957, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 957 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(958, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 958 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(959, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 959 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(960, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 960 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(961, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 961 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(962, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 962 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(963, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 963 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(964, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 964 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(965, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 965 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(966, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 966 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(967, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 967 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(968, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 968 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(969, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 969 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(970, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 970 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(971, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 971 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(972, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 972 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(973, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 973 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(974, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 974 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(975, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 975 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(976, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 976 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(977, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 977 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(978, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 978 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(979, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 979 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(980, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 980 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(981, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 981 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(982, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 982 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(983, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 983 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(984, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 984 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(985, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 985 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(986, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 986 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(987, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 987 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(988, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 988 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(989, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 989 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(990, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 990 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(991, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 991 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(992, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 992 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(993, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 993 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(994, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 994 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(995, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 995 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(996, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 996 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(997, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 997 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(998, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 998 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(999, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 999 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1000, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-900
text_input.shape
(1000, 14400)
learning_input_tmp.shape
(1000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1000, 80)
learning_output.shape
(750, 80)
Model: "sequential_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_21 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.6523562  0.7561569  1.0417877  0.7451089  0.48183078 0.5007262
 1.0344894  0.7747326  0.47075996 0.952981   1.0117868  0.72544044
 0.73188764 0.3536609  0.7494944  1.0433213  0.7550963  0.9880849
 0.748031   0.43733016 0.52891076 1.0256231  0.39054397 0.34753048
 0.5082483  0.47869787 0.46914482 0.45987687 0.4820386  0.50328565
 0.41776523 0.47626343 0.75916827 0.47389334 0.57977664 0.40430665
 1.0374982  0.48307267 0.9266942  0.75879204 0.422928   0.47108394
 0.47701198 0.5060879  0.77495486 0.47720155 0.36507016 0.7308202
 0.9528921  0.76723725]
tr_loss:[0.4627487  0.53760016 0.4887647  0.5036032  0.45260334 0.3435956
 0.56706196 0.4689055  0.5758884  0.5657605  0.5383595  0.5657605
 0.36143097 0.50184953 0.49171782 0.57043713 0.4695796  0.64681387
 0.40333167 0.36324912 0.36619306 0.5042575  0.6501457  0.5173464
 0.57588834 0.37036762 0.5926708  0.3601276  0.5028968  0.40105543
 0.39337218 0.62156934 0.5493876  0.468705   0.6412688  0.5848099
 0.44890222 0.46681    0.6420582  0.35738537 0.6330506  0.6251586
 0.50631684 0.508324   0.6411212  0.57588834 0.52583873 0.6179113
 0.6412586  0.47654414]
tr_loss:[0.3508739  0.39595303 0.3490161  0.49726877 0.3699546  0.348633
 0.30904737 0.3869772  0.31550807 0.35770506 0.40566888 0.3088433
 0.4779063  0.39332107 0.33711112 0.3092816  0.3749105  0.26665273
 0.38851985 0.32471165 0.49666756 0.4066204  0.26498803 0.25338444
 0.4617339  0.4441442  0.36427358 0.34797043 0.47051334 0.25929695
 0.26774845 0.5077303  0.389968   0.3084702  0.40566882 0.39647803
 0.47442216 0.2677327  0.36068487 0.43816185 0.4643467  0.5272572
 0.26333496 0.37381688 0.33735937 0.30793172 0.32062358 0.39749172
 0.26125988 0.34801787]
tr_loss:[0.24073043 0.38392794 0.22784343 0.23323718 0.23001575 0.38250375
 0.2254506  0.20318627 0.2251823  0.2219033  0.216881   0.25046214
 0.38334596 0.24430528 0.20363522 0.25835618 0.22393823 0.30942366
 0.3991503  0.28460503 0.218483   0.2343792  0.22517446 0.23652191
 0.21268947 0.20328459 0.21903054 0.25283676 0.44004494 0.24039707
 0.21943629 0.22932784 0.20158324 0.22389615 0.34560436 0.22952771
 0.23383863 0.24936242 0.22524388 0.22415364 0.22325893 0.24305168
 0.2243514  0.5081455  0.31540182 0.3169793  0.29985464 0.23625846
 0.24936238 0.22921029]
tr_loss:[0.140937   0.1368885  0.14009038 0.34568578 0.14144076 0.4268481
 0.14831123 0.42778015 0.1437639  0.1407384  0.1278483  0.19301376
 0.2137684  0.14400709 0.1441195  0.19192629 0.14386669 0.19806549
 0.3489929  0.13424742 0.15375738 0.20109129 0.35457453 0.13525125
 0.20349662 0.14432283 0.14285189 0.14069429 0.1464694  0.14646925
 0.14409073 0.20010328 0.14687474 0.12424314 0.20803109 0.14584407
 0.17056213 0.1471872  0.5405115  0.14646924 0.19527408 0.43436232
 0.14684783 0.19407538 0.14646928 0.41734856 0.16018434 0.3988121
 0.19743137 0.15053989]
tr_loss:[0.11771419 0.08867998 0.10243282 0.18164673 0.09555017 0.08875109
 0.22526784 0.356268   0.16489595 0.6086637  0.17885587 0.1262767
 0.1000561  0.24621642 0.11222206 0.1712286  0.15950802 0.15740202
 0.12869497 0.64546794 0.08715518 0.12890184 0.20188856 0.08926496
 0.23924895 0.2980833  0.17730953 0.17184038 0.11037968 0.13967091
 0.10913455 0.08667462 0.11130798 0.08421221 0.5416802  0.1088236
 0.43840924 0.08696351 0.17159763 0.16036716 0.08383235 0.16844822
 0.14075653 0.08714606 0.12914923 0.13032857 0.10005627 0.42699903
 0.1043721  0.1673527 ]
tr_loss:[0.08291373 0.13069844 0.12443116 0.11598841 0.10009544 0.3945362
 0.08739825 0.0787463  0.06426976 0.4215203  0.08752197 0.13073522
 0.09228721 0.4974679  0.07577124 0.15156095 0.5490801  0.07225285
 0.4009556  0.12213893 0.06426974 0.1406914  0.59994465 0.08046861
 0.07666932 0.08236096 0.45641392 0.4691429  0.10329032 0.5888072
 0.09274115 0.08712376 0.15825799 0.15039897 0.0884426  0.08956413
 0.5758192  0.12224527 0.20681019 0.4003322  0.1463826  0.08752327
 0.15329853 0.11971845 0.13404362 0.14866096 0.13680163 0.07975286
 0.07225283 0.08947991]
tr_loss:[0.08508775 0.41309017 0.07306509 0.1208233  0.09113825 0.0950657
 0.09604292 0.08263131 0.5930832  0.11896304 0.07432099 0.08600144
 0.09252483 0.08690853 0.08735029 0.15700164 0.13915667 0.56616133
 0.08498038 0.35419816 0.35876936 0.13644187 0.08719139 0.09450653
 0.13180777 0.0977366  0.09233341 0.4940049  0.0858437  0.09526926
 0.15863697 0.08751239 0.09772144 0.3870841  0.13617344 0.08760863
 0.0843576  0.08921472 0.14908384 0.09761824 0.0820852  0.07577287
 0.08640768 0.09974428 0.16006216 0.09095768 0.08811708 0.09357931
 0.09529079 0.08184122]
tr_loss:[0.09775463 0.44029206 0.10611875 0.19337337 0.09662535 0.4154994
 0.16011679 0.07947447 0.08745579 0.45161757 0.09705923 0.09757634
 0.5841745  0.09656225 0.11221949 0.07676546 0.13742742 0.10552974
 0.08557285 0.09554483 0.07371244 0.15281829 0.08887645 0.10287787
 0.15905955 0.09824201 0.07940343 0.07124291 0.10210874 0.10341058
 0.5631607  0.46498522 0.54110277 0.15932652 0.08719091 0.1010978
 0.0726965  0.13478315 0.44638062 0.11192844 0.06506403 0.08127675
 0.13427448 0.07940347 0.12829295 0.15639909 0.08294176 0.10531718
 0.09518751 0.0794035 ]
tr_loss:[0.09282745 0.46668702 0.05943698 0.4903234  0.10677443 0.09333408
 0.09618723 0.40946198 0.08764176 0.1299406  0.3829772  0.08346
 0.41673094 0.09549202 0.4288726  0.4861842  0.13381144 0.09139912
 0.27934104 0.10758124 0.46234766 0.08879046 0.39883858 0.1447779
 0.3271315  0.08761799 0.10743584 0.13367358 0.06550761 0.3976492
 0.10681815 0.05633353 0.09749035 0.06640311 0.07678497 0.08314897
 0.27106053 0.08294635 0.0886488  0.5897035  0.09439134 0.13528182
 0.07618808 0.54971516 0.1017554  0.08078152 0.09563611 0.4474547
 0.06026071 0.12597156]
tr_loss:[0.11034654 0.3631264  0.07415763 0.07626496 0.07209822 0.05038745
 0.07606474 0.07445408 0.06737167 0.32935834 0.08204684 0.05038742
 0.13118024 0.36052424 0.07894261 0.07059444 0.06286865 0.08469898
 0.06520993 0.08346575 0.06655388 0.26458982 0.0881875  0.07948623
 0.07749739 0.3238492  0.08346579 0.40134946 0.07144733 0.65102494
 0.1278017  0.06565326 0.08552956 0.08003731 0.38445455 0.07421166
 0.13204542 0.06165562 0.09729217 0.07316055 0.05396581 0.07114147
 0.07825001 0.07660999 0.07177428 0.06352067 0.07830484 0.05787338
 0.0858107  0.11796646]
tr_loss:[0.576105   0.05642042 0.06321485 0.07455486 0.4679955  0.30632836
 0.1131433  0.07259885 0.05168195 0.07696684 0.04650036 0.09010705
 0.0769902  0.38352627 0.05560397 0.05817245 0.35622114 0.06506461
 0.12167408 0.09518914 0.1155741  0.3160598  0.07294942 0.05658164
 0.05353525 0.06140941 0.05434976 0.11706245 0.48698634 0.4371756
 0.05434976 0.4362034  0.06129647 0.2835949  0.06140583 0.11538158
 0.371376   0.41081104 0.06262078 0.05308396 0.05846571 0.06937142
 0.5059556  0.15294734 0.0696616  0.06712906 0.06763054 0.09045721
 0.04999609 0.06266318]
tr_loss:[0.09663926 0.41894698 0.0990871  0.10266104 0.06018685 0.07859199
 0.06683409 0.06024797 0.070829   0.06891521 0.0388561  0.06042397
 0.06698658 0.2721083  0.15689063 0.05799659 0.06810887 0.06719366
 0.06694868 0.06142817 0.38289255 0.06025344 0.06600013 0.09591917
 0.4100698  0.10044118 0.08062927 0.06751044 0.06817542 0.07192706
 0.06868412 0.08066681 0.0585769  0.06748269 0.6095193  0.4501071
 0.06727739 0.36713624 0.44420996 0.06777207 0.06183587 0.06373228
 0.0891537  0.5049263  0.08274826 0.05940412 0.06624185 0.09837805
 0.09526974 0.06900059]
tr_loss:[0.44616055 0.34614205 0.05342316 0.06866159 0.06020465 0.0519283
 0.06143171 0.05755908 0.05416195 0.09722774 0.5599941  0.04949795
 0.05698102 0.05635355 0.44147587 0.08660914 0.0603121  0.500697
 0.0824305  0.06080096 0.06200097 0.06684884 0.08481076 0.09326451
 0.06292655 0.27307573 0.05958291 0.06282574 0.06493695 0.08562078
 0.40416986 0.07433923 0.05071341 0.05818103 0.51559347 0.04849388
 0.06093255 0.43866715 0.05589852 0.39122105 0.0563535  0.05811628
 0.0621589  0.25973243 0.0829424  0.51341295 0.05098822 0.06148083
 0.04841865 0.05529829]
tr_loss:[0.22641154 0.0507869  0.05773634 0.06377355 0.06952865 0.3646849
 0.06560586 0.05403678 0.05740079 0.04954892 0.05202017 0.0547512
 0.05448028 0.05951164 0.50569284 0.05801218 0.05178375 0.07440908
 0.06498029 0.05500508 0.06246803 0.0829271  0.05041449 0.0539422
 0.40406337 0.06213982 0.05102857 0.05102917 0.08092445 0.0470484
 0.2928074  0.05500504 0.07187653 0.06319475 0.05956621 0.06103712
 0.05957273 0.08047962 0.07793199 0.35170078 0.39614168 0.70676196
 0.2611094  0.06885727 0.05071052 0.05842343 0.0960521  0.07475464
 0.05988215 0.05102854]
tr_loss:[0.08014975 0.08181728 0.04099045 0.05205464 0.04172779 0.08154921
 0.05250107 0.05934093 0.07945821 0.07593024 0.3613351  0.08949872
 0.08828757 0.06525718 0.07090157 0.38787654 0.35212564 0.07074554
 0.0881796  0.05658542 0.05253553 0.07474543 0.07941236 0.05273577
 0.07665453 0.08044811 0.0755114  0.44342965 0.04214656 0.4993294
 0.3387197  0.08116028 0.4220732  0.05338272 0.02821181 0.06635918
 0.039794   0.27928945 0.0551879  0.04651088 0.05331863 0.05282168
 0.08061387 0.04099044 0.05335852 0.08094151 0.05466286 0.24223968
 0.07436933 0.07087114]
tr_loss:[0.24690881 0.04465787 0.04952205 0.1885263  0.05007445 0.05110047
 0.04333177 0.04623032 0.04466208 0.14655149 0.04754391 0.03260299
 0.04408222 0.47945642 0.03262205 0.04209219 0.49717227 0.33398527
 0.26289517 0.2854889  0.46912622 0.03777736 0.37429678 0.24532786
 0.16519889 0.07599924 0.04144584 0.05357655 0.0441677  0.04399338
 0.05417888 0.38754457 0.04185643 0.04895216 0.06570055 0.06716999
 0.04690112 0.03260414 0.04679861 0.04164568 0.06668472 0.29657418
 0.07748612 0.04425774 0.06156636 0.45690638 0.04660199 0.06199014
 0.04507028 0.04384595]
tr_loss:[0.03819596 0.03979816 0.02583257 0.34302154 0.03277975 0.02909497
 0.33913177 0.03230123 0.50766116 0.04749069 0.03470878 0.06176969
 0.0448858  0.04615644 0.03218121 0.3555387  0.03208203 0.05944716
 0.5914018  0.04377215 0.33915085 0.04926397 0.06095613 0.0607257
 0.03017833 0.03201405 0.04386259 0.06167721 0.05845632 0.07285766
 0.03210676 0.35476032 0.02953016 0.02570789 0.03218121 0.4086843
 0.03051586 0.04403163 0.07520969 0.02571912 0.32618737 0.03575449
 0.03456611 0.04157997 0.02583067 0.03218134 0.05358713 0.02597919
 0.04220346 0.03575452]
tr_loss:[0.40346795 0.03549951 0.41854733 0.05809822 0.48555833 0.04129852
 0.04455507 0.03268027 0.02755806 0.03483532 0.06244248 0.04593735
 0.34551954 0.44270077 0.27223098 0.40679646 0.02356183 0.05529344
 0.04653122 0.0613867  0.02815871 0.02788136 0.05502099 0.32040405
 0.02351525 0.04909263 0.16777459 0.02351524 0.23835823 0.03805377
 0.06295858 0.02183431 0.09639381 0.05806048 0.03055084 0.03552001
 0.48291987 0.24636987 0.06037821 0.27984363 0.03131474 0.06066724
 0.06525455 0.29653198 0.02512931 0.06251444 0.03043161 0.0209884
 0.02815873 0.3165669 ]
tr_loss:[0.03033262 0.03834626 0.08441298 0.03776873 0.02501203 0.29889917
 0.06186365 0.03830169 0.02560156 0.05348327 0.0232891  0.44005075
 0.05037061 0.37061337 0.04446398 0.03730207 0.0615987  0.0191436
 0.03437812 0.4797399  0.05388837 0.04572858 0.03700892 0.06193774
 0.08058603 0.03251436 0.06284584 0.04720327 0.03894701 0.2607254
 0.03067962 0.03946263 0.05884521 0.03091032 0.01914237 0.0389715
 0.03780432 0.0254268  0.03751428 0.03820021 0.08186378 0.03044707
 0.04509802 0.06139884 0.05185678 0.05022025 0.0559549  0.04462998
 0.04086559 0.02798061]
tr_loss:[0.02061082 0.03141249 0.2519327  0.0280844  0.19750461 0.0591669
 0.03899362 0.02426569 0.05709811 0.27516013 0.03974066 0.06434792
 0.02427815 0.38555592 0.02109506 0.06337829 0.35473892 0.02109507
 0.03404151 0.0275959  0.40518126 0.12499714 0.23997936 0.03462642
 0.33572212 0.05239993 0.3795258  0.2879078  0.04470475 0.03472991
 0.05624083 0.06368225 0.38421425 0.05035477 0.02096831 0.41599193
 0.05503024 0.05994419 0.06246759 0.3116188  0.03758978 0.05620436
 0.05019777 0.05298135 0.03514468 0.02814387 0.03567893 0.0206108
 0.04715364 0.02619758]
tr_loss:[0.5097144  0.0413328  0.02344732 0.04600336 0.039893   0.03354926
 0.03372135 0.43301636 0.04031121 0.03244233 0.03031341 0.0595384
 0.02886157 0.03036176 0.33993822 0.04756012 0.06928301 0.03942754
 0.2762487  0.03206722 0.04066253 0.4603281  0.09289221 0.03055264
 0.06117032 0.02742713 0.03240954 0.0422866  0.02464464 0.06422675
 0.06922916 0.40355283 0.03122773 0.03955124 0.04006924 0.06537884
 0.064244   0.04308304 0.07888457 0.06763235 0.0456862  0.03597064
 0.05203335 0.05550308 0.03767676 0.04616867 0.03471187 0.07669425
 0.03468894 0.03575196]
tr_loss:[0.36037835 0.02917351 0.0289677  0.06220549 0.3165416  0.2920668
 0.0607783  0.062384   0.02678165 0.13239455 0.04272288 0.06272478
 0.01869018 0.02539998 0.04167379 0.32509297 0.20193978 0.02704581
 0.04815053 0.05297044 0.05131029 0.03119028 0.04209394 0.0400517
 0.06007916 0.02917349 0.04778079 0.04100345 0.06205876 0.3877161
 0.0602015  0.25314435 0.02754069 0.04748402 0.04358771 0.06218227
 0.03897791 0.03943899 0.33509284 0.35942525 0.03167897 0.02896772
 0.04399022 0.03302332 0.05006343 0.04790532 0.34517813 0.04349778
 0.0307559  0.02647341]
tr_loss:[0.02183123 0.03772474 0.19574155 0.03477412 0.0348547  0.3625616
 0.05978339 0.02671377 0.06103912 0.25063792 0.04076893 0.04834125
 0.0601694  0.03098151 0.33631366 0.42999625 0.0267138  0.477079
 0.03808072 0.05971958 0.02547653 0.02651783 0.05894046 0.35674018
 0.2607728  0.03001165 0.02977022 0.04856021 0.02651778 0.33905753
 0.04557768 0.04974505 0.27332166 0.44107503 0.04276793 0.39436534
 0.0593247  0.02982107 0.03529716 0.03492878 0.01662955 0.33275008
 0.3734347  0.0268216  0.32246724 0.04715994 0.04721919 0.03438334
 0.03775755 0.02972426]
tr_loss:[0.02943683 0.03700799 0.05477449 0.02942524 0.02299124 0.03449279
 0.02232032 0.01571813 0.05569901 0.0367761  0.05507269 0.03359566
 0.05723023 0.02193737 0.3499334  0.03476226 0.03273232 0.40873832
 0.32934594 0.04125986 0.02471507 0.02980188 0.0573541  0.04509305
 0.41818342 0.0331087  0.05662091 0.0418786  0.03567349 0.02998222
 0.05722668 0.03686183 0.03256138 0.03377174 0.03363837 0.33251986
 0.46931013 0.0303961  0.03420758 0.02913177 0.0223607  0.407
 0.03143163 0.03291085 0.03557422 0.03071221 0.0309196  0.02450923
 0.03140074 0.03052852]
tr_loss:[0.0604509  0.0227627  0.03335594 0.31290907 0.02198728 0.0370431
 0.04883876 0.43521184 0.05889328 0.02836096 0.02448916 0.04440875
 0.502638   0.05194717 0.11784818 0.05177253 0.03633792 0.02483442
 0.02589838 0.3193275  0.3305277  0.30142036 0.01902185 0.03472137
 0.03086157 0.02427752 0.05316362 0.05281646 0.03963001 0.01984534
 0.06268612 0.05390928 0.02938734 0.04143845 0.28770906 0.49255514
 0.03443795 0.02728033 0.02448849 0.03629166 0.02592372 0.02761951
 0.30015272 0.17248651 0.05618718 0.02727476 0.02606444 0.02946864
 0.03234879 0.03218033]
tr_loss:[0.02981551 0.30730385 0.02282009 0.02345636 0.019863   0.01986302
 0.28979188 0.04621682 0.04911887 0.0273653  0.01979598 0.0466804
 0.4012974  0.02267368 0.42027313 0.02105506 0.04093672 0.02529258
 0.02546782 0.04173367 0.04013184 0.02545114 0.0276511  0.0483982
 0.02991581 0.03265322 0.05573016 0.03986456 0.05031698 0.05066547
 0.0459029  0.04690424 0.30386662 0.3867105  0.04660156 0.03692323
 0.27211004 0.02696778 0.02276804 0.43913287 0.04660447 0.02646906
 0.3286076  0.02445879 0.01768441 0.31584424 0.39614305 0.30554608
 0.01931873 0.0403423 ]
tr_loss:[0.04310673 0.02512723 0.21064559 0.048085   0.43154985 0.05062383
 0.02669325 0.26924458 0.25318468 0.02606352 0.02851661 0.04255851
 0.01914926 0.03994117 0.3365614  0.33881837 0.01899954 0.02471191
 0.02769851 0.54236156 0.01701258 0.0446507  0.020751   0.3937579
 0.04140582 0.42772302 0.01589127 0.01830641 0.31578732 0.0232993
 0.01939665 0.05521978 0.4387371  0.03718207 0.0250174  0.02913399
 0.02682604 0.01976705 0.04877584 0.02302239 0.0377803  0.02467483
 0.02554635 0.03730109 0.02356922 0.02327363 0.02561766 0.28605086
 0.04203818 0.01920096]
tr_loss:[0.26312652 0.05219302 0.02396636 0.01987453 0.02072885 0.05361799
 0.25941926 0.31163716 0.03681617 0.04179905 0.25140807 0.04125883
 0.3986186  0.02265064 0.04395941 0.02357772 0.02449807 0.48815536
 0.02529407 0.02265101 0.43398887 0.02727193 0.01691624 0.03793111
 0.37256235 0.02254061 0.01921507 0.02152858 0.04028042 0.02449238
 0.02773033 0.02101067 0.02697857 0.02644167 0.01921088 0.04241762
 0.02353667 0.01672653 0.02750059 0.04844579 0.04294543 0.02375087
 0.02014583 0.04466716 0.0248138  0.4243493  0.02204528 0.17478313
 0.34667927 0.04273318]
tr_loss:[0.25842756 0.03027752 0.02343516 0.042055   0.0200951  0.02478069
 0.01872111 0.02738738 0.04028695 0.37952352 0.23725648 0.04101225
 0.02599373 0.03784439 0.02177948 0.02013449 0.04044289 0.04085906
 0.03704532 0.09052608 0.02177947 0.02132102 0.46794963 0.01828936
 0.03485239 0.04453039 0.04172872 0.03410529 0.02215697 0.02631416
 0.02389323 0.02190216 0.01872551 0.02632891 0.3213954  0.04104834
 0.02315684 0.31936535 0.01756026 0.03734934 0.02190217 0.02190216
 0.4176442  0.03993446 0.2695761  0.02877526 0.03366185 0.18521813
 0.03954435 0.3675692 ]
text_input.shape
(1000, 14400)
learning_input_tmp.shape
(1000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1000, 80)
learning_output.shape
(750, 80)
Model: "sequential_22"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_22 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.8913166  0.6240076  0.73312545 0.51889324 0.43648833 0.7465476
 0.7217677  0.8379568  0.92014486 0.8455852  0.7147081  0.5984889
 0.7903789  0.91674596 0.88844174 0.52370656 0.4363473  0.50524116
 0.71406966 0.75856227 0.75136167 0.78526676 0.4954988  0.7094158
 0.91053504 0.4785959  0.8844536  0.5113227  0.89098966 0.8040911
 0.913288   0.70826685 0.51586777 0.88849735 0.3222958  0.5088609
 0.525103   0.51217735 0.7565877  0.79357034 0.8913166  0.9227375
 0.91053516 0.520031   0.5229562  0.8823743  0.8448561  0.91549367
 0.8068787  0.5183404 ]
tr_loss:[0.37613794 0.49627376 0.5871504  0.5599579  0.4768606  0.4474062
 0.3657747  0.4954496  0.47925854 0.49082175 0.55164605 0.49097905
 0.6232457  0.4798929  0.36398807 0.6440474  0.39637226 0.48929328
 0.63077325 0.6064161  0.49332127 0.49629432 0.63780195 0.5318694
 0.3328496  0.48695746 0.4959538  0.5768396  0.6004217  0.52833414
 0.47788    0.5081463  0.48875046 0.49197847 0.37780485 0.35563
 0.6353091  0.41417933 0.5871503  0.47119227 0.58697027 0.6452278
 0.46113473 0.5487169  0.61915433 0.59989613 0.63144326 0.49557143
 0.47629672 0.6271328 ]
tr_loss:[0.29256803 0.35389608 0.4082775  0.34308255 0.35622853 0.31433788
 0.30303735 0.5178081  0.30360845 0.22809859 0.3794352  0.25355473
 0.53954506 0.30102283 0.29626873 0.3045114  0.22778077 0.74522686
 0.3005448  0.30676395 0.6497366  0.29245478 0.34498295 0.29817313
 0.29768106 0.22623464 0.30292654 0.29870024 0.42585364 0.22155991
 0.57678205 0.30086    0.2297452  0.37320572 0.32435414 0.4164242
 0.6171782  0.63858813 0.2651349  0.30324203 0.30428123 0.42976794
 0.58062613 0.29946905 0.32478905 0.23729415 0.29890895 0.29690018
 0.2889832  0.3909523 ]
tr_loss:[0.4068029  0.42978573 0.221892   0.19018202 0.21868877 0.19354217
 0.5136239  0.20033225 0.5578016  0.25346175 0.16828689 0.20612185
 0.42530403 0.1697636  0.20716581 0.17246771 0.2230558  0.19830807
 0.19440174 0.20274568 0.16309953 0.21591239 0.20164709 0.20373578
 0.23131041 0.4929758  0.19236293 0.24922152 0.20740333 0.41393232
 0.22732496 0.23885545 0.20042333 0.19578986 0.19174273 0.1763393
 0.32119125 0.20117362 0.18800113 0.21333559 0.39768273 0.18380791
 0.16138987 0.17099553 0.58413523 0.20115058 0.16918345 0.32171923
 0.17172301 0.4433427 ]
tr_loss:[0.14395586 0.14938185 0.09833542 0.14884472 0.15958123 0.11265548
 0.32380652 0.33478862 0.3748011  0.36604998 0.16469164 0.11840846
 0.46281824 0.11360534 0.12750642 0.10684631 0.13135247 0.11877587
 0.09437031 0.13453308 0.387169   0.49802858 0.14867143 0.37598565
 0.11840843 0.09667146 0.15792874 0.11840854 0.09445477 0.1514499
 0.12024669 0.43251377 0.1240628  0.1310161  0.10660873 0.16113676
 0.15799773 0.13397238 0.12583444 0.09604464 0.610359   0.10435047
 0.37378544 0.13063014 0.15601087 0.15693952 0.12628552 0.15192568
 0.11067798 0.11074145]
tr_loss:[0.09340421 0.08171014 0.07378989 0.07852419 0.10010324 0.08961572
 0.07347667 0.10111264 0.07915714 0.13004127 0.08219595 0.07142109
 0.36745137 0.15765236 0.5120077  0.43974537 0.09221311 0.1209539
 0.10809775 0.14683571 0.12086029 0.08171273 0.36871922 0.07101391
 0.12893546 0.08422588 0.5374107  0.37950718 0.08772496 0.07451966
 0.1450351  0.47429332 0.5108496  0.0744193  0.46888742 0.43863654
 0.12010336 0.45271462 0.08965348 0.0769449  0.07772027 0.09425536
 0.08015794 0.08683799 0.0848213  0.09745085 0.06999396 0.12463031
 0.07868006 0.07405876]
tr_loss:[0.09109819 0.44631967 0.06632967 0.40457392 0.06536259 0.0870134
 0.09067214 0.06642875 0.06867425 0.06942514 0.44241238 0.0803469
 0.15636317 0.06966398 0.07867175 0.27496466 0.11801367 0.64380246
 0.46084833 0.06024675 0.05269013 0.06250754 0.5239424  0.06020628
 0.15306656 0.07334214 0.08045958 0.45665208 0.4742526  0.08887962
 0.06422635 0.0526901  0.06252516 0.07393111 0.10017991 0.06803875
 0.15655808 0.55849606 0.12015285 0.06975086 0.42195433 0.10078019
 0.06024673 0.47336188 0.07794813 0.06436447 0.07719265 0.06555646
 0.11872196 0.06311138]
tr_loss:[0.05496202 0.04114102 0.14573073 0.04731288 0.15096195 0.05895724
 0.04517399 0.45966607 0.08860622 0.07970743 0.08191836 0.08464137
 0.09814315 0.2697491  0.05083843 0.22408693 0.0563023  0.15559678
 0.42140657 0.04877666 0.0421705  0.0874275  0.08795955 0.0421702
 0.06075335 0.04517397 0.05282827 0.09720025 0.04656888 0.35441464
 0.09494896 0.07541417 0.05951525 0.5257392  0.57031035 0.04854239
 0.04216765 0.08870738 0.10579146 0.10070251 0.09404112 0.04517416
 0.34654856 0.0429729  0.0596035  0.06449424 0.06764801 0.14907849
 0.36097217 0.04324403]
tr_loss:[0.37389162 0.07518387 0.06942424 0.04538513 0.14599672 0.03900471
 0.04529895 0.03638601 0.15733765 0.55317795 0.146283   0.15030864
 0.08978497 0.50639015 0.48350173 0.08343197 0.03827259 0.44618565
 0.38771853 0.05031341 0.04147507 0.10943638 0.08369161 0.08398504
 0.37993076 0.09035595 0.08948932 0.03758822 0.11461268 0.03887608
 0.08149035 0.05915853 0.08423574 0.4994564  0.04978773 0.08612411
 0.4050247  0.05666287 0.46028155 0.08644934 0.08427664 0.14522925
 0.03073896 0.08580221 0.15297166 0.49676532 0.42440596 0.07426252
 0.05535102 0.33823755]
tr_loss:[0.06722192 0.14763054 0.049148   0.03964404 0.0745133  0.4546892
 0.06596122 0.05188925 0.05921371 0.07192618 0.04890138 0.554857
 0.06776828 0.3631478  0.07820181 0.08109632 0.04589576 0.09532581
 0.05431347 0.07919873 0.4298745  0.04866912 0.06015478 0.08327852
 0.1465414  0.4646454  0.08094651 0.06153731 0.06169107 0.1479135
 0.08820125 0.09668405 0.07959384 0.13952795 0.14280066 0.140713
 0.03539039 0.38103133 0.13829294 0.31567812 0.5118398  0.48900574
 0.04448421 0.04821188 0.07571375 0.14358512 0.07132997 0.56679344
 0.04866999 0.66653633]
tr_loss:[0.04046597 0.07357549 0.06729381 0.06369935 0.45207962 0.06472443
 0.05170165 0.07062284 0.10709789 0.07787496 0.0878979  0.12606199
 0.31301063 0.06243271 0.12500986 0.1311009  0.066605   0.05399669
 0.040466   0.08576881 0.14480755 0.04529383 0.07397157 0.06558321
 0.05577535 0.09637084 0.13637125 0.44873935 0.06594025 0.3915359
 0.43018255 0.06913449 0.06324813 0.05482283 0.06829438 0.07025925
 0.04514755 0.09531772 0.47012323 0.06838409 0.05520959 0.06855187
 0.06927623 0.06846626 0.05509204 0.05487886 0.0624548  0.06786755
 0.05834514 0.07818017]
tr_loss:[0.04658695 0.04402007 0.31534624 0.06437887 0.05033124 0.04714365
 0.51483095 0.0686648  0.05218993 0.09470772 0.05333285 0.09335326
 0.06977896 0.08499436 0.07207634 0.51202524 0.09597851 0.05653898
 0.36462465 0.09506512 0.07382272 0.05868642 0.06969257 0.06784676
 0.07352041 0.07691232 0.36285692 0.09613734 0.5062844  0.0407454
 0.5190059  0.4923214  0.04733299 0.063515   0.04733165 0.04876183
 0.05924131 0.12190487 0.07573763 0.12533537 0.17752261 0.11788456
 0.07957577 0.07043512 0.07350097 0.34570968 0.0407454  0.19415705
 0.2821141  0.04965614]
tr_loss:[0.33883998 0.04469391 0.07760731 0.524195   0.04535817 0.05543594
 0.10343941 0.42633453 0.0772372  0.1094685  0.11036207 0.06148013
 0.06187244 0.07866444 0.188307   0.047842   0.07307117 0.04818927
 0.0470972  0.30996627 0.04972555 0.04698407 0.0770704  0.26868373
 0.07328586 0.04356287 0.04469509 0.35985392 0.04469392 0.42809024
 0.3772421  0.07479227 0.27302724 0.10356914 0.05702084 0.04535873
 0.07406767 0.04784191 0.04467835 0.10808484 0.07036151 0.04073951
 0.54204667 0.05082551 0.06642663 0.07049712 0.05225263 0.41693574
 0.0469841  0.11029004]
tr_loss:[0.10516503 0.04015514 0.06715058 0.04616016 0.03731127 0.06688657
 0.06688663 0.06893108 0.07013296 0.3952995  0.1012304  0.09255477
 0.04831894 0.10275743 0.04585702 0.03833738 0.04642162 0.09483923
 0.0407504  0.0351744  0.04595258 0.10597079 0.03833739 0.04775078
 0.04684126 0.0383378  0.09696276 0.10028173 0.06438498 0.0368442
 0.2883273  0.10086399 0.05205778 0.06367669 0.09803949 0.04373988
 0.04578964 0.27454203 0.04785243 0.39460456 0.10556314 0.39555356
 0.06682439 0.06514569 0.10147271 0.0437399  0.09265096 0.0625459
 0.6118165  0.07058775]
tr_loss:[0.06239636 0.04681351 0.09184925 0.05783991 0.04163144 0.51102036
 0.04478002 0.06052833 0.08991088 0.04163314 0.04108728 0.08410107
 0.04229074 0.5731872  0.0309668  0.03314061 0.05549253 0.3751759
 0.2748328  0.0385032  0.362929   0.0418955  0.40370846 0.08149441
 0.3588591  0.36563367 0.09354622 0.5765236  0.05059034 0.05088954
 0.04545435 0.08944608 0.02789674 0.07369182 0.08525525 0.42931944
 0.0872073  0.3745733  0.06305293 0.06530394 0.04500419 0.03854263
 0.05737994 0.05459867 0.04640058 0.0618784  0.15932216 0.03670515
 0.44468433 0.08910004]
tr_loss:[0.08390702 0.0483468  0.05505601 0.06325616 0.03986803 0.05317538
 0.07377932 0.03495885 0.3103578  0.5534282  0.08450794 0.12334818
 0.37796238 0.08283069 0.08267593 0.454307   0.0414359  0.06499194
 0.04008294 0.5303378  0.06514077 0.1721417  0.57462996 0.08476915
 0.04881329 0.05724621 0.04031345 0.04883051 0.03449902 0.05840957
 0.08357804 0.03438976 0.06325187 0.04892607 0.05624113 0.43220967
 0.08459177 0.06575792 0.03590465 0.04172309 0.03438978 0.06626793
 0.05657265 0.14933348 0.05387174 0.04842822 0.39008564 0.3756156
 0.5688636  0.26118886]
tr_loss:[0.04168619 0.3958525  0.24424085 0.3183976  0.42998686 0.4700047
 0.04027931 0.04702053 0.03931811 0.04316431 0.06293736 0.04747616
 0.4832012  0.07525995 0.03552026 0.03965051 0.05307841 0.08121328
 0.04206259 0.31509462 0.04354782 0.08164278 0.05148202 0.04654778
 0.07665846 0.07748389 0.04770926 0.06387983 0.04698171 0.37447685
 0.44633532 0.03109767 0.09194431 0.039946   0.05986872 0.04870213
 0.44444895 0.46137047 0.07839604 0.03189153 0.4443296  0.26454848
 0.04380157 0.4070402  0.04280096 0.04519121 0.05850316 0.30578956
 0.06223927 0.04386942]
tr_loss:[0.04329602 0.35651138 0.04014406 0.07606431 0.05141785 0.07712376
 0.38187742 0.05504974 0.0853719  0.04332361 0.04038312 0.05718455
 0.03510756 0.03701859 0.03370898 0.05170353 0.24199334 0.03809616
 0.07870114 0.08048953 0.03282979 0.07790373 0.03838421 0.02947174
 0.03584189 0.03892703 0.33955112 0.06747649 0.07692906 0.05472269
 0.3487424  0.04487827 0.04099334 0.48168725 0.07924167 0.0503235
 0.04068501 0.0665947  0.07652314 0.02914993 0.03344405 0.22540636
 0.03849066 0.36308843 0.28680485 0.04014767 0.39252788 0.07605048
 0.04028155 0.02931942]
tr_loss:[0.08119544 0.2523964  0.08373837 0.45871    0.03983749 0.30516893
 0.04916963 0.07097866 0.03655213 0.07989981 0.30402887 0.35818225
 0.08127338 0.02945795 0.04245765 0.0532131  0.0331382  0.03655214
 0.03909643 0.03655212 0.03755442 0.02910136 0.03861811 0.02993165
 0.03755441 0.05975362 0.31337875 0.04649006 0.02740302 0.03343705
 0.36922988 0.03717437 0.08329072 0.03568268 0.08040506 0.04687664
 0.04858272 0.03792509 0.033273   0.02788762 0.05936869 0.0870855
 0.39826345 0.03736395 0.02866575 0.054444   0.05858897 0.34713155
 0.04000242 0.04484644]
tr_loss:[0.08423994 0.08223417 0.05725466 0.08204611 0.03249621 0.04589195
 0.3248605  0.05504051 0.47660607 0.08476181 0.03034247 0.04328013
 0.38314685 0.08188514 0.03515911 0.02820036 0.07146008 0.03115536
 0.0292551  0.08161449 0.03372178 0.29632014 0.08127879 0.03446259
 0.28866395 0.02973805 0.02687297 0.3154316  0.03120257 0.30881754
 0.02424866 0.05391794 0.03568007 0.04275861 0.03038542 0.32880062
 0.35104623 0.03553259 0.03738986 0.0530247  0.02429575 0.03180168
 0.03355925 0.03209221 0.03478748 0.02679126 0.08856751 0.02922806
 0.03229455 0.04285954]
tr_loss:[0.02542715 0.05255573 0.02398833 0.05727642 0.03135284 0.10400365
 0.02656423 0.28609166 0.32804152 0.02237363 0.46894187 0.05222033
 0.03599092 0.50604194 0.05843931 0.02697288 0.31795824 0.03545903
 0.386818   0.05865186 0.24101727 0.40739346 0.03390357 0.02748969
 0.03296404 0.03315235 0.04234476 0.23370023 0.05933219 0.05198613
 0.0316119  0.40113503 0.02234621 0.03621204 0.02830856 0.02701164
 0.02238595 0.0301592  0.04092199 0.0360725  0.02780327 0.08070244
 0.43522692 0.03288075 0.02991157 0.04518892 0.36825728 0.0261096
 0.03095886 0.02971873]
tr_loss:[0.03773792 0.0709146  0.28207815 0.39885712 0.02962923 0.03090309
 0.05917974 0.28122205 0.02157441 0.29151288 0.07124579 0.35793453
 0.02271575 0.32656214 0.03409293 0.06439275 0.49225196 0.0749779
 0.02258283 0.02271577 0.02283348 0.04227816 0.03637413 0.022163
 0.03002153 0.03457466 0.0186904  0.07673017 0.03237671 0.02517189
 0.03243358 0.35283554 0.03115113 0.33603427 0.23071904 0.02943538
 0.02768354 0.37930933 0.02214534 0.02738246 0.33902836 0.03579443
 0.02270789 0.05125972 0.07691674 0.01838348 0.02803255 0.04532883
 0.03115112 0.02157441]
tr_loss:[0.48593217 0.06923256 0.07122131 0.0412255  0.03552654 0.05006132
 0.03449821 0.02861868 0.023254   0.23514466 0.02508971 0.26718336
 0.03235281 0.03482082 0.07151321 0.02329671 0.0298012  0.03440877
 0.546837   0.05419459 0.02090145 0.04680291 0.42100725 0.5506683
 0.03091902 0.33386055 0.0246921  0.027923   0.05465251 0.02418186
 0.05373268 0.26494354 0.01987582 0.03936784 0.07188542 0.03105698
 0.2997981  0.02079639 0.34848076 0.23696104 0.05662258 0.36812523
 0.03496193 0.06724355 0.0380828  0.05455908 0.03137854 0.0393674
 0.46694002 0.02950785]
tr_loss:[0.06587572 0.06807654 0.06715455 0.06548836 0.06581174 0.23807557
 0.02062496 0.02970316 0.03075581 0.0221801  0.03261187 0.06658702
 0.07538535 0.02856581 0.30103606 0.39430612 0.06574859 0.02295254
 0.0678528  0.02786753 0.05220519 0.4712471  0.15877563 0.24175854
 0.02202622 0.04295902 0.02300288 0.02066744 0.02794174 0.02203089
 0.02471115 0.03195869 0.04211696 0.06510359 0.02228635 0.02240244
 0.04576577 0.03943972 0.02228633 0.02955734 0.03249709 0.04408212
 0.03357607 0.05596994 0.05180103 0.14517958 0.0320741  0.14200363
 0.04920099 0.05556499]
tr_loss:[0.04921874 0.33195895 0.31628245 0.03072431 0.4600924  0.43841523
 0.02941392 0.06257244 0.06174254 0.02199746 0.06401414 0.05211527
 0.02045433 0.04954115 0.01568489 0.3184293  0.0215953  0.02736536
 0.02580365 0.06935383 0.02705522 0.37653384 0.04771385 0.02811825
 0.02878685 0.2561494  0.03927941 0.06636734 0.29267356 0.0632176
 0.06256733 0.02784069 0.02135305 0.02093857 0.37468737 0.02151696
 0.06648036 0.04564878 0.02414969 0.0199126  0.05328795 0.4132859
 0.04571562 0.04937492 0.02580428 0.12193233 0.02586992 0.03802098
 0.03111752 0.03234534]
tr_loss:[0.03502019 0.03512478 0.02009582 0.31266904 0.0274322  0.02742214
 0.03411689 0.36325714 0.28955615 0.01353488 0.14776085 0.0335682
 0.02268239 0.03463374 0.33768657 0.0277699  0.2779553  0.24337876
 0.03290176 0.30626938 0.01842563 0.01842249 0.3677755  0.25451988
 0.01787582 0.03524961 0.05896763 0.38757625 0.0490515  0.02879989
 0.02848684 0.0255908  0.02756181 0.02341205 0.41622478 0.3564082
 0.01932827 0.02014916 0.05850723 0.30436367 0.01889944 0.01842562
 0.01787573 0.01694406 0.04741881 0.32871923 0.02435912 0.05429052
 0.29454595 0.02769489]
tr_loss:[0.0280823  0.02483437 0.01721667 0.01639193 0.02548233 0.02710017
 0.02949521 0.02583233 0.03063385 0.40278906 0.01501313 0.01721669
 0.01501314 0.4427479  0.046627   0.27724615 0.01484299 0.02659566
 0.03998836 0.06130015 0.3728595  0.02544194 0.01829758 0.24129423
 0.0364402  0.02732185 0.0168103  0.02028083 0.01474309 0.03131398
 0.04123706 0.29072165 0.01884113 0.03187733 0.30131853 0.05961243
 0.05782195 0.02204418 0.34475756 0.02615018 0.04208077 0.02745989
 0.0439343  0.05234545 0.05675777 0.37144127 0.02392054 0.06406397
 0.04053765 0.04308375]
tr_loss:[0.01876652 0.03190805 0.01701125 0.02942127 0.02951133 0.03216397
 0.02022746 0.30800295 0.02718917 0.02671429 0.04030205 0.01701123
 0.01842509 0.29772314 0.01755493 0.01791625 0.01882319 0.0276106
 0.01973792 0.14526846 0.03738772 0.06324661 0.02596509 0.02632904
 0.26487976 0.03373684 0.02015337 0.03175979 0.01384776 0.06840213
 0.0297731  0.05309045 0.01777157 0.61934763 0.04056481 0.02670693
 0.28996906 0.04476077 0.02957506 0.06286213 0.0511416  0.06242681
 0.297995   0.02746152 0.06654593 0.03799325 0.40008873 0.03456526
 0.02030515 0.02769972]
tr_loss:[0.02245054 0.41748247 0.03395197 0.06070585 0.0548199  0.03224916
 0.01478805 0.06274478 0.0280623  0.43077826 0.06206638 0.03422999
 0.04639802 0.06111325 0.03117377 0.05577762 0.04182037 0.06134021
 0.15191421 0.04739719 0.35139495 0.13455543 0.03883427 0.03008804
 0.02390596 0.01857183 0.03590065 0.04746398 0.05333712 0.02391826
 0.02972628 0.06041926 0.03914311 0.32036734 0.01789729 0.3722003
 0.3634328  0.4867247  0.03527157 0.01827246 0.22054124 0.02263514
 0.01947085 0.03047115 0.03280865 0.38753954 0.03131584 0.33807144
 0.01478805 0.35790524]
tr_loss:[0.03626374 0.05769608 0.01602144 0.03916241 0.39313182 0.278365
 0.01857932 0.02790245 0.05763278 0.05979336 0.05008351 0.04385526
 0.01734228 0.03247325 0.02983747 0.0275552  0.02938133 0.05227982
 0.01922143 0.03032631 0.0201274  0.01801836 0.02814699 0.03268147
 0.05016375 0.05202525 0.01907356 0.0139886  0.02011085 0.19671027
 0.03619011 0.01430556 0.03491846 0.01508065 0.02498124 0.02252869
 0.47618753 0.02573859 0.4223267  0.02620424 0.02447163 0.03284036
 0.05230184 0.02264151 0.01922904 0.01907601 0.0558179  0.03855022
 0.018018   0.32647577]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1000 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1001, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1001 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1002, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1002 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1003, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1003 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1004, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1004 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1005, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1005 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1006, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1006 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1007, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1007 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1008, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1008 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1009, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1009 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1010, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1010 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1011, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1011 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1012, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1012 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1013, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1013 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1014, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1014 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1015, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1015 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1016, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1016 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1017, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1017 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1018, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1018 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1019, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1019 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1020, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1020 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1021, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1021 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1022, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1022 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1023, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1023 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1024, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1024 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1025, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1025 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1026, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1026 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1027, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1027 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1028, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1028 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1029, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1029 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1030, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1030 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1031, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1031 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1032, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1032 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1033, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1033 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1034, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1034 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1035, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1035 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1036, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1036 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1037, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1037 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1038, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1038 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1039, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1039 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1040, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1040 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1041, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1041 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1042, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1042 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1043, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1043 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1044, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1044 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1045, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1045 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1046, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1046 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1047, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1047 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1048, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1048 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1049, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1049 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1050, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1050 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1051, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1051 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1052, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1052 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1053, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1053 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1054, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1054 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1055, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1055 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1056, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1056 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1057, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1057 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1058, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1058 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1059, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1059 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1060, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1060 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1061, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1061 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1062, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1062 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1063, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1063 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1064, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1064 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1065, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1065 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1066, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1066 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1067, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1067 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1068, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1068 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1069, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1069 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1070, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1070 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1071, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1071 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1072, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1072 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1073, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1073 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1074, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1074 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1075, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1075 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1076, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1076 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1077, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1077 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1078, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1078 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1079, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1079 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1080, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1080 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1081, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1081 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1082, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1082 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1083, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1083 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1084, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1084 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1085, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1085 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1086, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1086 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1087, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1087 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1088, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1088 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1089, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1089 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1090, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1090 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1091, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1091 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1092, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1092 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1093, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1093 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1094, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1094 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1095, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1095 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1096, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1096 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1097, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1097 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1098, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1098 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1099, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1099 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1100, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-1000
text_input.shape
(1100, 14400)
learning_input_tmp.shape
(1100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1100, 80)
learning_output.shape
(750, 80)
Model: "sequential_23"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_23 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.726828   1.0459923  1.0459869  0.8412008  0.42367783 0.73790455
 0.8311771  0.83366215 0.39428493 1.0459923  0.3864758  0.39389133
 0.37551513 0.6723692  0.8412018  0.6571156  0.73678344 0.3837329
 0.9764104  0.7132771  0.71340024 0.6523138  1.045997   0.35115585
 0.9831454  0.7707778  0.5723518  0.8339575  0.6696187  0.49088693
 0.7175809  0.3872431  0.67190635 0.6712788  0.71129787 0.40072805
 0.8339571  0.7591487  0.72895527 0.81411207 0.83226573 0.6764285
 0.8412015  0.39355817 0.9355138  0.66241133 0.9291228  0.95105135
 0.3762853  0.45458165]
tr_loss:[0.55038345 0.6606339  0.47262278 0.5289115  0.45541722 0.3740471
 0.5029523  0.5208663  0.46712503 0.5851987  0.6206378  0.52151906
 0.6343235  0.34856567 0.6208375  0.55038244 0.57565546 0.5859515
 0.363185   0.5223141  0.46033087 0.47659045 0.4502406  0.5626327
 0.58384883 0.44981027 0.568647   0.5046835  0.45444784 0.58517635
 0.5753655  0.41088963 0.3708806  0.45864183 0.363707   0.4500924
 0.58453196 0.58512485 0.44737616 0.46768504 0.44692546 0.4502141
 0.36217266 0.49311742 0.49627972 0.44291186 0.4728263  0.3711957
 0.4671742  0.36207294]
tr_loss:[0.33297762 0.38555858 0.43108043 0.33731553 0.360618   0.3296524
 0.4120508  0.4311618  0.3382201  0.42997617 0.40469676 0.40972885
 0.30471164 0.40490755 0.33101362 0.33785477 0.3333861  0.4961009
 0.33901578 0.4253037  0.31449375 0.37061968 0.35235095 0.39424315
 0.5080183  0.22593994 0.40536103 0.33832914 0.2231346  0.3322319
 0.34329143 0.30874228 0.4026981  0.41233104 0.33525237 0.43789244
 0.38526064 0.38491553 0.4139886  0.32948065 0.43441075 0.307373
 0.37066892 0.22130355 0.2959643  0.32489973 0.36017153 0.21938097
 0.29789275 0.3980407 ]
tr_loss:[0.23714527 0.24549726 0.20469622 0.20184541 0.19391952 0.19763346
 0.1710567  0.20395187 0.50278217 0.21493575 0.2116305  0.18594304
 0.21428788 0.17699306 0.21475334 0.19284214 0.28331262 0.2250884
 0.25633532 0.1741839  0.23736496 0.2047083  0.17000619 0.1715379
 0.45326796 0.33695152 0.28291366 0.17590548 0.16686913 0.1703929
 0.28334838 0.19991161 0.23567514 0.39986044 0.20456862 0.23457828
 0.22754784 0.19414982 0.16703871 0.23485465 0.2038182  0.38400945
 0.23214237 0.21329896 0.23580495 0.28334847 0.23589146 0.4438706
 0.2095468  0.16797212]
tr_loss:[0.13345742 0.14603722 0.11345141 0.15599456 0.11618042 0.11270399
 0.11660162 0.11506722 0.16721866 0.1351119  0.13861412 0.17943673
 0.16696236 0.13392162 0.13120824 0.17943668 0.11955684 0.17943606
 0.12595916 0.17943633 0.11912458 0.16848533 0.13848053 0.13917103
 0.14808032 0.11428805 0.14078423 0.17943673 0.13725376 0.15648028
 0.4361105  0.14616391 0.139191   0.11622305 0.12127168 0.1434792
 0.1339182  0.1503363  0.17943671 0.47848964 0.15622261 0.1607213
 0.14054348 0.14653234 0.13792628 0.11647926 0.15137994 0.14780319
 0.13392165 0.17653553]
tr_loss:[0.12147892 0.13357511 0.0858989  0.11752848 0.1285347  0.08180682
 0.12145128 0.09091886 0.10331213 0.13081537 0.11750349 0.10275261
 0.10070795 0.08840135 0.11031272 0.11742914 0.09632163 0.09772862
 0.08938371 0.13815837 0.08972178 0.10085259 0.08349688 0.09205084
 0.12264023 0.08981621 0.13835444 0.10410754 0.09540211 0.10677537
 0.11689866 0.09091886 0.11752854 0.09195691 0.10809156 0.0927242
 0.08184484 0.12104534 0.0984874  0.30661982 0.13347928 0.12541863
 0.10569807 0.09273221 0.12369654 0.10523975 0.11240034 0.08895903
 0.12352824 0.31574982]
tr_loss:[0.09532987 0.10281377 0.0818978  0.08532004 0.09903412 0.07435129
 0.0743512  0.0839024  0.09738805 0.10198387 0.10118079 0.07134567
 0.10374036 0.07435127 0.08617686 0.07183937 0.07435124 0.10298061
 0.07004847 0.07434548 0.48314494 0.07939114 0.07438534 0.08762252
 0.10226933 0.10151245 0.07004844 0.10211824 0.10961816 0.09947278
 0.06706733 0.10047196 0.07435123 0.11342573 0.08304854 0.07435117
 0.07238732 0.07435124 0.08479504 0.41351405 0.07788523 0.08774128
 0.07300676 0.07183947 0.07434287 0.08709019 0.08045399 0.07845573
 0.1097281  0.08373372]
tr_loss:[0.05235548 0.04567979 0.36171037 0.05584293 0.33808127 0.3529756
 0.04567985 0.08347646 0.09926961 0.04565044 0.12140775 0.05177223
 0.06491399 0.31956968 0.07060982 0.07639766 0.20175385 0.10074179
 0.0456751  0.05814531 0.04567982 0.06789385 0.07600681 0.06497811
 0.0658011  0.08869709 0.05584282 0.08405051 0.06318042 0.40164232
 0.2462287  0.0760013  0.10299401 0.05004994 0.09207387 0.04567984
 0.0572288  0.07426604 0.09949964 0.07078379 0.4530058  0.10171326
 0.08791028 0.0517722  0.10501353 0.04567981 0.0838373  0.07574632
 0.06781923 0.04567928]
tr_loss:[0.04368235 0.06076971 0.04723657 0.09397119 0.03407242 0.1095109
 0.09505385 0.05489234 0.04467327 0.06099945 0.3315205  0.05653065
 0.03407254 0.04916615 0.05068284 0.2919969  0.04467332 0.04246689
 0.07307921 0.0970569  0.05387115 0.22612341 0.03933105 0.07660927
 0.5083769  0.03407248 0.07848232 0.04441087 0.1344895  0.06535195
 0.05908933 0.05485469 0.06507319 0.05122558 0.04904804 0.11446142
 0.04342199 0.08035545 0.0727646  0.04447313 0.11390574 0.08888291
 0.07083439 0.09983888 0.0495069  0.03407253 0.06209929 0.05416059
 0.06114005 0.10994023]
tr_loss:[0.0361464  0.08373243 0.04130469 0.207172   0.08675332 0.05792446
 0.1132771  0.04836679 0.06494704 0.55923665 0.05759041 0.06479175
 0.06051837 0.05988262 0.05503448 0.20663722 0.27257258 0.05744883
 0.03614618 0.03873699 0.09227158 0.07584678 0.09821846 0.03610495
 0.10782743 0.0486417  0.10787984 0.05007838 0.4059197  0.07593197
 0.06841099 0.09333564 0.1191044  0.06692235 0.08873997 0.0686201
 0.03614641 0.05943872 0.04933967 0.05759992 0.10838778 0.10159352
 0.07457938 0.04067301 0.05759348 0.03614642 0.05019097 0.03599348
 0.05960049 0.10629404]
tr_loss:[0.07758272 0.06778546 0.10976789 0.09550709 0.11243904 0.05154649
 0.06779518 0.08746041 0.0604042  0.07360764 0.10030375 0.09509691
 0.04901338 0.06779523 0.09344945 0.16706553 0.10850313 0.09305415
 0.07091636 0.09968303 0.06660714 0.10137284 0.1069694  0.4763221
 0.11317712 0.0638565  0.3730001  0.11205421 0.05731742 0.1078244
 0.05901031 0.04682513 0.06862639 0.05914959 0.04826333 0.11411119
 0.09646298 0.11128576 0.23147544 0.11164619 0.04648963 0.06067222
 0.38803118 0.10882735 0.07757092 0.33125624 0.06092735 0.07526771
 0.11756066 0.11204485]
tr_loss:[0.05593842 0.06649552 0.06975875 0.10842504 0.50031835 0.08007631
 0.08609145 0.118481   0.04721185 0.06489322 0.06089634 0.46153504
 0.0437851  0.15115759 0.10762161 0.06746742 0.1060874  0.07141189
 0.07476288 0.05968642 0.16102982 0.1075118  0.10793903 0.07603075
 0.05968648 0.04978944 0.05944536 0.08814728 0.07277967 0.04444679
 0.04378511 0.46713895 0.07703878 0.04378511 0.11175768 0.0437851
 0.06765658 0.11110935 0.09770529 0.04451011 0.0437851  0.04378506
 0.04378508 0.06765665 0.0725053  0.0676709  0.08733205 0.10578328
 0.07611748 0.05736591]
tr_loss:[0.07832842 0.03417402 0.05752438 0.09975529 0.02985884 0.0911835
 0.06626923 0.05365278 0.11140857 0.11352845 0.07569362 0.04573423
 0.05437751 0.04880338 0.05011405 0.08445811 0.05752577 0.05268665
 0.07840727 0.06218705 0.06378718 0.04961425 0.10062227 0.04900542
 0.08070829 0.0852659  0.10172329 0.03614925 0.41925782 0.03847473
 0.04052892 0.2896822  0.04871858 0.04859541 0.0536528  0.06691159
 0.03417414 0.03417399 0.42605352 0.10219412 0.05717145 0.08865788
 0.06577773 0.35576257 0.03417509 0.04009502 0.04995722 0.04853596
 0.0380644  0.04948258]
tr_loss:[0.02977387 0.08110242 0.07721615 0.05048759 0.05951037 0.0297739
 0.02995992 0.1370544  0.03716844 0.03736097 0.06336646 0.03452365
 0.04684807 0.0484674  0.02984219 0.6294623  0.05559316 0.02977386
 0.0761383  0.07839218 0.03645573 0.04450394 0.03691817 0.02977384
 0.04484999 0.06803126 0.08332476 0.0563008  0.09367586 0.04718684
 0.0864426  0.04970725 0.03020246 0.20130165 0.09039903 0.04829545
 0.08396285 0.05163629 0.04537449 0.02977138 0.08061875 0.02977386
 0.25609866 0.04744025 0.02977385 0.05675956 0.09184126 0.03081122
 0.49713516 0.04652722]
tr_loss:[0.0757103  0.04915539 0.03885317 0.05974174 0.03193205 0.04608671
 0.0336691  0.09107094 0.04049895 0.12730232 0.02521552 0.09873194
 0.09414132 0.07298711 0.08329855 0.04485191 0.03532527 0.06063819
 0.02521551 0.09377761 0.07088305 0.02521548 0.03777345 0.07542942
 0.03233985 0.05609103 0.07768252 0.03794087 0.03532548 0.0252155
 0.09534707 0.0549063  0.04943657 0.03959015 0.02521552 0.06698254
 0.03372762 0.04537363 0.08075304 0.03951582 0.02521897 0.0252155
 0.04047297 0.05474175 0.03296761 0.04389757 0.04598327 0.03366911
 0.50202835 0.08566754]
tr_loss:[0.07298902 0.04883709 0.05043895 0.08423485 0.05110203 0.07044052
 0.06983804 0.02271133 0.04881787 0.02996359 0.03380714 0.04906944
 0.03866251 0.48176193 0.09046146 0.0562786  0.02271132 0.0314398
 0.08495269 0.03822262 0.19358799 0.03557723 0.0876026  0.0568035
 0.03470942 0.05573838 0.08967211 0.03599034 0.1239166  0.02271135
 0.0896317  0.04056581 0.03726619 0.05125451 0.03599087 0.06910705
 0.03380718 0.04804262 0.07437436 0.06928355 0.04624758 0.07100622
 0.43161735 0.02271136 0.07538986 0.03203379 0.04804288 0.02271137
 0.06300871 0.04804267]
tr_loss:[0.0608666  0.07182512 0.06658527 0.04335974 0.05050532 0.01862655
 0.06032797 0.02574963 0.2957271  0.06982006 0.02641847 0.0560041
 0.02904663 0.3653528  0.01862117 0.01862118 0.09008147 0.05209683
 0.03866918 0.04193882 0.01862117 0.0434688  0.18633112 0.0595791
 0.01862119 0.21462038 0.07931968 0.01862115 0.06226543 0.06877264
 0.0662864  0.0447071  0.05060619 0.04194245 0.02720157 0.03789606
 0.04462413 0.07889914 0.04486829 0.04353229 0.01862116 0.07525368
 0.03485495 0.01862128 0.04491056 0.0692635  0.08019359 0.4281455
 0.04335959 0.0343719 ]
tr_loss:[0.04094004 0.05018883 0.35990566 0.07160809 0.07039647 0.02015742
 0.02852586 0.03190291 0.024829   0.04057296 0.05268423 0.04257634
 0.03513386 0.06144016 0.0484159  0.02471518 0.07043839 0.04097818
 0.03534376 0.04891262 0.04208168 0.04192449 0.02539949 0.02471515
 0.01989626 0.07064527 0.01566455 0.03446773 0.02377635 0.04165596
 0.04195923 0.07128209 0.0704532  0.01636644 0.3032546  0.04525042
 0.04903336 0.4612549  0.02469236 0.03190264 0.254807   0.05362644
 0.07112701 0.03214365 0.0648997  0.07147754 0.01572036 0.03237773
 0.03841672 0.024829  ]
tr_loss:[0.06834838 0.01987665 0.03681708 0.05037241 0.05154598 0.05149942
 0.04172375 0.02531046 0.06578865 0.06796646 0.04924343 0.05203614
 0.02523679 0.04778712 0.05115646 0.04103888 0.03698397 0.31173316
 0.01809365 0.47260395 0.40588102 0.03247715 0.01742464 0.0387666
 0.06807021 0.0743366  0.04921088 0.04022964 0.0515781  0.03389529
 0.07868274 0.06097869 0.07336693 0.0253105  0.05622774 0.02716827
 0.06328307 0.01809365 0.06779963 0.04809717 0.06597254 0.01809366
 0.05454675 0.01842782 0.07746283 0.05970309 0.01809369 0.01809544
 0.03953963 0.04170177]
tr_loss:[0.03907455 0.02100265 0.49391156 0.04007739 0.06586999 0.33612448
 0.03333323 0.05877595 0.04758393 0.06676088 0.02265467 0.0364406
 0.03616467 0.06766979 0.05116876 0.03197027 0.11149553 0.03640022
 0.05868023 0.03856562 0.04591627 0.06873399 0.04816633 0.03215429
 0.06690636 0.06731522 0.08909891 0.03415848 0.05303957 0.02092395
 0.06707085 0.02581136 0.03294225 0.02919831 0.49866867 0.03224952
 0.02323639 0.21052232 0.01968087 0.04299429 0.03221787 0.06808122
 0.07571814 0.01969278 0.03710354 0.07329504 0.02770298 0.06523378
 0.02623481 0.04337656]
tr_loss:[0.03521899 0.03467688 0.03606921 0.43098974 0.04517181 0.04539683
 0.19568574 0.0445403  0.06384556 0.04302446 0.02309072 0.02319805
 0.02755669 0.04294707 0.0817185  0.08415218 0.02319807 0.05857513
 0.04006333 0.06855744 0.06292769 0.06253137 0.0705861  0.03302065
 0.04371965 0.03349084 0.03374904 0.02319635 0.03677467 0.0616312
 0.03084843 0.06494965 0.04202903 0.01789906 0.03094245 0.03501219
 0.03111824 0.03640277 0.04302341 0.02929436 0.03990183 0.04585835
 0.04068374 0.33948475 0.04808324 0.02471646 0.04043314 0.06213253
 0.0179058  0.06229164]
tr_loss:[0.35292998 0.02132049 0.03558902 0.03400481 0.02725445 0.02422836
 0.04580809 0.02945582 0.02081383 0.05125194 0.0216734  0.22162452
 0.03826005 0.02490561 0.02527846 0.02877165 0.02580965 0.0214197
 0.31691578 0.02877165 0.03651854 0.02081441 0.03742469 0.03936674
 0.03259119 0.03425505 0.02081442 0.02814422 0.05114415 0.04023392
 0.05546697 0.02699966 0.02566135 0.02876478 0.03118991 0.03036597
 0.02476624 0.02795115 0.04934141 0.02078401 0.03162214 0.02081312
 0.38062963 0.03279834 0.04254355 0.03901971 0.30886683 0.02081431
 0.03380524 0.2963942 ]
tr_loss:[0.01701517 0.01535683 0.01535681 0.0316728  0.03225189 0.02751118
 0.01535657 0.05337995 0.3221925  0.03148091 0.12757179 0.05783714
 0.01701518 0.05469279 0.02208746 0.02602633 0.03092309 0.03180694
 0.03145343 0.05497123 0.0284174  0.0573352  0.02140636 0.02208721
 0.0226912  0.05587075 0.06050051 0.02754268 0.0153336  0.02263572
 0.05909842 0.0153449  0.0220886  0.02757081 0.01535684 0.04886451
 0.0546433  0.02168459 0.03378219 0.03486852 0.04729097 0.02107724
 0.05427551 0.05657693 0.0400442  0.02183539 0.02602612 0.02168453
 0.05865717 0.0221004 ]
tr_loss:[0.02587045 0.05101124 0.01119487 0.05024416 0.05724707 0.05734577
 0.02579795 0.03613593 0.01119486 0.05631449 0.24072793 0.01752344
 0.02495813 0.04274143 0.02554627 0.04101532 0.02283098 0.01119487
 0.01912401 0.02542466 0.03092129 0.01119487 0.04031846 0.22190645
 0.02528444 0.04112514 0.0495738  0.02525677 0.02838466 0.03026244
 0.01622449 0.02293165 0.04119053 0.04223304 0.02083837 0.04429871
 0.02899832 0.03660949 0.01145583 0.02970036 0.01865516 0.05008689
 0.02197985 0.02968541 0.03189374 0.02919928 0.05739136 0.15060483
 0.02209187 0.02411468]
tr_loss:[0.01051484 0.01051485 0.03096968 0.01051515 0.03050343 0.02564064
 0.04637168 0.03933235 0.01622459 0.01106503 0.02930766 0.03445935
 0.1630809  0.0367743  0.02195718 0.05206196 0.02567771 0.02119491
 0.01941831 0.01901889 0.01248867 0.01533108 0.01797216 0.02249426
 0.15881816 0.02529079 0.02728629 0.04688921 0.01750558 0.05788102
 0.02195726 0.04351043 0.04890361 0.37762576 0.0332425  0.04751109
 0.02004838 0.01051482 0.01051494 0.02712915 0.02156504 0.02560049
 0.02079579 0.01897585 0.02091606 0.14258358 0.03998389 0.02667728
 0.0309793  0.02201813]
tr_loss:[0.04397298 0.0459582  0.03167274 0.31486973 0.01013327 0.02644282
 0.04399425 0.01013327 0.22531295 0.04356445 0.01013325 0.03119637
 0.04925679 0.04461234 0.02445083 0.02886263 0.03119542 0.04601836
 0.0270866  0.04668191 0.0189134  0.02413185 0.469706   0.02657043
 0.02071285 0.02972499 0.3045336  0.04822126 0.28873467 0.01016883
 0.03205984 0.02268204 0.02883537 0.01077705 0.02714392 0.04725168
 0.01013326 0.03112631 0.04762425 0.03018568 0.31353956 0.03972376
 0.06059077 0.01013326 0.0468349  0.01013325 0.03185267 0.2693193
 0.04366987 0.02562009]
tr_loss:[0.01031561 0.03719883 0.41126317 0.02503064 0.02897987 0.01339496
 0.01212837 0.01875847 0.03083941 0.0269669  0.02582013 0.01031561
 0.02178913 0.02520718 0.02733089 0.01339495 0.01917829 0.42855358
 0.02492118 0.01032191 0.03071384 0.02286669 0.03147821 0.01031562
 0.02842256 0.0103156  0.01031584 0.02883056 0.03891898 0.03035111
 0.02668458 0.04604567 0.02859537 0.01031561 0.0451427  0.03555735
 0.01339495 0.03013125 0.03297407 0.17794888 0.02575288 0.02812132
 0.03085127 0.02362479 0.02507278 0.02803831 0.03738232 0.01031606
 0.01693778 0.05015526]
tr_loss:[0.0269056  0.02074049 0.05347789 0.04728219 0.02492732 0.0209212
 0.02556209 0.0466125  0.02023873 0.01299043 0.04337062 0.02124256
 0.352659   0.01958159 0.01834594 0.02538144 0.01651432 0.01061956
 0.26787198 0.06046122 0.02552083 0.04508217 0.04388525 0.369009
 0.01299031 0.02237648 0.01834891 0.03821499 0.03128129 0.01061128
 0.0194486  0.01688306 0.01061952 0.02242891 0.04720046 0.02977645
 0.01061955 0.02081855 0.02656241 0.04626013 0.02922512 0.01676939
 0.02640484 0.01991629 0.03243444 0.3033235  0.02064642 0.02527266
 0.02292555 0.0359001 ]
tr_loss:[0.01079712 0.04613071 0.03298967 0.04861363 0.43998307 0.01375627
 0.02843208 0.01375427 0.24649616 0.26805434 0.02445831 0.03873814
 0.03877084 0.02598969 0.02584299 0.01065128 0.02511501 0.02547251
 0.03628881 0.02606584 0.01065127 0.03387098 0.02207355 0.04853797
 0.01654738 0.01673247 0.25458944 0.02731987 0.02889941 0.01065127
 0.01522245 0.01065127 0.02849758 0.0417546  0.02497624 0.01065127
 0.02614143 0.04570074 0.02626314 0.02735418 0.02393893 0.04577297
 0.01851699 0.04825255 0.03401252 0.02238022 0.01438602 0.02666094
 0.32158074 0.04622612]
tr_loss:[0.01013151 0.01013161 0.01587232 0.13716522 0.03006614 0.25488016
 0.01758186 0.04589493 0.0441028  0.02335086 0.04570227 0.01843702
 0.02821724 0.0456756  0.02163234 0.02260969 0.01944622 0.01013165
 0.02717635 0.02525684 0.02129939 0.04433506 0.01013165 0.01012508
 0.25620192 0.04851443 0.01013165 0.02649749 0.03848394 0.02187159
 0.024388   0.0183121  0.02973953 0.01591916 0.09358    0.029871
 0.04411284 0.02625797 0.02723267 0.0342567  0.06688301 0.0145938
 0.04798416 0.0263775  0.01974081 0.35714158 0.04497266 0.24594013
 0.02574909 0.47116518]
text_input.shape
(1100, 14400)
learning_input_tmp.shape
(1100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1100, 80)
learning_output.shape
(750, 80)
Model: "sequential_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_24 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.6366806  0.61156666 0.62452966 0.40498298 0.513656   0.5351229
 0.64112437 0.518287   0.61434585 0.59630954 0.62057835 0.5048951
 0.47514796 0.5232187  0.46477523 0.65387726 0.60159767 0.602786
 0.5872043  0.60916084 0.4990031  0.4404087  0.6282122  0.5237249
 0.3641378  0.623932   0.46034542 0.51532996 0.6360512  0.5209256
 0.46040526 0.5370582  0.47431293 0.50907844 0.49317795 0.49844408
 0.6189871  0.638387   0.5842608  0.5875998  0.6391807  0.610347
 0.60742646 0.49645346 0.63964593 0.5092134  0.46026444 0.64818066
 0.5820071  0.5808643 ]
tr_loss:[0.4170746  0.40867385 0.42173702 0.36465803 0.5087969  0.41335258
 0.39371765 0.42019024 0.554857   0.42580962 0.50683683 0.3730189
 0.41705984 0.33538404 0.51051676 0.55485696 0.55485696 0.4213921
 0.41715306 0.38947967 0.36005992 0.38666397 0.55485696 0.5067949
 0.55485696 0.554857   0.4388458  0.410412   0.45948738 0.5145008
 0.4995554  0.3400794  0.3625334  0.42422065 0.51051646 0.51285225
 0.5156255  0.40604967 0.55519015 0.46471778 0.5213989  0.3456915
 0.49397868 0.3864892  0.5172106  0.496286   0.4560516  0.40753108
 0.44550633 0.38444293]
tr_loss:[0.30267715 0.3477247  0.39477712 0.3444046  0.2218359  0.34090263
 0.21871182 0.35049665 0.22492298 0.22189581 0.3370363  0.2920793
 0.34233716 0.35931677 0.30961838 0.37516093 0.3504966  0.3044059
 0.2991112  0.29311696 0.36320847 0.33704025 0.3480544  0.34197205
 0.35327968 0.30719241 0.5660922  0.35436663 0.23948398 0.30233866
 0.22859287 0.23392788 0.3947776  0.33769268 0.39299864 0.28449887
 0.39477763 0.39477766 0.2987879  0.34197208 0.3323453  0.3418621
 0.23634899 0.35049662 0.23334375 0.3077786  0.33377942 0.3274995
 0.37627453 0.3947638 ]
tr_loss:[0.15898994 0.17667572 0.15491517 0.14198823 0.1832174  0.15898494
 0.1832178  0.20042972 0.16251558 0.19400522 0.14338158 0.14040107
 0.18554857 0.1492846  0.17434743 0.1758807  0.18760172 0.17652807
 0.15921298 0.13709942 0.16179618 0.3079258  0.33999047 0.4843165
 0.15638837 0.33827102 0.17556064 0.15885353 0.16801485 0.18385899
 0.19800082 0.14365172 0.3394354  0.13887589 0.13988927 0.19916537
 0.183214   0.19691667 0.20033804 0.16251563 0.15731728 0.15885362
 0.17811525 0.13722391 0.18110102 0.17415576 0.2054303  0.1590502
 0.15656984 0.16702947]
tr_loss:[0.13253072 0.30668622 0.11418291 0.0925153  0.15531375 0.09148815
 0.1870822  0.09435494 0.13361195 0.15041193 0.1204164  0.10191616
 0.19222407 0.10771064 0.16986306 0.12041643 0.12047935 0.39125928
 0.1821018  0.1430499  0.09343451 0.15091653 0.1204164  0.19362369
 0.15751138 0.08392678 0.18262187 0.14795086 0.12041645 0.18521237
 0.15576491 0.47718143 0.15797368 0.13363211 0.42070752 0.18427205
 0.11044679 0.12696359 0.3292152  0.12041666 0.15528068 0.12041648
 0.09919927 0.1313545  0.18680504 0.10434928 0.11412901 0.12019225
 0.12002085 0.19248658]
tr_loss:[0.10026653 0.09157577 0.08464891 0.09862424 0.06795993 0.09048647
 0.12373351 0.10069875 0.11276287 0.08406861 0.1102262  0.3437081
 0.13312604 0.06849699 0.08512159 0.08298014 0.21983854 0.1065333
 0.09862423 0.16816124 0.0967305  0.13185333 0.09182806 0.16278347
 0.16920586 0.09862446 0.10747936 0.58950573 0.09959386 0.45162672
 0.44381085 0.17309996 0.10550535 0.10393135 0.06795993 0.08282543
 0.08457188 0.08646796 0.08326129 0.12495401 0.11166155 0.06849536
 0.12897083 0.07493919 0.11789975 0.16832642 0.11981912 0.11662021
 0.12308776 0.08311719]
tr_loss:[0.07083327 0.07304279 0.07629023 0.08710681 0.380203   0.08623024
 0.1435737  0.06744017 0.09933814 0.0866876  0.09740887 0.08408238
 0.06025799 0.11845716 0.06759447 0.07675143 0.08408235 0.07228117
 0.07087062 0.08245884 0.10868847 0.11765963 0.08294414 0.32151645
 0.11885651 0.05230427 0.05442785 0.08408237 0.14196265 0.13818426
 0.05581945 0.11412381 0.08407626 0.06742813 0.1014055  0.08149073
 0.0794497  0.05715687 0.07086396 0.05444542 0.10439839 0.08408181
 0.46577486 0.13946047 0.06869847 0.11777358 0.07297704 0.07310236
 0.08413216 0.07301079]
tr_loss:[0.04540125 0.05522889 0.12988088 0.04879927 0.04540329 0.10221877
 0.04540326 0.05373465 0.06443147 0.10155208 0.11987241 0.04490566
 0.04652376 0.10879135 0.09735977 0.08625942 0.12757361 0.35873315
 0.04592962 0.09991739 0.05751916 0.05517008 0.29596385 0.04558419
 0.12068808 0.12263598 0.06450173 0.06457516 0.08861557 0.08690415
 0.07861693 0.06457518 0.09929405 0.05517007 0.07892687 0.05788941
 0.6367379  0.06457515 0.08134943 0.04914668 0.08320753 0.05689744
 0.12136054 0.10053834 0.12515496 0.0645751  0.04540327 0.06224383
 0.09032347 0.25661856]
tr_loss:[0.05594018 0.55505407 0.10350237 0.09496959 0.1222026  0.04500324
 0.11287639 0.10008556 0.06415381 0.12170937 0.08016071 0.37638143
 0.12217307 0.2103378  0.05543732 0.09567348 0.06270995 0.09566215
 0.11911249 0.04918898 0.04786584 0.08019507 0.12047352 0.04666581
 0.05800677 0.05229104 0.05172687 0.05543707 0.05480241 0.12029091
 0.04483827 0.0516756  0.06335958 0.06310546 0.05552509 0.12159149
 0.07959982 0.0651644  0.0804109  0.0727488  0.06758328 0.07862532
 0.07984322 0.3806269  0.11285226 0.06319932 0.06294834 0.062803
 0.08163199 0.1227927 ]
tr_loss:[0.06628103 0.10100378 0.07783349 0.11465069 0.04007084 0.05318367
 0.0678698  0.04007109 0.05844816 0.04329211 0.04007114 0.43346295
 0.07949202 0.0450056  0.07234608 0.05948042 0.03915675 0.04315349
 0.03836031 0.07005505 0.07256927 0.04007112 0.04491318 0.04007108
 0.06024327 0.0423399  0.07102767 0.11444982 0.09471892 0.07540156
 0.04191412 0.0440921  0.3934496  0.06378509 0.34541005 0.04007108
 0.11571002 0.16719529 0.07273294 0.0659311  0.07405534 0.07214411
 0.39707923 0.08168238 0.03983118 0.115831   0.09993771 0.04329229
 0.06024299 0.45103034]
tr_loss:[0.10325925 0.1535748  0.02805823 0.09872057 0.11037476 0.41810074
 0.06450149 0.11243428 0.07059397 0.05590652 0.04341113 0.2755544
 0.05035248 0.04994124 0.0459612  0.02806874 0.09381644 0.08941016
 0.09367    0.0876404  0.07790086 0.08718248 0.07042237 0.06743745
 0.03984495 0.04768598 0.06786653 0.0405411  0.04596115 0.06894096
 0.04456576 0.02807002 0.10350122 0.0802604  0.10982983 0.06849144
 0.02807004 0.05325267 0.07541753 0.04747054 0.05844473 0.58552516
 0.07884094 0.03683703 0.0534942  0.09277176 0.04054117 0.11001363
 0.10946812 0.02806998]
tr_loss:[0.04887702 0.04501364 0.03502852 0.02321218 0.06074262 0.08098213
 0.0614332  0.03758611 0.08216039 0.08041511 0.41174632 0.07351893
 0.08167261 0.10996629 0.2111655  0.3860851  0.06111269 0.11222985
 0.04386118 0.06950258 0.07451233 0.04874828 0.037559   0.07995649
 0.35624233 0.03820758 0.08884463 0.34424964 0.04013184 0.06842544
 0.08766333 0.02321215 0.10475212 0.08148182 0.0753689  0.04501363
 0.03962081 0.07795538 0.0232122  0.06873684 0.02321217 0.07323597
 0.02418149 0.03513239 0.1058378  0.05746363 0.03819113 0.08639042
 0.03705425 0.0481713 ]
tr_loss:[0.0485604  0.03559164 0.13530713 0.09549932 0.05055552 0.10460749
 0.11533873 0.07365347 0.12720215 0.05608962 0.05064889 0.02505756
 0.44194284 0.02505758 0.04235504 0.02505757 0.11476419 0.02505813
 0.2839567  0.07645019 0.02505757 0.03461151 0.0663685  0.0250576
 0.05891654 0.04531553 0.03609471 0.07900529 0.03559168 0.04531556
 0.03686477 0.04512123 0.11194614 0.10628748 0.05516317 0.08161559
 0.06042256 0.04178341 0.06620272 0.02507129 0.5233188  0.0794381
 0.03925212 0.06472075 0.07701534 0.03548385 0.06981681 0.0477795
 0.05946409 0.07760178]
tr_loss:[0.07230767 0.07036014 0.04721029 0.04046371 0.02612135 0.06922525
 0.03541956 0.06726028 0.07790275 0.10931218 0.04280873 0.0848005
 0.03140659 0.10942987 0.05478783 0.05975976 0.03446169 0.4831484
 0.04280793 0.05814464 0.02613867 0.02612132 0.07316934 0.04088825
 0.3966474  0.07582295 0.02612131 0.02612135 0.07496377 0.05198444
 0.04727965 0.02337345 0.09777077 0.04108727 0.08690234 0.04336128
 0.10955064 0.4847328  0.10718571 0.02612136 0.07912996 0.07281828
 0.02612134 0.07752274 0.05435835 0.07165943 0.04233479 0.0597788
 0.03600321 0.02744832]
tr_loss:[0.43436447 0.029293   0.04533513 0.05996203 0.03860706 0.04000575
 0.07556395 0.09602449 0.03674116 0.07319441 0.02927469 0.03776198
 0.06857141 0.09842746 0.03678714 0.08087737 0.02902399 0.15160778
 0.07597578 0.03392622 0.04744571 0.04062963 0.0368911  0.03218531
 0.0790513  0.0464413  0.02970568 0.38018838 0.0515948  0.03294821
 0.02927186 0.03417038 0.03611412 0.52887464 0.0832487  0.03044074
 0.10463182 0.02970527 0.0615292  0.02927179 0.06453963 0.03277028
 0.0290796  0.08325648 0.11048283 0.05243371 0.52514803 0.06009845
 0.04775123 0.02970571]
tr_loss:[0.07580033 0.10088651 0.06196208 0.03918407 0.04731186 0.07483409
 0.07074136 0.06092079 0.06959368 0.10117761 0.03899149 0.03335844
 0.31997338 0.389826   0.07426912 0.03206594 0.03458955 0.04707779
 0.05169895 0.05259746 0.03408305 0.0681095  0.0379156  0.03335845
 0.24861744 0.0769486  0.03030651 0.04189069 0.07394662 0.04193389
 0.0645059  0.03907726 0.07650356 0.07426926 0.06886227 0.05391802
 0.05007334 0.03039001 0.04193519 0.04787974 0.02992093 0.03160984
 0.0321507  0.03961623 0.09091979 0.03408305 0.09167594 0.0532188
 0.07297431 0.0299209 ]
tr_loss:[0.02807972 0.02707192 0.03061186 0.03475476 0.09920339 0.09348706
 0.02832681 0.04794633 0.07288533 0.0464042  0.10098119 0.05963942
 0.0457165  0.07080606 0.04869661 0.04547042 0.09017763 0.30119506
 0.03692589 0.04980153 0.05721221 0.03298338 0.03284137 0.03657173
 0.05168163 0.08819795 0.3330996  0.03884738 0.06483512 0.05639757
 0.06522683 0.02808004 0.08910436 0.07222696 0.04541028 0.03119065
 0.03577707 0.05735848 0.32424587 0.11494455 0.09149267 0.08627069
 0.03600793 0.42314833 0.07201276 0.07081416 0.02802126 0.06728135
 0.08913724 0.05011215]
tr_loss:[0.3339983  0.08841348 0.02649222 0.02650355 0.06608207 0.07159792
 0.0424817  0.03065767 0.06922595 0.02649223 0.04663945 0.06969669
 0.08656099 0.0459741  0.02649224 0.07096995 0.02971765 0.02869251
 0.08395886 0.02546762 0.02996672 0.03056535 0.03004607 0.08456746
 0.06361761 0.05227173 0.31824094 0.07177377 0.03132305 0.2862777
 0.08213988 0.03626528 0.03446569 0.02454831 0.02649223 0.07282493
 0.02649221 0.26479778 0.27257812 0.02649223 0.02725791 0.03163386
 0.05184169 0.05578157 0.0526559  0.06767933 0.35641092 0.07772112
 0.03566189 0.05525676]
tr_loss:[0.07059987 0.0789583  0.02416554 0.06462067 0.07572468 0.03277626
 0.02676718 0.2996055  0.02783865 0.02416553 0.02823921 0.02895871
 0.04207299 0.02416555 0.08207996 0.05438991 0.04402667 0.08408391
 0.07465243 0.02400586 0.5339356  0.04197879 0.06775824 0.05588381
 0.06104039 0.37915868 0.03106979 0.06021339 0.02416559 0.05931851
 0.3962626  0.08784149 0.0284643  0.04082219 0.04372796 0.0304423
 0.03308438 0.04289315 0.02416553 0.03712454 0.03535286 0.07384361
 0.03059603 0.08192609 0.02581045 0.04368571 0.036768   0.02630657
 0.02714211 0.04387781]
tr_loss:[0.02518452 0.04866346 0.0474794  0.02043284 0.0219385  0.07436679
 0.04293917 0.02129311 0.0491911  0.04232352 0.02128855 0.3710568
 0.30068508 0.02745077 0.39857846 0.01944893 0.04039349 0.25035676
 0.12096648 0.04513141 0.04920707 0.02128858 0.03992135 0.04012752
 0.05491425 0.02402786 0.0447484  0.04012158 0.49980897 0.02337758
 0.07488844 0.03976751 0.02130154 0.04189738 0.04577709 0.03701764
 0.05057021 0.07110287 0.04543041 0.05437647 0.06119052 0.04068988
 0.04261588 0.02956907 0.02098314 0.37013882 0.02337721 0.07220826
 0.02750884 0.05220304]
tr_loss:[0.02200866 0.02206949 0.0205628  0.04412638 0.04353992 0.0394939
 0.02056149 0.02358073 0.05203895 0.03293245 0.02056148 0.02566149
 0.06360439 0.03017349 0.04880218 0.1676498  0.06993107 0.07454257
 0.03943771 0.04756965 0.02056148 0.0431166  0.072854   0.06471719
 0.04882463 0.07191595 0.04963496 0.03335951 0.02395685 0.02206445
 0.04846222 0.03861753 0.02053056 0.3552032  0.02570662 0.02359635
 0.04531377 0.0235195  0.03029858 0.07100054 0.0394359  0.04697688
 0.06998096 0.02358092 0.03746694 0.04075314 0.04347752 0.07201566
 0.02665755 0.02056865]
tr_loss:[0.04902994 0.02037712 0.04438132 0.06855194 0.0203771  0.06835449
 0.02366027 0.08025287 0.03514615 0.02037709 0.0374339  0.02532364
 0.04098343 0.03711594 0.07137144 0.02037709 0.04386793 0.04719272
 0.07198964 0.1904993  0.06066693 0.29816    0.46346545 0.02374835
 0.04752732 0.05934698 0.04217761 0.02896857 0.20398721 0.06184845
 0.05785764 0.06954198 0.02037706 0.30260745 0.07047488 0.04393164
 0.04648899 0.02679451 0.02240789 0.03292768 0.04429884 0.04721835
 0.06876376 0.04358529 0.03988322 0.02037943 0.23454754 0.16236112
 0.06910019 0.02585348]
tr_loss:[0.02207457 0.06663581 0.03513696 0.07546766 0.0335305  0.04845632
 0.05774969 0.01900107 0.06933268 0.03184722 0.01900107 0.01900038
 0.06749446 0.02252408 0.04137247 0.02156161 0.03333344 0.01900105
 0.03737407 0.06690034 0.02429158 0.02077255 0.0220746  0.02565596
 0.02077258 0.06705372 0.02434503 0.02862481 0.02156163 0.02107046
 0.02658998 0.03138266 0.06882604 0.0215616  0.06948532 0.05013965
 0.01671762 0.03704237 0.03153142 0.06916234 0.03911438 0.02185253
 0.02727788 0.0367187  0.02212555 0.03113085 0.0189     0.02865863
 0.1753886  0.03641732]
tr_loss:[0.02225232 0.01527069 0.06425851 0.01592729 0.02524931 0.03658412
 0.03673244 0.26241323 0.01902624 0.071087   0.36020556 0.03953358
 0.06579009 0.02157074 0.0306607  0.06426825 0.01527043 0.02112786
 0.02225574 0.03405663 0.04406982 0.04708832 0.40706292 0.0263237
 0.02976765 0.01527067 0.36748245 0.04501384 0.026324   0.06511588
 0.0341941  0.02139878 0.28215662 0.0152606  0.06326453 0.02906252
 0.01976591 0.04909412 0.01527068 0.02225233 0.02162949 0.01527057
 0.04505332 0.01816921 0.02723501 0.03920952 0.03459471 0.02652458
 0.01527067 0.02939222]
tr_loss:[0.02761161 0.01338855 0.07412796 0.05250088 0.0398247  0.01338858
 0.01338855 0.03552584 0.01338854 0.03660965 0.02296123 0.04560126
 0.47256345 0.02499889 0.01335785 0.02081764 0.01685876 0.2736693
 0.02161564 0.01338855 0.41784555 0.02718405 0.06341803 0.01338852
 0.06065933 0.01338854 0.03557035 0.02781568 0.03329227 0.01673524
 0.04783066 0.02797697 0.03309625 0.01332822 0.01338709 0.04290956
 0.06391849 0.02537169 0.03573479 0.02861094 0.04794801 0.0220933
 0.1340386  0.06374092 0.0625443  0.06259751 0.04582939 0.03674884
 0.06226433 0.06346001]
tr_loss:[0.01184168 0.02376628 0.0301948  0.03164772 0.05300961 0.02804464
 0.01184169 0.03618981 0.06074942 0.02787699 0.04856951 0.21753152
 0.02702466 0.3435564  0.4179996  0.02140748 0.03091221 0.03420701
 0.04344375 0.03683532 0.25730732 0.02478191 0.3926935  0.02259939
 0.03365082 0.02445178 0.05055655 0.02479389 0.02787696 0.02862424
 0.04150384 0.02598234 0.05114381 0.48373908 0.02406698 0.02773008
 0.02151094 0.02836646 0.03748447 0.4572224  0.01174697 0.03004426
 0.05126989 0.05867208 0.02261576 0.02439259 0.06112971 0.02352416
 0.06144534 0.03648629]
tr_loss:[0.04049182 0.02503939 0.06432546 0.03466568 0.01242607 0.06759564
 0.02890683 0.4410314  0.06448592 0.02256078 0.02706223 0.02429621
 0.02662203 0.03167128 0.06129529 0.02300256 0.05494636 0.01242614
 0.0361756  0.10302682 0.02407338 0.02157789 0.02161482 0.03199127
 0.06585205 0.04297629 0.0370598  0.06693915 0.07091868 0.02617295
 0.03161234 0.02332671 0.04993614 0.01242609 0.06492992 0.02756717
 0.01241989 0.3079861  0.03176264 0.03282354 0.02449096 0.02445294
 0.01977576 0.06342508 0.20330338 0.03141112 0.0348479  0.2590273
 0.03140455 0.05286466]
tr_loss:[0.0466768  0.03049194 0.02168623 0.03461006 0.01146661 0.02313497
 0.01146661 0.02042868 0.16369252 0.06126574 0.03018231 0.01146436
 0.02783393 0.03821129 0.03148332 0.06100671 0.03341817 0.02938665
 0.07420784 0.04924271 0.03315237 0.06014072 0.03212947 0.0370758
 0.0607246  0.0285111  0.01146658 0.02358579 0.0346228  0.15825228
 0.03165361 0.04005953 0.06028698 0.01146658 0.06753509 0.2900378
 0.03971096 0.06096506 0.02971486 0.01093026 0.04165222 0.01146659
 0.02416818 0.03298797 0.03435059 0.03115246 0.01973728 0.03336122
 0.04227362 0.02412627]
tr_loss:[0.02630766 0.02925159 0.05484551 0.05854067 0.03531866 0.00910121
 0.02359598 0.04395857 0.02049671 0.02485895 0.04553691 0.01916595
 0.04081676 0.03000936 0.02874985 0.03157607 0.03251195 0.03251948
 0.01863771 0.02778075 0.02326272 0.04139697 0.00867001 0.03736013
 0.01979635 0.0091026  0.02192216 0.03081055 0.0296517  0.0221472
 0.03534546 0.0327225  0.00898203 0.04826519 0.0621125  0.32192773
 0.02842755 0.00910344 0.03095255 0.05769958 0.04853966 0.04372254
 0.05713378 0.13573809 0.03557832 0.03092619 0.02307634 0.05705843
 0.3296121  0.01983486]
tr_loss:[0.02296564 0.03933841 0.03112897 0.03198782 0.02145037 0.0222912
 0.05496969 0.05509249 0.21351452 0.02520022 0.06247235 0.02757914
 0.01974049 0.00833785 0.03817863 0.03669899 0.30023345 0.02317983
 0.01640265 0.00833786 0.00831244 0.29339105 0.02426448 0.04016681
 0.0298741  0.01974048 0.14711884 0.03628372 0.03801679 0.00833787
 0.04934162 0.03635968 0.0230302  0.03224205 0.02046029 0.02937756
 0.03862851 0.01686121 0.01897558 0.01974039 0.00833788 0.03168753
 0.05488618 0.02398511 0.00833786 0.01766835 0.03911377 0.02642806
 0.05249237 0.05658631]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1100 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1101, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1101 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1102, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1102 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1103, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1103 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1104, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1104 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1105, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1105 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1106, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1106 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1107, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1107 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1108, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1108 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1109, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1109 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1110, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1110 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1111, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1111 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1112, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1112 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1113, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1113 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1114, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1114 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1115, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1115 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1116, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1116 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1117, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1117 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1118, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1118 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1119, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1119 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1120, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1120 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1121, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1121 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1122, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1122 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1123, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1123 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1124, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1124 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1125, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1125 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1126, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1126 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1127, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1127 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1128, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1128 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1129, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1129 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1130, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1130 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1131, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1131 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1132, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1132 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1133, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1133 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1134, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1134 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1135, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1135 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1136, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1136 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1137, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1137 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1138, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1138 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1139, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1139 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1140, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1140 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1141, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1141 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1142, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1142 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1143, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1143 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1144, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1144 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1145, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1145 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1146, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1146 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1147, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1147 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1148, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1148 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1149, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1149 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1150, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1150 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1151, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1151 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1152, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1152 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1153, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1153 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1154, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1154 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1155, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1155 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1156, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1156 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1157, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1157 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1158, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1158 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1159, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1159 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1160, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1160 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1161, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1161 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1162, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1162 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1163, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1163 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1164, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1164 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1165, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1165 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1166, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1166 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1167, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1167 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1168, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1168 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1169, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1169 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1170, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1170 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1171, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1171 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1172, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1172 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1173, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1173 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1174, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1174 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1175, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1175 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1176, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1176 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1177, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1177 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1178, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1178 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1179, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1179 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1180, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1180 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1181, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1181 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1182, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1182 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1183, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1183 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1184, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1184 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1185, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1185 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1186, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1186 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1187, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1187 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1188, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1188 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1189, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1189 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1190, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1190 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1191, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1191 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1192, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1192 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1193, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1193 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1194, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1194 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1195, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1195 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1196, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1196 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1197, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1197 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1198, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1198 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1199, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1199 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1200, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-1100
text_input.shape
(1200, 14400)
learning_input_tmp.shape
(1200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1200, 80)
learning_output.shape
(750, 80)
Model: "sequential_25"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_25 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0738387  1.0368477  0.79002404 1.0410794  0.8526289  0.791004
 0.99843615 0.53283083 0.87815535 0.790094   1.0738387  1.0740181
 0.81820977 0.8624261  1.0598418  0.7839773  0.81113565 0.8575432
 0.96344554 0.5423008  0.99115646 0.8789047  0.8576854  0.87662727
 0.790304   0.9635245  0.84110606 1.053592   0.87259007 1.0276198
 0.5386066  0.94644415 0.79005814 0.8072144  1.0347483  0.8575219
 0.88056517 0.78950614 1.0738474  1.001559   0.8444532  0.7912742
 0.8492883  1.0483396  0.9993685  0.8561553  1.0709068  0.7993191
 1.0277239  0.9241716 ]
tr_loss:[0.51654446 0.42417344 0.49780187 0.52850497 0.5179453  0.5099225
 0.42519957 0.41412473 0.4019041  0.50999254 0.53632563 0.55281484
 0.50342476 0.5262118  0.42654592 0.49782142 0.50688946 0.53310317
 0.55281496 0.41215783 0.40640813 0.51642215 0.52850807 0.5137691
 0.42622477 0.538235   0.55281484 0.45901698 0.5202261  0.5233793
 0.5528032  0.51555717 0.4447419  0.5361351  0.42661133 0.49669576
 0.4883214  0.552815   0.4861614  0.55277836 0.55275935 0.52216357
 0.5059538  0.4823648  0.42386732 0.501505   0.42838138 0.48193517
 0.51908696 0.4109705 ]
tr_loss:[0.3857939  0.357432   0.3960947  0.36385995 0.38024625 0.3621399
 0.3126981  0.36425394 0.39602956 0.39176098 0.3375899  0.4205343
 0.38058835 0.3749196  0.34566486 0.29560217 0.37593168 0.37713927
 0.31745252 0.38065082 0.31615385 0.3860739  0.36837873 0.37491968
 0.37492007 0.294701   0.36448413 0.37194818 0.36448425 0.31487006
 0.2957272  0.36689338 0.2957343  0.34696358 0.3428337  0.2852242
 0.37630957 0.3749196  0.37116182 0.301588   0.28677127 0.31184334
 0.33639508 0.36490715 0.3757589  0.31849518 0.38212615 0.37491962
 0.37960777 0.3752131 ]
tr_loss:[0.20076323 0.24450226 0.23644666 0.21269313 0.24617997 0.24060765
 0.20172557 0.24618001 0.23713577 0.22796085 0.2399344  0.24819171
 0.2368259  0.25355205 0.21338043 0.24450223 0.25681502 0.24438985
 0.26850215 0.23947938 0.22945943 0.2699279  0.24028239 0.22381906
 0.22782001 0.23756953 0.23414874 0.2146533  0.19883572 0.2073144
 0.24308228 0.2622821  0.24546418 0.24459787 0.22765036 0.27094746
 0.24450216 0.2082552  0.23627229 0.24450323 0.23690204 0.27132294
 0.22725353 0.21697631 0.24457245 0.22401233 0.21444187 0.2025077
 0.25024265 0.24256048]
tr_loss:[0.14979604 0.15792312 0.1699247  0.1457914  0.14150906 0.1470065
 0.17102082 0.14416607 0.1630623  0.1793161  0.17588755 0.14592965
 0.14153364 0.16306242 0.14317909 0.1752123  0.1406773  0.15925431
 0.16130237 0.14191401 0.1646482  0.15956137 0.14148946 0.14511058
 0.15961502 0.13021754 0.16596034 0.13899097 0.1597071  0.13825628
 0.16020477 0.13839383 0.16308156 0.16309005 0.15657349 0.1470451
 0.18856558 0.16287915 0.1674814  0.17999576 0.13496785 0.1692858
 0.14571352 0.14481978 0.16331227 0.15562555 0.14579627 0.15596482
 0.15084001 0.14462125]
tr_loss:[0.1018528  0.11238401 0.09006442 0.09838103 0.10691887 0.09466769
 0.09808331 0.10783136 0.09442274 0.09709883 0.09681933 0.09025618
 0.13701746 0.11109485 0.11084168 0.10868528 0.09117072 0.10098841
 0.10625718 0.1112953  0.09777509 0.1612738  0.10576461 0.12656455
 0.15467913 0.10812507 0.10185145 0.1037485  0.10354575 0.095673
 0.10301851 0.10185144 0.10751133 0.10625718 0.09418486 0.09899284
 0.11970885 0.10747949 0.10126052 0.1076685  0.10102196 0.10197437
 0.08920945 0.08851486 0.09357447 0.09006479 0.1079098  0.10547622
 0.13747807 0.1577229 ]
tr_loss:[0.0917813  0.16182439 0.08772216 0.10335355 0.1688491  0.06442247
 0.07670099 0.06813812 0.08223355 0.06679959 0.16574137 0.06389247
 0.07724822 0.12057004 0.10608635 0.07873595 0.11802378 0.08147265
 0.15364389 0.06636038 0.06679965 0.10228894 0.0885828  0.07924431
 0.0886052  0.12383872 0.08758776 0.08787358 0.06693693 0.09682928
 0.07391109 0.10882793 0.08298191 0.14171374 0.07029883 0.06813811
 0.08255338 0.11802293 0.08901404 0.09232282 0.08624994 0.16103046
 0.09087941 0.10674922 0.09362803 0.06728403 0.07743471 0.16635457
 0.06813817 0.13320245]
tr_loss:[0.04171779 0.0508549  0.04171718 0.16524926 0.05573566 0.11393962
 0.04788984 0.14800008 0.03512054 0.04171719 0.05445854 0.1536258
 0.16640529 0.08239979 0.05598606 0.07482719 0.05085492 0.09524588
 0.07495985 0.07830065 0.06835677 0.08453336 0.04285951 0.06094569
 0.06579095 0.04466141 0.0559881  0.09446233 0.07566937 0.07571633
 0.07557367 0.09548737 0.07637826 0.07361202 0.04532441 0.0417172
 0.07597367 0.07175677 0.09189501 0.07611106 0.05520022 0.06505404
 0.05473402 0.0658654  0.09724712 0.11801545 0.06416529 0.08871533
 0.05520017 0.04171732]
tr_loss:[0.15030804 0.09270225 0.13711043 0.0404695  0.13110735 0.10353591
 0.15736091 0.04418002 0.08632495 0.04782225 0.05843281 0.05458508
 0.07828642 0.08525623 0.04046952 0.14049348 0.0953753  0.05032162
 0.08865077 0.11083575 0.04331223 0.05650599 0.04046953 0.03952315
 0.07812168 0.07890041 0.07931118 0.08518809 0.08024943 0.04857889
 0.07935443 0.09311526 0.08007564 0.03617063 0.03478298 0.0404695
 0.09577755 0.08828957 0.06134919 0.10676785 0.04046953 0.04850771
 0.04046836 0.04895659 0.07850654 0.05047579 0.08236294 0.09046837
 0.04771022 0.04730633]
tr_loss:[0.04695892 0.05563084 0.0464711  0.0857607  0.09174941 0.08385855
 0.07971974 0.13226373 0.09414048 0.06707753 0.04158121 0.06707795
 0.0868446  0.05514282 0.06201614 0.04824988 0.14607912 0.05971669
 0.07947079 0.10171805 0.04928739 0.06246845 0.09300752 0.08934762
 0.08506404 0.07971625 0.0882949  0.08485667 0.0655992  0.03723212
 0.04840431 0.08840298 0.0586391  0.09295875 0.1427594  0.0736279
 0.04366447 0.07735127 0.07867189 0.04928745 0.04337702 0.04161645
 0.08389212 0.06388535 0.0492874  0.06707756 0.13709226 0.05309469
 0.06723122 0.06061358]
tr_loss:[0.08057997 0.06392992 0.13003068 0.11051643 0.05657274 0.04994921
 0.07220284 0.05212529 0.04870445 0.05555288 0.08940326 0.05464379
 0.08307841 0.09373058 0.11437494 0.10890962 0.06423354 0.05403166
 0.05274753 0.05093274 0.09221999 0.08647452 0.0811642  0.04131145
 0.0501558  0.09628487 0.06101374 0.05770975 0.08140766 0.08098201
 0.05017997 0.0847256  0.08124264 0.08015347 0.1282516  0.08112204
 0.08086969 0.04811009 0.05624612 0.07846294 0.04419576 0.04352636
 0.04687271 0.07872252 0.06882511 0.04868412 0.08014284 0.08641578
 0.10253312 0.10632342]
tr_loss:[0.08265083 0.07882991 0.07713395 0.04717252 0.08666451 0.08249821
 0.07598937 0.03957301 0.04078776 0.10173704 0.08001967 0.06526388
 0.11148994 0.08109144 0.03718737 0.04717248 0.04990949 0.08403151
 0.05736512 0.05173016 0.1317278  0.05751511 0.06194843 0.03956417
 0.058133   0.08082385 0.07808688 0.07775216 0.11897614 0.13936469
 0.05943617 0.04678952 0.08543174 0.08324463 0.04597776 0.04675957
 0.0785384  0.0784816  0.07793435 0.0763417  0.05588372 0.05129595
 0.08592325 0.08968874 0.08239322 0.05518822 0.08345904 0.07590101
 0.08352254 0.03956422]
tr_loss:[0.08551369 0.08622082 0.08450422 0.03165726 0.13651292 0.03375341
 0.03165727 0.07614858 0.05223299 0.03821582 0.09157456 0.03165727
 0.13299558 0.03165727 0.08348657 0.03849599 0.05142886 0.11750723
 0.08260757 0.03165727 0.03165726 0.14405188 0.05312824 0.07294221
 0.04197438 0.04652491 0.05047754 0.05096934 0.04083215 0.04312002
 0.06848367 0.03165723 0.04011149 0.03167566 0.03165726 0.03772606
 0.04666135 0.03351442 0.04791823 0.07475487 0.03165727 0.03931411
 0.05223296 0.13265233 0.07492082 0.06629437 0.08240833 0.06701811
 0.04937361 0.05834866]
tr_loss:[0.02567449 0.07867064 0.04041957 0.09129745 0.07942847 0.04676952
 0.10745661 0.08458807 0.04710661 0.02567451 0.05116672 0.02567447
 0.04095548 0.04676955 0.07184324 0.05278961 0.04676988 0.05296853
 0.14477685 0.04432397 0.0256745  0.10176945 0.05186021 0.08163232
 0.0508946  0.03099132 0.0419569  0.0793507  0.04763756 0.09641423
 0.05606393 0.07570113 0.07539736 0.10365097 0.11212911 0.04114322
 0.03413913 0.03719099 0.10189535 0.03906044 0.02567448 0.02567447
 0.07309517 0.05116668 0.04732867 0.0985287  0.03521695 0.0587712
 0.04303818 0.07951506]
tr_loss:[0.03439105 0.14069267 0.07186837 0.06920569 0.03883392 0.04005775
 0.08430861 0.1484383  0.01987929 0.03865517 0.13587233 0.03997129
 0.01992425 0.05277298 0.07077783 0.10482566 0.01994402 0.01998752
 0.07284399 0.03900101 0.03709596 0.04235941 0.02718812 0.06864835
 0.03594047 0.03359903 0.04512709 0.06943618 0.08212785 0.06883681
 0.01987929 0.04933597 0.01990635 0.02932551 0.03616684 0.03714763
 0.07078134 0.05400588 0.0198793  0.0495597  0.06912769 0.06981774
 0.0336058  0.0622151  0.02036441 0.0686288  0.02746205 0.06987211
 0.01987929 0.0385399 ]
tr_loss:[0.05254159 0.06438304 0.03537378 0.13049902 0.03231688 0.03231686
 0.05785527 0.01647543 0.08128868 0.05800175 0.02875781 0.05894626
 0.05734358 0.03574379 0.09677233 0.03191669 0.03826727 0.02000708
 0.0581973  0.02797761 0.03590964 0.10699383 0.04532925 0.02783013
 0.04785496 0.06797638 0.04332888 0.04641952 0.01655242 0.08791855
 0.06049724 0.03104755 0.01639892 0.08123817 0.0377131  0.02975064
 0.01639889 0.04594994 0.03816732 0.05915012 0.08834272 0.04164386
 0.05485557 0.13070276 0.06448369 0.05813666 0.01639938 0.06222925
 0.1301659  0.04167877]
tr_loss:[0.03461279 0.06426597 0.05696474 0.02895657 0.05738918 0.13166241
 0.05795009 0.03017176 0.03423846 0.05454134 0.03878486 0.09247091
 0.0415298  0.02599959 0.06075559 0.03220603 0.0266281  0.06180893
 0.05953401 0.05452553 0.03848733 0.02528892 0.02217136 0.04299998
 0.05528037 0.06964417 0.07869438 0.03784706 0.02564507 0.05811948
 0.06593402 0.06756938 0.05479559 0.06282541 0.02068793 0.0713322
 0.02587283 0.13805506 0.03947639 0.04782917 0.02068793 0.1504983
 0.0553758  0.06274261 0.02881132 0.06723966 0.03309223 0.10087629
 0.05466504 0.04339562]
tr_loss:[0.02697311 0.03844399 0.05697586 0.03518072 0.06068703 0.02752909
 0.0679879  0.05519861 0.04640289 0.02711955 0.07544532 0.04658693
 0.05524522 0.06263064 0.059133   0.08815578 0.04307499 0.05913705
 0.04823815 0.03697027 0.03643807 0.05995169 0.08097262 0.02719464
 0.04685777 0.05613168 0.04189452 0.03462702 0.08816558 0.03448189
 0.05572374 0.02920936 0.06627049 0.05016454 0.05567664 0.02804729
 0.09403463 0.10800276 0.03701089 0.03901883 0.0270361  0.02472677
 0.0269735  0.06080814 0.06593097 0.05909234 0.03538436 0.14337945
 0.02697312 0.04126706]
tr_loss:[0.04127657 0.03302621 0.05680592 0.10340218 0.02722649 0.07406532
 0.0550262  0.04643065 0.08612899 0.02722646 0.06027831 0.03575657
 0.0323476  0.04512312 0.08794937 0.06715918 0.04110282 0.0566398
 0.09707655 0.03550747 0.03575657 0.03576093 0.05919091 0.03585989
 0.02722649 0.04440091 0.03388157 0.04927738 0.06039401 0.09438229
 0.06744236 0.05358226 0.04551216 0.05971699 0.02722648 0.02878037
 0.05511796 0.13481522 0.03486405 0.05096098 0.03480079 0.14277777
 0.04368124 0.09580763 0.05750077 0.05423044 0.02722665 0.05399931
 0.0272499  0.09171542]
tr_loss:[0.09223036 0.12734208 0.04988233 0.06352638 0.0500543  0.02170481
 0.03805948 0.03506571 0.05965927 0.03415731 0.02170484 0.0524205
 0.03575314 0.03110624 0.1307926  0.08598782 0.0594149  0.05058409
 0.06719436 0.03887133 0.05010223 0.03506577 0.03400458 0.03466819
 0.03916833 0.02170489 0.03224298 0.03415734 0.03613811 0.05958236
 0.0416419  0.02569867 0.02170483 0.03578176 0.03120672 0.04973951
 0.0445431  0.08601489 0.05105165 0.06385443 0.05151321 0.03155406
 0.02904907 0.06070781 0.03401174 0.12227541 0.06596533 0.03072637
 0.08793296 0.12335663]
tr_loss:[0.06409937 0.03320532 0.03979501 0.03028025 0.04630812 0.08729814
 0.0353883  0.02611555 0.05502423 0.03028029 0.04518672 0.0836039
 0.06410581 0.07095435 0.04094176 0.03181015 0.03267721 0.03538831
 0.05181316 0.07215891 0.03836666 0.03028027 0.07240088 0.05161146
 0.03388166 0.02261083 0.03196765 0.0308777  0.02092045 0.05199609
 0.05906402 0.03168241 0.08439317 0.04345209 0.03842386 0.04492925
 0.05447758 0.05111672 0.05152416 0.03450623 0.03297878 0.03388162
 0.02092038 0.03009641 0.02235364 0.05140275 0.03105401 0.03009641
 0.04326373 0.05176759]
tr_loss:[0.03624656 0.03115749 0.06404968 0.12124413 0.0518074  0.04877258
 0.05116792 0.01910416 0.04860837 0.01910418 0.10769957 0.04989909
 0.10722692 0.01910416 0.04499275 0.04963075 0.04867657 0.02834797
 0.04933503 0.07466732 0.04906189 0.04175509 0.06983455 0.02833995
 0.04056172 0.07503415 0.01911133 0.04887623 0.05011944 0.10907888
 0.0191047  0.03678931 0.04587373 0.1030824  0.03025661 0.03605084
 0.11832647 0.06664752 0.02530298 0.05992356 0.02224139 0.03323834
 0.02616763 0.03733741 0.05177087 0.0489273  0.03846793 0.04972878
 0.0191042  0.05114297]
tr_loss:[0.04492932 0.02519848 0.04849373 0.03092484 0.10633661 0.11022687
 0.03172287 0.06836681 0.01896989 0.02642424 0.05067797 0.02544208
 0.01896997 0.03025558 0.04553106 0.06791781 0.07132509 0.07289001
 0.0227843  0.03164609 0.01908405 0.11445552 0.02297027 0.04290807
 0.02900732 0.02839158 0.03802417 0.02721532 0.03591146 0.11708225
 0.03106233 0.05088749 0.05037703 0.0189699  0.02522128 0.05215185
 0.04824817 0.02258064 0.06554016 0.01896988 0.04547857 0.07034951
 0.06648826 0.03249923 0.03894404 0.02941569 0.04854961 0.02996115
 0.04985379 0.0189699 ]
tr_loss:[0.02759805 0.11558463 0.1075361  0.01851022 0.02267215 0.05149313
 0.0508388  0.05527342 0.02941369 0.05209691 0.02654749 0.01851022
 0.04202731 0.02494101 0.10748021 0.02264424 0.02664286 0.06381217
 0.05795731 0.02251881 0.0236159  0.02017651 0.11497054 0.02875649
 0.01851092 0.0195022  0.02113094 0.11724275 0.01851022 0.03113454
 0.02389271 0.01851022 0.03216454 0.01851025 0.04593814 0.01986111
 0.0294137  0.02531785 0.02646726 0.01870585 0.02878935 0.06368574
 0.06590058 0.04525089 0.04629072 0.01851021 0.05131506 0.03231936
 0.05203972 0.06023463]
tr_loss:[0.04969885 0.02607703 0.0464657  0.02369374 0.04948024 0.03068531
 0.0161196  0.03031176 0.0472343  0.01646768 0.03410212 0.02025616
 0.02101393 0.11606268 0.11653571 0.11406051 0.01783805 0.02624699
 0.05273324 0.01611959 0.03215453 0.02141757 0.05120107 0.03190577
 0.03932415 0.04276334 0.04762691 0.04057227 0.02245574 0.01661396
 0.03068533 0.11728545 0.03213905 0.03909968 0.02025323 0.04769812
 0.02584542 0.05307178 0.05828305 0.01611961 0.02696413 0.01611963
 0.1115392  0.05354459 0.04879674 0.08314066 0.01614353 0.02033486
 0.02456545 0.0170067 ]
tr_loss:[0.04303332 0.02640337 0.02916912 0.0556842  0.01870421 0.01760608
 0.02916172 0.0569878  0.05476422 0.0284187  0.11956453 0.05372462
 0.0218509  0.01989906 0.05475397 0.04521159 0.11867521 0.01344434
 0.0312102  0.02640335 0.0299162  0.05260407 0.04419414 0.01343852
 0.05910288 0.05008138 0.02305282 0.0282361  0.01746771 0.04188937
 0.10272968 0.02751927 0.04246251 0.11199403 0.02286254 0.0732011
 0.04976292 0.04813267 0.04727111 0.06750945 0.01343853 0.0469424
 0.01343852 0.0580963  0.05836933 0.02762623 0.06024887 0.02306108
 0.02088549 0.06529256]
tr_loss:[0.02369182 0.02307113 0.05290613 0.02941933 0.04678025 0.06822006
 0.02146385 0.11731543 0.03335439 0.02399886 0.01908868 0.01802078
 0.02777782 0.02609031 0.02748131 0.02437059 0.02510638 0.04624109
 0.07614818 0.02340806 0.04552477 0.01817407 0.02411571 0.02307759
 0.06047557 0.11792523 0.01293564 0.11571022 0.07571888 0.02420172
 0.02412686 0.02675516 0.01293011 0.02167369 0.05179977 0.05914865
 0.03593783 0.04599268 0.07511212 0.06723715 0.0311762  0.02152484
 0.02056963 0.01292848 0.05986376 0.05916015 0.07052482 0.057029
 0.01778753 0.02348917]
tr_loss:[0.02348115 0.06449679 0.02667219 0.01982585 0.06260234 0.0260725
 0.02783629 0.02783715 0.0569925  0.05308748 0.06869586 0.06388141
 0.04675124 0.01720838 0.05351445 0.05102311 0.06283215 0.04780465
 0.0479774  0.02822777 0.0466271  0.01509877 0.04521785 0.01301594
 0.0265489  0.04702278 0.01300996 0.02048649 0.01301593 0.01912186
 0.04990721 0.11444718 0.03844664 0.10956661 0.02562649 0.02600088
 0.01301591 0.11151259 0.01301591 0.06877543 0.06795441 0.02403567
 0.01301594 0.02836718 0.01982202 0.08884053 0.04737123 0.02344616
 0.02276827 0.01315353]
tr_loss:[0.02014566 0.10519771 0.01751876 0.0444082  0.10101049 0.02857026
 0.04520901 0.02860761 0.01941249 0.03250289 0.04598765 0.04586578
 0.02195569 0.10314785 0.01882162 0.04552897 0.05186905 0.04976188
 0.02875997 0.03809026 0.03276528 0.06271482 0.10188071 0.01941249
 0.10229914 0.04515428 0.04398316 0.02454012 0.02427803 0.0329744
 0.04486261 0.10554622 0.02115521 0.0434326  0.02766601 0.01183457
 0.01776348 0.01183458 0.0118346  0.01183476 0.0439245  0.05066808
 0.02454077 0.03941188 0.06306454 0.01964572 0.04393915 0.10148066
 0.07101057 0.01974232]
tr_loss:[0.10296325 0.03577887 0.01577613 0.0467638  0.01116875 0.03632526
 0.03034927 0.01116844 0.04278585 0.04142422 0.04170636 0.04303666
 0.01116979 0.09941959 0.06218258 0.04418858 0.01116843 0.05188614
 0.01116843 0.01116842 0.05389068 0.04148031 0.01375422 0.05977943
 0.04906712 0.02015653 0.06581604 0.0233029  0.02321451 0.02219641
 0.01561792 0.01116844 0.02105648 0.04617793 0.02720994 0.04922337
 0.01939086 0.03034925 0.01116843 0.02233922 0.02309062 0.05748148
 0.02128567 0.04920831 0.10699997 0.02141469 0.04254332 0.01116844
 0.05003361 0.01826921]
text_input.shape
(1200, 14400)
learning_input_tmp.shape
(1200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1200, 80)
learning_output.shape
(750, 80)
Model: "sequential_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_26 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.8900732  0.9810378  0.89078283 1.1193637  0.7736446  1.027362
 0.8597948  0.87518775 0.9701767  0.7587865  1.0342373  1.0231007
 0.804464   1.1180385  1.1180286  0.98132074 0.990849   0.9166374
 0.97350293 1.085427   1.0366408  1.1180284  0.8029526  1.0666349
 0.6450879  1.1180284  0.64213485 0.91577417 0.92112464 1.1180285
 0.99954253 1.0355566  0.80255127 1.045819   0.8024729  1.118964
 1.1180284  1.0081165  0.88563395 1.0142521  0.9894196  0.8026187
 1.1181865  0.8604702  0.8025819  0.9895002  0.6477464  0.80244255
 0.80245286 1.0217322 ]
tr_loss:[0.6106947  0.45658177 0.46134862 0.45374447 0.4467798  0.42262086
 0.46600017 0.5997549  0.5985832  0.61771935 0.6052922  0.65146816
 0.5803944  0.44427767 0.6521691  0.4308433  0.52078354 0.6521691
 0.621778   0.5615498  0.45922804 0.4667635  0.44215846 0.4448437
 0.46439514 0.55265313 0.5757159  0.44495088 0.4369568  0.59495527
 0.62749493 0.618104   0.6116396  0.6060321  0.64184636 0.64885044
 0.59975463 0.65216917 0.65216905 0.4443241  0.6470423  0.56669164
 0.5178765  0.59593356 0.6205644  0.6559502  0.6274562  0.46228904
 0.5886424  0.522607  ]
tr_loss:[0.3544814  0.44109297 0.35865864 0.44965833 0.40824825 0.35484868
 0.42597762 0.3774015  0.39807743 0.43810853 0.34372836 0.3436108
 0.43871942 0.42810598 0.41021377 0.43810853 0.41754645 0.35398403
 0.41027704 0.44769892 0.4214131  0.35912815 0.41283065 0.34743404
 0.33882183 0.4411725  0.35820085 0.4381085  0.45422632 0.43784267
 0.35778818 0.4393323  0.35515687 0.4147138  0.3550946  0.35499755
 0.4381086  0.43405572 0.45801863 0.38189825 0.3878667  0.43810835
 0.3591078  0.44727483 0.42141294 0.35440502 0.41754657 0.43768993
 0.42695493 0.37375057]
tr_loss:[0.27109796 0.24839655 0.26801667 0.2616097  0.27062482 0.27375895
 0.27910823 0.2786706  0.25315097 0.3106685  0.28373367 0.25714895
 0.26352972 0.27852076 0.27279082 0.22615656 0.2710959  0.2834799
 0.25638467 0.26160964 0.27262565 0.25522637 0.2822802  0.2616096
 0.23092262 0.24919438 0.26763916 0.28653616 0.27790722 0.2616016
 0.23075771 0.25377744 0.22514987 0.22531275 0.25801688 0.30259508
 0.24671671 0.24839763 0.26405612 0.27251548 0.23347576 0.23121572
 0.2828969  0.23018296 0.2605757  0.28213984 0.26878124 0.29994392
 0.283504   0.2684255 ]
tr_loss:[0.19050804 0.20502248 0.18729863 0.17491624 0.16770817 0.18726774
 0.21183237 0.2032986  0.2049915  0.18187895 0.1822029  0.17961396
 0.18715656 0.17950603 0.17966604 0.21771947 0.19489968 0.16973679
 0.20169763 0.18418464 0.1609895  0.18723777 0.18297634 0.20122609
 0.16960469 0.17993243 0.1725531  0.19050805 0.17098868 0.19898762
 0.19432977 0.23847106 0.16218789 0.16116767 0.20051503 0.20262566
 0.22672978 0.17432877 0.18220289 0.20163755 0.1822029  0.18062842
 0.2003349  0.19216372 0.16648982 0.18127167 0.17462175 0.1716471
 0.18095106 0.16466196]
tr_loss:[0.13798746 0.14641319 0.15292516 0.14544898 0.12994137 0.15292108
 0.12535162 0.13364755 0.1759358  0.16305251 0.17054471 0.15222678
 0.16857296 0.14273757 0.17518392 0.15445632 0.14353144 0.14548743
 0.16283143 0.15292513 0.15292516 0.14634329 0.12835117 0.14000764
 0.1527697  0.15281779 0.1568189  0.1480979  0.22522421 0.12551486
 0.14487198 0.1351858  0.15053144 0.13536464 0.14332587 0.14703044
 0.16430047 0.15292518 0.13518585 0.1796057  0.15292516 0.12385325
 0.15292516 0.15637138 0.15291938 0.14455098 0.16361935 0.14696875
 0.15285242 0.20924716]
tr_loss:[0.12849078 0.12256183 0.12206533 0.17375636 0.12849082 0.16740373
 0.11780083 0.12732534 0.14556476 0.16159454 0.1993157  0.14409918
 0.13393542 0.19522358 0.14714858 0.12732604 0.12700003 0.14046356
 0.12544367 0.1352633  0.12732601 0.13704064 0.12029827 0.12732573
 0.11878879 0.20317379 0.1272815  0.20085712 0.13360271 0.12715797
 0.14110978 0.14577998 0.13106772 0.19065827 0.12125675 0.17323928
 0.20629768 0.12114991 0.16991295 0.13737552 0.17361602 0.127326
 0.12281676 0.1434271  0.12732601 0.16076764 0.16214737 0.20854649
 0.11698232 0.12732601]
tr_loss:[0.1133757  0.13997969 0.09089839 0.15731819 0.09933853 0.09607463
 0.1038877  0.15617819 0.11746867 0.1135629  0.13449284 0.18079352
 0.10388768 0.11268332 0.10301912 0.10388744 0.11393368 0.16053723
 0.09645206 0.12105469 0.11103038 0.11305098 0.18649653 0.128622
 0.11830912 0.13751508 0.12518398 0.10388768 0.13084562 0.08787283
 0.11393373 0.10393985 0.14409491 0.1189091  0.09780054 0.13361984
 0.10874176 0.12776808 0.11304144 0.11223413 0.11827717 0.12103959
 0.1175004  0.11739407 0.15848541 0.13975039 0.11739755 0.11173494
 0.11903546 0.13641934]
tr_loss:[0.0894395  0.0767329  0.07592038 0.08608501 0.07286016 0.12344442
 0.09204538 0.07888881 0.09077594 0.09036931 0.10183114 0.09634821
 0.08154172 0.16005126 0.09106763 0.10990216 0.07555424 0.15843399
 0.10648279 0.09738936 0.09038433 0.13412592 0.09738941 0.09318968
 0.13567866 0.08995892 0.09568175 0.08913998 0.0839905  0.075683
 0.09139844 0.13426483 0.09036109 0.12980692 0.0663208  0.07332343
 0.07384758 0.08382308 0.11266637 0.12667423 0.13299441 0.09016329
 0.14097705 0.15328352 0.0939721  0.09738941 0.11099257 0.07336777
 0.09086436 0.07988049]
tr_loss:[0.14955452 0.10524783 0.06386155 0.09749476 0.0544712  0.086154
 0.10482788 0.1044888  0.07178366 0.11704753 0.10381402 0.10216926
 0.07175177 0.06674214 0.09251948 0.0758438  0.11867235 0.08063091
 0.11170135 0.07175187 0.08625473 0.04728347 0.15235828 0.06026159
 0.04728351 0.05633786 0.10559374 0.06710993 0.04727637 0.04728354
 0.09639905 0.08861734 0.05690805 0.06643429 0.12381484 0.08293543
 0.05422095 0.05913111 0.09580366 0.06974257 0.06666604 0.04694608
 0.14898562 0.07455654 0.12957174 0.0472815  0.06922416 0.06769918
 0.12391822 0.07017393]
tr_loss:[0.15308341 0.08137043 0.11965185 0.06449835 0.05012038 0.0522926
 0.06429897 0.07183076 0.04800867 0.03616454 0.10068329 0.05482389
 0.11942901 0.15085717 0.12564877 0.09975426 0.09977292 0.09267467
 0.07009686 0.05539105 0.14324112 0.05497433 0.09621336 0.05844823
 0.05290401 0.07369111 0.06259794 0.12466769 0.06371625 0.04897306
 0.08714221 0.07977016 0.07187807 0.05489681 0.06046538 0.04865243
 0.10756905 0.07912048 0.04800823 0.05760499 0.04669512 0.05984013
 0.12600577 0.0789028  0.10503626 0.05006041 0.04798716 0.04470212
 0.04933866 0.09781773]
tr_loss:[0.11777474 0.11406319 0.03238653 0.04277027 0.09957246 0.05822521
 0.03238654 0.03238655 0.15197517 0.03274461 0.05037399 0.04614826
 0.15168121 0.04128604 0.08780058 0.04128607 0.03830695 0.07587413
 0.07538317 0.04128601 0.08634134 0.04583303 0.05234375 0.07596262
 0.03238652 0.04933877 0.05239026 0.05807278 0.12567978 0.04894621
 0.04632215 0.09454776 0.04456836 0.0424798  0.04065032 0.12132664
 0.10766105 0.07672858 0.03237781 0.06505611 0.07272489 0.05701284
 0.04613212 0.0323865  0.07628403 0.03798541 0.10777278 0.15079316
 0.05341132 0.04201301]
tr_loss:[0.1196635  0.05944831 0.04834918 0.04754207 0.0473652  0.10701649
 0.10430793 0.04513074 0.072373   0.04851473 0.07790343 0.03157399
 0.11203229 0.05860316 0.04639309 0.06491945 0.07216918 0.06023598
 0.03143214 0.10822701 0.06920543 0.11489256 0.03157408 0.05301953
 0.06934866 0.05152083 0.04686487 0.04196477 0.07018731 0.06217328
 0.02896299 0.03436307 0.06924105 0.06424718 0.03134478 0.07486627
 0.04851183 0.05913511 0.06966275 0.1564177  0.09816565 0.03157405
 0.09101021 0.06953032 0.08328154 0.09204024 0.07117207 0.05003343
 0.11934447 0.03157406]
tr_loss:[0.02731046 0.03691497 0.06537999 0.02986539 0.15966234 0.16019784
 0.02986538 0.0298654  0.04103968 0.1021991  0.03985437 0.16006109
 0.03077411 0.04388739 0.12338997 0.09424962 0.05893169 0.04695048
 0.04585965 0.06557324 0.16084187 0.15938947 0.08525868 0.15996745
 0.04235065 0.04179563 0.02699812 0.06732644 0.1611007  0.15955302
 0.02986538 0.02986518 0.10386981 0.11249229 0.04937354 0.06730162
 0.08424012 0.03043198 0.10123082 0.09358013 0.04603335 0.04194751
 0.03476947 0.04978654 0.06679599 0.0300002  0.03403101 0.03877732
 0.0584155  0.09150717]
tr_loss:[0.03785852 0.06798073 0.08862943 0.05698126 0.06769763 0.03282156
 0.08931223 0.03587744 0.10348443 0.03919318 0.15648656 0.06372813
 0.0547915  0.03231832 0.03750572 0.05058745 0.03686457 0.08868192
 0.0411256  0.04944747 0.03939868 0.02982474 0.03686566 0.06753352
 0.08029959 0.06047767 0.15220737 0.06859842 0.0675423  0.05377507
 0.03916644 0.03700504 0.07397316 0.15434834 0.03605596 0.03554742
 0.03615197 0.03319684 0.03390373 0.08598562 0.15252344 0.03594992
 0.06160523 0.06278332 0.05193681 0.05011751 0.06661812 0.0339036
 0.05058753 0.08796438]
tr_loss:[0.1462789  0.03368072 0.06565284 0.03368074 0.05467024 0.08511285
 0.14608163 0.05088445 0.03242102 0.03368071 0.09142499 0.03197569
 0.03727015 0.14701165 0.03018046 0.06445587 0.05444374 0.15016004
 0.07580982 0.05311431 0.09356104 0.05398808 0.1455669  0.14763659
 0.07132567 0.06639671 0.03249813 0.0336807  0.07309828 0.08710168
 0.07882202 0.08545022 0.05681681 0.05539012 0.03368071 0.04544108
 0.04664845 0.03920482 0.09927705 0.0710396  0.03923076 0.0664719
 0.06248821 0.14867273 0.08691151 0.07457359 0.05444379 0.08776984
 0.03374675 0.03368076]
tr_loss:[0.09413018 0.07972788 0.07472633 0.05166962 0.13951851 0.05010835
 0.05542456 0.05710619 0.03136608 0.07070994 0.0353663  0.06022428
 0.02712155 0.06921346 0.09501474 0.02713178 0.02877743 0.0244049
 0.02814489 0.05749115 0.05756496 0.06900872 0.05814307 0.06640826
 0.02713173 0.09390285 0.1395452  0.08517839 0.05729944 0.02716575
 0.03940491 0.0699945  0.09510566 0.07387219 0.06722035 0.0870871
 0.02203523 0.03143414 0.07971051 0.05749804 0.03461792 0.06139589
 0.03451008 0.08520359 0.03465686 0.08326544 0.0271318  0.03675058
 0.03125929 0.09666412]
tr_loss:[0.03182779 0.04755667 0.0359618  0.0857136  0.02334113 0.04120036
 0.03730958 0.06490715 0.05143564 0.14805886 0.09547226 0.05280605
 0.02921102 0.05086931 0.02334112 0.06767406 0.10309105 0.06282099
 0.02334114 0.04529784 0.09766456 0.03542877 0.05646243 0.03730961
 0.03032956 0.06337205 0.07218137 0.030825   0.06721117 0.03080506
 0.0570017  0.05733978 0.0266146  0.03181939 0.07806327 0.02334114
 0.03181936 0.03470743 0.10914439 0.01952877 0.03917959 0.02334114
 0.14160141 0.0390689  0.02334114 0.04447713 0.09910148 0.04486487
 0.04288702 0.02334019]
tr_loss:[0.05241858 0.0798402  0.08472473 0.03364036 0.03229341 0.08488402
 0.05252421 0.02674805 0.07314396 0.03554721 0.02733243 0.04496755
 0.0602851  0.02091667 0.05056616 0.02747725 0.09290006 0.03364041
 0.08732232 0.06202047 0.13952747 0.02569794 0.06660745 0.091802
 0.14379473 0.05294804 0.03974589 0.07392229 0.13789468 0.01742015
 0.06983496 0.03835488 0.07705772 0.08466724 0.02895696 0.03426379
 0.02817113 0.03674323 0.07365645 0.02251754 0.07422804 0.05270246
 0.02871228 0.06413484 0.05264826 0.03603699 0.04018963 0.0309637
 0.11850481 0.04315342]
tr_loss:[0.03285309 0.05354114 0.02288536 0.07637312 0.0575094  0.03280283
 0.02250076 0.02250073 0.02444008 0.12702987 0.03180449 0.03742319
 0.0332189  0.05196314 0.12793943 0.03531416 0.13524845 0.02250071
 0.05588322 0.03531406 0.02203881 0.06670365 0.0532959  0.03641831
 0.08033168 0.0818745  0.02246358 0.03285247 0.08210589 0.13341627
 0.03284407 0.02206564 0.1317874  0.04086768 0.06071397 0.03531406
 0.03773166 0.06907692 0.03725469 0.08214493 0.01609723 0.05276648
 0.02171475 0.02250032 0.08792344 0.02166832 0.0532615  0.07755532
 0.03056994 0.03725852]
tr_loss:[0.04761379 0.03389849 0.04687247 0.08150681 0.05293399 0.05643082
 0.03367826 0.06728665 0.04819556 0.12370274 0.055487   0.03177151
 0.05582833 0.03157514 0.03157514 0.08268303 0.02195756 0.04643695
 0.02876061 0.0317737  0.02813507 0.12113442 0.09147903 0.03391042
 0.02683529 0.03134494 0.02214238 0.03655197 0.12657148 0.03202536
 0.07558936 0.0507291  0.03425607 0.12570572 0.05721154 0.03157518
 0.02839503 0.0472664  0.1253277  0.06304709 0.05906395 0.03622507
 0.03202533 0.05565977 0.03389848 0.07930744 0.06188185 0.07918911
 0.07760578 0.0302898 ]
tr_loss:[0.03286859 0.11877839 0.07934552 0.07329838 0.03064221 0.05817053
 0.07772222 0.029955   0.02474712 0.08034794 0.05474699 0.08547524
 0.01902949 0.07692049 0.03708471 0.03483739 0.03191179 0.03273349
 0.10061029 0.07967834 0.02525876 0.07529478 0.02282591 0.03885262
 0.07080064 0.07185583 0.02972951 0.03161618 0.12399739 0.07230382
 0.02691558 0.05558126 0.03149227 0.0719289  0.01894329 0.12529881
 0.06968191 0.01902948 0.07651655 0.0310111  0.03034012 0.05522133
 0.10449843 0.033489   0.03278156 0.05715756 0.02706751 0.03330387
 0.03053225 0.01902948]
tr_loss:[0.06285676 0.02623631 0.0320973  0.07239702 0.03257875 0.02478443
 0.01675444 0.06117337 0.05437148 0.02541935 0.07047313 0.06860649
 0.01734464 0.01675516 0.0731963  0.06119349 0.05882321 0.01675515
 0.05419799 0.0707501  0.02302083 0.05520122 0.02030437 0.01675517
 0.07852298 0.02729881 0.07552044 0.06084678 0.03081905 0.03456876
 0.02916377 0.07896444 0.05478623 0.01624358 0.03091284 0.0725285
 0.03056169 0.12475884 0.01675516 0.07296111 0.01675518 0.03314345
 0.02061063 0.02623338 0.07799287 0.05720405 0.07099883 0.03205335
 0.0768002  0.08035392]
tr_loss:[0.0299848  0.06076538 0.07650614 0.02635182 0.03549011 0.02693995
 0.02545036 0.01514381 0.06621955 0.11714538 0.06714471 0.01514381
 0.03061736 0.03122574 0.03007119 0.02590999 0.02940304 0.03549013
 0.04964595 0.0287208  0.05063118 0.03076645 0.01514381 0.05370251
 0.03495311 0.03029002 0.02189578 0.0280614  0.03134357 0.07195953
 0.0511336  0.02756149 0.05355223 0.04714993 0.03029    0.02906013
 0.06628042 0.03399359 0.06257558 0.08998124 0.05273573 0.02783842
 0.0321875  0.11855166 0.02694014 0.05667112 0.05425992 0.02851876
 0.06652758 0.01514381]
tr_loss:[0.02040347 0.06178816 0.02956022 0.03417384 0.11754986 0.04924328
 0.03029174 0.07019393 0.06503911 0.01512155 0.0524413  0.01512164
 0.04840133 0.12087207 0.01512156 0.11741062 0.03461053 0.05210566
 0.06680949 0.02246004 0.02208129 0.04796548 0.01512156 0.04749796
 0.06037009 0.0578159  0.02950267 0.04883628 0.06880639 0.03444446
 0.02947364 0.04870749 0.04747914 0.02752586 0.04752234 0.01915622
 0.05057045 0.11839988 0.01512156 0.07378843 0.02328947 0.04852881
 0.015779   0.0546499  0.02752726 0.06694849 0.05907538 0.01521887
 0.06263675 0.06099831]
tr_loss:[0.04771396 0.03058267 0.02034877 0.05505513 0.08120392 0.02893246
 0.03423601 0.03417623 0.05887967 0.03423105 0.04801827 0.01667727
 0.03308012 0.11890057 0.02843323 0.06255929 0.03110719 0.05720167
 0.11895312 0.03058269 0.04790992 0.0304316  0.11769967 0.03067875
 0.03043159 0.04995644 0.01929976 0.11550973 0.01668059 0.01667739
 0.0304316  0.11542919 0.02813015 0.03873077 0.05079412 0.04995036
 0.03209423 0.01667731 0.02800173 0.04820791 0.03415958 0.05860372
 0.05726003 0.11728697 0.11912719 0.04735409 0.03214529 0.03188757
 0.03662492 0.02327785]
tr_loss:[0.02968376 0.0726407  0.02753944 0.04783465 0.03041506 0.04814172
 0.06547612 0.03374879 0.04872616 0.11783437 0.01783743 0.04765258
 0.02912767 0.05963609 0.05995893 0.02210056 0.05627806 0.03418717
 0.03411042 0.03574506 0.03381456 0.03234219 0.05208956 0.06806313
 0.02378874 0.03579916 0.05742068 0.02713347 0.06253646 0.03367805
 0.01783752 0.09766871 0.01783744 0.03846261 0.01784356 0.01783742
 0.03320103 0.03067252 0.03432012 0.0358671  0.03586709 0.01785016
 0.04766081 0.03245185 0.0353762  0.03029236 0.01853923 0.02197214
 0.02760696 0.07570007]
tr_loss:[0.0307859  0.02399096 0.0167852  0.03148592 0.0344881  0.06594589
 0.02044256 0.06925317 0.11765797 0.06313257 0.01651345 0.11997814
 0.02832902 0.03046521 0.03810573 0.01652103 0.06321267 0.02738433
 0.0483132  0.03440581 0.01651346 0.03083939 0.01656368 0.06581986
 0.05850263 0.03810494 0.05704505 0.01985473 0.02546867 0.04795465
 0.04876683 0.02832971 0.11571161 0.11838762 0.04770582 0.01651347
 0.02806035 0.05735476 0.05538406 0.02696837 0.02476542 0.03810572
 0.03810577 0.06485219 0.06307654 0.06279974 0.11684545 0.03147398
 0.03545252 0.04936033]
tr_loss:[0.01269117 0.11868058 0.06304605 0.01263634 0.02619978 0.0455789
 0.06918889 0.02596258 0.01263599 0.01263748 0.03058168 0.02536884
 0.02805093 0.0687523  0.0500815  0.01656754 0.01263597 0.01271639
 0.01897294 0.0343424  0.04558339 0.06033653 0.04680619 0.02790428
 0.01883922 0.05787031 0.05411066 0.01263599 0.03475446 0.05599875
 0.05846234 0.04581688 0.02933661 0.04956934 0.03063334 0.05569125
 0.01833899 0.05347854 0.05738379 0.02978694 0.12089118 0.03073941
 0.02824357 0.03379567 0.01263623 0.046341   0.0251642  0.012637
 0.03379287 0.04664466]
tr_loss:[0.05317818 0.02703128 0.05983398 0.01864989 0.05089346 0.05862654
 0.03517818 0.12602977 0.06574863 0.00998581 0.07579376 0.04440725
 0.05061697 0.03805036 0.04560473 0.05951169 0.00998581 0.02719205
 0.00998612 0.00998581 0.04385639 0.12130022 0.04487695 0.02688742
 0.04801256 0.02728467 0.04053678 0.02868268 0.026798   0.04944574
 0.02231746 0.05600433 0.02410958 0.01035945 0.04428421 0.0436284
 0.05842421 0.04517276 0.01691749 0.05986106 0.04435898 0.02703133
 0.0099858  0.00998579 0.01844108 0.04484567 0.04462824 0.02208484
 0.02288498 0.01730303]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1200 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1201, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1201 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1202, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1202 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1203, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1203 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1204, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1204 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1205, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1205 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1206, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1206 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1207, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1207 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1208, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1208 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1209, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1209 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1210, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1210 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1211, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1211 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1212, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1212 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1213, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1213 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1214, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1214 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1215, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1215 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1216, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1216 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1217, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1217 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1218, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1218 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1219, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1219 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1220, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1220 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1221, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1221 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1222, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1222 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1223, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1223 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1224, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1224 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1225, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1225 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1226, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1226 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1227, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1227 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1228, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1228 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1229, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1229 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1230, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1230 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1231, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1231 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1232, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1232 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1233, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1233 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1234, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1234 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1235, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1235 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1236, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1236 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1237, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1237 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1238, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1238 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1239, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1239 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1240, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1240 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1241, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1241 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1242, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1242 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1243, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1243 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1244, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1244 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1245, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1245 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1246, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1246 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1247, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1247 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1248, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1248 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1249, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1249 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1250, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1250 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1251, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1251 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1252, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1252 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1253, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1253 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1254, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1254 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1255, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1255 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1256, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1256 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1257, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1257 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1258, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1258 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1259, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1259 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1260, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1260 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1261, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1261 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1262, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1262 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1263, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1263 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1264, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1264 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1265, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1265 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1266, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1266 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1267, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1267 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1268, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1268 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1269, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1269 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1270, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1270 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1271, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1271 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1272, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1272 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1273, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1273 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1274, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1274 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1275, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1275 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1276, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1276 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1277, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1277 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1278, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1278 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1279, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1279 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1280, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1280 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1281, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1281 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1282, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1282 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1283, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1283 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1284, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1284 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1285, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1285 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1286, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1286 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1287, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1287 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1288, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1288 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1289, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1289 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1290, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1290 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1291, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1291 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1292, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1292 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1293, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1293 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1294, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1294 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1295, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1295 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1296, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1296 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1297, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1297 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1298, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1298 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1299, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1299 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1300, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-1200
text_input.shape
(1300, 14400)
learning_input_tmp.shape
(1300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1300, 80)
learning_output.shape
(750, 80)
Model: "sequential_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_27 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.90752345 1.227866   0.9100606  1.2202591  0.91236365 1.2270073
 1.131892   1.2275388  1.153765   1.2277848  1.2112414  1.0212519
 1.2389742  1.2118652  1.2389942  1.0890255  1.1309     1.1262493
 1.1168524  0.9049568  1.2094915  1.1245065  1.0893439  0.89423597
 1.2389944  0.91167927 1.116885   1.2277321  1.1325185  1.2273761
 0.89051074 0.9702116  0.98019964 1.0952044  1.1260827  0.9233259
 1.1250696  1.2255557  0.89246196 0.97787905 1.2389944  0.9005276
 0.9356063  0.912823   1.0289919  1.1367447  0.8938586  1.2277637
 0.8933957  1.2389944 ]
tr_loss:[0.6815992  0.68160474 0.6673472  0.68160284 0.48087922 0.5896595
 0.58964694 0.68776715 0.6223184  0.51769733 0.68159705 0.68159425
 0.68776214 0.6815956  0.6578163  0.6713358  0.5994047  0.67658234
 0.6877681  0.5975002  0.54067117 0.6414108  0.64554125 0.61963737
 0.6184508  0.62064505 0.58905727 0.65844095 0.65608543 0.6070668
 0.5289273  0.63000923 0.642046   0.61963725 0.63729644 0.6123109
 0.61011297 0.68159944 0.68707156 0.54226536 0.5139026  0.6196801
 0.6815959  0.56541455 0.6348722  0.48045573 0.63989246 0.5470675
 0.68160146 0.54495776]
tr_loss:[0.42457923 0.40760398 0.4692498  0.47674927 0.45458084 0.46953893
 0.4422248  0.4695546  0.47681683 0.4700056  0.41859895 0.32188472
 0.37752175 0.43642616 0.42633638 0.4545807  0.41073838 0.41878834
 0.39234298 0.4401992  0.40254125 0.3211751  0.4049352  0.42906466
 0.42486683 0.4122035  0.3985447  0.4327666  0.3855421  0.40115538
 0.4698596  0.4459408  0.41979355 0.46943107 0.46899962 0.4545807
 0.4085632  0.4313918  0.361818   0.35789996 0.45458078 0.46945843
 0.45458072 0.4127821  0.45458078 0.4060862  0.4801147  0.4727083
 0.40443477 0.4143099 ]
tr_loss:[0.27921742 0.31267735 0.26086622 0.27630407 0.29870775 0.26236114
 0.31704935 0.2571222  0.29714975 0.27917814 0.30562615 0.3133853
 0.26782376 0.28080812 0.29770142 0.23307037 0.27463025 0.31188083
 0.29756624 0.2997323  0.27121058 0.24374974 0.2885529  0.31338516
 0.28540835 0.24480471 0.30035603 0.31288487 0.2885147  0.26646224
 0.24953297 0.26098698 0.2723716  0.24909055 0.2334425  0.29029894
 0.287216   0.26498738 0.31300932 0.3133851  0.2584566  0.27727947
 0.26470596 0.3076684  0.29332355 0.23367849 0.3009036  0.299711
 0.2972978  0.29671437]
tr_loss:[0.17211083 0.18529055 0.17321388 0.21296044 0.18554834 0.20092869
 0.17957465 0.17291972 0.16652632 0.18529055 0.1786751  0.17548811
 0.17327507 0.21764822 0.21216793 0.18041077 0.17207408 0.17437014
 0.16886508 0.16548792 0.19542736 0.17090705 0.21630068 0.18675648
 0.18993053 0.18499592 0.16617987 0.16120303 0.20137277 0.18677664
 0.14631239 0.21008778 0.18774578 0.18435995 0.1911943  0.16225268
 0.20091312 0.17187992 0.16935994 0.19498247 0.1962007  0.19996572
 0.17452094 0.1750876  0.19494215 0.19033417 0.21789059 0.18529019
 0.19560328 0.19323617]
tr_loss:[0.11209382 0.11916854 0.10237356 0.14134516 0.11207362 0.13151637
 0.12004034 0.11220522 0.09932782 0.11209382 0.101143   0.11480936
 0.11047294 0.1018167  0.10179865 0.11209385 0.11310618 0.11112325
 0.11134215 0.09481664 0.09722408 0.11334892 0.10182525 0.11666784
 0.1120561  0.11188759 0.11102567 0.11209385 0.12037915 0.12468028
 0.14698078 0.12950565 0.10198257 0.10182875 0.0991606  0.1033241
 0.10399594 0.10650089 0.09372406 0.11209382 0.11563198 0.10965465
 0.12949932 0.11209389 0.09725398 0.10196223 0.101795   0.09725448
 0.10208108 0.09898318]
tr_loss:[0.06602234 0.08968131 0.06602702 0.1076265  0.06865013 0.08447072
 0.10302819 0.06627055 0.0922737  0.08153139 0.11677804 0.06602697
 0.0687061  0.06865396 0.07645978 0.11582971 0.11967906 0.0851697
 0.06877463 0.10541302 0.10248318 0.07883239 0.0684458  0.09976184
 0.08810465 0.06730878 0.08104132 0.06602698 0.07303987 0.066027
 0.06647995 0.06868628 0.06602702 0.08033236 0.11439373 0.06863347
 0.0749187  0.076975   0.09348805 0.0975439  0.15919434 0.07141167
 0.06602696 0.09417035 0.0673115  0.07919099 0.07425998 0.09878425
 0.10258856 0.10089566]
tr_loss:[0.06942544 0.11954677 0.06290139 0.08720995 0.08738152 0.05046567
 0.06528004 0.07452963 0.07695012 0.05046562 0.06151278 0.0705599
 0.08333301 0.10454664 0.0557071  0.10066719 0.05140882 0.05046565
 0.08099326 0.07094403 0.07696144 0.07190758 0.05073737 0.05945419
 0.05974393 0.07608463 0.08106878 0.08916362 0.05849306 0.05947533
 0.07150459 0.05975985 0.06148155 0.11464491 0.08079151 0.08091027
 0.08122141 0.05975676 0.11026082 0.06380971 0.08078317 0.10906961
 0.0668969  0.10202094 0.05937776 0.09760532 0.10690872 0.07653987
 0.05022501 0.1069319 ]
tr_loss:[0.06000161 0.11256853 0.08067309 0.05726447 0.06644613 0.07762639
 0.04588937 0.07287277 0.08724874 0.12872455 0.08646952 0.05647708
 0.07697905 0.04588933 0.04589094 0.0681213  0.08603629 0.04588957
 0.07296993 0.05616666 0.11120498 0.06516652 0.05797196 0.05651783
 0.10268246 0.07277758 0.05794721 0.09202582 0.06172689 0.12814423
 0.06079891 0.05645842 0.10980792 0.07699378 0.11193936 0.05997577
 0.05650441 0.06926923 0.07426242 0.06110748 0.0547354  0.05825107
 0.05652408 0.06656114 0.05869091 0.04588943 0.05631394 0.14134178
 0.05658004 0.08958291]
tr_loss:[0.06641245 0.05496986 0.0663864  0.08245546 0.1010705  0.05636344
 0.08487792 0.05581517 0.11340494 0.10896389 0.04077959 0.06647546
 0.05639386 0.05650108 0.04396491 0.0460842  0.06106294 0.1217772
 0.05861083 0.0907252  0.07202929 0.12552878 0.10983129 0.1180619
 0.04078027 0.11032701 0.13751885 0.05926021 0.10895802 0.04077959
 0.05975966 0.04273087 0.0420291  0.05581294 0.09704977 0.0546911
 0.07191296 0.07294137 0.06009636 0.06319849 0.05642188 0.04497045
 0.08805522 0.10760286 0.04966202 0.04077961 0.05522685 0.06068099
 0.08079268 0.05997451]
tr_loss:[0.05720192 0.12334871 0.0428231  0.08298348 0.08349174 0.07867952
 0.05156364 0.06985643 0.07197003 0.05013902 0.08153011 0.05013899
 0.05187991 0.11395118 0.06829626 0.09200154 0.06955037 0.05955357
 0.0476568  0.07638089 0.04215778 0.10013755 0.04846392 0.05506359
 0.03635182 0.07431681 0.09708842 0.03484225 0.05154545 0.06955118
 0.06393238 0.06575926 0.04758325 0.08216919 0.05153523 0.04196429
 0.05674286 0.08041342 0.0802163  0.03631278 0.03634703 0.10487626
 0.09689625 0.06673397 0.07580023 0.0974087  0.05407215 0.06328459
 0.05040649 0.06328455]
tr_loss:[0.05671589 0.05619263 0.06562109 0.05050468 0.08491948 0.0443727
 0.05062913 0.08793744 0.0782331  0.04930862 0.1001149  0.04820956
 0.03610075 0.03659168 0.09945812 0.05058963 0.10880826 0.08073566
 0.06286754 0.09461419 0.0801128  0.07870545 0.08775456 0.03653827
 0.05014324 0.05063638 0.04114984 0.0908389  0.09128617 0.06588248
 0.04567903 0.06085854 0.08011166 0.03659167 0.08717649 0.04169925
 0.04576895 0.04346671 0.07876088 0.06864189 0.04387393 0.09849542
 0.07712015 0.04167834 0.07224558 0.10741861 0.0776324  0.06028136
 0.06864183 0.04371973]
tr_loss:[0.03981439 0.03981289 0.03981436 0.05407254 0.04649729 0.05856498
 0.07492505 0.03869801 0.0416145  0.05113571 0.08450387 0.03981439
 0.06286953 0.10603587 0.03981434 0.0392457  0.0628922  0.11705252
 0.04777096 0.03980826 0.05135998 0.05104049 0.03977606 0.03981435
 0.0767526  0.05112069 0.06289224 0.04100608 0.04356969 0.05108044
 0.06270166 0.06043683 0.08899949 0.03981437 0.08687    0.07241907
 0.04691977 0.04334976 0.03981329 0.04779857 0.06289217 0.03981439
 0.07634246 0.03926325 0.03981442 0.11618255 0.1060643  0.0420755
 0.05114307 0.04093867]
tr_loss:[0.0415741  0.04471176 0.04154707 0.03128022 0.14380631 0.13949952
 0.0482473  0.07122132 0.03446621 0.03254371 0.0352083  0.02856491
 0.11050031 0.12347205 0.07520059 0.04024024 0.06888095 0.11785848
 0.04156949 0.03575843 0.04063072 0.07769914 0.03995219 0.04158276
 0.0566176  0.07152675 0.06794228 0.03721173 0.03522937 0.07075334
 0.06664995 0.03254367 0.06969032 0.04822521 0.03499521 0.06510404
 0.04158029 0.04172855 0.03598857 0.04301812 0.03388327 0.11819677
 0.04247041 0.10294958 0.13959074 0.04822523 0.03905991 0.04241293
 0.0349952  0.08622395]
tr_loss:[0.0742254  0.03769818 0.03712894 0.03893997 0.12309848 0.04489962
 0.03726504 0.07798649 0.03470041 0.0871042  0.03610038 0.04483218
 0.04254718 0.03884922 0.0357627  0.05025246 0.03470136 0.03730287
 0.06731068 0.05025247 0.03568185 0.03739572 0.10873368 0.03769509
 0.05831198 0.03022924 0.04303419 0.06864376 0.08391035 0.03022918
 0.09057967 0.0373999  0.07194819 0.03715566 0.02590574 0.04860706
 0.11643382 0.04511067 0.03697117 0.02944394 0.03739432 0.0421717
 0.11869548 0.03022921 0.11781506 0.05046545 0.03022924 0.06866884
 0.03470454 0.07631586]
tr_loss:[0.03770866 0.03533694 0.02600766 0.09753875 0.06764561 0.07215673
 0.10468843 0.04652334 0.03208352 0.04627931 0.03208475 0.05298586
 0.07996176 0.11942868 0.0405476  0.09387505 0.08846211 0.10401116
 0.08924395 0.03208476 0.04661591 0.05138855 0.03471749 0.04252038
 0.08181605 0.08905021 0.03495592 0.04461738 0.06179195 0.04333536
 0.0678764  0.03910831 0.06817055 0.03496901 0.11533723 0.08370401
 0.03208473 0.09049925 0.03771839 0.0257225  0.03208142 0.03508671
 0.03182013 0.04285624 0.1082057  0.05138851 0.03432295 0.03415294
 0.06986329 0.07831168]
tr_loss:[0.03525432 0.03831393 0.06488432 0.03924986 0.12769431 0.03819967
 0.04680844 0.03674032 0.04383154 0.04298042 0.08322217 0.06053089
 0.03283099 0.06031141 0.06038731 0.03169216 0.03106253 0.04050276
 0.03042967 0.02954439 0.03763824 0.03042399 0.09392015 0.08233526
 0.03588102 0.03033439 0.03371694 0.04894622 0.06531893 0.04875037
 0.0298249  0.03579993 0.03407025 0.03575889 0.03043815 0.03050488
 0.03525434 0.04338811 0.04072098 0.03169216 0.03031207 0.03821415
 0.08190151 0.03137964 0.03137962 0.03636356 0.02824504 0.09648023
 0.03037889 0.06080765]
tr_loss:[0.03506834 0.09527186 0.029813   0.03112504 0.02846183 0.03342858
 0.02506939 0.02649478 0.02644728 0.09909055 0.04219241 0.03276867
 0.02678686 0.02783954 0.02632063 0.06905393 0.0278389  0.10645008
 0.02750046 0.05691016 0.02783954 0.02432567 0.03456711 0.03976282
 0.03330399 0.04138265 0.05772807 0.02667021 0.09298624 0.02783952
 0.08736517 0.02783954 0.02847057 0.0374589  0.07409182 0.03746757
 0.05705622 0.03614559 0.08337192 0.02955553 0.1062156  0.04178209
 0.1094497  0.04004735 0.03619644 0.06893896 0.02783955 0.03484637
 0.03010912 0.04766211]
tr_loss:[0.03287887 0.02508536 0.04566817 0.03254174 0.02385624 0.02542242
 0.0345347  0.02479539 0.06061558 0.02542243 0.02509255 0.02456331
 0.07901423 0.02509485 0.11114037 0.02685267 0.0291548  0.03629129
 0.0259056  0.02510333 0.02542243 0.03582969 0.02542242 0.02511939
 0.10210451 0.02555959 0.08389273 0.0465814  0.04566821 0.08742043
 0.02689072 0.09213698 0.07437662 0.04566818 0.07445858 0.07870254
 0.04692547 0.0245538  0.09427025 0.07592362 0.03705507 0.03699786
 0.03472733 0.03582757 0.02520202 0.04545734 0.0867706  0.02542241
 0.08654509 0.0253864 ]
tr_loss:[0.03076045 0.03612605 0.06142978 0.03784366 0.07344551 0.02954666
 0.03224592 0.02479592 0.02770432 0.04910215 0.08343269 0.07760058
 0.08047346 0.02814693 0.08540735 0.08119218 0.02248011 0.05224335
 0.0461266  0.02647989 0.06079645 0.06136025 0.02451012 0.08112103
 0.0377249  0.07785112 0.0800557  0.02763664 0.10929515 0.03533773
 0.08560561 0.08541072 0.02149624 0.02439444 0.06854345 0.07878166
 0.02450945 0.02450944 0.07895732 0.02450939 0.03362324 0.0584292
 0.02450942 0.05996171 0.02799089 0.02450941 0.0302208  0.02277288
 0.03093905 0.07846214]
tr_loss:[0.0490133  0.04194199 0.0321391  0.07727589 0.0717118  0.02297784
 0.02098384 0.02264513 0.02607774 0.03812087 0.02889697 0.05932074
 0.04017155 0.0210649  0.0424114  0.02351279 0.04360787 0.06424356
 0.05822922 0.04091528 0.02547615 0.02257309 0.04028624 0.02254199
 0.02120214 0.02351277 0.04091573 0.03153808 0.03110992 0.05363194
 0.07136044 0.03043426 0.02351299 0.0235128  0.02260844 0.06486972
 0.02351277 0.04194527 0.03871692 0.02261288 0.02275066 0.0226479
 0.02351276 0.02289948 0.04158472 0.01956199 0.06656796 0.02351278
 0.02278819 0.08929327]
tr_loss:[0.05508935 0.05640267 0.036115   0.03348761 0.04920831 0.0200805
 0.02490906 0.02412342 0.03881678 0.06161259 0.01912157 0.02823851
 0.03128811 0.0200806  0.01961351 0.07454427 0.03951035 0.10376382
 0.0768132  0.05511941 0.02009767 0.06481494 0.03763287 0.02010434
 0.0633522  0.07461005 0.05647016 0.02592393 0.05592385 0.05650777
 0.01964228 0.02667761 0.03904352 0.05510368 0.02176983 0.03669099
 0.07139088 0.03881519 0.05706061 0.06935599 0.07585814 0.03615291
 0.07444479 0.01935811 0.02573404 0.02008051 0.03128813 0.03611035
 0.03128814 0.03873318]
tr_loss:[0.01785766 0.02899985 0.02504145 0.03150637 0.06499776 0.02347263
 0.02658874 0.02203714 0.02866505 0.03160877 0.01876154 0.07198232
 0.03311228 0.0250056  0.0283226  0.03109308 0.01691051 0.05105475
 0.01691049 0.02853902 0.01892598 0.0169105  0.03410042 0.05127304
 0.01691048 0.02071627 0.03269631 0.02915461 0.06363211 0.03430025
 0.01740575 0.04683806 0.01739284 0.01706511 0.05458827 0.01731691
 0.01713365 0.03936114 0.02203714 0.02596499 0.02873018 0.05131619
 0.06536473 0.01738102 0.02866504 0.02658874 0.06142871 0.06579246
 0.02633372 0.0707327 ]
tr_loss:[0.04929256 0.018428   0.05325193 0.02726655 0.01861982 0.06774111
 0.02939401 0.01890137 0.04965042 0.01715564 0.04926917 0.07471371
 0.03333817 0.02133115 0.06458133 0.02325204 0.02078035 0.01893498
 0.07721207 0.03120307 0.0257863  0.02826354 0.01851885 0.0494619
 0.02561078 0.03333814 0.02528927 0.03220669 0.06176403 0.01731807
 0.04143585 0.07755044 0.06187426 0.07570231 0.0492648  0.02268718
 0.02472852 0.06618948 0.04928476 0.01716265 0.01896141 0.02660896
 0.11288667 0.02380829 0.01844607 0.01887947 0.03195439 0.02788876
 0.01883853 0.04605978]
tr_loss:[0.02086365 0.05030582 0.01885636 0.06314493 0.02067578 0.06921761
 0.04843406 0.05352306 0.04884192 0.01885636 0.05131706 0.06402495
 0.03549686 0.02679034 0.04631745 0.05081113 0.02738037 0.02068218
 0.03095476 0.01885616 0.01885633 0.02803147 0.0611973  0.02576605
 0.03692757 0.03017421 0.01885634 0.01884647 0.02668119 0.05320582
 0.02803149 0.02864196 0.05803078 0.01885636 0.0480899  0.0205242
 0.03060994 0.02667523 0.02677783 0.01871178 0.02801766 0.03130705
 0.04955848 0.01885396 0.02428185 0.060685   0.02061662 0.02054621
 0.0212084  0.02068558]
tr_loss:[0.02746076 0.07308455 0.02516836 0.05853272 0.01820505 0.01820506
 0.07095306 0.02895985 0.02705676 0.0479827  0.01820508 0.02211227
 0.03067251 0.03496048 0.04800827 0.02006575 0.02382146 0.0199699
 0.028452   0.05472509 0.02023688 0.07064186 0.0582207  0.05898226
 0.05392603 0.03644564 0.02010569 0.03576908 0.03643388 0.06170879
 0.0250953  0.06546248 0.02497812 0.02895913 0.02014217 0.02631946
 0.04872537 0.02706179 0.02503743 0.03608531 0.05984682 0.02941183
 0.02864196 0.04866292 0.02007751 0.05749016 0.0211022  0.02803621
 0.02845196 0.04824954]
tr_loss:[0.01869316 0.03481676 0.02697657 0.05854533 0.01890658 0.04580263
 0.01870172 0.0239709  0.06093935 0.0167617  0.05868774 0.07100387
 0.01860118 0.02048592 0.02150467 0.02247952 0.07533348 0.05911093
 0.01868723 0.03658468 0.06862847 0.05816737 0.01659232 0.02492216
 0.02397875 0.02275048 0.02613862 0.03295059 0.08719956 0.04610588
 0.04984158 0.02157048 0.04820804 0.02059468 0.02615871 0.02368012
 0.01676172 0.0212662  0.11461015 0.04965452 0.04940427 0.05015634
 0.05806106 0.03028599 0.04914066 0.01867382 0.04797635 0.06586165
 0.05110044 0.01850081]
tr_loss:[0.03180648 0.06859332 0.01666532 0.01765279 0.01551903 0.02814072
 0.01765603 0.05688713 0.02556213 0.04948556 0.06189345 0.09653936
 0.05055212 0.02750105 0.05044128 0.06115194 0.05979959 0.01761471
 0.05916125 0.01758978 0.03356525 0.03356523 0.02395495 0.01762538
 0.01543295 0.02041759 0.06556502 0.01551903 0.0532359  0.01551904
 0.0238131  0.01789062 0.06415109 0.02608911 0.05511351 0.01551902
 0.02810012 0.01548238 0.04911589 0.05728788 0.05986822 0.01551901
 0.04709645 0.0154705  0.0220045  0.02232521 0.01782238 0.02212528
 0.05791585 0.03356525]
tr_loss:[0.02236224 0.04767875 0.04759502 0.05197461 0.06302731 0.01694475
 0.02404494 0.04759987 0.02387661 0.0169323  0.0608207  0.05686512
 0.04761692 0.01692484 0.01694127 0.02701936 0.05059196 0.02950957
 0.03453792 0.05697979 0.04727421 0.01492906 0.02290626 0.01693365
 0.09875005 0.04754969 0.01496978 0.04504409 0.01852497 0.05534689
 0.05632621 0.0234814  0.01691763 0.01940624 0.05049811 0.02374351
 0.01898494 0.01495324 0.0169495  0.05168319 0.08119677 0.0169441
 0.01496978 0.01496976 0.01855178 0.01496582 0.01745585 0.01496973
 0.02436792 0.02591686]
tr_loss:[0.02328143 0.02619205 0.06158324 0.02338335 0.02329382 0.02182017
 0.03177015 0.02962775 0.01737321 0.05339205 0.04420918 0.03065644
 0.04462486 0.0218689  0.0550283  0.0265558  0.02155651 0.01550731
 0.01919474 0.04035641 0.04984811 0.02568836 0.04881069 0.0174665
 0.04508964 0.07800503 0.05462807 0.02331855 0.05078778 0.01728132
 0.05153121 0.01739248 0.0172618  0.01531017 0.03067824 0.02351999
 0.01989913 0.01734847 0.01550728 0.03241518 0.05550256 0.04429379
 0.05294332 0.04453124 0.01732385 0.08731858 0.02563805 0.02273017
 0.01550731 0.0258714 ]
text_input.shape
(1300, 14400)
learning_input_tmp.shape
(1300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1300, 80)
learning_output.shape
(750, 80)
Model: "sequential_28"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_28 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.80196124 0.8600523  0.9581693  0.74564755 0.82717    0.7826606
 0.8620415  0.6484809  0.87175035 0.831812   0.6745049  0.9052266
 0.95803994 0.8505605  0.9058367  0.9057314  0.8461798  0.7290052
 0.8653118  0.7870736  0.9581987  0.6768042  0.781569   0.95841247
 0.8580968  0.8448876  0.89140856 0.70668143 0.90583646 0.70559204
 0.7146288  0.67434883 0.92301047 0.9581051  0.8374729  0.7527083
 0.85242826 0.8812326  0.7957285  0.82760334 0.8600521  0.75160897
 0.7656836  0.8293684  0.6818719  0.8174904  0.95811397 0.8732519
 0.9042637  0.83725756]
tr_loss:[0.43322992 0.47710004 0.5015658  0.5784451  0.510156   0.5510746
 0.58114094 0.53126013 0.50999576 0.4322811  0.5296519  0.521903
 0.42691693 0.5510747  0.52133256 0.51781374 0.53126013 0.5172294
 0.570059   0.54882264 0.53126013 0.4938531  0.49736118 0.5145357
 0.46733046 0.53126    0.5786396  0.4540369  0.42324042 0.5790464
 0.42738733 0.512161   0.5079493  0.54669875 0.5312597  0.5101552
 0.55891997 0.5077806  0.5777696  0.4490673  0.5145756  0.5687221
 0.5627501  0.5213324  0.51112103 0.51693267 0.48803768 0.5315491
 0.46090287 0.4494075 ]
tr_loss:[0.3334331  0.2965895  0.36414212 0.3138322  0.3152708  0.35609013
 0.2829204  0.3174494  0.28173786 0.34419674 0.3301448  0.28330255
 0.2936409  0.34419483 0.34419674 0.32585496 0.29574996 0.27481848
 0.32564297 0.3441969  0.3441836  0.36387724 0.35388264 0.3078122
 0.34419674 0.31388277 0.3441968  0.31565174 0.3545305  0.32219118
 0.30319625 0.36091137 0.3071597  0.2998792  0.3441931  0.31584898
 0.28027132 0.28196886 0.27856243 0.30944818 0.3152255  0.37736994
 0.27743268 0.32384866 0.28660113 0.34977156 0.26316017 0.31523004
 0.36884958 0.3497716 ]
tr_loss:[0.25465605 0.19615266 0.17035742 0.19234362 0.20211568 0.19239216
 0.18682301 0.17354111 0.1527721  0.24853949 0.24936494 0.17486677
 0.17042609 0.1730231  0.17445712 0.17345361 0.20161375 0.19472358
 0.20088525 0.16847174 0.16298923 0.2290059  0.20293605 0.15375774
 0.15375826 0.17534038 0.19003662 0.17014198 0.15593913 0.17418545
 0.16231702 0.17369786 0.18434107 0.17647715 0.1697329  0.16036311
 0.18330726 0.17347111 0.17352936 0.16856728 0.17274773 0.17196555
 0.18787594 0.17025271 0.22055197 0.17308082 0.18293712 0.16408062
 0.17272034 0.18767425]
tr_loss:[0.15478905 0.15698329 0.15562634 0.14965773 0.14136134 0.14459252
 0.15574877 0.14584884 0.13905163 0.13924152 0.15487824 0.13752371
 0.15698329 0.15727414 0.15698294 0.1352404  0.1552116  0.14633639
 0.13925508 0.13888487 0.13419513 0.14028561 0.15067947 0.1549458
 0.16555798 0.15017107 0.1385459  0.13632426 0.13275886 0.14161268
 0.13936748 0.14004767 0.13937423 0.15698245 0.13486458 0.15607324
 0.15698329 0.15487821 0.1353241  0.14229086 0.14232448 0.14112975
 0.13776757 0.16139477 0.1534718  0.16299221 0.13952368 0.14429681
 0.15127654 0.13513137]
tr_loss:[0.10406113 0.14235848 0.11955263 0.13397785 0.1195526  0.14919195
 0.09252065 0.09966296 0.10379982 0.11955267 0.0932629  0.11379664
 0.11955271 0.1225512  0.10378005 0.10474221 0.11026035 0.15150507
 0.08755855 0.13342246 0.11955105 0.09751743 0.08788992 0.10623908
 0.10649035 0.11842513 0.0911309  0.11573267 0.11600423 0.09331349
 0.11834919 0.13460657 0.10383804 0.11945908 0.11464673 0.11943688
 0.10196505 0.13485534 0.11524053 0.10648936 0.10372283 0.11834977
 0.11800261 0.10466492 0.11676719 0.10365919 0.10751756 0.11125109
 0.09788469 0.11273227]
tr_loss:[0.06996118 0.05697181 0.0569718  0.05633185 0.12121563 0.0588314
 0.06332285 0.10266946 0.05824235 0.05597704 0.0638022  0.09667306
 0.05823213 0.09655975 0.12110656 0.0581808  0.09655816 0.07029364
 0.06390855 0.05428721 0.06629984 0.06629984 0.0589481  0.12100705
 0.09020443 0.09033649 0.11500578 0.05830298 0.05786326 0.06821191
 0.0612788  0.09755482 0.09209174 0.05828528 0.1059916  0.05827161
 0.10555599 0.14976582 0.07062502 0.05833197 0.06334502 0.05831288
 0.05837794 0.05961341 0.06072258 0.05999251 0.08074603 0.107743
 0.12914357 0.05921031]
tr_loss:[0.04653537 0.05132511 0.08777884 0.05838136 0.13568477 0.13271524
 0.05851376 0.08826387 0.06736921 0.06317238 0.07295525 0.05894926
 0.12803733 0.06941744 0.05941255 0.06792016 0.1254825  0.0902684
 0.05108552 0.05835885 0.05862529 0.06425567 0.08311512 0.05853176
 0.05132489 0.05132513 0.05886587 0.11529572 0.05291815 0.05655693
 0.07209559 0.11205278 0.05847825 0.05899063 0.1376675  0.0667692
 0.04795414 0.10703363 0.13339339 0.0694776  0.0589236  0.05885608
 0.09032037 0.05904073 0.06628161 0.06220087 0.0744829  0.06673732
 0.11895837 0.05131031]
tr_loss:[0.11715791 0.06932545 0.09594341 0.06107938 0.08544457 0.09258956
 0.07356115 0.1187398  0.05952962 0.0606424  0.08652469 0.07081921
 0.07619029 0.04903465 0.08827808 0.11080648 0.08578845 0.12759414
 0.13341984 0.04903468 0.10617121 0.04890702 0.09180696 0.06664469
 0.10256274 0.06101183 0.05254162 0.11212926 0.04210135 0.06505378
 0.07462271 0.07174541 0.10677372 0.05879588 0.0434152  0.08174638
 0.06135591 0.05709727 0.06100315 0.10852985 0.04222142 0.07198668
 0.0479568  0.04903467 0.06058528 0.05554612 0.08766752 0.1195633
 0.04903466 0.06221374]
tr_loss:[0.06263915 0.12510327 0.06496076 0.1338516  0.07353195 0.12266858
 0.06113522 0.13307132 0.06501666 0.08593986 0.06062421 0.06178722
 0.06501861 0.06521787 0.05975484 0.05762114 0.06986277 0.0759445
 0.0633985  0.08727908 0.06213734 0.12281089 0.14660445 0.0579432
 0.15188089 0.06343515 0.1207123  0.08550332 0.07728262 0.111901
 0.06495239 0.12984468 0.06261086 0.06502555 0.06263908 0.06065008
 0.11339559 0.07460041 0.06430568 0.09071635 0.08516905 0.05927407
 0.06852692 0.05375006 0.11023147 0.06852689 0.08713504 0.063211
 0.06502835 0.05894075]
tr_loss:[0.05672822 0.05305331 0.05641095 0.12360307 0.05313817 0.11861958
 0.05693823 0.054159   0.09967777 0.05708997 0.11118243 0.05885447
 0.06630664 0.05693891 0.06741358 0.05415743 0.05415897 0.0577523
 0.04589361 0.05268468 0.1197385  0.1257017  0.11588319 0.11921956
 0.06020115 0.09617628 0.06931898 0.05997635 0.08025549 0.10446402
 0.09529851 0.13201742 0.0587519  0.0983106  0.05296911 0.04976159
 0.12013422 0.09473787 0.04770784 0.08282132 0.08103855 0.05297972
 0.05320816 0.05415899 0.12238246 0.11059475 0.05875193 0.054159
 0.054159   0.11017976]
tr_loss:[0.06018788 0.10381331 0.06109184 0.10547411 0.13229752 0.10382767
 0.11075024 0.06293315 0.06182984 0.04846534 0.05186791 0.05207906
 0.10342989 0.05207912 0.06210456 0.06411247 0.066662   0.05213888
 0.06753437 0.09605557 0.09861947 0.052325   0.05207906 0.06117098
 0.10109536 0.06317848 0.05207816 0.1216471  0.0907925  0.04879384
 0.04824194 0.04811454 0.12587225 0.05329544 0.09042516 0.09676321
 0.06246834 0.04460092 0.05207909 0.06207809 0.06033262 0.06212714
 0.09808513 0.05267317 0.05824817 0.04754367 0.05207858 0.06195029
 0.10010795 0.12111406]
tr_loss:[0.06743451 0.08185355 0.05817466 0.05051725 0.0446466  0.05833796
 0.03699868 0.03699647 0.13460556 0.04464654 0.05335587 0.10259118
 0.08918449 0.03700307 0.07791754 0.11850642 0.05456755 0.08863176
 0.10068409 0.08899453 0.05455495 0.03697436 0.1013817  0.04464658
 0.05576097 0.03694651 0.04464639 0.09821441 0.04432309 0.07544734
 0.03697905 0.08811224 0.0798737  0.04016713 0.09640172 0.10403042
 0.08693642 0.036958   0.06003888 0.10249253 0.05180115 0.08775329
 0.09904164 0.08759969 0.05211971 0.05290266 0.05102556 0.10019495
 0.0570069  0.05607318]
tr_loss:[0.0577724  0.04490744 0.11123276 0.03423123 0.04490744 0.10159401
 0.03426109 0.04253771 0.05760738 0.04490719 0.10953836 0.10040937
 0.10906391 0.08544483 0.09846717 0.04935039 0.07544579 0.05193431
 0.05970107 0.09450518 0.05041818 0.0453422  0.09753469 0.05110767
 0.04927913 0.04870404 0.08272009 0.03424236 0.04490745 0.08649045
 0.04490586 0.07732753 0.05077541 0.11358456 0.05759412 0.09521685
 0.0588988  0.04843009 0.07184073 0.04775227 0.06620195 0.10185951
 0.05406036 0.10374882 0.0343004  0.09905271 0.03430782 0.10110172
 0.03507628 0.092356  ]
tr_loss:[0.05156235 0.06353513 0.06640463 0.05885421 0.05156232 0.07801609
 0.06386596 0.04664934 0.05156236 0.07597747 0.03804714 0.04733436
 0.03796192 0.0600853  0.08452164 0.09366436 0.0856006  0.05175861
 0.04538713 0.03794934 0.04952187 0.0654941  0.0638659  0.07281438
 0.05156226 0.03796664 0.0573841  0.06403406 0.03795551 0.05784299
 0.05156235 0.11450984 0.09337661 0.06602158 0.05747488 0.08393186
 0.08544408 0.0851252  0.06062586 0.06069178 0.05156235 0.04837655
 0.05288498 0.05789351 0.05132509 0.04084172 0.06238617 0.11629393
 0.09845975 0.04380402]
tr_loss:[0.04617509 0.04916841 0.06078376 0.09207488 0.02908052 0.02919266
 0.02908203 0.08010316 0.0290879  0.04758798 0.10401263 0.10812277
 0.02945336 0.04617506 0.07851899 0.09375744 0.04613105 0.10403599
 0.09698458 0.08552372 0.05689212 0.07927327 0.04617507 0.12830797
 0.03688838 0.02908246 0.04617506 0.06875704 0.039651   0.05048046
 0.04617507 0.02908292 0.08542106 0.07950577 0.06268747 0.0787556
 0.05456918 0.07227741 0.03736223 0.02908128 0.08013786 0.04262462
 0.0570861  0.12159006 0.04402322 0.04851534 0.04533972 0.04961373
 0.0778607  0.04135652]
tr_loss:[0.04328425 0.09016366 0.0351614  0.07191178 0.03461169 0.08869696
 0.04298294 0.04911145 0.0603172  0.07951222 0.06431595 0.0429763
 0.02417412 0.0491114  0.10269494 0.05752788 0.0498606  0.05756105
 0.0632596  0.05106514 0.05734801 0.04612923 0.0535171  0.09559884
 0.07252571 0.02414503 0.03843578 0.04311769 0.04294353 0.02421623
 0.05196926 0.02418496 0.04585271 0.04298325 0.04239907 0.08084873
 0.08190646 0.05441984 0.0413297  0.04911139 0.08724046 0.04271449
 0.10308953 0.02424708 0.07766713 0.04298326 0.10887965 0.04035567
 0.04298324 0.04131893]
tr_loss:[0.0391007  0.04387565 0.11875663 0.0234265  0.05421363 0.12260585
 0.03296847 0.09413101 0.07939848 0.03865833 0.08485147 0.05332751
 0.02355041 0.07985604 0.04421332 0.03653408 0.03865832 0.09547974
 0.05313273 0.13223246 0.0386584  0.07936975 0.096394   0.04529323
 0.03865882 0.10768352 0.11014583 0.04955585 0.03940376 0.04169206
 0.05471558 0.04150723 0.08899023 0.02347498 0.09199406 0.12204786
 0.06993153 0.11058223 0.02355127 0.04235518 0.05421396 0.04132343
 0.10841067 0.04368132 0.04954997 0.04178843 0.03828425 0.04992893
 0.03865837 0.044604  ]
tr_loss:[0.11019234 0.05291456 0.03637956 0.09054937 0.05706842 0.02735357
 0.09634577 0.02736096 0.03993856 0.05221431 0.1009775  0.02736903
 0.09354894 0.02734777 0.08321778 0.052781   0.05321242 0.03635772
 0.08312865 0.08325547 0.03352929 0.05813415 0.03636136 0.09611213
 0.02751217 0.05372566 0.0363577  0.05014224 0.03635773 0.03635855
 0.0946361  0.03327081 0.02744721 0.02761806 0.03273158 0.05542526
 0.04966114 0.04282366 0.13138029 0.02730782 0.05813416 0.02737165
 0.05093828 0.02737479 0.04375937 0.02732213 0.04036515 0.05325643
 0.1095456  0.02709991]
tr_loss:[0.02354991 0.08931816 0.03286768 0.02342786 0.07947242 0.03239613
 0.05754976 0.07962813 0.02355953 0.03933369 0.10500014 0.04467337
 0.08906367 0.02359884 0.0300604  0.07956344 0.04132557 0.05457971
 0.07953472 0.10556629 0.02355247 0.02355918 0.08055524 0.03063099
 0.09630713 0.05157172 0.08851616 0.03006038 0.04513174 0.08218877
 0.03491202 0.02355994 0.03177188 0.03006038 0.05457979 0.04556137
 0.0799496  0.02354828 0.08694907 0.04091077 0.03565069 0.07871284
 0.08806962 0.04007639 0.08064242 0.05508038 0.02355983 0.03518033
 0.07694726 0.04465587]
tr_loss:[0.04915196 0.05621691 0.07008737 0.08119334 0.06676792 0.04031799
 0.07518661 0.03348217 0.02707418 0.04470383 0.05621688 0.02159357
 0.04265616 0.02730577 0.03727949 0.04135284 0.03787432 0.09193873
 0.04734553 0.08575799 0.02730575 0.05288235 0.0873128  0.02730576
 0.02146397 0.03178698 0.0405631  0.04553284 0.07646891 0.05369598
 0.02730577 0.07525229 0.10310396 0.02148168 0.1002514  0.02730572
 0.04369313 0.05328888 0.02156519 0.10720714 0.04040516 0.08369323
 0.02727403 0.04449712 0.02154931 0.04103388 0.07325779 0.08768138
 0.12414721 0.02160012]
tr_loss:[0.05032482 0.04479512 0.02588527 0.03540281 0.0739699  0.0410594
 0.06206507 0.02588979 0.08108419 0.03504029 0.03015179 0.02137921
 0.0258898  0.10375702 0.03074018 0.03970597 0.04291638 0.10015764
 0.07243307 0.03607064 0.02588908 0.02137676 0.07839994 0.03707502
 0.03372075 0.02575335 0.02588978 0.03996919 0.08232898 0.08110885
 0.07073885 0.03707443 0.07392126 0.07286917 0.0269832  0.03468744
 0.10577516 0.03081643 0.06469016 0.03759635 0.02588979 0.07765161
 0.0749291  0.03941814 0.04485957 0.06382556 0.03848556 0.04028204
 0.07399339 0.04423091]
tr_loss:[0.03022841 0.04593844 0.04079019 0.0407902  0.07263192 0.03907042
 0.02887446 0.02185011 0.02560836 0.02195932 0.02138676 0.09892087
 0.06675236 0.03092998 0.04088019 0.10069565 0.03573822 0.09157447
 0.07262591 0.02560837 0.02193366 0.02186347 0.03065038 0.04217034
 0.04007255 0.09817249 0.03012462 0.02560837 0.03420991 0.03025763
 0.06811254 0.06398918 0.03588735 0.03205566 0.04051847 0.02560833
 0.021892   0.0424768  0.02137266 0.02184489 0.03097417 0.03435107
 0.02560805 0.02201981 0.06825403 0.07318871 0.04175509 0.03653573
 0.03654829 0.04292254]
tr_loss:[0.04093398 0.02597005 0.03032557 0.02979599 0.02598245 0.02164536
 0.0647148  0.02580447 0.02165474 0.04093401 0.02598265 0.0603855
 0.025967   0.04214154 0.07047214 0.07201669 0.03183571 0.06850051
 0.05597936 0.07960632 0.04758566 0.02184148 0.03598129 0.06999309
 0.03257091 0.03838063 0.02598263 0.04407927 0.08465062 0.07020497
 0.08977889 0.03779237 0.06847831 0.07109491 0.02598262 0.06118191
 0.06550996 0.0330073  0.03829049 0.0330084  0.07893727 0.10055251
 0.03857573 0.02164805 0.03782899 0.07053395 0.08315273 0.02571398
 0.07077581 0.07477999]
tr_loss:[0.08478566 0.04327199 0.03960258 0.09707858 0.02102429 0.03641193
 0.05087382 0.06024788 0.06896969 0.04238418 0.07011762 0.06570384
 0.02656196 0.02656265 0.04896883 0.03918885 0.05134658 0.05993555
 0.02086694 0.02656266 0.04930799 0.07016273 0.03699402 0.03739298
 0.02656269 0.04173542 0.0374152  0.03703665 0.02117203 0.02656266
 0.02062062 0.04038154 0.05654583 0.04278718 0.059917   0.05821406
 0.02706799 0.03741523 0.02114469 0.02108077 0.03960257 0.06863277
 0.04136249 0.07449131 0.08473545 0.07924558 0.03008727 0.04256572
 0.02762717 0.05260546]
tr_loss:[0.02053614 0.07304604 0.03286732 0.06745087 0.0828862  0.03151201
 0.04741194 0.0326168  0.06326959 0.03929328 0.02895283 0.02043493
 0.02893671 0.0466933  0.08269773 0.03015209 0.06949188 0.0458502
 0.03192944 0.02062701 0.04306296 0.02033162 0.04436057 0.03868495
 0.02867671 0.03872768 0.05505935 0.02062044 0.02071243 0.02066932
 0.06349973 0.02068134 0.03447277 0.04436134 0.04660558 0.02830886
 0.04067178 0.07031934 0.02085849 0.08341666 0.04132798 0.03261552
 0.06908921 0.03841522 0.02681429 0.09961881 0.04581859 0.02068565
 0.02085399 0.02821123]
tr_loss:[0.09817906 0.06805378 0.03238242 0.04640623 0.08423921 0.05008782
 0.02772838 0.01923283 0.01948028 0.08214653 0.04640626 0.06801218
 0.04035237 0.06861387 0.0672443  0.02653914 0.1055351  0.041257
 0.0707135  0.06421789 0.04564344 0.02659586 0.03668972 0.0195603
 0.02653912 0.0671766  0.02653916 0.03100426 0.03004926 0.07468138
 0.10000443 0.01956752 0.06744589 0.05894466 0.07186941 0.04640306
 0.01951587 0.04141154 0.0627415  0.02653913 0.06864543 0.05131998
 0.04640626 0.03800038 0.03198021 0.04423338 0.04640607 0.06159253
 0.07066059 0.0616252 ]
tr_loss:[0.06468476 0.03588167 0.03843253 0.05229735 0.06346355 0.01796529
 0.03041939 0.06365672 0.04326201 0.08613166 0.03299132 0.02499574
 0.07544699 0.03339501 0.01796685 0.05833025 0.03922462 0.02499573
 0.01798191 0.03717073 0.09006628 0.02985147 0.03634181 0.03922464
 0.04974308 0.03377176 0.06661819 0.06526162 0.06627114 0.02749517
 0.04192643 0.06608927 0.03703151 0.03843252 0.04192393 0.01793978
 0.02258614 0.09110048 0.03299146 0.03479306 0.03494935 0.03922462
 0.02703744 0.02110798 0.03128961 0.02494181 0.04979395 0.06648223
 0.02983795 0.07410221]
tr_loss:[0.03881575 0.03350859 0.05722202 0.01743527 0.06104497 0.07691064
 0.04170683 0.01736918 0.02439828 0.06472864 0.04480519 0.08071853
 0.03803601 0.01748239 0.01746963 0.04884366 0.06042956 0.09326803
 0.02575983 0.04442638 0.07466119 0.05549647 0.0649951  0.02439829
 0.04054743 0.01733379 0.02002155 0.02439827 0.08949656 0.02439829
 0.03720542 0.0547672  0.05733    0.05668105 0.03801887 0.05802077
 0.03478689 0.03001138 0.07741245 0.06531064 0.01738719 0.08481802
 0.03554056 0.02439828 0.04133932 0.07769611 0.02560056 0.03644352
 0.02273726 0.03881576]
tr_loss:[0.02436346 0.05538147 0.01766714 0.0979025  0.03941549 0.058234
 0.06309685 0.06778903 0.02458243 0.01767998 0.03539997 0.02624885
 0.06553982 0.02484227 0.01765019 0.03979816 0.07223427 0.02458584
 0.06273843 0.03686895 0.07602294 0.05517121 0.02732734 0.06389654
 0.027154   0.06180135 0.05966373 0.02458582 0.06334772 0.02672997
 0.04172971 0.05471975 0.0322197  0.02458583 0.05743317 0.01768193
 0.02733657 0.01766594 0.03147688 0.06171001 0.06441767 0.03499403
 0.059084   0.05144333 0.01797321 0.02449745 0.05912395 0.05483003
 0.02458535 0.03039315]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1300 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1301, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1301 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1302, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1302 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1303, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1303 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1304, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1304 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1305, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1305 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1306, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1306 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1307, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1307 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1308, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1308 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1309, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1309 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1310, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1310 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1311, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1311 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1312, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1312 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1313, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1313 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1314, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1314 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1315, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1315 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1316, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1316 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1317, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1317 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1318, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1318 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1319, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1319 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1320, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1320 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1321, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1321 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1322, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1322 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1323, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1323 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1324, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1324 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1325, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1325 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1326, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1326 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1327, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1327 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1328, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1328 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1329, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1329 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1330, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1330 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1331, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1331 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1332, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1332 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1333, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1333 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1334, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1334 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1335, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1335 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1336, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1336 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1337, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1337 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1338, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1338 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1339, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1339 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1340, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1340 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1341, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1341 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1342, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1342 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1343, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1343 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1344, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1344 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1345, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1345 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1346, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1346 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1347, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1347 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1348, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1348 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1349, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1349 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1350, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1350 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1351, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1351 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1352, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1352 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1353, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1353 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1354, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1354 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1355, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1355 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1356, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1356 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1357, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1357 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1358, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1358 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1359, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1359 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1360, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1360 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1361, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1361 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1362, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1362 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1363, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1363 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1364, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1364 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1365, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1365 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1366, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1366 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1367, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1367 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1368, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1368 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1369, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1369 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1370, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1370 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1371, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1371 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1372, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1372 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1373, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1373 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1374, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1374 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1375, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1375 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1376, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1376 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1377, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1377 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1378, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1378 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1379, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1379 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1380, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1380 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1381, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1381 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1382, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1382 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1383, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1383 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1384, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1384 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1385, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1385 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1386, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1386 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1387, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1387 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1388, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1388 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1389, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1389 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1390, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1390 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1391, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1391 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1392, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1392 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1393, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1393 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1394, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1394 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1395, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1395 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1396, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1396 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1397, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1397 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1398, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1398 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1399, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1399 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1400, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-1300
text_input.shape
(1400, 14400)
learning_input_tmp.shape
(1400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1400, 80)
learning_output.shape
(750, 80)
Model: "sequential_29"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_29 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.70425534 1.0825516  0.6998569  0.96918356 0.71464974 0.95153254
 1.0475012  1.0825516  0.8373607  0.83299124 0.9523859  0.84176433
 0.91021854 0.8627167  0.8481312  0.8471533  0.7070763  0.9524988
 0.95190686 0.83736056 0.6345097  0.7504261  0.83442056 0.9005585
 0.7056993  0.8661033  0.9524946  0.7072331  0.8595131  0.8916143
 0.81265986 0.878448   1.0470245  0.85678023 1.0475012  0.71685356
 0.8825011  0.9691836  0.95249856 0.95146906 0.8440877  0.96918344
 0.83151186 0.9522235  0.91297436 0.7839983  0.9524994  0.85128653
 1.0475013  0.8715746 ]
tr_loss:[0.6388493  0.55083627 0.43855515 0.51077473 0.52831477 0.53656715
 0.49645358 0.44207096 0.60517347 0.5365293  0.582819   0.5540361
 0.55077416 0.5365674  0.52042156 0.43984842 0.5828191  0.53654206
 0.5651938  0.5113034  0.49530822 0.5583339  0.53523695 0.5508238
 0.49106807 0.49440822 0.5024703  0.5507393  0.63884974 0.46259442
 0.5433892  0.5421561  0.55089396 0.45840645 0.4729519  0.5594984
 0.48573017 0.41313744 0.54280657 0.55529463 0.44855946 0.5251478
 0.5828191  0.5608965  0.63884926 0.5365675  0.5365675  0.53314716
 0.55074847 0.5364193 ]
tr_loss:[0.3611228  0.3161422  0.2585117  0.27343926 0.3045751  0.30140918
 0.33784205 0.32555762 0.3139721  0.31177026 0.3378942  0.31033117
 0.3450922  0.31901842 0.34896114 0.3486143  0.3043258  0.33665133
 0.35659608 0.30457506 0.3378926  0.3045751  0.35655227 0.33563113
 0.32550138 0.33110005 0.33277088 0.35639492 0.30312115 0.29899868
 0.3037478  0.32867873 0.33794132 0.33789662 0.31231457 0.31901106
 0.31901112 0.3045751  0.29187915 0.33787334 0.2825603  0.3185683
 0.3061625  0.35639507 0.3082105  0.35639486 0.3286788  0.34572306
 0.26398245 0.34106836]
tr_loss:[0.195202   0.20872898 0.20801055 0.21922009 0.22860284 0.21088013
 0.20800917 0.21755108 0.21291153 0.24758486 0.1898373  0.20522816
 0.195202   0.21922013 0.18983145 0.19298276 0.19972593 0.19958545
 0.21551082 0.23178414 0.18167412 0.18983683 0.18983726 0.19335535
 0.2069175  0.18983729 0.18983725 0.20842631 0.21165045 0.2533973
 0.23354857 0.18289872 0.1956548  0.22262025 0.2082187  0.21623048
 0.21835764 0.2370023  0.21146145 0.22241244 0.21922016 0.1898373
 0.23696966 0.20730364 0.2165515  0.21827504 0.20803042 0.19455388
 0.22744353 0.18983729]
tr_loss:[0.10619557 0.12689714 0.13045807 0.13933925 0.10620723 0.13219109
 0.13611689 0.1965281  0.13106251 0.19792588 0.13106255 0.1268448
 0.17101069 0.10620664 0.14257857 0.13123363 0.14311182 0.14013596
 0.12971386 0.14277966 0.14986646 0.13325433 0.13798404 0.1268976
 0.1283152  0.1062073  0.12998287 0.18717995 0.17904198 0.14340337
 0.15319315 0.12689707 0.17108823 0.13046911 0.17780323 0.1305075
 0.13106255 0.12491606 0.1062073  0.12689713 0.12831609 0.12599
 0.14624596 0.10620733 0.13049158 0.1337878  0.14289376 0.10620737
 0.12813976 0.130451  ]
tr_loss:[0.09863563 0.15153325 0.1616704  0.0987127  0.09884401 0.07255487
 0.09480258 0.17218094 0.07249708 0.07708395 0.10954644 0.07272743
 0.10899551 0.09867009 0.11276629 0.07272745 0.11250903 0.10798822
 0.09867362 0.09960179 0.15777685 0.10035381 0.07272653 0.07272746
 0.09571268 0.11264378 0.11602056 0.06970228 0.09152539 0.10461333
 0.08458789 0.07255777 0.10468785 0.17079371 0.07255778 0.10760138
 0.07272749 0.10035386 0.09689812 0.09865435 0.09844    0.09259786
 0.0725575  0.11830702 0.08458789 0.11462865 0.09865941 0.09915396
 0.11920515 0.1015685 ]
tr_loss:[0.08009161 0.08691181 0.08282831 0.06528399 0.08942129 0.17823002
 0.09308417 0.09382127 0.07095382 0.06484585 0.19211009 0.17162232
 0.06528412 0.09285517 0.08614136 0.09724677 0.06170011 0.05861713
 0.06528417 0.11317311 0.08679555 0.09312962 0.05993053 0.10671706
 0.0918548  0.19977668 0.09229872 0.07989329 0.09999631 0.09300945
 0.06110667 0.12619288 0.07329854 0.06528412 0.10792116 0.10166492
 0.10936501 0.06528416 0.11642265 0.09311644 0.06360759 0.17396107
 0.09490316 0.09149752 0.09247364 0.17488223 0.09258772 0.064947
 0.16879301 0.06528413]
tr_loss:[0.08381334 0.07110713 0.08221868 0.08576028 0.19558807 0.07807473
 0.12221949 0.07154424 0.07260003 0.17068261 0.07996033 0.20120788
 0.07776887 0.18510303 0.05619575 0.08259016 0.19357193 0.10758986
 0.09026237 0.07298534 0.09774487 0.07811236 0.17561856 0.08285421
 0.07995391 0.08106361 0.09772488 0.18135421 0.04404139 0.10059836
 0.07830485 0.05619591 0.05817445 0.1557974  0.05970802 0.16973759
 0.08072181 0.07156592 0.09355137 0.0741208  0.07792117 0.07126837
 0.07642718 0.07911462 0.16426796 0.04510802 0.07909232 0.05619588
 0.11073323 0.1758166 ]
tr_loss:[0.09252046 0.04659034 0.08051801 0.10771915 0.08309204 0.06655176
 0.10867472 0.07640427 0.14053567 0.09235153 0.06035708 0.04682856
 0.1253909  0.07529475 0.04404662 0.07507731 0.06035673 0.06035705
 0.07716481 0.14752759 0.10048699 0.06548488 0.05005473 0.06632185
 0.08309206 0.07977815 0.09361129 0.0665986  0.0667909  0.08077001
 0.08437037 0.2363226  0.08051808 0.09174503 0.07976145 0.05004562
 0.08202915 0.11919259 0.06659699 0.19728014 0.06035705 0.08505651
 0.08202897 0.14973418 0.08202912 0.06641246 0.08172308 0.06669835
 0.08752356 0.0668117 ]
tr_loss:[0.07075883 0.07942303 0.05417594 0.07919711 0.09440984 0.22334477
 0.10691402 0.09780543 0.08956355 0.20552793 0.06766435 0.09464534
 0.07075822 0.07075825 0.04605536 0.13036983 0.20129499 0.06793617
 0.21318623 0.0924622  0.0707582  0.05613832 0.07075818 0.17538366
 0.1250214  0.0561383  0.09394266 0.10425188 0.09056596 0.06757928
 0.05417592 0.19192882 0.10056174 0.09169071 0.09186281 0.06756879
 0.07080235 0.06762994 0.07075817 0.07110497 0.0761237  0.07799192
 0.08959321 0.0841894  0.09233452 0.23329535 0.09434521 0.18498495
 0.09478839 0.09053764]
tr_loss:[0.0859734  0.0472606  0.08597337 0.04763512 0.17752108 0.17732728
 0.0849825  0.12896697 0.12222936 0.12542155 0.07930615 0.07620369
 0.08723937 0.06839491 0.07570205 0.09579124 0.07067951 0.19614443
 0.07223218 0.12422786 0.1378378  0.18931821 0.04717401 0.08457443
 0.0616838  0.04726063 0.11671938 0.08893158 0.06951392 0.06232095
 0.1209193  0.06196845 0.11740226 0.08517638 0.16940513 0.08850728
 0.07917443 0.08579892 0.06787502 0.08087059 0.06634979 0.08876217
 0.16912337 0.08843755 0.11975016 0.19127087 0.06887557 0.18945408
 0.06887554 0.04726062]
tr_loss:[0.17730299 0.06468447 0.06512029 0.11795871 0.07277571 0.12430014
 0.06504067 0.06388438 0.06428382 0.07002996 0.07270562 0.06208463
 0.06430059 0.18166277 0.14749992 0.05034743 0.11803804 0.07599045
 0.19939299 0.10942324 0.07838005 0.06599034 0.03916798 0.03916796
 0.12372558 0.07277298 0.06937238 0.08165218 0.06512803 0.06521209
 0.04118483 0.06499548 0.08165216 0.07746615 0.08425374 0.03916801
 0.04134056 0.07277568 0.18432203 0.0727265  0.07667191 0.06047324
 0.06550246 0.06511126 0.06721377 0.12375202 0.17322819 0.08190034
 0.05458285 0.20192175]
tr_loss:[0.04004463 0.04255987 0.1176305  0.06457666 0.06446498 0.06735075
 0.0775186  0.06311785 0.06187876 0.05455644 0.04255987 0.06445758
 0.06350309 0.06456061 0.03717571 0.07656731 0.0645661  0.06455419
 0.1300705  0.10899826 0.18080726 0.0631178  0.06600305 0.07705028
 0.06403624 0.06502933 0.13720739 0.0626937  0.0400449  0.07610314
 0.04004462 0.0425598  0.052215   0.04004461 0.1843263  0.06311779
 0.18407664 0.08361878 0.19835387 0.06796313 0.06462659 0.12018454
 0.11936526 0.07558393 0.11928059 0.19542897 0.06311776 0.04004464
 0.07323668 0.06547211]
tr_loss:[0.05255832 0.08341639 0.06502948 0.07201194 0.08680477 0.06194951
 0.08340387 0.05745466 0.06614663 0.05956181 0.06122708 0.08699442
 0.03745446 0.03328995 0.03328998 0.05982159 0.10767686 0.13117929
 0.16889194 0.08172081 0.07410579 0.05995385 0.08628636 0.06195594
 0.07105615 0.05918511 0.07070222 0.07105597 0.03745448 0.06778739
 0.07472069 0.04799457 0.07126812 0.03328995 0.05855636 0.06884755
 0.10873044 0.17819043 0.15490356 0.14583689 0.04799454 0.07283024
 0.15743227 0.03328992 0.06377075 0.08058195 0.04799335 0.04799454
 0.04930105 0.06307455]
tr_loss:[0.06711593 0.08680551 0.05239004 0.03199998 0.02707666 0.06436752
 0.06911443 0.16249423 0.16142419 0.05279814 0.09516544 0.05235144
 0.0496304  0.03725975 0.06436737 0.03638922 0.06643815 0.06393965
 0.05365865 0.06595197 0.03725266 0.05339183 0.02707474 0.03418401
 0.05246495 0.03725972 0.08013733 0.05608537 0.05269708 0.03199999
 0.16622049 0.06594702 0.16094856 0.06133221 0.02708087 0.05221885
 0.19631031 0.06685467 0.0542186  0.03718035 0.07474627 0.06685485
 0.05101918 0.11536559 0.06213794 0.07322665 0.16164143 0.02707666
 0.1499202  0.05230661]
tr_loss:[0.06305555 0.05731688 0.03644817 0.08263659 0.10388537 0.06560729
 0.06914251 0.05121754 0.06484491 0.05014412 0.03680991 0.05016262
 0.14774731 0.06819747 0.03654018 0.10411663 0.05330346 0.06123339
 0.02628451 0.05451671 0.03887214 0.0364482  0.03671964 0.08215971
 0.03644818 0.03650987 0.0560036  0.05037753 0.05594135 0.14779088
 0.17096005 0.05653196 0.06860778 0.06860781 0.10641678 0.06913938
 0.03650994 0.05708138 0.05732297 0.03644821 0.06816877 0.05146756
 0.05124605 0.06556664 0.06199714 0.05680444 0.05007832 0.04952658
 0.08003597 0.07294409]
tr_loss:[0.12236644 0.0386754  0.03548204 0.11812347 0.04622126 0.03926522
 0.09410122 0.05800428 0.04632576 0.12070239 0.11220729 0.07830987
 0.06072484 0.16014263 0.10770371 0.06833392 0.06746654 0.03582399
 0.03867598 0.02679528 0.08954497 0.05182453 0.06263264 0.03548203
 0.04572025 0.0843217  0.03867599 0.10726441 0.10068417 0.04539617
 0.02679525 0.0267953  0.03548205 0.1443077  0.06526633 0.038676
 0.06746795 0.05254662 0.04606694 0.09213968 0.03867598 0.0397087
 0.04581458 0.03548206 0.04641863 0.15808043 0.05193813 0.03818101
 0.05481523 0.07008879]
tr_loss:[0.05303764 0.11386956 0.05652129 0.03654854 0.05636409 0.05895279
 0.07027759 0.03737491 0.08711638 0.06189011 0.03664606 0.09388206
 0.05914612 0.09232051 0.0256561  0.10898855 0.06431824 0.03789623
 0.07167527 0.06431799 0.03681286 0.16095746 0.02513027 0.02513025
 0.03737489 0.0419619  0.0643163  0.16734962 0.04273032 0.09112951
 0.03658894 0.03819675 0.02512763 0.06768287 0.0378921  0.03378585
 0.06002617 0.03789619 0.02513018 0.03679382 0.03789622 0.06150051
 0.03647604 0.0915307  0.14211369 0.0459838  0.06150066 0.04807457
 0.04479662 0.03805379]
tr_loss:[0.05578124 0.06248967 0.06238576 0.0560786  0.0383089  0.0897175
 0.18144397 0.03830893 0.06528436 0.03021757 0.03830894 0.06058734
 0.0303931  0.05656577 0.06013511 0.04788031 0.06248971 0.03021761
 0.02252701 0.06976337 0.02253735 0.05247502 0.08235729 0.06025224
 0.08408831 0.10655273 0.02252701 0.02252707 0.03041599 0.06784768
 0.11911895 0.03830893 0.05684472 0.03830891 0.06784772 0.14927337
 0.06784777 0.12245425 0.03040457 0.17621854 0.05940959 0.05388265
 0.06987587 0.03825403 0.03021756 0.03368502 0.04743656 0.16066514
 0.03039081 0.033685  ]
tr_loss:[0.06158825 0.0299632  0.01753175 0.02730883 0.11713181 0.02730787
 0.04050691 0.16060527 0.02631063 0.05350001 0.14968856 0.0477846
 0.06256209 0.17935982 0.04616044 0.14665358 0.05549918 0.02730787
 0.02623221 0.03064302 0.05371387 0.0814029  0.05363173 0.13597564
 0.02996324 0.05502232 0.02622898 0.06256209 0.15965798 0.05193964
 0.13844304 0.14932613 0.0261194  0.09700415 0.1608748  0.05071517
 0.02621254 0.13476677 0.02996318 0.04455386 0.04070307 0.0592926
 0.04944106 0.04434376 0.07952613 0.05193936 0.04790875 0.0470266
 0.16392367 0.164636  ]
tr_loss:[0.02719457 0.02399115 0.023985   0.04459395 0.02398517 0.06419043
 0.05789874 0.04772485 0.104363   0.04941505 0.04766262 0.02398499
 0.02719964 0.04796318 0.05745196 0.02398504 0.02567808 0.11365388
 0.06179583 0.07454598 0.07632115 0.02825754 0.02723087 0.02487932
 0.02719014 0.02218405 0.02969161 0.05277669 0.04757072 0.02704393
 0.05675776 0.04959453 0.12318154 0.05035729 0.02398502 0.05303802
 0.02825719 0.04756783 0.0282575  0.02720074 0.1374695  0.05498555
 0.02719661 0.02825752 0.06515893 0.09079878 0.02718936 0.05261119
 0.07368623 0.06515891]
tr_loss:[0.13559386 0.02490751 0.02967606 0.10351934 0.05043712 0.11165667
 0.02659779 0.0299328  0.0299814  0.06115452 0.03877797 0.0658258
 0.07584245 0.12501553 0.02306833 0.0297804  0.06793578 0.11717758
 0.09097105 0.02490752 0.05447638 0.03184887 0.04557803 0.02513204
 0.02306744 0.02833914 0.13066837 0.05671287 0.03739432 0.01989248
 0.02513205 0.03001242 0.14346583 0.02996564 0.01989247 0.04190336
 0.02306743 0.05986092 0.11180713 0.02998181 0.05791038 0.08436153
 0.06233595 0.02547632 0.02490747 0.02306739 0.02306742 0.05139979
 0.12590829 0.02490754]
tr_loss:[0.04862292 0.08776589 0.05348181 0.02217976 0.09493102 0.05563123
 0.04862293 0.15221582 0.02270308 0.04976015 0.07053261 0.02585947
 0.03034057 0.02383515 0.12441701 0.03446775 0.02420411 0.03013818
 0.05356907 0.03031816 0.05310363 0.04655501 0.02270307 0.05343012
 0.09657643 0.04787552 0.05254486 0.05662568 0.03029766 0.04279821
 0.10388217 0.02217976 0.03049661 0.02217978 0.07053324 0.1535439
 0.04921981 0.05537361 0.15134498 0.07053275 0.02270238 0.05520735
 0.12630142 0.08101414 0.02420411 0.03594132 0.09635837 0.02944222
 0.05744749 0.13941851]
tr_loss:[0.04355596 0.02658598 0.05313385 0.02820791 0.04923408 0.028242
 0.05137702 0.05864332 0.03542425 0.02846237 0.05619174 0.02658435
 0.02658631 0.04712168 0.01985256 0.01984926 0.03627519 0.02618655
 0.09696713 0.11192869 0.08765611 0.0600643  0.14226167 0.02826721
 0.02618655 0.12664962 0.06772137 0.08485907 0.04367287 0.02830161
 0.05141532 0.02668139 0.02421511 0.03483969 0.03421202 0.06169173
 0.02658629 0.02690161 0.02811759 0.06869726 0.05088143 0.02658542
 0.06892432 0.02658631 0.12447514 0.01985266 0.02772635 0.03127218
 0.02820182 0.04712183]
tr_loss:[0.07841502 0.11868446 0.0792952  0.02749918 0.02750996 0.02751026
 0.03637384 0.10236122 0.04380007 0.02771997 0.02570319 0.04236662
 0.08026763 0.03608959 0.02571927 0.11648075 0.02564591 0.02279131
 0.02748231 0.0305664  0.04655301 0.02511137 0.02572113 0.02571288
 0.11350875 0.12827405 0.02771993 0.05120073 0.05046495 0.04648735
 0.05330833 0.03698702 0.04581871 0.02771994 0.02565908 0.09959909
 0.05454053 0.06424405 0.01886994 0.02580189 0.02751029 0.12448525
 0.03187986 0.02751029 0.03976911 0.043041   0.07928099 0.04196824
 0.03846755 0.05623909]
tr_loss:[0.0501684  0.02669919 0.0864346  0.03904137 0.02286444 0.0369801
 0.11570992 0.02969681 0.02329104 0.07943131 0.04212683 0.04058816
 0.0456853  0.02330583 0.05425486 0.04398835 0.03559098 0.0410689
 0.01870827 0.08805251 0.02669918 0.11572993 0.05881641 0.10188411
 0.03223926 0.0353464  0.0505822  0.02665756 0.02669919 0.04278253
 0.04046324 0.03566235 0.02342791 0.05238025 0.05238029 0.07090417
 0.05100857 0.10100331 0.02669918 0.04543696 0.02969681 0.02320691
 0.02531445 0.0416191  0.04912971 0.02969683 0.03134282 0.06205346
 0.0266992  0.03447973]
tr_loss:[0.04088008 0.02641753 0.05045632 0.1023251  0.0414045  0.04338721
 0.05435183 0.04236208 0.08815247 0.04815773 0.02142328 0.08631118
 0.02662883 0.02662881 0.0342954  0.02150857 0.08308277 0.0424377
 0.04904751 0.03902368 0.04094766 0.02152531 0.03868409 0.10503507
 0.02662883 0.06540461 0.04012017 0.02177295 0.02361274 0.02132436
 0.09706841 0.029833   0.10601728 0.04088007 0.04072901 0.02693779
 0.02181374 0.01612053 0.03958469 0.10227571 0.02115013 0.02226316
 0.10454975 0.07767657 0.0319782  0.02130952 0.09855098 0.043697
 0.02640561 0.07742661]
tr_loss:[0.09170319 0.02669215 0.02315638 0.05096397 0.02356906 0.04055679
 0.08081285 0.02339967 0.04488721 0.03117923 0.03530929 0.01531994
 0.07272817 0.02672449 0.03188183 0.13547072 0.01532    0.10985444
 0.03705836 0.04488723 0.0280601  0.02408177 0.05082214 0.02672447
 0.05417804 0.03805261 0.13281073 0.0289534  0.10744739 0.12200715
 0.0274863  0.10884477 0.0285853  0.02734214 0.03372275 0.10638604
 0.04529877 0.09463985 0.148225   0.0410633  0.02755925 0.03338897
 0.03790869 0.02313758 0.03289173 0.12203453 0.04273732 0.03950752
 0.02672448 0.02321   ]
tr_loss:[0.02389    0.02280634 0.05392339 0.03385282 0.05053212 0.04148809
 0.03564357 0.04335247 0.02281323 0.02281323 0.02281324 0.02425441
 0.02281158 0.01593812 0.02279819 0.03168704 0.03595694 0.02392952
 0.04004908 0.0505321  0.05053211 0.10196389 0.0255902  0.02421179
 0.03718394 0.0333292  0.02281324 0.11947437 0.07587641 0.02381061
 0.03095821 0.02413177 0.09115182 0.0531047  0.02441939 0.02414094
 0.02281325 0.02975153 0.10815044 0.02281324 0.13909304 0.08818398
 0.02425044 0.02354157 0.02347175 0.02281323 0.11316583 0.05053088
 0.11854831 0.04685727]
tr_loss:[0.02073322 0.02507304 0.04005209 0.04318676 0.03911612 0.02073322
 0.02601626 0.03425907 0.04001426 0.02073267 0.02051261 0.09546454
 0.10031049 0.02073322 0.10863955 0.02505519 0.04584072 0.03167882
 0.01875564 0.02162892 0.02534404 0.03994654 0.11078274 0.05521723
 0.10207395 0.0249315  0.1062177  0.0205867  0.11837174 0.03924837
 0.02498479 0.04440687 0.01819856 0.02009698 0.02069489 0.05191179
 0.03482708 0.02504945 0.03944031 0.05036006 0.02009705 0.06206272
 0.041026   0.02009705 0.02073322 0.10562904 0.1055335  0.12241621
 0.02509188 0.04134163]
text_input.shape
(1400, 14400)
learning_input_tmp.shape
(1400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1400, 80)
learning_output.shape
(750, 80)
Model: "sequential_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_30 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0336126  0.9520397  0.823785   1.0336304  1.0559597  0.95542735
 1.0594171  1.1714224  1.0559505  0.96666443 1.0336466  0.7959508
 0.9517414  0.88348216 1.0336574  0.82917434 1.0559032  1.1291889
 0.9622777  0.795562   1.1718594  0.9533148  0.97716415 1.0335662
 1.0559598  0.8035258  1.1714227  0.97700137 1.1354845  1.1360945
 0.98361814 1.1311631  0.96239346 0.95555    0.96421355 0.8117107
 1.0559597  0.82648486 0.90761864 0.9392969  0.96883315 0.94680864
 1.0336258  0.90761316 1.0559598  1.0455489  0.96490777 1.0336567
 0.8204338  1.0339578 ]
tr_loss:[0.53519136 0.39498323 0.42224073 0.49668264 0.48189744 0.5863191
 0.53390634 0.41725674 0.45691323 0.47834343 0.54780227 0.60077506
 0.5338742  0.50026226 0.45089912 0.5344394  0.51655406 0.44265518
 0.5929483  0.547816   0.5478159  0.5478159  0.4829256  0.4300769
 0.47158384 0.5928957  0.49634004 0.5478158  0.5478157  0.46419612
 0.43811917 0.46503896 0.533912   0.3967367  0.52123964 0.42777866
 0.47872075 0.5338813  0.4621728  0.43743753 0.5169219  0.4585766
 0.58235914 0.4131674  0.53390807 0.4426548  0.44791907 0.5478159
 0.53391737 0.4437231 ]
tr_loss:[0.22012238 0.26130486 0.27928263 0.25951582 0.2709657  0.27568614
 0.23995134 0.2744735  0.27901402 0.27444425 0.26488394 0.24542932
 0.2390013  0.26653868 0.24496405 0.23602386 0.27912164 0.25739673
 0.2577346  0.27910796 0.25739658 0.2766567  0.24266234 0.26511535
 0.23031273 0.33139402 0.26552528 0.24046978 0.26879996 0.26472774
 0.25950256 0.22792502 0.24779539 0.27932197 0.26047578 0.27567953
 0.27959388 0.27557334 0.27911648 0.27568612 0.2756862  0.3352279
 0.236588   0.25664836 0.2789871  0.2653244  0.27955946 0.2686355
 0.27568617 0.26377764]
tr_loss:[0.16444838 0.17126432 0.1670666  0.15789409 0.2079592  0.21783955
 0.17107238 0.16641416 0.15940431 0.17117226 0.1613436  0.17925784
 0.1655449  0.15527575 0.16635919 0.1638395  0.17126438 0.17665347
 0.17126435 0.16934521 0.16661508 0.18719149 0.14710613 0.16108167
 0.17146023 0.17126437 0.16934521 0.1660575  0.16148642 0.17126438
 0.16803817 0.17147665 0.17126426 0.15734974 0.21788473 0.1573498
 0.17345837 0.1873068  0.13901412 0.16602936 0.16934733 0.22718373
 0.17325112 0.17160395 0.21783957 0.2288423  0.17551461 0.15557173
 0.16317491 0.14466257]
tr_loss:[0.11551309 0.13586776 0.13586774 0.11165557 0.09544753 0.12551382
 0.10382509 0.11328268 0.09324448 0.08751587 0.10763372 0.09997465
 0.10475516 0.08763539 0.14184877 0.09250776 0.11545293 0.09449334
 0.09791599 0.10170303 0.10813208 0.10762696 0.08606479 0.13846388
 0.12720358 0.12398832 0.09857984 0.10787261 0.10850112 0.1076269
 0.10152964 0.11409333 0.13586776 0.14060609 0.10116197 0.09663381
 0.13586776 0.12609367 0.11287923 0.09260928 0.10312983 0.10077052
 0.12212043 0.10746311 0.09663383 0.10121534 0.0965265  0.09904953
 0.08682589 0.13586047]
tr_loss:[0.05456828 0.0693178  0.07546784 0.09766026 0.0692216  0.11717568
 0.05566786 0.06806754 0.0645738  0.08757214 0.06918148 0.06933065
 0.0546199  0.05568535 0.06891113 0.05568538 0.064321   0.08757214
 0.07283713 0.06127002 0.0546654  0.06239556 0.12634666 0.09495645
 0.0546654  0.06941915 0.07637841 0.06473143 0.06926338 0.07700185
 0.05568536 0.06401045 0.05337531 0.05337517 0.06826936 0.08572963
 0.09246149 0.07700167 0.13515864 0.13241307 0.06865724 0.12046174
 0.06827457 0.07700168 0.09246184 0.1211375  0.13768855 0.05337521
 0.09066378 0.12335791]
tr_loss:[0.12844063 0.06699533 0.06271023 0.09896895 0.12497602 0.05383373
 0.05686902 0.06271025 0.07593515 0.05383371 0.12642232 0.12041397
 0.05789009 0.05673744 0.05203643 0.06105221 0.11011606 0.07593513
 0.07593511 0.1443311  0.05383377 0.06109621 0.06765518 0.05820908
 0.12489857 0.06624889 0.0627102  0.07422853 0.05383376 0.06010098
 0.05788603 0.06098134 0.10436922 0.05486288 0.05371878 0.07334796
 0.06361596 0.0566497  0.13536556 0.05417774 0.0605759  0.06097063
 0.10593039 0.05697063 0.06608504 0.05912076 0.05383372 0.0633633
 0.1156131  0.05383279]
tr_loss:[0.06386147 0.05360507 0.05826586 0.06255218 0.05332867 0.06235173
 0.05360507 0.05360319 0.0681394  0.05284252 0.05558723 0.1322841
 0.10225968 0.05360509 0.0548476  0.05562001 0.05314039 0.05890187
 0.05434803 0.05434802 0.05360491 0.07151844 0.0993201  0.05392068
 0.05342988 0.05558063 0.06050133 0.05562608 0.05542633 0.06235171
 0.06701336 0.06406031 0.0555524  0.05689301 0.05689299 0.06177487
 0.15239993 0.05701405 0.09824517 0.08925913 0.05557394 0.05805219
 0.0676759  0.09186431 0.10289621 0.06979794 0.05434807 0.1406444
 0.04866093 0.05377612]
tr_loss:[0.06158636 0.05854911 0.05853527 0.06929871 0.05022005 0.05542632
 0.05435637 0.0552517  0.09597791 0.15143266 0.05853523 0.05435638
 0.07035099 0.06137421 0.05853524 0.13362506 0.06289805 0.06624971
 0.05286652 0.10679386 0.05775203 0.0554216  0.0576445  0.06158642
 0.0504332  0.06516035 0.05853523 0.0585352  0.05853469 0.05852306
 0.05976366 0.05377043 0.05043323 0.05928542 0.06439318 0.05767893
 0.06133179 0.05022008 0.05022007 0.06082655 0.05853527 0.0688251
 0.1478253  0.14839977 0.14518705 0.11553357 0.16035783 0.06690902
 0.05435642 0.0543564 ]
tr_loss:[0.05057912 0.04800697 0.12813003 0.04915463 0.05900937 0.05380884
 0.05832189 0.05608106 0.13387486 0.07999365 0.15939471 0.12397423
 0.04800683 0.05399579 0.0496219  0.05047271 0.13915685 0.05609584
 0.0497437  0.0571036  0.05034476 0.05032863 0.04615316 0.04799914
 0.13512246 0.05543024 0.0585083  0.05390981 0.04419111 0.05123316
 0.0503516  0.06503628 0.05479808 0.04718976 0.05032764 0.06248979
 0.05595633 0.04859239 0.05410451 0.05685318 0.04799177 0.03707872
 0.05820984 0.05408871 0.12611882 0.05797755 0.03463791 0.05592146
 0.07540382 0.03724285]
tr_loss:[0.06391113 0.09592106 0.135641   0.06334078 0.06603693 0.05837131
 0.05246321 0.05504515 0.08813693 0.05463183 0.05307227 0.04499764
 0.05509897 0.05130959 0.06498897 0.0449977  0.05938116 0.05570822
 0.05246196 0.06126495 0.14567402 0.14185697 0.0449977  0.05271535
 0.06803187 0.05511601 0.06569757 0.11236142 0.06561897 0.14020531
 0.15175289 0.05246321 0.12864828 0.04499771 0.04006869 0.04133941
 0.06515088 0.05246301 0.14574069 0.05195232 0.11958574 0.06088709
 0.0705778  0.11438847 0.06404892 0.11911738 0.07501872 0.06432234
 0.1506069  0.1469742 ]
tr_loss:[0.04481075 0.0382384  0.06642829 0.04861151 0.05306412 0.05568105
 0.03823838 0.05568094 0.05043005 0.04677805 0.05367106 0.04861151
 0.06063765 0.05710628 0.09474967 0.04092913 0.04861148 0.1345698
 0.0591313  0.05878284 0.10435896 0.14426759 0.05602206 0.0520284
 0.13632885 0.05933594 0.03823727 0.0488144  0.04483088 0.06025457
 0.0572637  0.04092913 0.04481073 0.03823837 0.05043577 0.05065933
 0.05482029 0.0551825  0.04481075 0.11696093 0.05226994 0.05913132
 0.05367112 0.11408897 0.04092909 0.04460095 0.13106152 0.04861145
 0.04861146 0.05051876]
tr_loss:[0.03313739 0.03328608 0.04113582 0.09392325 0.11618753 0.04907861
 0.02870466 0.03352746 0.02870466 0.0333307  0.04182562 0.1001523
 0.12628138 0.09614356 0.03368425 0.031783   0.15171449 0.04041188
 0.0413282  0.03347232 0.033491   0.04943023 0.11961563 0.12958641
 0.03735114 0.14350548 0.03178301 0.04289216 0.02949753 0.03347548
 0.10000422 0.04193669 0.04952741 0.04443264 0.03293943 0.03346158
 0.04213917 0.13825205 0.03188133 0.03353681 0.03434877 0.03350024
 0.04132818 0.1489857  0.04149675 0.04505938 0.0360924  0.0986624
 0.03178294 0.04241514]
tr_loss:[0.03459108 0.02670632 0.02982125 0.03120664 0.04938526 0.04181086
 0.03019101 0.04519718 0.02981538 0.04938385 0.03016042 0.0301607
 0.13624391 0.04391985 0.04058786 0.15018652 0.04330685 0.03016254
 0.13851438 0.05207068 0.03015748 0.05207162 0.12390816 0.04702216
 0.02949465 0.02671095 0.05809747 0.11688421 0.06463112 0.02670625
 0.10955377 0.03015887 0.03123274 0.0267063  0.03015903 0.13684002
 0.02670633 0.05882313 0.04713693 0.12157933 0.07178341 0.0900583
 0.02981279 0.04802912 0.0305766  0.02921175 0.04399272 0.1350374
 0.02928844 0.03111634]
tr_loss:[0.03601918 0.02635417 0.03692712 0.04806147 0.0493529  0.04197408
 0.05937652 0.04423748 0.04828315 0.04234677 0.0888952  0.03041661
 0.120679   0.0481983  0.1318935  0.11223985 0.0303643  0.04554002
 0.12063426 0.08749837 0.10373683 0.1303544  0.12564279 0.02473447
 0.04399689 0.05327653 0.03896537 0.0384104  0.04083504 0.08627168
 0.03041658 0.08138963 0.03041658 0.04304648 0.0263542  0.03447669
 0.12871234 0.03872244 0.04713675 0.10569712 0.03562973 0.0247348
 0.03041657 0.02476216 0.04032927 0.02476297 0.02472698 0.02473433
 0.03360837 0.03041656]
tr_loss:[0.02733432 0.03581904 0.04567863 0.03244492 0.10511974 0.03796587
 0.02730791 0.1170377  0.04484313 0.03836496 0.04053892 0.02732838
 0.0295851  0.02958509 0.04110952 0.1030187  0.03536414 0.0295851
 0.0374827  0.02704969 0.1057183  0.0960391  0.0353641  0.04821829
 0.0392943  0.02958515 0.02732257 0.03935196 0.05114304 0.09955361
 0.09187086 0.07334498 0.03695317 0.11578047 0.03095148 0.04202253
 0.03848174 0.03245259 0.02730082 0.11028316 0.02733528 0.10598904
 0.03771101 0.03172396 0.04201908 0.08129249 0.03942887 0.03458183
 0.03037121 0.04165658]
tr_loss:[0.09109205 0.03900003 0.03039995 0.03944344 0.0378413  0.09550534
 0.03362172 0.03479104 0.0378413  0.09720574 0.03464594 0.04414062
 0.03632047 0.04173773 0.04414064 0.03039129 0.03039153 0.03028106
 0.0400453  0.03827644 0.04392417 0.03753957 0.03039153 0.03039118
 0.04590407 0.08372436 0.04166195 0.04627173 0.07783812 0.03525361
 0.03536426 0.10316348 0.03537186 0.03784129 0.0359134  0.09671402
 0.03520032 0.03784132 0.03596887 0.04400244 0.03039153 0.0303636
 0.03531024 0.04680161 0.0334997  0.08566378 0.03039153 0.03038462
 0.03249601 0.03970754]
tr_loss:[0.02720279 0.03572048 0.04283928 0.03575826 0.0408477  0.03461564
 0.02720283 0.03917872 0.03572556 0.02720282 0.02720282 0.03575174
 0.04713298 0.0549249  0.07705016 0.12247046 0.04319834 0.03574989
 0.02718942 0.0955269  0.04022438 0.03711593 0.09503855 0.04686869
 0.035771   0.04283983 0.04022434 0.03572046 0.03577466 0.03575687
 0.08314468 0.08657752 0.04619319 0.04659377 0.03472526 0.09523625
 0.0767379  0.02720271 0.03814552 0.0452061  0.04283927 0.10051847
 0.08997796 0.03575746 0.03712106 0.03710013 0.09378962 0.0311208
 0.02718113 0.04319803]
tr_loss:[0.02349751 0.02752363 0.03932842 0.08381708 0.08192962 0.08382443
 0.02749955 0.02755034 0.04468252 0.02935728 0.07661946 0.02935841
 0.08533986 0.03998491 0.04016046 0.02750254 0.04219802 0.11909201
 0.03906233 0.09442018 0.02748878 0.03424909 0.04892753 0.03494245
 0.0234975  0.02748361 0.02757406 0.03492458 0.03921739 0.08566248
 0.02753188 0.03541936 0.02749367 0.08555916 0.03424908 0.02349751
 0.02763056 0.11296566 0.04239613 0.0342123  0.0929497  0.09999649
 0.03515489 0.02749609 0.09862945 0.11089458 0.0915945  0.02750807
 0.02935841 0.10393884]
tr_loss:[0.08234822 0.0351669  0.0848452  0.02335622 0.04433958 0.10050182
 0.02443696 0.04285281 0.0988723  0.0233562  0.02802554 0.02443697
 0.0204523  0.03788169 0.02335263 0.02443697 0.0369936  0.04151648
 0.03464177 0.03292511 0.0233562  0.02443697 0.0365638  0.10431187
 0.02042948 0.04291329 0.02386262 0.0449194  0.07437378 0.03711062
 0.0733334  0.03927235 0.042095   0.04859357 0.02666672 0.08372651
 0.02666691 0.0420296  0.02049767 0.03464179 0.02335617 0.07700117
 0.03993212 0.03180378 0.04165511 0.08331947 0.04055726 0.02666673
 0.05063295 0.08971544]
tr_loss:[0.02458298 0.02630668 0.02458458 0.02173811 0.0830496  0.03450244
 0.033448   0.02172826 0.03000524 0.01393649 0.02173783 0.07529029
 0.01388944 0.01392855 0.01395021 0.02715026 0.02173097 0.08777929
 0.02458295 0.01391847 0.06592491 0.04228623 0.07371594 0.01392811
 0.01392705 0.07914702 0.08577113 0.02536747 0.02106792 0.03716648
 0.03297289 0.01395861 0.02173814 0.02173816 0.03711228 0.01418146
 0.02715475 0.0285637  0.01386257 0.02106792 0.01392938 0.03716648
 0.03770815 0.0138743  0.03652745 0.02325989 0.02940342 0.02173812
 0.02844465 0.02863756]
tr_loss:[0.03347075 0.02707966 0.01221648 0.02407524 0.02747962 0.02375896
 0.01222329 0.10131949 0.01248968 0.07296798 0.03243991 0.0299811
 0.03044195 0.01230891 0.03403709 0.06292459 0.01222921 0.02308296
 0.02986247 0.07634784 0.02376767 0.02618669 0.0302182  0.02999844
 0.03504562 0.022305   0.0122476  0.02752721 0.07516756 0.07214527
 0.02375829 0.03449744 0.02375831 0.08420436 0.0354368  0.02198296
 0.02198298 0.02198296 0.02556202 0.07868574 0.03166177 0.0717399
 0.0307672  0.01220523 0.03534465 0.02518087 0.02556201 0.02230508
 0.01437797 0.02923048]
tr_loss:[0.01415846 0.02447795 0.0282562  0.0360401  0.03655925 0.02265195
 0.02644658 0.02480249 0.01370193 0.01371683 0.08003706 0.03735576
 0.02491913 0.05372017 0.01371141 0.02915091 0.02938972 0.01370344
 0.02173699 0.02478387 0.02176024 0.03454351 0.0226524  0.06780044
 0.03571802 0.02265238 0.0304986  0.07549049 0.03468196 0.02348078
 0.08062896 0.02688038 0.07537787 0.03227969 0.0137134  0.02265238
 0.02991983 0.03796945 0.03412949 0.02550962 0.03799781 0.03120724
 0.01372822 0.01379292 0.07149965 0.02965848 0.03716379 0.02265238
 0.02190822 0.07742208]
tr_loss:[0.03632615 0.01938218 0.0237913  0.02098065 0.02098068 0.02955562
 0.03632639 0.02098064 0.0542642  0.10157759 0.03573166 0.01938218
 0.02601751 0.05559428 0.01937423 0.04361825 0.02098066 0.08815292
 0.01938218 0.02379129 0.02938915 0.03515561 0.03573404 0.0228079
 0.03146433 0.02214755 0.10208485 0.03123181 0.03690677 0.08401351
 0.0835384  0.0289948  0.02003077 0.03573241 0.03576795 0.01297336
 0.02494631 0.03626297 0.02887037 0.08556611 0.02634116 0.02794309
 0.03745838 0.02394754 0.07179715 0.01285993 0.01895111 0.02080224
 0.02472913 0.03666035]
tr_loss:[0.08932959 0.0298695  0.01299619 0.04493896 0.0295753  0.06306526
 0.08787289 0.07795049 0.0295753  0.0231579  0.01291453 0.01306444
 0.03717982 0.02257359 0.03717982 0.02648855 0.07314192 0.09474805
 0.08297956 0.02257361 0.06879147 0.02027088 0.02344962 0.0242363
 0.0761021  0.02631124 0.07111135 0.03611607 0.04094606 0.01297269
 0.0242363  0.01308065 0.01285066 0.06488625 0.01654394 0.02257364
 0.08261355 0.01654392 0.05432854 0.03533997 0.03717967 0.03537763
 0.01282435 0.04654199 0.02968183 0.01305635 0.02423563 0.08654898
 0.01654388 0.03821169]
tr_loss:[0.01487795 0.01487808 0.03644411 0.02807952 0.02583405 0.02447522
 0.01487811 0.03100791 0.03516215 0.02904226 0.02904798 0.02621117
 0.01487811 0.02235836 0.01346234 0.0351697  0.07261722 0.03106925
 0.03209647 0.0148781  0.02647326 0.03295369 0.033612   0.02447521
 0.03220174 0.07070474 0.07599525 0.07575069 0.01485199 0.02897325
 0.01301521 0.01460412 0.02737151 0.01487807 0.02904803 0.12133761
 0.03327172 0.03327706 0.02900348 0.03516965 0.01337301 0.04938744
 0.02447517 0.01818417 0.03050003 0.01487751 0.01598506 0.03681181
 0.03476236 0.04559567]
tr_loss:[0.03223778 0.01381837 0.07026176 0.03578746 0.02167047 0.01310006
 0.03015803 0.02260131 0.02680163 0.03526012 0.0350062  0.02697634
 0.02167042 0.02274167 0.03223776 0.03280017 0.02344823 0.01367351
 0.01577582 0.0159713  0.03765868 0.04733745 0.04771613 0.0159713
 0.02747306 0.08360657 0.01307553 0.0827672  0.01322765 0.03223777
 0.06012053 0.06100244 0.02167066 0.01310007 0.02736093 0.04702742
 0.05588384 0.02817982 0.01597127 0.04938798 0.02187012 0.01366197
 0.06576512 0.03923606 0.06723233 0.02778028 0.03520525 0.06775202
 0.06608099 0.0327174 ]
tr_loss:[0.02101476 0.03981151 0.02717665 0.0211353  0.0560815  0.0207402
 0.0125029  0.01594314 0.02268099 0.02885348 0.02575144 0.01594315
 0.06886522 0.02496488 0.02648795 0.08170299 0.02905467 0.06133865
 0.0238421  0.02421533 0.02598273 0.02622216 0.01335118 0.0117216
 0.01314845 0.02114687 0.02509033 0.01169294 0.01889093 0.03359852
 0.0389884  0.01320061 0.02704644 0.01313258 0.02306765 0.02858773
 0.06228324 0.01313655 0.03916807 0.02601084 0.02169587 0.06135644
 0.08045725 0.03129172 0.02074021 0.03070709 0.02094459 0.02798671
 0.01161742 0.0216071 ]
tr_loss:[0.01958715 0.01156582 0.01156774 0.02927433 0.03213798 0.01157398
 0.01117236 0.01982818 0.01147973 0.0715557  0.02872107 0.02463437
 0.04538688 0.02420044 0.06983595 0.04556235 0.01650622 0.01943094
 0.0203462  0.08320047 0.02838157 0.0628483  0.01178767 0.02148627
 0.02347098 0.02682908 0.02604212 0.01982819 0.01650621 0.02885251
 0.01117281 0.01650623 0.02333432 0.02553948 0.01117282 0.06792177
 0.01111609 0.01650622 0.02367838 0.02680492 0.0184754  0.02331226
 0.02068093 0.02383392 0.08214907 0.05630279 0.02373366 0.03218462
 0.01131723 0.07395039]
tr_loss:[0.01161574 0.01912492 0.06906784 0.01090075 0.02684371 0.02464922
 0.01091856 0.01920839 0.01937229 0.09891549 0.02413084 0.07312644
 0.0109177  0.05505259 0.02571929 0.02014868 0.02046078 0.02684372
 0.01161808 0.01090114 0.02295771 0.0539115  0.08286617 0.02307101
 0.01161803 0.02463325 0.03293406 0.05882815 0.01664094 0.01090322
 0.05437261 0.01090676 0.0191249  0.01183419 0.0109005  0.01161808
 0.01688357 0.0754389  0.01090359 0.05298681 0.05884339 0.0773618
 0.0268437  0.02299355 0.02438202 0.01161809 0.02769841 0.01161808
 0.05491905 0.02059445]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1400 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1401, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1401 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1402, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1402 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1403, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1403 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1404, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1404 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1405, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1405 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1406, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1406 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1407, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1407 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1408, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1408 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1409, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1409 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1410, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1410 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1411, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1411 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1412, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1412 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1413, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1413 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1414, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1414 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1415, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1415 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1416, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1416 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1417, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1417 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1418, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1418 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1419, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1419 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1420, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1420 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1421, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1421 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1422, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1422 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1423, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1423 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1424, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1424 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1425, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1425 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1426, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1426 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1427, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1427 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1428, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1428 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1429, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1429 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1430, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1430 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1431, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1431 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1432, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1432 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1433, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1433 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1434, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1434 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1435, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1435 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1436, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1436 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1437, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1437 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1438, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1438 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1439, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1439 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1440, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1440 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1441, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1441 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1442, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1442 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1443, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1443 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1444, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1444 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1445, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1445 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1446, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1446 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1447, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1447 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1448, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1448 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1449, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1449 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1450, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1450 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1451, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1451 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1452, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1452 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1453, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1453 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1454, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1454 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1455, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1455 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1456, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1456 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1457, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1457 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1458, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1458 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1459, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1459 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1460, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1460 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1461, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1461 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1462, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1462 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1463, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1463 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1464, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1464 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1465, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1465 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1466, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1466 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1467, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1467 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1468, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1468 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1469, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1469 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1470, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1470 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1471, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1471 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1472, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1472 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1473, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1473 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1474, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1474 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1475, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1475 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1476, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1476 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1477, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1477 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1478, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1478 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1479, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1479 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1480, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1480 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1481, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1481 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1482, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1482 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1483, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1483 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1484, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1484 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1485, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1485 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1486, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1486 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1487, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1487 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1488, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1488 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1489, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1489 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1490, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1490 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1491, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1491 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1492, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1492 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1493, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1493 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1494, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1494 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1495, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1495 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1496, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1496 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1497, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1497 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1498, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1498 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1499, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1499 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1500, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-1400
text_input.shape
(1500, 14400)
learning_input_tmp.shape
(1500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1500, 80)
learning_output.shape
(750, 80)
Model: "sequential_31"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_31 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0299759  1.0453556  1.0778478  0.94269925 0.8407569  1.0299759
 1.0444138  1.0299759  1.11936    0.9171341  1.0778984  0.9212634
 1.0451419  1.0594769  1.0802805  0.9175531  1.0960064  0.9389149
 0.9607158  1.0540174  1.077928   0.91599405 0.93819344 0.84262055
 1.1052163  1.0778478  1.1052163  0.97671014 0.9401043  1.0299914
 1.0448586  1.0778503  1.0778478  0.9015834  1.0299761  0.9217928
 0.9200014  0.9531557  1.0960065  0.97585315 1.0299791  1.0299759
 0.93054664 1.0299885  0.93024266 1.0299761  0.950082   0.949536
 1.1042985  1.0778477 ]
tr_loss:[0.76495737 0.61485255 0.68529284 0.686357   0.6863569  0.7028235
 0.60674983 0.64835745 0.6817845  0.68631697 0.63675946 0.69316494
 0.76556766 0.71779686 0.643397   0.6064147  0.6698291  0.68630356
 0.74738216 0.7548034  0.686357   0.73146766 0.6659127  0.8064561
 0.5859281  0.65213567 0.6863654  0.7655677  0.7062483  0.7352637
 0.7655679  0.7038998  0.6863732  0.7511688  0.6534407  0.7466481
 0.57582456 0.6878514  0.6863156  0.7422716  0.74976194 0.74985605
 0.71214426 0.6521371  0.6487301  0.76535016 0.692568   0.69086325
 0.6656411  0.75129825]
tr_loss:[0.3623774  0.38343704 0.3623363  0.37834093 0.38343713 0.38511783
 0.36168474 0.36632237 0.33552018 0.3346851  0.33238673 0.3335991
 0.38343772 0.36233643 0.38506478 0.3834372  0.32727933 0.34621838
 0.41259775 0.3850363  0.38499886 0.33803517 0.35344464 0.44772425
 0.3632807  0.34979597 0.38343704 0.35340798 0.41259766 0.39305934
 0.38507953 0.38495597 0.35306388 0.33958623 0.37209502 0.38343707
 0.38693625 0.3546949  0.3537399  0.3934065  0.38511193 0.3623363
 0.35842338 0.38573512 0.3437263  0.3384781  0.38343695 0.37547666
 0.44772434 0.38504893]
tr_loss:[0.24623151 0.2616039  0.26132464 0.26171127 0.2567125  0.24532032
 0.29648152 0.24483815 0.24845763 0.26953852 0.26178274 0.26848766
 0.24730334 0.28135055 0.24730372 0.26118803 0.23987994 0.29998314
 0.27037033 0.24588537 0.26605    0.25194353 0.2372746  0.236092
 0.23120908 0.26662526 0.24352784 0.26173785 0.26844758 0.2473034
 0.24749859 0.2684204  0.2617355  0.25323576 0.26189756 0.2308679
 0.25650758 0.24278376 0.23984845 0.26105058 0.23596267 0.26847273
 0.26848763 0.24730381 0.23540115 0.261663   0.24857178 0.2615381
 0.26200777 0.26208568]
tr_loss:[0.20032005 0.167821   0.1601936  0.16819867 0.17658325 0.20789607
 0.1664767  0.15653355 0.16291778 0.14682743 0.15535614 0.1542939
 0.15692663 0.19055194 0.1451867  0.15411597 0.17658325 0.19354065
 0.15535624 0.1489974  0.16749358 0.1765832  0.17658333 0.15211749
 0.20306209 0.16612154 0.15587418 0.1507944  0.15230791 0.15470928
 0.16823283 0.15345988 0.15260932 0.2078959  0.20031996 0.16727026
 0.2010332  0.20789604 0.20789602 0.15271488 0.16814095 0.15271491
 0.14420095 0.20032004 0.15271485 0.15197143 0.16820061 0.1765832
 0.21250296 0.17658317]
tr_loss:[0.09730999 0.09209351 0.13413188 0.10585711 0.12308311 0.13691942
 0.14394173 0.12308311 0.11174107 0.13604395 0.12429474 0.11757024
 0.13140032 0.12308295 0.12163395 0.15354843 0.10866394 0.16617617
 0.10670452 0.16921762 0.11601327 0.10992552 0.12315734 0.123083
 0.10585722 0.11925016 0.12781802 0.1272818  0.10585723 0.09734156
 0.1369195  0.12148839 0.12256511 0.13604395 0.12308301 0.14054973
 0.09731174 0.11746371 0.09718442 0.10627133 0.10585727 0.11109139
 0.13691935 0.12308507 0.1058571  0.10585745 0.104133   0.12308302
 0.13660657 0.13030386]
tr_loss:[0.09530184 0.08275381 0.11560065 0.07445636 0.06965642 0.09530108
 0.08613159 0.08365517 0.08378907 0.07840136 0.08378883 0.09001029
 0.09507038 0.09747583 0.06875129 0.09895043 0.06872864 0.08332828
 0.06871808 0.06871782 0.10110635 0.10175749 0.07445647 0.06871793
 0.08365504 0.09001027 0.09530113 0.09118263 0.14810057 0.08378886
 0.08378897 0.07460141 0.08058649 0.0911826  0.06874797 0.07445635
 0.0744568  0.08055687 0.09895051 0.09009882 0.0745491  0.09530113
 0.08365514 0.08754124 0.07445638 0.074495   0.10615672 0.09530113
 0.09630091 0.08028669]
tr_loss:[0.13412645 0.04517905 0.05514895 0.05558225 0.06034671 0.06005213
 0.05278038 0.05008888 0.07673766 0.04981246 0.06082811 0.0547919
 0.04517902 0.06839667 0.04517906 0.04999593 0.06614234 0.15661402
 0.07539357 0.06034706 0.05878651 0.0500079  0.06517522 0.06095402
 0.04517905 0.0417606  0.04176059 0.0674814  0.0627417  0.04176036
 0.05181294 0.04517904 0.06508341 0.06035328 0.0631456  0.05026758
 0.05280987 0.06505547 0.0484689  0.13491555 0.13945447 0.06251229
 0.06314633 0.0694281  0.1287005  0.04515005 0.0736932  0.04176059
 0.04930045 0.04999962]
tr_loss:[0.07480551 0.05486776 0.04759321 0.0680858  0.08341734 0.06059884
 0.04759335 0.07480554 0.05550529 0.08128134 0.05473937 0.05474171
 0.04760463 0.05084094 0.04759318 0.0520883  0.04760625 0.06876095
 0.05468303 0.05482178 0.08925601 0.06676062 0.05473693 0.0748055
 0.07480548 0.0475932  0.07985069 0.04777478 0.05956364 0.14637129
 0.089256   0.05376683 0.06861772 0.05477956 0.07480517 0.05853884
 0.04759322 0.05209084 0.0531618  0.05915177 0.0541914  0.05199588
 0.04759323 0.07850349 0.05209767 0.05468035 0.15886065 0.077109
 0.0520977  0.06889874]
tr_loss:[0.07671893 0.08256884 0.06278373 0.15964746 0.06762459 0.07671893
 0.0558961  0.07671762 0.05583257 0.14225635 0.07170038 0.05153893
 0.05097814 0.06746856 0.04407013 0.07671896 0.06505948 0.07513887
 0.06736039 0.14577581 0.05754571 0.0687031  0.15524714 0.04089927
 0.04089643 0.15298775 0.06431551 0.08550994 0.05583488 0.0791973
 0.04089926 0.07491259 0.04089916 0.04089442 0.04089916 0.07671901
 0.05168916 0.05582526 0.06824835 0.05807394 0.05269309 0.04089932
 0.053971   0.03857385 0.07513873 0.07878002 0.04407009 0.05168915
 0.07671894 0.07573509]
tr_loss:[0.06595706 0.04762932 0.04718234 0.04746715 0.06185072 0.04728783
 0.04732481 0.03716936 0.07275505 0.04719628 0.05232539 0.03625427
 0.04737617 0.16138642 0.15819037 0.06481527 0.06098652 0.05624162
 0.04738801 0.0362686  0.04469115 0.05170105 0.04584255 0.15487057
 0.06116283 0.06497779 0.03716929 0.07914157 0.0659328  0.0458425
 0.04376143 0.04997095 0.06665662 0.04735547 0.05776536 0.04762153
 0.15095091 0.05598946 0.0458123  0.05855284 0.05531812 0.13613935
 0.06437536 0.04584251 0.0659297  0.07067019 0.06481545 0.04584249
 0.06592976 0.05714571]
tr_loss:[0.03878003 0.03619527 0.03858018 0.05912684 0.03044545 0.03845094
 0.03032831 0.03044548 0.05466817 0.0385573  0.04001433 0.03845399
 0.02910163 0.03044548 0.04858691 0.06328113 0.0574321  0.03847322
 0.0385779  0.03867101 0.04309266 0.14061043 0.06646495 0.04309273
 0.05106143 0.03044547 0.04382535 0.02645155 0.02645267 0.06248544
 0.03612194 0.03612183 0.03864905 0.03612193 0.04309274 0.05099837
 0.04971383 0.05999454 0.14499158 0.03612193 0.04309271 0.06285791
 0.04772481 0.0304455  0.03612194 0.06242325 0.1595631  0.0419744
 0.05923099 0.03570807]
tr_loss:[0.05142362 0.019773   0.01979029 0.04602531 0.14947826 0.02380285
 0.02407542 0.14602122 0.02476584 0.04682013 0.06640122 0.02407974
 0.03263152 0.06114784 0.03249887 0.02408154 0.05250919 0.05455997
 0.02680466 0.03169874 0.02408114 0.03264248 0.02405232 0.02407926
 0.06022225 0.02470718 0.06241228 0.0316987  0.05848866 0.01977297
 0.05075524 0.03798143 0.03169871 0.02332499 0.03263463 0.03169874
 0.04473116 0.02680467 0.0425064  0.1495022  0.02320509 0.03263422
 0.03169876 0.03262803 0.01977299 0.06727402 0.0479254  0.04761971
 0.02476585 0.04510232]
tr_loss:[0.04979666 0.03810295 0.0317458  0.03174524 0.02522801 0.03016561
 0.05064303 0.05869304 0.03174517 0.03169715 0.05702689 0.02376384
 0.05876903 0.0382702  0.05344132 0.05447849 0.05667493 0.05340081
 0.05659133 0.05209077 0.05899435 0.03962448 0.0534413  0.03095841
 0.03174583 0.05076579 0.03811256 0.03174581 0.06641093 0.03808327
 0.0396286  0.02376384 0.03963081 0.02706566 0.02376382 0.05356451
 0.03963082 0.04796584 0.15631555 0.02706568 0.05557285 0.02376383
 0.06726774 0.03804968 0.0317458  0.03174581 0.05391357 0.0664109
 0.03115263 0.04546989]
tr_loss:[0.08697131 0.05442164 0.03683048 0.02539489 0.06319959 0.05093651
 0.05856452 0.05767185 0.04739615 0.05198357 0.03553871 0.06358125
 0.03680488 0.03555153 0.02539488 0.05442166 0.04890709 0.0368002
 0.05775179 0.03555149 0.06071074 0.03221428 0.07048627 0.04624593
 0.02512171 0.03221431 0.03676831 0.05996847 0.03555152 0.02574442
 0.0251244  0.05700229 0.05505699 0.02512174 0.05502467 0.03679745
 0.03221425 0.06071072 0.15026213 0.02588663 0.0253949  0.03957792
 0.03221428 0.0552537  0.03680206 0.05964728 0.0367966  0.0479321
 0.05029457 0.04675239]
tr_loss:[0.05506719 0.03160291 0.02510608 0.02510635 0.03161012 0.05238851
 0.02786835 0.03331895 0.03161033 0.14566645 0.05882906 0.03332619
 0.05569207 0.06376388 0.05178091 0.03348264 0.14497426 0.0590743
 0.14821866 0.0517809  0.07313027 0.04749278 0.05264333 0.04042419
 0.0610723  0.02277919 0.159051   0.15952638 0.03161036 0.07345669
 0.03161033 0.05178093 0.03161017 0.05264343 0.02786838 0.03161033
 0.16554317 0.04793757 0.03352883 0.06186039 0.03334124 0.04303993
 0.03159617 0.03161027 0.07313031 0.0333401  0.02951974 0.06044573
 0.02786839 0.0526434 ]
tr_loss:[0.06955067 0.02959228 0.05263532 0.03536274 0.05634801 0.0328648
 0.14148885 0.03545753 0.03853343 0.05533617 0.03286511 0.05963288
 0.03552418 0.0750775  0.14527602 0.04837823 0.05150337 0.03266106
 0.03260688 0.07830553 0.03212108 0.05570403 0.03852722 0.03260715
 0.05570398 0.03516714 0.04536877 0.03853343 0.06433799 0.03286508
 0.06021793 0.0385253  0.03853344 0.05520741 0.04896992 0.02959223
 0.04839269 0.15995106 0.03286503 0.06194224 0.03573373 0.05104057
 0.03830068 0.05291504 0.03523378 0.03286512 0.06033527 0.03286503
 0.05891412 0.04710354]
tr_loss:[0.03317931 0.030518   0.02413361 0.04596329 0.05446808 0.0305398
 0.03078989 0.14005004 0.06075405 0.03033767 0.05741784 0.02411094
 0.05491921 0.03306901 0.05085615 0.030841   0.02908286 0.02323906
 0.0331941  0.02908284 0.04321598 0.05843949 0.04262207 0.03057132
 0.02309866 0.04580899 0.04681944 0.03319693 0.03574586 0.02908292
 0.05880241 0.03044007 0.03330086 0.14348581 0.1367226  0.06791607
 0.0481622  0.02413318 0.03737334 0.03988796 0.02413356 0.05867432
 0.06388253 0.03019238 0.0241336  0.03217766 0.05867361 0.02309864
 0.03319697 0.03319696]
tr_loss:[0.05208915 0.16233894 0.04027593 0.0209604  0.03154879 0.02096038
 0.0451503  0.03652124 0.03154906 0.04842927 0.03154906 0.03102561
 0.15111691 0.0167749  0.03154903 0.04212712 0.05057808 0.05221996
 0.04339232 0.04070897 0.03135088 0.03154906 0.04864858 0.03050227
 0.03125918 0.05057805 0.13600965 0.03154904 0.02096043 0.02748783
 0.03135088 0.04155261 0.02751434 0.03135089 0.02096038 0.02096042
 0.03091841 0.0181125  0.01677488 0.04211027 0.02096031 0.02096041
 0.03135092 0.03015909 0.0310761  0.0209604  0.03154907 0.02096041
 0.0513391  0.03101258]
tr_loss:[0.02110948 0.02722944 0.03451092 0.03453765 0.0564137  0.05427875
 0.0492984  0.03192681 0.03731735 0.034515   0.03192681 0.05809265
 0.02110921 0.04425199 0.01937358 0.03264556 0.0406738  0.03115083
 0.03450396 0.0204956  0.03718548 0.02143765 0.05889799 0.04224234
 0.14702328 0.03129743 0.03101838 0.034534   0.06754152 0.04401926
 0.02101061 0.1478354  0.03452672 0.04683844 0.04047719 0.03451361
 0.03731734 0.02722942 0.03129745 0.15032566 0.15299988 0.03492875
 0.03129744 0.03129745 0.03126055 0.16433835 0.03512539 0.05013995
 0.0401067  0.0563663 ]
tr_loss:[0.0275063  0.02401164 0.03515403 0.03617636 0.03101629 0.05358368
 0.05267372 0.14359097 0.02738644 0.03135728 0.0218219  0.02166214
 0.14800681 0.030947   0.0559639  0.05321418 0.03511612 0.02186383
 0.03136125 0.06788428 0.10183114 0.02154301 0.05073507 0.04586407
 0.04891885 0.04112838 0.05358364 0.0211668  0.05386984 0.04474012
 0.0419133  0.05850248 0.12617137 0.05357391 0.03135647 0.14196406
 0.04211645 0.03512093 0.03129547 0.05765907 0.03094697 0.06601826
 0.03512605 0.02186824 0.03133903 0.02186547 0.04226135 0.02155541
 0.0402374  0.04524168]
tr_loss:[0.0280444  0.03134727 0.02658958 0.02035951 0.03128772 0.03119152
 0.02554112 0.03214881 0.02129761 0.13034141 0.02070192 0.04339777
 0.04545003 0.02069592 0.03135811 0.03119143 0.04694501 0.06940554
 0.03119152 0.03119151 0.04950388 0.05184068 0.02068365 0.03132885
 0.02804432 0.05254649 0.04480702 0.04987618 0.13594581 0.04626625
 0.04233936 0.03129313 0.05630922 0.02135762 0.04031553 0.03107963
 0.02658953 0.03316173 0.02804439 0.04172547 0.04954623 0.04975949
 0.03134542 0.03119151 0.03105665 0.03989608 0.02658959 0.03987158
 0.05551828 0.02135761]
tr_loss:[0.03872874 0.02378606 0.0231796  0.04182744 0.02932176 0.12937985
 0.02932179 0.12895529 0.04098709 0.02634281 0.14215045 0.0409871
 0.03278346 0.01972339 0.02932168 0.01405056 0.03911239 0.0196824
 0.01972343 0.05260668 0.0409918  0.02444654 0.04318536 0.02634446
 0.05509503 0.01972343 0.04260308 0.0257928  0.04476335 0.04375771
 0.0361481  0.02636279 0.03650936 0.04156249 0.02633004 0.02635523
 0.02633197 0.02636391 0.02378609 0.02932178 0.05724214 0.01446294
 0.05400472 0.01972341 0.0523945  0.0263792  0.02634742 0.01436775
 0.01972221 0.04051559]
tr_loss:[0.03894877 0.02869507 0.03138383 0.0239091  0.02051355 0.05491114
 0.02038375 0.04212602 0.02390734 0.0226697  0.04066594 0.02869456
 0.02390739 0.02869433 0.03225453 0.02051352 0.04250822 0.04449695
 0.04212404 0.05054215 0.02869505 0.12357535 0.023864   0.03766518
 0.01242019 0.04073442 0.02392464 0.02390927 0.03764606 0.04436945
 0.02044204 0.04300475 0.0431488  0.05949672 0.0239074  0.04244623
 0.01242016 0.03708496 0.05247245 0.01894952 0.04298626 0.02869074
 0.12358999 0.02390777 0.04067939 0.02502408 0.02391076 0.12470485
 0.04186689 0.04305001]
tr_loss:[0.11698449 0.02177011 0.01972927 0.1244724  0.04825861 0.11716431
 0.1235489  0.03040192 0.03214572 0.03359412 0.02633231 0.03284737
 0.04429636 0.04231048 0.02470924 0.01375342 0.11286218 0.02470926
 0.12357134 0.04504352 0.04393994 0.03023092 0.01375343 0.0264099
 0.02709678 0.02709668 0.03237402 0.02709676 0.0233649  0.0325625
 0.02470926 0.03459603 0.11537826 0.01375277 0.04502674 0.04153636
 0.04225976 0.03853554 0.04719871 0.02177011 0.02206309 0.04454607
 0.02303139 0.01375342 0.04263824 0.04090989 0.02197278 0.05081498
 0.03744968 0.01972926]
tr_loss:[0.04451029 0.01508768 0.01920573 0.05336765 0.01893739 0.02216113
 0.0396421  0.03183582 0.06497692 0.01853516 0.01920574 0.01809767
 0.03634099 0.040911   0.0185144  0.01811454 0.11593477 0.02216112
 0.0397219  0.10495462 0.02216152 0.04497369 0.02421814 0.01811503
 0.01846115 0.04377152 0.04779367 0.01876348 0.03367757 0.02421809
 0.11081673 0.01811503 0.01853961 0.01790658 0.02214407 0.01811395
 0.01811501 0.04660366 0.02976309 0.02216112 0.02985806 0.04040027
 0.0182999  0.04123459 0.01811503 0.04124132 0.01725516 0.02701789
 0.0398082  0.01811292]
tr_loss:[0.02266834 0.01743914 0.01744153 0.01929091 0.01659404 0.01674602
 0.02215935 0.02765908 0.04775031 0.03848565 0.01929095 0.04086409
 0.02703011 0.05311217 0.04005166 0.03674323 0.02973332 0.11255505
 0.04078575 0.10453464 0.03634949 0.04390474 0.03307331 0.04054835
 0.03802247 0.01744152 0.01744151 0.04610617 0.02357558 0.02267078
 0.01744151 0.01666768 0.01688819 0.0471146  0.04727324 0.01645384
 0.01743778 0.02267078 0.02267077 0.01672506 0.03526706 0.03737171
 0.0437946  0.10854177 0.01929091 0.02611791 0.02267081 0.02932553
 0.02715073 0.01616484]
tr_loss:[0.01745086 0.01795777 0.0186123  0.01732378 0.04896783 0.01732525
 0.03648994 0.02357127 0.04255524 0.01745105 0.03838488 0.02158703
 0.01860386 0.02668889 0.02357128 0.01779917 0.02236232 0.02418965
 0.02236063 0.01861228 0.02667861 0.02800488 0.02236231 0.01756491
 0.02686916 0.03838446 0.02284053 0.03165662 0.02011797 0.0266783
 0.01749222 0.01861231 0.04026201 0.0363245  0.02236231 0.02011796
 0.0338285  0.01861226 0.01707854 0.0223623  0.0223573  0.10436314
 0.01861102 0.02892977 0.0223622  0.0185856  0.02284048 0.04593838
 0.01747729 0.02687558]
tr_loss:[0.03200782 0.02953542 0.0433379  0.02390518 0.01789519 0.03259322
 0.01727316 0.03390376 0.01735388 0.01786425 0.01944667 0.01735388
 0.03309562 0.02939506 0.04837668 0.03947602 0.02949883 0.01944665
 0.01944667 0.01735325 0.01735386 0.10341863 0.03419175 0.01735389
 0.01781393 0.04477731 0.0292516  0.01735387 0.01800704 0.03122398
 0.10011452 0.02260075 0.04477774 0.02888205 0.02305844 0.02970915
 0.02686604 0.04837668 0.02385155 0.01787559 0.03301028 0.04105552
 0.03944518 0.0173534  0.01944665 0.01794641 0.0334959  0.02964917
 0.02408833 0.01802132]
tr_loss:[0.01916492 0.04476561 0.01622639 0.01916489 0.03226823 0.04687458
 0.02446679 0.04475143 0.02689634 0.04666754 0.01622641 0.0178189
 0.01875921 0.10098439 0.01916492 0.01897729 0.0191649  0.01622641
 0.03067783 0.03019305 0.02682543 0.02670938 0.03687486 0.03970895
 0.04166507 0.01770746 0.10127731 0.03795359 0.01916464 0.03067782
 0.01769287 0.11583593 0.01777954 0.01911918 0.03719067 0.02671186
 0.03698501 0.01916489 0.03186305 0.01789302 0.02671183 0.03724307
 0.01622639 0.01622641 0.09738131 0.03970958 0.03970884 0.03298016
 0.01916491 0.03609413]
text_input.shape
(1500, 14400)
learning_input_tmp.shape
(1500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1500, 80)
learning_output.shape
(750, 80)
Model: "sequential_32"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_32 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.9597128  0.98949206 1.1322601  0.9843601  0.9002384  0.9568521
 1.1135552  1.0214983  1.0311344  1.027735   0.9606711  1.1224318
 1.1211885  1.0332778  1.1659749  0.9856659  0.8402128  1.0131071
 1.1322601  1.0080738  1.0715147  1.1135281  1.114492   1.1659749
 1.1160228  1.0381466  1.0226084  1.1135497  0.99494773 1.0381467
 1.021363   0.9821739  1.1862218  0.9340395  0.9848509  0.9617818
 0.90349656 1.0217769  0.92320776 1.0246073  1.0381469  1.0219796
 1.1862218  1.1135323  0.90302646 1.1997235  0.97283125 1.0214264
 1.1322601  0.9271065 ]
tr_loss:[0.6438363  0.6022223  0.6438366  0.64269304 0.49849692 0.52708614
 0.55577546 0.56658196 0.5450205  0.64383644 0.59568465 0.5345973
 0.59559935 0.5268754  0.5128294  0.6718796  0.49145693 0.5742197
 0.6123325  0.49171782 0.526997   0.5255254  0.6437737  0.59323907
 0.59302247 0.64383656 0.5446214  0.5761121  0.49145707 0.56029934
 0.5949494  0.49518546 0.59491605 0.5108111  0.5847356  0.58024424
 0.50146306 0.5764084  0.5741993  0.59560597 0.54082686 0.5953947
 0.50146306 0.595529   0.6383127  0.7082677  0.7082721  0.50146294
 0.52734447 0.6438365 ]
tr_loss:[0.3577443  0.47774363 0.33192086 0.38970503 0.38976425 0.37348133
 0.37554377 0.39099392 0.38952008 0.36421824 0.3766353  0.37267423
 0.38976005 0.37348178 0.48691806 0.3627806  0.32836923 0.3734813
 0.38973907 0.38985497 0.38924342 0.4777437  0.33051696 0.3769188
 0.37045068 0.37348133 0.37825269 0.34250405 0.48691815 0.45910493
 0.37653685 0.3897102  0.48691806 0.37694615 0.37262067 0.3897423
 0.33051696 0.43196434 0.36219555 0.36222234 0.36044735 0.37350485
 0.4777437  0.3897566  0.39770597 0.37348136 0.37636098 0.47774363
 0.36152202 0.3897087 ]
tr_loss:[0.2865523  0.28655237 0.2946329  0.23651275 0.27715373 0.27602887
 0.30549097 0.2945978  0.2771516  0.29463288 0.30628014 0.29464963
 0.2907354  0.29463464 0.26850587 0.30735728 0.26361912 0.2946329
 0.29364562 0.31720668 0.26449904 0.29311174 0.29463297 0.2771516
 0.23397589 0.34035152 0.28414592 0.27715164 0.3094493  0.28631377
 0.30295557 0.2537759  0.26380482 0.2946337  0.34032366 0.2893952
 0.29079145 0.25653666 0.27715164 0.29077923 0.34032363 0.22142616
 0.29083863 0.29077014 0.31720668 0.30490762 0.25538844 0.29077673
 0.27715164 0.23485947]
tr_loss:[0.16041215 0.15535049 0.25724158 0.17919008 0.27467775 0.17919007
 0.14946316 0.14864025 0.15189886 0.16697755 0.14939831 0.14864017
 0.1361412  0.16041523 0.14728451 0.1486402  0.16699484 0.16699488
 0.24584487 0.16050391 0.14825924 0.160814   0.15277553 0.16036502
 0.1338094  0.13975203 0.14864127 0.15535061 0.14864019 0.15535057
 0.16110018 0.14864044 0.17352423 0.16048136 0.14864035 0.14883764
 0.15535057 0.14354846 0.14866138 0.26522964 0.14864023 0.16580693
 0.14354849 0.13484864 0.16699488 0.2581977  0.14864014 0.17579913
 0.1558772  0.24356547]
tr_loss:[0.07934324 0.2040431  0.09883402 0.07934324 0.10703756 0.0793433
 0.09567635 0.0926318  0.09735741 0.10100289 0.0995803  0.10424985
 0.09533221 0.24400453 0.08269938 0.07934328 0.0793433  0.09290495
 0.09583958 0.19592632 0.100947   0.09883521 0.09448256 0.10538296
 0.09035004 0.09530701 0.10684624 0.10032696 0.09557791 0.11657421
 0.08762477 0.07934333 0.1097105  0.09817781 0.09603532 0.09530704
 0.10014693 0.09911345 0.1954342  0.09822282 0.08269937 0.0998656
 0.1019453  0.09530699 0.11657419 0.07934324 0.0976653  0.0943429
 0.09455076 0.07894294]
tr_loss:[0.06881126 0.10300626 0.11000476 0.03551088 0.20892015 0.19102588
 0.05227735 0.03551061 0.07306352 0.05546841 0.03551015 0.05397189
 0.05224938 0.07704704 0.05961108 0.06064166 0.05533845 0.05547395
 0.07076343 0.05225069 0.03551085 0.07409819 0.09670277 0.0355099
 0.05546956 0.06269549 0.05556129 0.05180896 0.06482415 0.03551071
 0.18026654 0.03551087 0.05224818 0.0515658  0.07989593 0.05551613
 0.07387731 0.03544302 0.05178751 0.05449773 0.03548325 0.03551088
 0.05547095 0.05546878 0.03551085 0.09566909 0.03551046 0.05224815
 0.10137127 0.05449773]
tr_loss:[0.05305674 0.06929419 0.1691637  0.05376508 0.09371223 0.07664832
 0.07500921 0.0325531  0.05119821 0.10639495 0.07454623 0.05757823
 0.05009682 0.09260584 0.05390438 0.06549102 0.05575112 0.05009679
 0.03255313 0.07189284 0.05189364 0.03255313 0.05021494 0.17415306
 0.05829932 0.0325531  0.08197594 0.05433403 0.17182048 0.18009138
 0.08666901 0.063886   0.05451953 0.05305719 0.18174037 0.05376738
 0.05436957 0.05009683 0.06682745 0.06688568 0.03254985 0.0325531
 0.0531258  0.06941491 0.05009685 0.03255315 0.05009715 0.04282615
 0.04881594 0.05377346]
tr_loss:[0.05677239 0.06142443 0.04967732 0.04959829 0.08105892 0.07093181
 0.03787354 0.08373328 0.05668427 0.0379247  0.07531879 0.08199783
 0.04952212 0.08702987 0.07250766 0.07532072 0.04979194 0.05677243
 0.07238737 0.04969321 0.05145307 0.08896993 0.08230046 0.06075197
 0.05059453 0.07719494 0.03787112 0.05144139 0.05144743 0.05145321
 0.05668429 0.03787115 0.05677242 0.03787109 0.05145317 0.08803444
 0.08803429 0.08198669 0.04936769 0.07060508 0.0496555  0.08105725
 0.06986256 0.07226441 0.03790013 0.03787108 0.04911797 0.07160409
 0.16047743 0.08803447]
tr_loss:[0.078593   0.06826329 0.04070821 0.06376813 0.0500813  0.04973315
 0.07859297 0.07731572 0.04796397 0.16444    0.04957865 0.07087342
 0.05254012 0.06692988 0.04973318 0.05192363 0.04994237 0.05055378
 0.07795197 0.06519205 0.05255014 0.04319075 0.06884035 0.04957863
 0.18251684 0.06857069 0.04973314 0.06292343 0.08477451 0.04659277
 0.04199347 0.15897503 0.078593   0.08129507 0.0497332  0.05589298
 0.07397307 0.06532007 0.05778356 0.04659273 0.04973312 0.04972128
 0.06618203 0.06818465 0.04973314 0.07484309 0.047964   0.07087342
 0.07789357 0.09148946]
tr_loss:[0.06290773 0.05199901 0.06500106 0.16260532 0.04550152 0.05159422
 0.05350016 0.0574244  0.05199898 0.05592746 0.08369925 0.05293028
 0.05177804 0.08852368 0.05216441 0.06290774 0.05293012 0.06343354
 0.05196393 0.06290774 0.15640604 0.05766615 0.05292182 0.07871388
 0.05293033 0.051999   0.06790958 0.06824743 0.05199898 0.05684765
 0.05401115 0.06062946 0.05293032 0.06118542 0.05998049 0.06317756
 0.05284097 0.16256936 0.06095343 0.15852003 0.05192635 0.16766755
 0.07040434 0.0547611  0.05061203 0.06596066 0.09161764 0.0449905
 0.05199899 0.05196512]
tr_loss:[0.07028538 0.03744861 0.06237895 0.04340751 0.05489289 0.05495321
 0.06178655 0.05931221 0.03766256 0.04418103 0.06167787 0.06075789
 0.06143005 0.04340751 0.05693292 0.05301329 0.03769434 0.0583782
 0.0529783  0.10504291 0.04864243 0.05966181 0.04664171 0.07345942
 0.07619154 0.16408129 0.05449005 0.04664166 0.04340752 0.03754707
 0.04187547 0.0433871  0.04418096 0.04816432 0.03899285 0.04099068
 0.04664169 0.03781558 0.05647118 0.0434075  0.04846358 0.06465694
 0.06237895 0.04418099 0.05953316 0.06238534 0.03766418 0.04340755
 0.04813506 0.03766718]
tr_loss:[0.05545158 0.05725751 0.05226938 0.02891301 0.04901503 0.05399094
 0.03657334 0.02892907 0.04815372 0.04054283 0.05524751 0.03800491
 0.05726466 0.02904744 0.04062761 0.06393429 0.04770278 0.02902124
 0.05929277 0.05151729 0.05494735 0.03484821 0.0555526  0.03657328
 0.05496733 0.02892806 0.03657378 0.05524749 0.03741673 0.04747622
 0.03864457 0.03657331 0.05460354 0.05184579 0.06790201 0.02897722
 0.0374167  0.0662779  0.03484823 0.04502212 0.15657286 0.062019
 0.05040606 0.05479342 0.055558   0.0348482  0.05399095 0.15682629
 0.03490962 0.03847539]
tr_loss:[0.04534712 0.04672185 0.03832874 0.03532529 0.15226783 0.03516673
 0.04519258 0.03516674 0.02459446 0.03141893 0.03529323 0.03516672
 0.03529321 0.03529412 0.03141894 0.0314239  0.05275357 0.04673566
 0.03516671 0.04664239 0.04136433 0.04662741 0.14145553 0.02505059
 0.05596873 0.05941864 0.02679323 0.02458345 0.03516672 0.05516041
 0.04647553 0.03504042 0.02679321 0.03516672 0.03516658 0.06419029
 0.03529321 0.02461573 0.03513308 0.02454686 0.02453813 0.02677318
 0.05763422 0.03141893 0.10555007 0.0267932  0.05362492 0.03516347
 0.03516146 0.06080998]
tr_loss:[0.03258743 0.02201286 0.04816337 0.04566425 0.0553172  0.0345359
 0.02045381 0.02527648 0.04350456 0.1407783  0.04872556 0.03914754
 0.02215094 0.03381286 0.03620611 0.02045232 0.03021353 0.03258743
 0.05288833 0.03258745 0.05237211 0.05567707 0.02528096 0.0470611
 0.02212105 0.02202233 0.0325874  0.02180115 0.13875106 0.03258742
 0.02045443 0.05583902 0.14218977 0.03464412 0.0504723  0.04873211
 0.05036233 0.02045441 0.02044587 0.03258745 0.02202184 0.0345359
 0.04435792 0.03620612 0.05057152 0.02528096 0.04561295 0.04715801
 0.02201327 0.04869217]
tr_loss:[0.02233793 0.03129398 0.0364157  0.03129396 0.07310947 0.04646993
 0.02232601 0.13607642 0.02035405 0.02258915 0.03597235 0.04968864
 0.02249575 0.12242393 0.03130553 0.04465199 0.12964325 0.03129397
 0.05100363 0.031294   0.02035406 0.04646954 0.03645373 0.04421002
 0.04465192 0.04418907 0.02183596 0.04465195 0.03129398 0.06336197
 0.02237182 0.05716755 0.04093197 0.04802272 0.05061442 0.04649802
 0.04253712 0.02035408 0.03129396 0.0533036  0.02035405 0.03738511
 0.04557103 0.03129395 0.04959745 0.03641575 0.03641567 0.02035402
 0.01988894 0.02035407]
tr_loss:[0.04366426 0.03973012 0.02464425 0.02803233 0.0479388  0.03100275
 0.03100115 0.03409243 0.02126095 0.04163044 0.03855529 0.02660542
 0.0410881  0.03855527 0.03749821 0.02126097 0.03855526 0.03855531
 0.02464429 0.03100076 0.04735856 0.03100112 0.0479187  0.03749821
 0.04137737 0.02464425 0.05703226 0.02636292 0.03483654 0.02126094
 0.13425945 0.0421306  0.02631279 0.03651812 0.04855801 0.03598354
 0.03388577 0.03855531 0.02505164 0.03962678 0.0413772  0.03100079
 0.02620009 0.02464428 0.04214673 0.02038776 0.0264935  0.04023198
 0.02634843 0.02126095]
tr_loss:[0.03034919 0.01965083 0.03034359 0.02700752 0.05109448 0.05487059
 0.03041926 0.04689845 0.0405153  0.04241591 0.03312245 0.03049412
 0.03331876 0.05728726 0.02560261 0.01964991 0.14709094 0.04689845
 0.03876131 0.06076381 0.043044   0.03312245 0.02778452 0.03045535
 0.03921639 0.13834925 0.0368103  0.0286556  0.05487037 0.03030808
 0.01965084 0.02865426 0.0258341  0.05019095 0.04831427 0.02870032
 0.02560259 0.04768249 0.04219586 0.0331224  0.05661654 0.03043158
 0.05350505 0.03416602 0.03488474 0.02559891 0.02986067 0.03921636
 0.1383886  0.05143085]
tr_loss:[0.03778601 0.13865371 0.06294869 0.02890329 0.04889689 0.02890259
 0.04748365 0.04293803 0.02894155 0.05595046 0.02085954 0.0294957
 0.03654298 0.03029521 0.03461058 0.02085948 0.06025088 0.13841318
 0.034626   0.05676365 0.02085958 0.02894156 0.02890261 0.14692493
 0.13650483 0.04890639 0.18027073 0.04252425 0.0302959  0.02894222
 0.02085959 0.02085956 0.05156661 0.05595044 0.02894152 0.0580088
 0.0208596  0.06932272 0.04369953 0.07480271 0.05030764 0.05778053
 0.04903883 0.05595043 0.0440951  0.03948369 0.03029521 0.1468899
 0.0208596  0.02892052]
tr_loss:[0.02021801 0.03357104 0.14631212 0.0291043  0.05018593 0.05391795
 0.02782248 0.04178758 0.0314087  0.02780084 0.02021799 0.02735649
 0.02778527 0.03622233 0.0526411  0.05275333 0.04106883 0.01980213
 0.05713379 0.06211716 0.02009666 0.02021803 0.06590971 0.03355329
 0.0326754  0.03452479 0.04260234 0.02021801 0.03068109 0.05672599
 0.03352943 0.020218   0.04190017 0.17813852 0.02021803 0.03372278
 0.0526309  0.02778528 0.05551989 0.13968591 0.04355315 0.04753499
 0.04920699 0.0196821  0.04039051 0.03140869 0.05391792 0.02735652
 0.05263019 0.05551968]
tr_loss:[0.01685943 0.03598368 0.02577676 0.04310837 0.03878878 0.04460407
 0.01725131 0.02401207 0.0285008  0.13156152 0.02860373 0.02256222
 0.13239834 0.04084511 0.01711667 0.05640493 0.04346851 0.02577674
 0.02721276 0.04682926 0.02866541 0.04148179 0.03878873 0.02577678
 0.03388122 0.02880058 0.02577675 0.02862519 0.05260745 0.02400158
 0.14124319 0.02577677 0.02864453 0.0225404  0.03878877 0.02860788
 0.02767217 0.02400157 0.02577672 0.0286709  0.04764255 0.03249235
 0.02254041 0.02400159 0.01725129 0.03933889 0.02577831 0.0424888
 0.0172513  0.02577674]
tr_loss:[0.01330312 0.04229859 0.15202777 0.01553286 0.02411266 0.04268425
 0.03666102 0.03666003 0.01572989 0.04817249 0.0506187  0.03073401
 0.04424613 0.02438569 0.02432235 0.03745648 0.02418594 0.03352829
 0.04163183 0.02438571 0.04556868 0.03143914 0.05335672 0.02401496
 0.0222229  0.02417964 0.02429401 0.04389701 0.01570796 0.02476684
 0.03973097 0.05889162 0.04497435 0.03378036 0.04614156 0.02403042
 0.04767385 0.04817246 0.03776185 0.04151455 0.02409906 0.02418592
 0.09239639 0.13214383 0.04229862 0.01572999 0.03350266 0.15207556
 0.04149919 0.02410075]
tr_loss:[0.03282333 0.02316215 0.01500062 0.04298844 0.12720536 0.03693677
 0.03681396 0.01460693 0.02893838 0.03382295 0.04424237 0.01499948
 0.0147935  0.04087859 0.04094726 0.01500062 0.03729768 0.01496928
 0.02151546 0.02303974 0.01500061 0.04094025 0.02316135 0.02305375
 0.017604   0.04749452 0.0149511  0.03800945 0.02303974 0.02065748
 0.01497791 0.0375955  0.0149977  0.02303973 0.03341543 0.01760401
 0.01930622 0.0512524  0.02303972 0.13290071 0.04175878 0.02040805
 0.02035347 0.1463137  0.04211344 0.04636154 0.04616218 0.0443593
 0.04194124 0.13349673]
tr_loss:[0.03451022 0.01470954 0.03765946 0.12436187 0.06236194 0.01870311
 0.0649264  0.01474851 0.03257737 0.04566404 0.0334335  0.03942848
 0.02379085 0.01849744 0.04093275 0.03029703 0.02266875 0.01474752
 0.03023121 0.04326618 0.04087614 0.01874506 0.0325411  0.04156216
 0.03677851 0.02286745 0.02286751 0.02260925 0.03521583 0.0366982
 0.02286776 0.03343305 0.12166116 0.02286744 0.01773516 0.03612459
 0.03456636 0.11900874 0.04663356 0.02286743 0.02379083 0.01873543
 0.04027795 0.16377702 0.04412121 0.048507   0.01474851 0.02266893
 0.01874174 0.04420524]
tr_loss:[0.12606506 0.04554067 0.02342183 0.02342183 0.03529897 0.0155397
 0.017011   0.04491367 0.04659431 0.01772684 0.02342187 0.04554063
 0.03943912 0.01553968 0.02006701 0.0466053  0.11955054 0.01553971
 0.01553957 0.02465644 0.03561573 0.02402034 0.01553958 0.02465644
 0.01553966 0.03098756 0.04924655 0.04405561 0.01933352 0.02342184
 0.04191549 0.01766616 0.0193335  0.04514755 0.01553969 0.03821722
 0.01553808 0.04178587 0.11330147 0.12240484 0.02402036 0.01764522
 0.02342183 0.02403935 0.0345484  0.01770996 0.1304734  0.01670044
 0.04581567 0.12335481]
tr_loss:[0.01527826 0.02342976 0.01527826 0.0370331  0.01523196 0.03814129
 0.02307485 0.01527817 0.10740511 0.03140992 0.01527806 0.03921158
 0.04389003 0.03171469 0.01562758 0.01578292 0.02332994 0.01746203
 0.04208102 0.02307483 0.01496919 0.04909981 0.04011046 0.04682039
 0.01527826 0.05972711 0.02942897 0.03482663 0.01564902 0.02386361
 0.01527827 0.03691018 0.04420479 0.04233489 0.01527404 0.04757817
 0.02386505 0.04173338 0.0452177  0.04557139 0.04681722 0.01746213
 0.12211581 0.01527829 0.02307483 0.04812868 0.01527828 0.02718552
 0.01746215 0.04286719]
tr_loss:[0.04844208 0.07668141 0.01408018 0.03742773 0.09787931 0.0136089
 0.01408018 0.01558207 0.02164959 0.04846349 0.03589481 0.04719421
 0.01358416 0.03801829 0.02179175 0.02269295 0.0154807  0.03532952
 0.01358282 0.01351462 0.0217988  0.02432179 0.04068763 0.04721125
 0.01361672 0.01369062 0.11399792 0.03909456 0.02179886 0.01378426
 0.02876165 0.02346852 0.02179174 0.10373794 0.04377026 0.0140802
 0.01378195 0.02164964 0.01357439 0.04583042 0.10343112 0.02179174
 0.03141976 0.10051718 0.02179174 0.02179172 0.0482357  0.02164963
 0.02249397 0.03338472]
tr_loss:[0.03664406 0.03363062 0.01311408 0.04010313 0.01311749 0.0127308
 0.01908152 0.03664402 0.01306771 0.02859556 0.01276192 0.04747377
 0.01268188 0.01908153 0.04074037 0.01908153 0.01310396 0.0423555
 0.01868285 0.01868266 0.0389104  0.01273124 0.01908163 0.01276193
 0.01324504 0.03709665 0.03335343 0.01868265 0.01307811 0.02813603
 0.05121067 0.03695446 0.01276175 0.03199242 0.03826172 0.04362858
 0.01313796 0.04421708 0.01275799 0.01908152 0.04747378 0.03744438
 0.01352165 0.04411513 0.01908467 0.0364712  0.01276034 0.09687416
 0.04298558 0.03017035]
tr_loss:[0.01261054 0.01261863 0.01613348 0.01626489 0.01057249 0.01626488
 0.039597   0.01619116 0.0126034  0.01619116 0.01059245 0.01624645
 0.10554068 0.01240709 0.01059425 0.0979446  0.01245975 0.01267158
 0.01948441 0.01624498 0.03666237 0.016245   0.03064882 0.02519282
 0.01059426 0.02936706 0.01972893 0.0194844  0.01059426 0.01948336
 0.03395072 0.01059412 0.03930327 0.01059397 0.03370434 0.01259792
 0.01059172 0.01058308 0.05860962 0.04191481 0.01256287 0.01260491
 0.01059364 0.01260842 0.01257796 0.01259368 0.01624602 0.04191478
 0.01257254 0.03943357]
tr_loss:[0.00752589 0.01447759 0.12212701 0.01447284 0.03750145 0.03681663
 0.03240597 0.02006116 0.01539532 0.03237788 0.03088627 0.02471132
 0.01063032 0.03188206 0.03237789 0.01098738 0.00752589 0.03237789
 0.01902876 0.01647486 0.03237816 0.02531816 0.01447286 0.01979034
 0.0363182  0.04052478 0.01060527 0.01102275 0.11093564 0.09723826
 0.03681108 0.01102695 0.01145665 0.03163124 0.01103296 0.09461541
 0.0368111  0.03138006 0.11159183 0.01447284 0.03177349 0.00752412
 0.00752589 0.02411523 0.01972471 0.01459269 0.01102465 0.01447286
 0.01188273 0.01447285]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1500 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1501, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1501 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1502, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1502 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1503, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1503 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1504, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1504 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1505, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1505 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1506, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1506 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1507, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1507 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1508, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1508 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1509, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1509 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1510, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1510 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1511, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1511 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1512, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1512 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1513, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1513 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1514, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1514 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1515, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1515 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1516, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1516 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1517, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1517 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1518, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1518 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1519, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1519 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1520, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1520 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1521, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1521 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1522, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1522 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1523, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1523 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1524, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1524 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1525, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1525 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1526, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1526 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1527, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1527 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1528, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1528 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1529, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1529 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1530, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1530 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1531, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1531 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1532, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1532 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1533, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1533 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1534, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1534 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1535, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1535 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1536, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1536 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1537, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1537 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1538, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1538 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1539, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1539 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1540, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1540 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1541, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1541 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1542, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1542 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1543, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1543 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1544, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1544 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1545, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1545 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1546, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1546 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1547, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1547 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1548, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1548 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1549, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1549 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1550, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1550 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1551, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1551 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1552, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1552 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1553, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1553 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1554, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1554 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1555, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1555 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1556, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1556 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1557, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1557 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1558, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1558 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1559, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1559 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1560, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1560 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1561, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1561 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1562, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1562 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1563, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1563 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1564, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1564 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1565, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1565 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1566, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1566 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1567, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1567 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1568, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1568 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1569, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1569 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1570, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1570 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1571, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1571 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1572, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1572 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1573, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1573 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1574, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1574 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1575, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1575 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1576, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1576 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1577, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1577 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1578, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1578 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1579, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1579 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1580, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1580 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1581, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1581 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1582, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1582 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1583, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1583 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1584, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1584 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1585, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1585 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1586, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1586 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1587, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1587 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1588, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1588 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1589, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1589 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1590, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1590 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1591, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1591 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1592, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1592 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1593, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1593 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1594, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1594 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1595, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1595 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1596, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1596 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1597, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1597 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1598, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1598 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1599, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1599 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1600, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-1500
text_input.shape
(1600, 14400)
learning_input_tmp.shape
(1600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1600, 80)
learning_output.shape
(750, 80)
Model: "sequential_33"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_33 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0817342  1.2031889  1.1899017  1.2511145  1.0892584  1.0804539
 0.94107026 1.040788   1.1891863  1.081042   1.0279704  1.2043941
 1.0389616  1.089404   1.2062985  0.9365185  1.0249798  1.0892599
 1.2031885  1.2202435  1.2031885  1.0892584  1.1649386  1.213377
 1.0892605  1.0892584  1.0803651  1.2193276  1.2035978  1.0892584
 1.2031887  1.0634629  0.9610437  0.96796024 0.9924404  0.96336824
 1.0892584  1.1891618  1.2511144  1.1893036  0.9990697  0.956127
 0.94231796 1.1845005  1.0584799  0.97334117 0.9586183  1.2062982
 1.0498072  1.0394834 ]
tr_loss:[0.6293388  0.62933874 0.6947451  0.572266   0.60619307 0.6790284
 0.62933874 0.6195693  0.67902946 0.65304726 0.60244906 0.6738977
 0.6738825  0.6790284  0.6541188  0.5676785  0.6329155  0.6325119
 0.68868697 0.69940567 0.6738825  0.6887059  0.6738825  0.6035821
 0.56562346 0.62926483 0.563866   0.6237306  0.6293263  0.65446913
 0.6738825  0.6326832  0.59813786 0.6099523  0.5355984  0.6293388
 0.68870085 0.63256353 0.6790285  0.68870085 0.6060032  0.6370466
 0.62933886 0.69474506 0.6738826  0.632621   0.63261235 0.68870085
 0.68870085 0.68870085]
tr_loss:[0.38292435 0.35492116 0.35527408 0.4134628  0.42756915 0.32604608
 0.33918872 0.37984324 0.38939762 0.35748073 0.38292435 0.32920748
 0.37286073 0.35540074 0.3606113  0.38018608 0.37984315 0.35494095
 0.33269516 0.29702514 0.31346622 0.35744172 0.34409595 0.3829244
 0.30031642 0.38292438 0.35568762 0.38292423 0.3829244  0.42505914
 0.3531425  0.3339134  0.3620973  0.29786855 0.33549944 0.34222078
 0.38292426 0.37980938 0.3461154  0.35560736 0.38600627 0.27555424
 0.38290602 0.32600638 0.38283235 0.34222075 0.344544   0.38939762
 0.37007317 0.35549447]
tr_loss:[0.2632417  0.2632417  0.23252054 0.22071639 0.23743641 0.26324165
 0.20511976 0.19960828 0.17746624 0.23754339 0.23252395 0.19935302
 0.199531   0.19955786 0.21397576 0.19941288 0.23252375 0.20569646
 0.19707331 0.20606771 0.23252368 0.2632417  0.2632601  0.20287642
 0.2313923  0.20569949 0.1994156  0.19585013 0.20560245 0.21426591
 0.19947097 0.19928493 0.1612068  0.19927451 0.1993954  0.15557483
 0.26261893 0.24288487 0.20296323 0.16120747 0.19366373 0.21426591
 0.2056993  0.26324126 0.2325238  0.15191594 0.26324168 0.17746623
 0.188216   0.19935918]
tr_loss:[0.16467771 0.13003942 0.12210006 0.12808    0.14263242 0.14131469
 0.12612842 0.12524508 0.16484846 0.10840514 0.16482952 0.15526731
 0.14263432 0.14263418 0.14263427 0.14081626 0.16484855 0.12612157
 0.12139989 0.13003941 0.16484857 0.14191416 0.16484866 0.14632592
 0.12607296 0.12480495 0.12564388 0.14081618 0.14081623 0.1221
 0.1426291  0.14876553 0.12600712 0.13512073 0.09854932 0.12610571
 0.1426342  0.12609127 0.14263421 0.13003945 0.12730202 0.12210008
 0.12258234 0.16484852 0.12210004 0.14263423 0.09037317 0.09992393
 0.12210002 0.13003942]
tr_loss:[0.11324314 0.09224446 0.12077177 0.11583553 0.10154377 0.09134992
 0.1129086  0.10115012 0.09467584 0.09238961 0.09317828 0.08486285
 0.09226523 0.09134994 0.09134998 0.0851623  0.1005886  0.12377457
 0.10473968 0.08895323 0.10262962 0.09119486 0.09937187 0.09134227
 0.08895238 0.10771523 0.1015449  0.10154489 0.08895294 0.09471663
 0.08273891 0.09134992 0.10154483 0.0890618  0.09226469 0.10155101
 0.10154484 0.13065255 0.08895314 0.0956784  0.09844591 0.09442489
 0.11474857 0.10154486 0.08871062 0.09134994 0.10771526 0.09134996
 0.13429287 0.1079969 ]
tr_loss:[0.08762085 0.06526095 0.06524783 0.06189392 0.07315914 0.06427603
 0.06394412 0.05888227 0.07556728 0.06260832 0.06423562 0.05888671
 0.07507923 0.05888669 0.07927255 0.06527473 0.06503446 0.07315911
 0.07347497 0.05894881 0.0652594  0.05888665 0.05897607 0.06524755
 0.07559833 0.05837375 0.07324149 0.09982368 0.05888668 0.11829253
 0.08568157 0.06503534 0.07315922 0.06503443 0.06670766 0.07720505
 0.05837392 0.06523357 0.05837391 0.06691827 0.08762353 0.0731592
 0.05888671 0.06503445 0.07315938 0.05888671 0.05888668 0.07119709
 0.07516678 0.07415707]
tr_loss:[0.05471021 0.04792157 0.0811101  0.05308333 0.04003304 0.07237931
 0.05526678 0.06736829 0.03651542 0.06997606 0.04792576 0.04790556
 0.04044755 0.07619064 0.09811404 0.04003362 0.05410898 0.03420405
 0.04044658 0.04784564 0.04790897 0.04030455 0.04030455 0.06997607
 0.03420402 0.07619067 0.03420417 0.05468068 0.04026317 0.06367195
 0.04003279 0.04791716 0.0737117  0.07166159 0.04044656 0.04030379
 0.04791489 0.07225929 0.04003283 0.04790669 0.04003283 0.07166162
 0.04562528 0.05411166 0.04003285 0.04027947 0.06898969 0.05339225
 0.03403838 0.0340384 ]
tr_loss:[0.08592974 0.07708516 0.0475995  0.06488462 0.04761078 0.07892785
 0.04558487 0.05850735 0.04761076 0.081485   0.08711042 0.05890621
 0.04308382 0.05899918 0.04238488 0.04558489 0.04308377 0.04761077
 0.05855467 0.07972416 0.04761074 0.108413   0.04558485 0.05895809
 0.07714771 0.04713727 0.09499462 0.05893732 0.06818208 0.08711046
 0.0423825  0.04760861 0.0423825  0.03447678 0.07977948 0.06572212
 0.0423825  0.03447678 0.04761078 0.07216611 0.06846581 0.07900032
 0.07512222 0.04761078 0.05894002 0.0423841  0.06854866 0.07230047
 0.0476108  0.04239407]
tr_loss:[0.05218126 0.08733045 0.05216823 0.06884521 0.08366387 0.04183734
 0.07400324 0.06987425 0.04248499 0.04957237 0.07449471 0.07057471
 0.08776246 0.07710914 0.05779858 0.0495915  0.07541979 0.09302562
 0.08817632 0.06586953 0.09749154 0.0523526  0.06277741 0.04248503
 0.065823   0.042485   0.04959151 0.07177154 0.03688874 0.04959152
 0.04240419 0.04481972 0.06632704 0.05216823 0.07150541 0.06589807
 0.05216823 0.07958297 0.09645662 0.04482416 0.04959148 0.0727263
 0.04472189 0.08877097 0.05869626 0.04482412 0.0654717  0.09282888
 0.09264649 0.06587287]
tr_loss:[0.09109586 0.0613272  0.06321017 0.03390393 0.05662463 0.0761927
 0.03560294 0.05791719 0.04441687 0.03970759 0.09271922 0.07118598
 0.04374986 0.07931665 0.06328855 0.06952279 0.06318448 0.08080712
 0.06315444 0.0397076  0.07685202 0.03560291 0.0724479  0.04441691
 0.07242382 0.06733441 0.0956689  0.03765232 0.09035625 0.06929872
 0.08349086 0.07629602 0.03390402 0.05662537 0.08159826 0.05662532
 0.0807898  0.06321672 0.07118283 0.06320864 0.04441694 0.04386573
 0.03970759 0.06341795 0.03765205 0.04441636 0.03560291 0.08197539
 0.09035627 0.03971002]
tr_loss:[0.05697573 0.05702572 0.05702572 0.06326203 0.03539852 0.06854541
 0.03406356 0.0570254  0.03616631 0.03406357 0.06231477 0.07836433
 0.06827976 0.08870582 0.03887629 0.0580209  0.05662546 0.0670193
 0.07241609 0.05625989 0.03013075 0.0710099  0.05663236 0.05702572
 0.05669544 0.06924714 0.04260383 0.03887898 0.07090779 0.03406351
 0.0637343  0.0300368  0.06464757 0.03406414 0.06115993 0.08098729
 0.03406357 0.03539857 0.03539853 0.0594879  0.038845   0.05529373
 0.06905285 0.03406354 0.08093645 0.03406353 0.03887565 0.05662736
 0.03616633 0.03886556]
tr_loss:[0.04643486 0.07208822 0.05391157 0.04800813 0.0333543  0.07674564
 0.04285524 0.06201594 0.055688   0.03335431 0.04636014 0.03027103
 0.03335432 0.03334828 0.02895688 0.05467329 0.03335058 0.03027101
 0.04803428 0.06807658 0.0665106  0.03027105 0.04636397 0.03027105
 0.04803347 0.05592867 0.04803431 0.07388698 0.03027103 0.04803431
 0.06159998 0.03088401 0.0600441  0.03252098 0.03027101 0.05957842
 0.03421102 0.03132793 0.03027099 0.030271   0.02895687 0.03306853
 0.0463567  0.03308938 0.03335432 0.03335431 0.03027101 0.06127946
 0.03076857 0.0590998 ]
tr_loss:[0.05771916 0.04000812 0.07424815 0.02971289 0.02900703 0.02910854
 0.03853742 0.06031187 0.02971306 0.0297129  0.06471507 0.03308211
 0.0297129  0.03019853 0.06506459 0.02920554 0.02971252 0.07204711
 0.04016341 0.06178579 0.03357708 0.04579202 0.07424814 0.03853839
 0.02971287 0.02920555 0.02912764 0.04000171 0.0297129  0.04900488
 0.03933137 0.0297054  0.03308212 0.06030353 0.07204709 0.06173209
 0.0400235  0.02971291 0.06128745 0.05764253 0.0297129  0.05687898
 0.06901439 0.02920437 0.02971286 0.0724869  0.03844676 0.04002825
 0.02971292 0.06139612]
tr_loss:[0.02892617 0.05315519 0.03748409 0.064968   0.05867686 0.05477338
 0.03744476 0.03729272 0.06256013 0.04899188 0.02596359 0.05653884
 0.05676951 0.02892617 0.02891131 0.06401205 0.02892617 0.02881179
 0.05714107 0.03950975 0.06016008 0.03748696 0.03729272 0.03950266
 0.03950262 0.05556576 0.03719003 0.02596364 0.03815544 0.05654951
 0.03744881 0.02892619 0.05406526 0.0259636  0.02596353 0.07043575
 0.04434323 0.03729274 0.02596358 0.05230238 0.03688349 0.03950264
 0.02510259 0.05761484 0.02892619 0.02892619 0.05838106 0.05585189
 0.03729254 0.06392701]
tr_loss:[0.02013786 0.02536678 0.03238251 0.03886287 0.05951782 0.04191302
 0.02012076 0.06353505 0.02536672 0.03886287 0.03885865 0.0552487
 0.04895479 0.05332588 0.03168711 0.03238248 0.02013761 0.03684304
 0.03684314 0.03238111 0.06281154 0.04932982 0.03238252 0.05785723
 0.03176359 0.05072718 0.0317632  0.03176174 0.04923619 0.03238251
 0.05128552 0.04857225 0.03176384 0.05640057 0.03125625 0.05681423
 0.03125506 0.02013898 0.04477882 0.05335341 0.05911157 0.03238239
 0.06295107 0.03173416 0.02013892 0.0254548  0.0627393  0.05657938
 0.04136842 0.02536674]
tr_loss:[0.02630263 0.02630264 0.02884296 0.02349094 0.01695181 0.02879883
 0.01564028 0.03779428 0.02910475 0.04639182 0.0388014  0.01702816
 0.02273891 0.05576275 0.01988447 0.05267682 0.02852201 0.01702819
 0.05218767 0.04456634 0.04307582 0.02273889 0.02939273 0.03413931
 0.02910472 0.05366297 0.04439298 0.02630263 0.05037192 0.02879884
 0.04036409 0.05366291 0.02733902 0.04886238 0.02884126 0.04547086
 0.02273888 0.02194729 0.02799323 0.02879884 0.02883648 0.02733892
 0.02880831 0.04325261 0.02630262 0.02273892 0.02273889 0.02273892
 0.02870684 0.028798  ]
tr_loss:[0.02232134 0.04320784 0.01712416 0.05101154 0.04060746 0.01778867
 0.03026095 0.04230646 0.03103705 0.03086581 0.02827149 0.04214057
 0.04783048 0.01770011 0.03110921 0.02342698 0.0393926  0.01776657
 0.01775357 0.04552296 0.05138534 0.02079239 0.03869469 0.01778867
 0.04387591 0.03093796 0.02342698 0.03087116 0.03094528 0.05346727
 0.04535031 0.02232135 0.07059469 0.05101151 0.01594351 0.04910912
 0.03375781 0.03603174 0.03092192 0.0309483  0.0202083  0.04758012
 0.02069437 0.02069429 0.0206943  0.02959676 0.0177887  0.01773412
 0.04436403 0.01778695]
tr_loss:[0.03085678 0.02569709 0.04184736 0.05366796 0.01849771 0.02860146
 0.03086457 0.0225228  0.03060987 0.05141705 0.05056703 0.05238058
 0.039691   0.02199438 0.02196676 0.04387073 0.01849773 0.02853453
 0.03003173 0.03086319 0.0402871  0.04440366 0.0184977  0.04702582
 0.02855702 0.02858346 0.04487858 0.03424859 0.07382611 0.03086447
 0.01849772 0.0383078  0.04031681 0.04977148 0.07123961 0.01849768
 0.05131606 0.02252683 0.02857923 0.03086123 0.03886103 0.03086456
 0.02196675 0.02855849 0.04542472 0.04489442 0.01849772 0.01763417
 0.03505076 0.02660065]
tr_loss:[0.01954103 0.02125328 0.03242315 0.05340029 0.02130293 0.03018958
 0.03242315 0.04884847 0.0195411  0.05138437 0.03242317 0.06757203
 0.03018952 0.04085539 0.03162799 0.03242315 0.027104   0.0195411
 0.02712168 0.01954115 0.0324154  0.03585451 0.01949075 0.0286502
 0.02130293 0.0324232  0.04329568 0.05044634 0.02715349 0.03242308
 0.03018958 0.0213029  0.02461348 0.01954107 0.02130294 0.03242313
 0.01954303 0.03242315 0.01954107 0.02130291 0.02130293 0.01954107
 0.02130294 0.04919729 0.01994372 0.02716812 0.02024577 0.03797035
 0.04752195 0.03240223]
tr_loss:[0.02841934 0.05676219 0.0283568  0.02590821 0.02590821 0.05195327
 0.01902549 0.01902453 0.04796628 0.02938934 0.06360552 0.03212536
 0.02938935 0.01837266 0.03793001 0.02280492 0.02279821 0.01902547
 0.0228033  0.02280494 0.02278429 0.0190255  0.04274771 0.0404623
 0.02280493 0.01902546 0.04571929 0.02273827 0.02697461 0.0190271
 0.02280495 0.02830897 0.04620196 0.03018563 0.02280494 0.04205283
 0.02279655 0.01914676 0.05187353 0.02593848 0.04521401 0.03650642
 0.02938933 0.06906258 0.02936844 0.04275772 0.04355728 0.03303424
 0.01902548 0.0524356 ]
tr_loss:[0.05084996 0.02742936 0.04384226 0.02064366 0.05080813 0.05507041
 0.04946703 0.04088724 0.02729593 0.0206436  0.02637216 0.02886966
 0.02742938 0.02730364 0.01738679 0.02631056 0.01807398 0.02637215
 0.02704418 0.02637216 0.02735345 0.05080815 0.03900807 0.02725605
 0.02637218 0.02886965 0.02064355 0.02739657 0.02728979 0.05245908
 0.02721949 0.04103535 0.04579788 0.05340853 0.04240807 0.02637214
 0.03792459 0.0596495  0.01738678 0.04081325 0.0173868  0.0205276
 0.03218891 0.03958678 0.02637213 0.02728239 0.02064364 0.04339208
 0.03790797 0.0274294 ]
tr_loss:[0.01766952 0.02194726 0.0176695  0.03469065 0.01766951 0.05126861
 0.02673541 0.01766948 0.01917406 0.01766951 0.03872186 0.02671411
 0.01903579 0.0358283  0.03907771 0.03985277 0.04154886 0.02763962
 0.04752766 0.02763963 0.0471269  0.02672285 0.01917404 0.0425186
 0.01917405 0.02607685 0.01917403 0.02607689 0.02679851 0.0176666
 0.02611012 0.01766935 0.02607687 0.02194724 0.01878284 0.01766948
 0.0191732  0.01766953 0.04454547 0.02176356 0.02616524 0.01917405
 0.01917406 0.04061206 0.03723415 0.04712691 0.05501381 0.05497632
 0.05921379 0.02998578]
tr_loss:[0.01675783 0.02500086 0.02500655 0.04728625 0.06024532 0.01661874
 0.01991341 0.02620859 0.04336359 0.01661899 0.03907586 0.02500992
 0.0252484  0.04240432 0.05933126 0.01675781 0.05672093 0.02503784
 0.02501926 0.01661686 0.04753556 0.01656393 0.04291552 0.02620658
 0.05571771 0.02499783 0.04333312 0.04313685 0.03565718 0.0252484
 0.04600448 0.0252979  0.03954287 0.01661902 0.01675768 0.02529785
 0.02502312 0.0433824  0.02502067 0.04736923 0.01440168 0.016619
 0.04753557 0.04590418 0.01653728 0.04503558 0.0282512  0.03918074
 0.04814781 0.05143759]
tr_loss:[0.02182749 0.02182174 0.01375857 0.02189338 0.01462801 0.01680481
 0.01375858 0.03531656 0.01680746 0.05519766 0.02183141 0.01375205
 0.01680743 0.01485054 0.0391792  0.02078732 0.01375858 0.02367462
 0.0146425  0.02183238 0.02191839 0.03581534 0.04168267 0.01464251
 0.01375859 0.02353684 0.05519767 0.02182382 0.02284295 0.01375858
 0.02737408 0.03600409 0.01464249 0.01375858 0.06033644 0.03977373
 0.03571442 0.04078489 0.0501888  0.01464253 0.02353681 0.03979969
 0.02353681 0.05215981 0.04158391 0.04997642 0.04836293 0.01375834
 0.01462478 0.03618521]
tr_loss:[0.02110784 0.05852462 0.04092147 0.03318597 0.01337602 0.04076364
 0.02179122 0.01966638 0.02456037 0.01420329 0.02103445 0.05555928
 0.01742818 0.01420328 0.02456037 0.02103637 0.01741953 0.04103094
 0.02456035 0.02105648 0.05116338 0.03828733 0.01420449 0.02456035
 0.01741951 0.01337994 0.04364353 0.0513878  0.05242331 0.0373407
 0.02454845 0.02103759 0.02104062 0.01420328 0.01377123 0.01337993
 0.01336996 0.02456027 0.02179367 0.0217937  0.01337992 0.05242327
 0.05116343 0.05086725 0.01337994 0.02111852 0.03397508 0.01337993
 0.02179368 0.04867312]
tr_loss:[0.05255119 0.04975573 0.02591023 0.02084493 0.01338177 0.04801754
 0.0235393  0.03994867 0.01938289 0.04384754 0.01419736 0.04502938
 0.02086525 0.02591312 0.04848639 0.05255115 0.02086987 0.03778184
 0.01419745 0.01338244 0.01338245 0.01601513 0.06287418 0.05020525
 0.01338244 0.02087428 0.01419747 0.0258595  0.01419744 0.04158331
 0.04097036 0.02591314 0.02085943 0.01419744 0.0257934  0.01419744
 0.03931794 0.01899309 0.01419752 0.01419733 0.04908493 0.05317748
 0.03857927 0.01337971 0.01337545 0.01899308 0.04127755 0.02584043
 0.04715832 0.02087327]
tr_loss:[0.01377809 0.01228036 0.02532259 0.01992914 0.01887713 0.01991307
 0.03991482 0.01338631 0.04830972 0.01471879 0.01340508 0.01338634
 0.01338632 0.02532255 0.01991266 0.02504569 0.01075135 0.01377306
 0.03867232 0.04557012 0.0133863  0.04227488 0.05119908 0.01990179
 0.0369409  0.0139838  0.01637403 0.02532259 0.0199111  0.0460526
 0.01228254 0.03918908 0.01377809 0.02532255 0.03438942 0.04288649
 0.01228256 0.01653041 0.02004974 0.01992379 0.0465777  0.02522455
 0.04830975 0.01989194 0.03406717 0.01228255 0.03720335 0.04298612
 0.02532258 0.03712753]
tr_loss:[0.01242833 0.04326136 0.05255766 0.04225502 0.04222307 0.04268556
 0.02056929 0.01807164 0.01462308 0.01462306 0.01462307 0.02490267
 0.01224383 0.01242832 0.04268159 0.01516556 0.02057329 0.02490267
 0.03570958 0.01807166 0.05277823 0.01807165 0.02057322 0.01242833
 0.02490267 0.04353222 0.02490221 0.01462306 0.04153217 0.01218265
 0.04378056 0.03903761 0.01462305 0.01143251 0.0525366  0.01235516
 0.01462309 0.01807167 0.01227227 0.04567694 0.01242832 0.01224383
 0.03486043 0.04495268 0.01517203 0.02057477 0.01462306 0.01807167
 0.01807168 0.01462304]
tr_loss:[0.01196881 0.02062353 0.04309769 0.02064067 0.01512448 0.0119689
 0.02069168 0.01711152 0.05120108 0.02060447 0.01310459 0.01196888
 0.02488258 0.01364822 0.01365853 0.01509636 0.04311096 0.01262866
 0.01196878 0.01512448 0.0136563  0.02062311 0.03909016 0.03241065
 0.05345557 0.03106735 0.02488256 0.01365851 0.01196864 0.02483814
 0.02487985 0.02060536 0.01365853 0.03278348 0.01196892 0.01196893
 0.03399239 0.03794942 0.02086127 0.03600098 0.01711191 0.01711151
 0.0410829  0.02488048 0.02488258 0.01379233 0.0457367  0.02063904
 0.01262862 0.04625213]
text_input.shape
(1600, 14400)
learning_input_tmp.shape
(1600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1600, 80)
learning_output.shape
(750, 80)
Model: "sequential_34"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_34 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1102295 1.0454799 1.1784708 1.2712228 1.0749401 1.2712225 1.2891104
 1.2131292 1.2891105 1.2891105 1.269541  1.0631863 1.127876  1.2109537
 1.2712246 1.2891104 1.2712225 1.2712234 1.2891104 1.0449343 1.079498
 1.0717375 1.2110062 1.0659878 1.2712225 1.1784712 1.0705038 1.1784625
 1.2891104 1.0783792 1.1162704 1.2452536 1.0922388 1.0962145 1.0708345
 1.2891119 1.0416064 1.241603  1.0456715 1.039752  1.0540231 1.1085193
 1.0579491 1.21102   1.2110192 1.0785567 1.2445935 1.0896777 1.2758228
 1.3044189]
tr_loss:[0.69789755 0.6978973  0.7153088  0.76337266 0.7274373  0.8069223
 0.8069223  0.71593285 0.72761184 0.64855564 0.6601809  0.731806
 0.7633769  0.80687064 0.78566456 0.7276107  0.71540135 0.69789743
 0.7151742  0.763377   0.7922314  0.67419636 0.69789743 0.7152551
 0.80692226 0.80692214 0.69789743 0.6124784  0.80692226 0.6741486
 0.7679273  0.80692255 0.8069223  0.6590924  0.7275758  0.6258607
 0.65621173 0.64625674 0.72479427 0.76797324 0.69077814 0.6580399
 0.71835405 0.72761166 0.64377487 0.6510149  0.76797295 0.64449733
 0.8069395  0.64114386]
tr_loss:[0.49596977 0.5078981  0.44078773 0.5475257  0.50977856 0.46718302
 0.46047553 0.46825942 0.46825933 0.40980014 0.5099733  0.4990549
 0.4989645  0.45493785 0.43047753 0.45762914 0.49039754 0.4990549
 0.46811682 0.44294223 0.42038116 0.4990549  0.4340008  0.54752576
 0.5475259  0.51002973 0.46825942 0.5475259  0.44122618 0.4479095
 0.45522028 0.44097847 0.54752576 0.4053782  0.49905473 0.5098342
 0.44313803 0.46825933 0.509374   0.45963487 0.4098     0.49596986
 0.54752576 0.43330687 0.49597138 0.4547345  0.50967586 0.5098478
 0.50789803 0.4959697 ]
tr_loss:[0.3084565  0.2857327  0.29394323 0.26992682 0.31022185 0.26528507
 0.285757   0.26528513 0.25863725 0.28261715 0.29858404 0.22772169
 0.2640163  0.3119027  0.30623382 0.30845657 0.31020895 0.2651019
 0.30665383 0.27498844 0.30665383 0.24533133 0.31020898 0.31020895
 0.29445544 0.2598711  0.2741081  0.31020898 0.29357028 0.27415437
 0.31020895 0.26528513 0.31020895 0.25436196 0.23691444 0.3102089
 0.28218815 0.27356    0.2620787  0.27159277 0.2857536  0.26365247
 0.2739253  0.23721282 0.2750175  0.2743767  0.2857571  0.30665395
 0.30273646 0.27385423]
tr_loss:[0.16399947 0.1611789  0.17896378 0.18736418 0.19010927 0.16088697
 0.15906999 0.17253059 0.1990229  0.17224549 0.16399941 0.16722395
 0.21340552 0.19902283 0.16467682 0.1613262  0.16151357 0.17224537
 0.18148756 0.17191783 0.17224537 0.17322145 0.18858649 0.16399749
 0.176871   0.19902293 0.18040653 0.17135614 0.16144535 0.15226841
 0.16107044 0.18526036 0.17253055 0.19520351 0.15304437 0.1581144
 0.16399945 0.17224552 0.17253071 0.1882292  0.16399196 0.1853555
 0.17598838 0.1722454  0.18142554 0.16399945 0.17224546 0.16033712
 0.17685775 0.16399944]
tr_loss:[0.12371968 0.11972935 0.1195379  0.16194493 0.12371971 0.12331331
 0.1508207  0.15793498 0.13298652 0.14562598 0.13907567 0.13164175
 0.12686796 0.12331343 0.16268693 0.15088663 0.12902446 0.13176723
 0.13907565 0.11939591 0.11906693 0.12371962 0.11948527 0.16194494
 0.13597557 0.12371967 0.12997322 0.12005661 0.15088597 0.1508866
 0.12331325 0.12331269 0.11716497 0.12331338 0.12371977 0.12686661
 0.1233134  0.12686794 0.14492592 0.1545398  0.12933592 0.12371969
 0.12371977 0.14203314 0.17232355 0.11635323 0.11960033 0.12943815
 0.13178134 0.11675884]
tr_loss:[0.1210853  0.08619575 0.09918034 0.10242443 0.08619574 0.09937631
 0.09383999 0.08156132 0.08594429 0.09922756 0.08968088 0.09349509
 0.09394417 0.08470923 0.08476856 0.10389628 0.11527677 0.08472035
 0.08620096 0.11527674 0.09518524 0.0952186  0.11593802 0.093506
 0.10928862 0.09394415 0.10025764 0.12108536 0.08473776 0.09592547
 0.09471546 0.08436774 0.09394419 0.09284349 0.09493447 0.0991804
 0.09498181 0.09444501 0.09918028 0.08620195 0.08903368 0.09384002
 0.08504255 0.11527677 0.10970273 0.10139321 0.09918032 0.09918039
 0.08893372 0.08619571]
tr_loss:[0.07283752 0.06675974 0.07568464 0.07293695 0.0657981  0.06091138
 0.0611689  0.06124455 0.06677017 0.07293638 0.07293643 0.0726626
 0.07625008 0.07293637 0.06116048 0.06712539 0.06125795 0.08456137
 0.05049268 0.06677017 0.07293644 0.07283755 0.06864176 0.07283755
 0.05952349 0.0760534  0.0674473  0.06031131 0.06133167 0.06897233
 0.07283752 0.07293769 0.0729364  0.06677017 0.06744833 0.06675563
 0.07283749 0.05952349 0.07638137 0.07283759 0.06744735 0.06677006
 0.07349735 0.07385918 0.05918925 0.07283751 0.06677015 0.05952346
 0.0674182  0.06676724]
tr_loss:[0.07078185 0.06309635 0.06600811 0.04317059 0.04757684 0.04311972
 0.05242971 0.04309728 0.06202549 0.05766788 0.04421298 0.07707454
 0.0700109  0.04800507 0.05232576 0.04762925 0.05986832 0.04261814
 0.06364036 0.06503631 0.04273573 0.0475529  0.04317004 0.05275569
 0.04555865 0.04261813 0.04756417 0.0624167  0.04261814 0.04261815
 0.04761238 0.04317017 0.04317056 0.05783337 0.04555858 0.04756836
 0.04421299 0.07265382 0.04758011 0.04261815 0.047606   0.05289196
 0.07249162 0.04555843 0.04317036 0.04555862 0.04753856 0.07307873
 0.04290738 0.04056384]
tr_loss:[0.05709077 0.03799257 0.04727778 0.08139657 0.04791292 0.04791289
 0.05696112 0.04375895 0.04791287 0.05708836 0.04791294 0.04073121
 0.04073076 0.07201409 0.0813966  0.0570944  0.04375888 0.06896249
 0.04073099 0.07638405 0.04783163 0.05715948 0.08885355 0.04791241
 0.07922339 0.05719359 0.05707288 0.05708947 0.03799259 0.03799259
 0.05630083 0.05708979 0.04073116 0.07024376 0.04791288 0.03799257
 0.06678452 0.05990071 0.04779065 0.06903394 0.06508227 0.07729518
 0.04375891 0.03415932 0.04029427 0.0633387  0.04791293 0.05710765
 0.04129707 0.0612339 ]
tr_loss:[0.03335609 0.06691741 0.03801102 0.07083392 0.03801196 0.03325303
 0.06248906 0.03376805 0.04222199 0.06037243 0.05629415 0.04588954
 0.05645957 0.04228085 0.03801104 0.05402378 0.04892662 0.03801101
 0.05907717 0.04210403 0.04890489 0.03801109 0.06143639 0.04228071
 0.05402156 0.04893455 0.06861059 0.06861061 0.04890439 0.03325424
 0.0458755  0.06089044 0.03325423 0.04587545 0.05497222 0.0413147
 0.04096235 0.03801106 0.06873226 0.03325421 0.06504806 0.03325424
 0.04890053 0.04228086 0.05065614 0.04899191 0.03801104 0.0333561
 0.0968038  0.03801107]
tr_loss:[0.06796833 0.05899091 0.04229396 0.07158385 0.05063256 0.04268491
 0.02389892 0.03355488 0.04206193 0.06396742 0.042062   0.05791647
 0.04024052 0.04024799 0.03420978 0.05064837 0.05638081 0.06473412
 0.03419425 0.04025002 0.05132481 0.03382272 0.03420978 0.04025071
 0.04268762 0.06515642 0.04206198 0.03923277 0.07563615 0.04268668
 0.06319022 0.03420378 0.03988969 0.04042803 0.03420977 0.04036817
 0.06017171 0.03418519 0.0395178  0.03417009 0.03349631 0.04268764
 0.05271471 0.04206201 0.04157641 0.02389889 0.04206207 0.04024912
 0.0821171  0.05218769]
tr_loss:[0.03217307 0.03213846 0.06059016 0.03074888 0.05521422 0.05319363
 0.03162227 0.05520947 0.03217309 0.05319365 0.06084599 0.0431791
 0.04569288 0.05319389 0.03074166 0.04001204 0.03081661 0.01693399
 0.04794449 0.05086015 0.05667521 0.03161731 0.03212472 0.05870898
 0.05068086 0.03989104 0.04518285 0.0473791  0.06675355 0.04106462
 0.04892308 0.04178668 0.04001202 0.06215773 0.06571481 0.04472855
 0.06369735 0.04001198 0.04178667 0.03073715 0.03100085 0.0478625
 0.04178657 0.05185257 0.04708824 0.03621977 0.05319367 0.04794589
 0.04178669 0.05771419]
tr_loss:[0.02933466 0.0559142  0.0261326  0.01638279 0.03946818 0.05546935
 0.03945508 0.04549048 0.02614891 0.04509756 0.04981429 0.03946501
 0.02935643 0.04542816 0.0429213  0.05392454 0.02931827 0.02614371
 0.05006526 0.03683827 0.02931929 0.04331923 0.02614787 0.0163828
 0.03941743 0.03726911 0.05043648 0.03643947 0.04655143 0.02931827
 0.04785709 0.02931973 0.05568822 0.04950342 0.03946625 0.0293183
 0.02931823 0.03125087 0.03946503 0.04756433 0.04565882 0.02931826
 0.04095095 0.04941198 0.04423169 0.02931887 0.0438456  0.05227523
 0.02931879 0.01638279]
tr_loss:[0.03656857 0.05193023 0.05642545 0.03470224 0.03656861 0.03656734
 0.05131971 0.02744023 0.04098922 0.02690103 0.06406178 0.04936018
 0.04981975 0.03924149 0.04204115 0.02743232 0.05332065 0.03656852
 0.05905869 0.03572568 0.02743237 0.04398579 0.05851031 0.02743228
 0.03656856 0.02129184 0.05199261 0.02743231 0.07615075 0.04493105
 0.03578254 0.0369678  0.04931809 0.02743227 0.03578246 0.03656858
 0.03715054 0.02129183 0.0357825  0.03654998 0.0274323  0.04596227
 0.03656856 0.0497447  0.0274323  0.02532074 0.02698293 0.02130621
 0.02689014 0.02726363]
tr_loss:[0.0250666  0.03498549 0.03675782 0.0350204  0.03373958 0.0250666
 0.03770898 0.04761962 0.0350204  0.05605089 0.04931537 0.03373957
 0.0303192  0.04298628 0.02452524 0.02506662 0.04362073 0.04691377
 0.02801826 0.03826119 0.04266679 0.04763294 0.05223502 0.03501963
 0.03501052 0.03839324 0.06959231 0.0254843  0.03712061 0.0337396
 0.04461244 0.05156279 0.0371206  0.04172055 0.02506663 0.05366433
 0.02507465 0.05261825 0.05880512 0.03429136 0.05112894 0.04880829
 0.02519174 0.02998235 0.02550181 0.06097405 0.03374306 0.04351243
 0.04380792 0.03502041]
tr_loss:[0.04463322 0.05449446 0.02158902 0.03600758 0.02831014 0.04736721
 0.02120742 0.05168479 0.02126267 0.03451012 0.0413016  0.0438514
 0.03853447 0.03451009 0.04132748 0.05021689 0.05234013 0.03451008
 0.03928078 0.03451012 0.0249563  0.02831013 0.05173856 0.02831015
 0.0437706  0.02679356 0.02685841 0.02975386 0.0267413  0.02126268
 0.03223156 0.03451012 0.02126285 0.03851702 0.0345101  0.05350803
 0.0283101  0.02831314 0.03648991 0.02127298 0.02126267 0.03853448
 0.0385345  0.05956919 0.02831012 0.04806266 0.05527116 0.03450994
 0.042496   0.03633166]
tr_loss:[0.03385967 0.04780062 0.06738362 0.02540145 0.0189254  0.04255552
 0.02322889 0.01892543 0.02540107 0.02404636 0.03494447 0.01889638
 0.01892539 0.03426139 0.03288417 0.02549835 0.03962104 0.04829412
 0.01892542 0.02547767 0.0189254  0.01892539 0.03426329 0.0342631
 0.03128096 0.02912405 0.02506394 0.03426139 0.0450938  0.05099495
 0.03290441 0.02542881 0.03378901 0.04054553 0.0258313  0.03096821
 0.03426148 0.03426143 0.02894592 0.0231722  0.02535321 0.03865182
 0.03426144 0.03426141 0.02534029 0.04923462 0.04181139 0.03426135
 0.03425686 0.01892542]
tr_loss:[0.04433241 0.02130042 0.02130261 0.02946178 0.0238302  0.02130259
 0.03878116 0.05025738 0.04085607 0.02946197 0.03761302 0.0238142
 0.03483747 0.01677583 0.04347531 0.02130498 0.02130262 0.02376245
 0.03233372 0.0213026  0.02728232 0.03620968 0.03729956 0.0338071
 0.01709291 0.02728232 0.01673022 0.02728233 0.02056162 0.02728235
 0.05892085 0.03780473 0.02130261 0.04687585 0.02946195 0.03274562
 0.03672861 0.03483742 0.02374745 0.04422949 0.02377515 0.01680478
 0.0224139  0.02318715 0.03856941 0.02960288 0.016797   0.04773535
 0.02379335 0.04854255]
tr_loss:[0.04887387 0.04307426 0.02335589 0.03809971 0.01677185 0.02364006
 0.05290193 0.02335591 0.02620065 0.02370462 0.0461885  0.04883445
 0.03449994 0.02620153 0.04680633 0.04096292 0.02368877 0.02620063
 0.02620061 0.01677182 0.02370726 0.02620072 0.04336037 0.04092757
 0.02716652 0.02335592 0.02989781 0.03525179 0.02365981 0.02620066
 0.0271665  0.03324396 0.04130187 0.02619368 0.02989471 0.02342992
 0.02620066 0.02305068 0.02372552 0.04736481 0.03718207 0.03651183
 0.016771   0.03324395 0.01677115 0.03982269 0.02620063 0.03677065
 0.04192792 0.01677183]
tr_loss:[0.02477346 0.02056946 0.02273884 0.03925052 0.05491214 0.02491252
 0.03027387 0.02273882 0.05078404 0.01578668 0.03287114 0.02163547
 0.02170601 0.02180806 0.01578667 0.02164004 0.03529937 0.05491217
 0.05078404 0.02477318 0.03808467 0.0286661  0.02491251 0.02477037
 0.04214305 0.0157866  0.02175781 0.02273883 0.02491253 0.0423728
 0.04160386 0.02491251 0.02173378 0.02109703 0.01578669 0.05155301
 0.02183275 0.03027392 0.03880693 0.02491248 0.01578553 0.03786441
 0.04790487 0.02162023 0.04293225 0.02491275 0.01578668 0.01578667
 0.02174444 0.01578668]
tr_loss:[0.04145202 0.04818103 0.01266127 0.03492504 0.0239291  0.0202882
 0.01849597 0.02009203 0.01276351 0.01890993 0.01277057 0.02486992
 0.02487002 0.04024512 0.01907701 0.03940908 0.02486915 0.04136936
 0.05282474 0.02009203 0.02009201 0.05101275 0.03671731 0.02038647
 0.01899125 0.020092   0.02486981 0.03318936 0.02735905 0.03896172
 0.01897815 0.01893272 0.02007611 0.06366251 0.03473419 0.01815161
 0.02735901 0.02735905 0.02876631 0.05019231 0.01276999 0.02009202
 0.0200718  0.02487002 0.03785011 0.02392911 0.01277056 0.02471139
 0.03763836 0.02423225]
tr_loss:[0.01947393 0.02009611 0.01968313 0.04787203 0.01968312 0.01963696
 0.01962763 0.05766052 0.05118012 0.03555501 0.05045939 0.04242439
 0.01458105 0.06105366 0.05045933 0.03268258 0.0395997  0.0268601
 0.02678259 0.01295424 0.01963031 0.05724102 0.02685847 0.01968312
 0.05056383 0.01968311 0.01295817 0.06981395 0.01962711 0.04678919
 0.04236342 0.0413738  0.04176098 0.02854824 0.01968316 0.05513597
 0.01295303 0.01965137 0.03956378 0.05233173 0.04200153 0.04077975
 0.02590523 0.03959974 0.01295794 0.02590523 0.01961919 0.01968316
 0.02855573 0.0268601 ]
tr_loss:[0.02462227 0.01874185 0.03254797 0.02646616 0.01973359 0.03846595
 0.01849799 0.02639761 0.01976204 0.03947502 0.01878838 0.04694708
 0.03753665 0.05607052 0.01295004 0.02732027 0.02610188 0.04614552
 0.01976202 0.04689702 0.01815854 0.01976041 0.01874292 0.02462253
 0.01295004 0.01414944 0.03748269 0.03700288 0.02646615 0.02646614
 0.04689707 0.01414935 0.01295003 0.01986661 0.01414944 0.04689701
 0.04411217 0.03784007 0.04786648 0.02646617 0.01875364 0.01976179
 0.03868586 0.01823527 0.05295609 0.04393388 0.03713428 0.01976204
 0.03170744 0.01295002]
tr_loss:[0.01703693 0.01597584 0.01689857 0.02327109 0.04047861 0.01363817
 0.02432932 0.0289458  0.01597502 0.02327113 0.02432933 0.01703606
 0.02432932 0.01705002 0.02319309 0.01597583 0.04158388 0.04589341
 0.02432927 0.01363817 0.02584078 0.06399017 0.01701703 0.01703563
 0.03779534 0.04336981 0.03725747 0.034127   0.02327115 0.01597575
 0.01875597 0.03579496 0.01875596 0.03053091 0.02742942 0.01702979
 0.01597451 0.0159719  0.03912783 0.01702217 0.01597552 0.02664253
 0.01596667 0.03025045 0.02503598 0.01875599 0.03501134 0.01875594
 0.04318053 0.03581357]
tr_loss:[0.02176924 0.03229786 0.01447932 0.01506898 0.02098821 0.02098821
 0.01606359 0.01556592 0.01506899 0.01568135 0.01506898 0.02229924
 0.03344692 0.03318098 0.02098824 0.01647685 0.01506909 0.01506898
 0.02098821 0.01611879 0.03030436 0.01559313 0.01724684 0.01724684
 0.02098766 0.04120759 0.01561227 0.03769733 0.01506899 0.01537473
 0.01506896 0.01543177 0.01867536 0.02666293 0.02818257 0.02660983
 0.01569982 0.01557827 0.01506898 0.02229926 0.02828134 0.01504324
 0.03603312 0.01724685 0.01506897 0.01447933 0.03120607 0.01775337
 0.03759301 0.01792288]
tr_loss:[0.02392136 0.01188693 0.03661161 0.01582623 0.01188693 0.02963665
 0.01582627 0.01582629 0.02992256 0.03604142 0.01732846 0.01188693
 0.02739624 0.01594869 0.02953515 0.01451621 0.01475015 0.02250948
 0.02919459 0.01826001 0.01468812 0.01188695 0.01610343 0.0118869
 0.01189505 0.01826858 0.01458474 0.0145978  0.02916903 0.01188806
 0.01582626 0.02250947 0.01188692 0.02310507 0.03242606 0.03510719
 0.01188693 0.03696848 0.01476434 0.03562689 0.02250946 0.02910694
 0.01188693 0.01829128 0.01452127 0.01455328 0.04172708 0.0322591
 0.01470557 0.01829113]
tr_loss:[0.01724702 0.017247   0.02253396 0.01722876 0.00878754 0.01476713
 0.0158558  0.00924521 0.01475272 0.01724702 0.04582777 0.01585686
 0.01691999 0.02967993 0.01585686 0.00878762 0.03155912 0.03585743
 0.01724702 0.00878762 0.01724702 0.00878763 0.01467376 0.01585684
 0.01569742 0.03309383 0.00878761 0.02939203 0.03309388 0.04343695
 0.02253395 0.01724702 0.01723428 0.01569738 0.01585685 0.03117086
 0.03495734 0.01585684 0.04590537 0.0200716  0.0225347  0.02253678
 0.01465404 0.03011531 0.01585685 0.03764978 0.01330577 0.02484636
 0.02241807 0.017247  ]
tr_loss:[0.01457151 0.00801217 0.02420386 0.05452291 0.00771901 0.02139385
 0.01675392 0.04565289 0.01675389 0.02839456 0.03148212 0.03722195
 0.0386351  0.02903966 0.04379191 0.01675387 0.01675391 0.02823508
 0.02452336 0.01465171 0.01461876 0.02143721 0.01934173 0.03147667
 0.0167539  0.0167525  0.01675391 0.01567855 0.00801216 0.01715376
 0.01567858 0.04785561 0.01567856 0.01455618 0.04558633 0.01567857
 0.00801216 0.02314419 0.03438029 0.04305782 0.03635047 0.03189496
 0.01451504 0.00801215 0.03208108 0.04056115 0.01934178 0.01675391
 0.01703096 0.01454934]
tr_loss:[0.01812235 0.03145014 0.0093179  0.01460894 0.02203565 0.01245493
 0.0162041  0.00931809 0.03494725 0.01519409 0.02780696 0.03530974
 0.01620409 0.01950038 0.01950044 0.00930228 0.01620491 0.02787983
 0.01798176 0.01812235 0.01620406 0.01532479 0.01243158 0.01813818
 0.01531906 0.00931825 0.02821157 0.00931825 0.01244123 0.01532475
 0.01812235 0.03265638 0.02732833 0.02839914 0.01243663 0.0375616
 0.02991756 0.02991067 0.0194871  0.01620404 0.00931648 0.04537226
 0.01950043 0.02170675 0.03380818 0.01950041 0.00931827 0.01243304
 0.01950043 0.01620407]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1600 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1601, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1601 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1602, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1602 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1603, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1603 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1604, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1604 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1605, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1605 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1606, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1606 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1607, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1607 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1608, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1608 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1609, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1609 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1610, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1610 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1611, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1611 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1612, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1612 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1613, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1613 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1614, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1614 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1615, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1615 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1616, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1616 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1617, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1617 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1618, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1618 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1619, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1619 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1620, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1620 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1621, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1621 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1622, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1622 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1623, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1623 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1624, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1624 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1625, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1625 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1626, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1626 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1627, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1627 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1628, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1628 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1629, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1629 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1630, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1630 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1631, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1631 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1632, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1632 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1633, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1633 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1634, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1634 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1635, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1635 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1636, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1636 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1637, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1637 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1638, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1638 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1639, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1639 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1640, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1640 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1641, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1641 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1642, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1642 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1643, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1643 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1644, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1644 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1645, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1645 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1646, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1646 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1647, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1647 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1648, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1648 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1649, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1649 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1650, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1650 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1651, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1651 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1652, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1652 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1653, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1653 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1654, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1654 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1655, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1655 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1656, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1656 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1657, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1657 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1658, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1658 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1659, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1659 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1660, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1660 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1661, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1661 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1662, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1662 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1663, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1663 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1664, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1664 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1665, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1665 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1666, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1666 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1667, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1667 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1668, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1668 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1669, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1669 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1670, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1670 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1671, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1671 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1672, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1672 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1673, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1673 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1674, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1674 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1675, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1675 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1676, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1676 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1677, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1677 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1678, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1678 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1679, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1679 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1680, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1680 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1681, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1681 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1682, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1682 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1683, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1683 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1684, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1684 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1685, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1685 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1686, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1686 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1687, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1687 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1688, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1688 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1689, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1689 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1690, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1690 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1691, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1691 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1692, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1692 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1693, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1693 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1694, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1694 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1695, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1695 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1696, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1696 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1697, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1697 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1698, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1698 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1699, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1699 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1700, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-1600
text_input.shape
(1700, 14400)
learning_input_tmp.shape
(1700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1700, 80)
learning_output.shape
(750, 80)
Model: "sequential_35"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_35 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.9160145  0.9618765  0.8755537  0.93005097 0.86186486 0.9577425
 0.9500102  0.86507577 0.8709342  0.8701547  0.96241283 0.88003236
 1.0323957  0.96241283 0.868906   0.87664604 0.9577425  1.0323076
 1.0368726  0.93005097 0.9583192  0.8766516  1.032396   0.9823059
 0.9823058  1.0368726  1.0323957  0.9577425  0.900293   1.0323824
 0.87887144 0.8633021  0.91364384 0.87015456 0.8531057  1.0368726
 0.94188344 0.95774996 0.8701545  0.9577424  0.9429952  1.0378124
 0.89075124 0.9300853  0.8681402  0.85163325 0.930051   0.8480738
 0.851995   0.8701545 ]
tr_loss:[0.5575882  0.5414368  0.46504197 0.530627   0.51296407 0.53062654
 0.5306276  0.5392178  0.5306266  0.51296395 0.4371066  0.41622964
 0.43321642 0.4697837  0.50756633 0.463015   0.47407418 0.5392176
 0.53066796 0.4644856  0.5075577  0.44667307 0.54143655 0.47407398
 0.47407407 0.5392171  0.5306266  0.50754046 0.4589416  0.45983878
 0.45840186 0.5575882  0.54143685 0.5411149  0.47407418 0.5392178
 0.5575883  0.47386068 0.541436   0.44155854 0.53921705 0.5505532
 0.4381606  0.5414368  0.47407413 0.5306266  0.43968573 0.5412261
 0.5013453  0.47407418]
tr_loss:[0.23879018 0.24490651 0.25451574 0.21383019 0.25138798 0.21332279
 0.23681517 0.20303217 0.2531307  0.21384692 0.25607285 0.2565761
 0.24663503 0.25659177 0.23877487 0.23879066 0.2563839  0.25711355
 0.25641394 0.25838107 0.25665915 0.23912509 0.2567116  0.25600713
 0.23879063 0.2130566  0.25705996 0.2387907  0.2547463  0.20326301
 0.23912506 0.25660557 0.25639948 0.25563043 0.23912506 0.2391232
 0.25561023 0.23912509 0.2387906  0.2696558  0.25607008 0.26965585
 0.25645936 0.2636213  0.25592807 0.21305618 0.2047886  0.2696558
 0.2387907  0.21384692]
tr_loss:[0.12804767 0.11934119 0.13394663 0.12804767 0.1588787  0.11934116
 0.12804775 0.15439829 0.15439716 0.13621973 0.13106409 0.14987221
 0.16401166 0.1280478  0.12268957 0.12887989 0.1543984  0.12804773
 0.1592845  0.13199624 0.14326039 0.15071884 0.18439484 0.12804766
 0.18251897 0.12804767 0.14326334 0.14744279 0.1497986  0.16169582
 0.12887982 0.12887982 0.15886109 0.15886104 0.12805808 0.14326027
 0.14974077 0.14987093 0.12805116 0.14966807 0.1588611  0.14326036
 0.14326033 0.11391824 0.15876701 0.12561801 0.12171068 0.1466053
 0.15439838 0.12804766]
tr_loss:[0.10080858 0.11372919 0.11372916 0.08965562 0.10152011 0.09736232
 0.10161725 0.0906723  0.09765604 0.09596918 0.08965554 0.07645208
 0.1137292  0.10146886 0.11370947 0.10666565 0.10029854 0.0896556
 0.11920962 0.09327058 0.10623495 0.10288505 0.10161724 0.08153446
 0.07889497 0.0896556  0.08153445 0.10161735 0.10160255 0.09334763
 0.11372919 0.09420075 0.09067061 0.14518146 0.11788034 0.07645212
 0.09985323 0.1016155  0.09067063 0.10137548 0.09495921 0.09067063
 0.11131839 0.0836705  0.12090333 0.09011478 0.09731561 0.07988112
 0.08965558 0.08965553]
tr_loss:[0.08261152 0.0823539  0.10041962 0.07539392 0.07718996 0.07512359
 0.07355281 0.06606449 0.07539399 0.07105476 0.0821367  0.07552917
 0.07105478 0.08175729 0.08205728 0.0818544  0.07539406 0.03457176
 0.07105477 0.0755292  0.05814662 0.08605971 0.08201049 0.0701879
 0.07023369 0.08745714 0.06095873 0.03457173 0.07539393 0.07365596
 0.07552863 0.07032835 0.08747023 0.08189233 0.0660645  0.08098903
 0.07552917 0.08239466 0.08218207 0.08146606 0.07032834 0.07032547
 0.07539399 0.07405814 0.08207105 0.08257724 0.07552912 0.08578385
 0.07105475 0.06971024]
tr_loss:[0.06264315 0.09010433 0.06330876 0.06133473 0.08198947 0.06360464
 0.06330869 0.11550567 0.13792697 0.06330879 0.05985044 0.07937321
 0.06264317 0.02744707 0.06264313 0.0626432  0.09674015 0.08930261
 0.05985031 0.07535739 0.06745402 0.05402314 0.05407754 0.08346529
 0.07704905 0.07778043 0.06745408 0.06330875 0.05407757 0.06264315
 0.06216291 0.06745408 0.06654517 0.06264316 0.06330867 0.06264321
 0.05985036 0.0544004  0.07921047 0.07993747 0.0626354  0.06330874
 0.08058166 0.07807106 0.07918374 0.08259289 0.06745301 0.09852853
 0.06264317 0.06127412]
tr_loss:[0.04190452 0.07449104 0.07967573 0.04737779 0.05349151 0.09016986
 0.07616721 0.07487343 0.07482927 0.04189911 0.04190453 0.08723958
 0.07853589 0.04191179 0.07782409 0.05662692 0.04966722 0.07501476
 0.12856016 0.079535   0.04190451 0.08658302 0.07494815 0.07518625
 0.05354125 0.05495787 0.05351844 0.07221299 0.05685474 0.1087389
 0.05082388 0.06940715 0.05685477 0.05355341 0.04966726 0.08506586
 0.04966634 0.05278461 0.04737777 0.0825267  0.05685472 0.04671593
 0.0496672  0.04850405 0.0496683  0.05355342 0.04966725 0.0792152
 0.0568548  0.05355338]
tr_loss:[0.07772136 0.06038463 0.04722518 0.06038467 0.05131201 0.04943746
 0.04952408 0.04952788 0.06038467 0.0356628  0.07821599 0.04143513
 0.07106031 0.04722527 0.04952787 0.04951716 0.04387899 0.07737995
 0.05137723 0.0693921  0.04722527 0.04952789 0.03565825 0.07750143
 0.04997564 0.05982522 0.07255758 0.05425004 0.03508873 0.04722532
 0.03477845 0.0356628  0.03566328 0.07768597 0.03566279 0.06028344
 0.04722505 0.04951257 0.03566281 0.04952785 0.07699862 0.06244106
 0.06038469 0.12241855 0.060321   0.07778261 0.04742607 0.04952783
 0.07747786 0.04722529]
tr_loss:[0.04774207 0.04591783 0.07351567 0.03057061 0.05812231 0.05425041
 0.05811698 0.08679422 0.04774208 0.07425319 0.07321143 0.07423993
 0.04774205 0.07390968 0.03057063 0.04591785 0.07374324 0.04774206
 0.04774    0.03057065 0.07613353 0.05812234 0.04591784 0.04591747
 0.08433501 0.05812233 0.04591781 0.07369697 0.07899296 0.05791866
 0.04591317 0.0305706  0.06834444 0.05812231 0.05812193 0.05426342
 0.04591782 0.05026967 0.04591783 0.04774106 0.05812179 0.09748219
 0.05811539 0.09055299 0.05812233 0.0542232  0.05811356 0.0305706
 0.08453026 0.05026961]
tr_loss:[0.06862877 0.02835852 0.06628871 0.04825152 0.08856622 0.02835852
 0.08803108 0.04824312 0.02835852 0.05346974 0.02835852 0.0283585
 0.04026818 0.02835851 0.02835853 0.08886547 0.04026819 0.05346977
 0.05346977 0.06878972 0.04696173 0.02835852 0.02835851 0.05346972
 0.05346978 0.07885569 0.047216   0.05346973 0.04721529 0.06882138
 0.06873205 0.06629238 0.06861497 0.0402682  0.04794689 0.06628875
 0.02950841 0.04026816 0.10652904 0.04976802 0.05414375 0.08782088
 0.06659026 0.04918922 0.02830816 0.04721598 0.04978271 0.0779966
 0.06847284 0.06889363]
tr_loss:[0.03018332 0.04174579 0.0301833  0.08410118 0.04174581 0.04887649
 0.04197227 0.0557604  0.09235379 0.03018331 0.05114766 0.04540457
 0.04890558 0.06390616 0.04196597 0.03018332 0.06964262 0.0618911
 0.09965106 0.04890566 0.0301833  0.05821608 0.04195875 0.06551945
 0.04197165 0.04890559 0.04197225 0.05989458 0.06505746 0.04197226
 0.04890569 0.03018333 0.08902612 0.04197226 0.06514677 0.09599014
 0.06291439 0.04197224 0.06988432 0.04890569 0.04196215 0.06511325
 0.0419723  0.04816095 0.03018333 0.07429326 0.03018332 0.03018328
 0.04174581 0.04174304]
tr_loss:[0.077341   0.04484363 0.06759222 0.02755183 0.07045677 0.04875378
 0.03472781 0.05388778 0.03472786 0.03472786 0.04477894 0.03472784
 0.07099193 0.05916234 0.0538784  0.04484474 0.06214535 0.06199608
 0.03472783 0.05399777 0.05424075 0.08313935 0.04484371 0.0732046
 0.05743133 0.02756915 0.04641513 0.04641515 0.0347278  0.06870057
 0.04484368 0.06870051 0.06870057 0.05992051 0.06870054 0.02727629
 0.04477894 0.03472783 0.05580392 0.05377812 0.05352592 0.05397604
 0.04477897 0.03472782 0.04477898 0.07188462 0.04484367 0.02755183
 0.03472779 0.05378886]
tr_loss:[0.0675154  0.02985891 0.04466582 0.0416136  0.03100656 0.09017111
 0.05629884 0.04161362 0.02985892 0.04879018 0.03118567 0.06483951
 0.04461795 0.06331842 0.06419468 0.04879014 0.04707702 0.0416136
 0.0310066  0.04754671 0.08332084 0.0310066  0.04410858 0.04694876
 0.04240205 0.02985891 0.04719536 0.06564888 0.0765658  0.07261528
 0.0310066  0.04161568 0.04466569 0.04175626 0.04161362 0.04703566
 0.05941438 0.03100656 0.06567106 0.04879019 0.10374775 0.04726599
 0.02985893 0.09188247 0.04161363 0.06539138 0.02985877 0.06858395
 0.04707904 0.03100664]
tr_loss:[0.07063381 0.06769733 0.03818028 0.027315   0.06563969 0.05812523
 0.03812721 0.02751127 0.02731435 0.05277361 0.04451573 0.04522622
 0.02731431 0.04451571 0.03547216 0.02731431 0.02731436 0.0588029
 0.05192578 0.07532746 0.0273143  0.09448324 0.03810934 0.03692076
 0.05277354 0.04451576 0.03125011 0.02427696 0.06026653 0.06406452
 0.04923452 0.03486202 0.04758053 0.04459667 0.02731433 0.02731433
 0.0444504  0.04933418 0.04516581 0.03815231 0.04451573 0.05333788
 0.07768555 0.05277354 0.04451571 0.04889303 0.04889212 0.0278666
 0.04451575 0.04451573]
tr_loss:[0.04702235 0.0251759  0.03674319 0.01907544 0.04799976 0.03668172
 0.02517625 0.02517624 0.0408646  0.03543547 0.03685028 0.0271751
 0.03557334 0.03684824 0.02517622 0.02717509 0.02517617 0.0500825
 0.02471205 0.05210758 0.03549914 0.03701191 0.04327948 0.03557315
 0.05013269 0.02718754 0.02517625 0.02517623 0.03799336 0.02717512
 0.01907542 0.02517581 0.03557335 0.03620223 0.0389817  0.02517624
 0.03557334 0.03831489 0.03557333 0.01907543 0.06224479 0.03557275
 0.03768448 0.01907544 0.01907545 0.025169   0.06893732 0.0389542
 0.02717509 0.03768452]
tr_loss:[0.03725497 0.0534601  0.0556383  0.02988591 0.02988594 0.05787008
 0.0284778  0.03725498 0.03469886 0.02988598 0.03471383 0.03389837
 0.03471623 0.03497521 0.02988595 0.0284778  0.03225511 0.03497521
 0.03473697 0.06992995 0.02847778 0.03725495 0.03473549 0.03238767
 0.03725494 0.03466422 0.03725494 0.02946684 0.02626455 0.05433027
 0.03725494 0.05022856 0.03825109 0.03725495 0.02988596 0.02988594
 0.03491028 0.0632413  0.0290775  0.05345628 0.02842521 0.03492938
 0.02988598 0.02988598 0.01332402 0.03475598 0.04411219 0.02847884
 0.02988593 0.02847781]
tr_loss:[0.03336285 0.02873444 0.05341538 0.03392693 0.03335981 0.03608811
 0.07684018 0.05563205 0.04082925 0.0134299  0.03369524 0.04092365
 0.07892175 0.05076237 0.04082926 0.06329558 0.0287344  0.03336377
 0.03336374 0.03383601 0.03464016 0.0339311  0.04082928 0.02873443
 0.03369526 0.02873445 0.07000697 0.03464017 0.03217791 0.03464014
 0.02873442 0.03464017 0.05629802 0.03835431 0.04082923 0.03589054
 0.03589053 0.03589051 0.04082928 0.04082926 0.04476191 0.03336374
 0.0338503  0.01342991 0.04201322 0.0346402  0.02873442 0.02873443
 0.05502625 0.04908673]
tr_loss:[0.03938757 0.04490849 0.04733635 0.03529686 0.03529911 0.02983112
 0.0818748  0.02983112 0.03791688 0.03768701 0.04474145 0.04016175
 0.03580759 0.03562857 0.03529171 0.03530054 0.04185034 0.01744379
 0.04026658 0.02983109 0.02983108 0.03938757 0.06739384 0.04111541
 0.02983111 0.03529811 0.03938753 0.03701983 0.04474161 0.03938758
 0.03938759 0.03890823 0.03782151 0.05000056 0.03767502 0.03938757
 0.01673815 0.0298311  0.05846141 0.04356129 0.03765466 0.04474158
 0.03938734 0.0447416  0.05132849 0.04474161 0.03776541 0.04474158
 0.04485065 0.04474164]
tr_loss:[0.02754634 0.03502369 0.03685978 0.04275078 0.02754631 0.03871208
 0.04275519 0.04957944 0.03685986 0.04058901 0.04739493 0.03908695
 0.03685986 0.03443775 0.0387115  0.06854334 0.02754629 0.04090012
 0.04160017 0.02754628 0.04258544 0.04169486 0.03871203 0.04272814
 0.04275523 0.03502362 0.03502368 0.0387122  0.03502347 0.04085313
 0.04074674 0.04275521 0.03819895 0.04049376 0.0400895  0.03684892
 0.06192672 0.03871221 0.03685984 0.07715268 0.01596064 0.03871224
 0.04385814 0.03786226 0.04189472 0.04012299 0.04499547 0.02754633
 0.04023976 0.03685981]
tr_loss:[0.04798203 0.03623285 0.03191185 0.03191153 0.05590324 0.04082083
 0.0412104  0.036233   0.03191155 0.03345394 0.03546325 0.03345394
 0.05921398 0.02241097 0.03623302 0.02241094 0.03345396 0.04207128
 0.03191155 0.02241096 0.0408254  0.03191151 0.06288006 0.03289517
 0.03343529 0.03623297 0.07280554 0.03191153 0.04246563 0.0334539
 0.03628757 0.04088141 0.06780289 0.01261657 0.03345391 0.03622278
 0.03808541 0.0224032  0.02241143 0.04280501 0.03537257 0.02241096
 0.05042393 0.05604187 0.0405692  0.03656185 0.03623298 0.03545569
 0.03623296 0.02241096]
tr_loss:[0.03329881 0.03569955 0.03289159 0.03301608 0.03919021 0.0405454
 0.05319351 0.05425991 0.03329878 0.0176557  0.03301609 0.04084478
 0.04222082 0.03057236 0.04066693 0.01818168 0.03057145 0.04052212
 0.03301609 0.01765573 0.0332988  0.0307119  0.04094183 0.04060936
 0.03057142 0.05273135 0.03057146 0.01230257 0.03569955 0.03569953
 0.03262768 0.03057148 0.0326922  0.03329291 0.05733885 0.01765572
 0.03206402 0.04166403 0.03057144 0.03327661 0.03803045 0.04057681
 0.01681391 0.04502099 0.03057148 0.03057145 0.01765571 0.01214132
 0.0332988  0.01210058]
tr_loss:[0.02684175 0.03937531 0.01261382 0.03272243 0.01467287 0.0491435
 0.07730873 0.06385073 0.03042564 0.0304252  0.03946226 0.01465226
 0.02895763 0.05244613 0.03929232 0.06076737 0.02895766 0.02684171
 0.05546115 0.01261384 0.02682685 0.05615706 0.01467088 0.02227176
 0.01467176 0.02684175 0.02572831 0.02895641 0.01261383 0.02895765
 0.02671087 0.02895765 0.01467086 0.03042566 0.05151754 0.02836063
 0.02895452 0.04885698 0.02881148 0.03950027 0.03040941 0.03042566
 0.02684174 0.03042564 0.03941971 0.03041198 0.0289557  0.03395217
 0.02661907 0.04312992]
tr_loss:[0.03264603 0.03879889 0.02510211 0.04839544 0.01379521 0.02348049
 0.02581627 0.02215465 0.02526494 0.02510208 0.06360321 0.02510211
 0.03049954 0.02510208 0.03642406 0.06172984 0.04574583 0.0622886
 0.02581629 0.02537838 0.01379497 0.04545867 0.0137952  0.03049952
 0.02581628 0.0137952  0.02581628 0.03554862 0.0234805  0.02581628
 0.02667021 0.04494456 0.01413853 0.02348009 0.02510209 0.02348051
 0.03049954 0.02303568 0.02343442 0.03753478 0.0251021  0.02526408
 0.03770631 0.02510208 0.01379521 0.01379691 0.01379521 0.01414145
 0.03753362 0.0258104 ]
tr_loss:[0.04458922 0.04134313 0.03193596 0.0216235  0.03529081 0.01530176
 0.03501076 0.01530175 0.02342884 0.02884471 0.07471211 0.02161882
 0.03537004 0.02342888 0.01530292 0.02342885 0.03523306 0.05454025
 0.02739326 0.03299015 0.03792294 0.01530175 0.03533677 0.02739369
 0.03551586 0.02162346 0.02162348 0.02739126 0.02152862 0.0288447
 0.01791798 0.0288447  0.0216235  0.02162331 0.0396288  0.035191
 0.0216235  0.01530175 0.0216063  0.02739327 0.0153016  0.07985003
 0.02161212 0.04216527 0.01791801 0.03526241 0.02739327 0.01791801
 0.01530174 0.02137368]
tr_loss:[0.02812217 0.02814175 0.01589023 0.0203416  0.03661698 0.04970348
 0.03411217 0.02553121 0.01589022 0.02034748 0.02781172 0.027911
 0.03410468 0.01589023 0.01543236 0.03602269 0.02798059 0.03700591
 0.0653214  0.02772208 0.01601669 0.02802405 0.05165863 0.02772635
 0.0277221  0.02819821 0.027953   0.03021558 0.02770987 0.02553119
 0.02034161 0.0203415  0.03979696 0.02034506 0.03363929 0.01589023
 0.0255322  0.02793225 0.01589024 0.02792716 0.03508954 0.03945276
 0.03410469 0.01589024 0.02799725 0.04129578 0.02767796 0.02034162
 0.02772208 0.02788323]
tr_loss:[0.03547193 0.02144717 0.02520884 0.03360583 0.02501844 0.05474538
 0.03114828 0.01901788 0.03603976 0.03071395 0.0239458  0.02504051
 0.02882622 0.02506214 0.02159228 0.06735526 0.05113323 0.05313875
 0.03841233 0.02159233 0.030714   0.04289831 0.02939537 0.04755063
 0.02268714 0.03071396 0.02939372 0.05339627 0.0190179  0.02510402
 0.06128075 0.02176777 0.03508691 0.06294626 0.02939362 0.01910688
 0.05208668 0.01901781 0.03841411 0.03841228 0.02939359 0.02499118
 0.02275208 0.05690441 0.02500525 0.0190316  0.02940339 0.02534081
 0.01901788 0.01901789]
tr_loss:[0.02870863 0.04138512 0.02870864 0.02003814 0.02003809 0.04139904
 0.02003814 0.03783743 0.01894852 0.02440163 0.0228621  0.02003808
 0.02526269 0.0312921  0.02915634 0.02252396 0.02366601 0.03324053
 0.03129209 0.03129211 0.02870869 0.02870867 0.03129208 0.05838195
 0.01893908 0.03129208 0.04699982 0.03309353 0.02252401 0.05311518
 0.03129208 0.03129167 0.0244696  0.02912146 0.01894872 0.03865347
 0.02870829 0.03865001 0.02436676 0.03129207 0.03210846 0.03060979
 0.02526943 0.02003809 0.02013344 0.0200381  0.0200381  0.0247284
 0.03129211 0.02702926]
tr_loss:[0.0261101  0.02529173 0.03625714 0.0374246  0.01976308 0.02506033
 0.02559378 0.01996099 0.05275158 0.03577176 0.03742461 0.02678388
 0.03934578 0.0252374  0.02514276 0.03765593 0.02528835 0.02534347
 0.03097603 0.02611012 0.02524077 0.01996721 0.02678386 0.02500158
 0.01981553 0.06873792 0.03480066 0.04258118 0.01976307 0.04728661
 0.01976309 0.06476939 0.01996668 0.02611017 0.03407321 0.01976314
 0.02446205 0.01970187 0.03012218 0.01853408 0.01976308 0.02611092
 0.01976312 0.03709896 0.01976311 0.04716513 0.03742463 0.0357744
 0.01949497 0.02524474]
tr_loss:[0.01824501 0.03963004 0.02432071 0.01905527 0.02210521 0.03425386
 0.04714232 0.0252797  0.018245   0.03279848 0.06026764 0.018245
 0.02178207 0.02432069 0.03669689 0.0501147  0.0327985  0.0221052
 0.02202566 0.01267161 0.02432069 0.01899504 0.05921075 0.01824501
 0.01267034 0.03294013 0.02201248 0.0541342  0.01905964 0.03255217
 0.02432066 0.02441242 0.02210517 0.02262562 0.0409186  0.01905964
 0.03348409 0.04354011 0.01899021 0.02195687 0.03935155 0.05383692
 0.01905965 0.02432065 0.05235976 0.01905854 0.04154354 0.053483
 0.01533102 0.0243207 ]
text_input.shape
(1700, 14400)
learning_input_tmp.shape
(1700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1700, 80)
learning_output.shape
(750, 80)
Model: "sequential_36"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_36 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[0.77227664 0.77149457 0.6162389  0.71647996 0.7722766  0.74921817
 0.7455986  0.71352684 0.77113473 0.70446455 0.7164731  0.7135267
 0.7224995  0.71899116 0.7125332  0.71339095 0.7580277  0.71688443
 0.7722767  0.6271338  0.7164818  0.7045506  0.7044485  0.77353585
 0.7188641  0.7164726  0.70600665 0.6909091  0.74559855 0.713523
 0.74559855 0.71737397 0.7580276  0.7024176  0.7164717  0.7044417
 0.7164715  0.6229659  0.7580276  0.7722766  0.6535288  0.6850133
 0.60037464 0.77236044 0.67776316 0.71822494 0.7231687  0.71361
 0.75802773 0.71352684]
tr_loss:[0.43194515 0.5095681  0.56573266 0.56525743 0.43157548 0.5621399
 0.43447796 0.43129522 0.5479385  0.50961834 0.42205983 0.5497354
 0.45221242 0.4610257  0.49456397 0.5494283  0.5657326  0.54095256
 0.4931622  0.43161735 0.42260885 0.54253095 0.50961894 0.48148555
 0.50961906 0.56213963 0.43120155 0.54793847 0.4481514  0.4313898
 0.5494283  0.46207967 0.49316245 0.4313189  0.50961894 0.4315508
 0.5494282  0.5494283  0.5494277  0.4931662  0.54854983 0.43465918
 0.4322783  0.5092277  0.46313637 0.4312252  0.54942816 0.45006686
 0.49322662 0.4116531 ]
tr_loss:[0.19572355 0.24917547 0.20096898 0.20845485 0.2553993  0.23408374
 0.27017912 0.25663337 0.2627496  0.27017915 0.2101027  0.22518103
 0.24917555 0.2701791  0.2701791  0.2566333  0.26274955 0.23401129
 0.27017912 0.21110503 0.23401122 0.27017894 0.26274958 0.23401125
 0.20359866 0.25663328 0.19745024 0.23401126 0.20306739 0.25663334
 0.2701791  0.25878    0.20569897 0.1988532  0.20372911 0.25663334
 0.19638342 0.24917552 0.2566333  0.22992706 0.24917552 0.25878006
 0.256631   0.22533509 0.1996511  0.24645329 0.19487438 0.20577307
 0.22204809 0.23401117]
tr_loss:[0.16236751 0.15938795 0.16266914 0.14031033 0.17319633 0.16266605
 0.16236745 0.15935245 0.16236751 0.16266933 0.15089801 0.16236773
 0.15040901 0.1484751  0.1626693  0.16236751 0.15022552 0.17318198
 0.15041035 0.17319396 0.17882311 0.15336339 0.15935242 0.14123693
 0.15003541 0.16266932 0.16261788 0.15038309 0.17315975 0.16266933
 0.15938804 0.15593033 0.17319661 0.15618846 0.1731966  0.1482255
 0.1503804  0.14929955 0.1501473  0.1624058  0.17319658 0.13431187
 0.17319651 0.1623677  0.14924292 0.15938799 0.17319593 0.17319654
 0.17319663 0.1731954 ]
tr_loss:[0.11980498 0.12797514 0.10104744 0.0948834  0.12238374 0.10104759
 0.1010474  0.11627188 0.10303372 0.12600325 0.12256564 0.10749342
 0.127975   0.12045662 0.11391159 0.10104744 0.12797506 0.12797508
 0.1010474  0.11980499 0.12167142 0.10015766 0.11617408 0.12139072
 0.12252919 0.10432913 0.11980496 0.10104804 0.12797493 0.12797508
 0.12194093 0.12797262 0.10104746 0.12217398 0.10470108 0.1019505
 0.10104747 0.12186177 0.12223045 0.13114838 0.12797497 0.12793295
 0.10749204 0.12797484 0.1074921  0.10104747 0.10749201 0.10749204
 0.11565928 0.10720877]
tr_loss:[0.09410289 0.09928536 0.07923599 0.07288779 0.0765525  0.0887547
 0.08969475 0.0962589  0.08557186 0.09664896 0.07288792 0.09695996
 0.06791285 0.06791284 0.0697367  0.08557056 0.11338588 0.08875351
 0.09231298 0.09627186 0.06791282 0.06973569 0.09638555 0.0855719
 0.1014393  0.06973667 0.06767702 0.07214047 0.0697367  0.08572543
 0.0817885  0.13059485 0.0844047  0.08875521 0.06791289 0.08557186
 0.06791284 0.0866389  0.08378743 0.09632412 0.06791285 0.079233
 0.08024571 0.08875299 0.09638345 0.05296204 0.08903267 0.06339817
 0.08875541 0.0923309 ]
tr_loss:[0.08943751 0.08819813 0.06921087 0.07629407 0.06184343 0.08868386
 0.06924947 0.05499616 0.09326252 0.06162848 0.073795   0.05500559
 0.09725745 0.08845767 0.07207279 0.08865443 0.06921081 0.07629398
 0.06921084 0.06431854 0.07920555 0.06090261 0.08869679 0.08872525
 0.08877969 0.07205038 0.08870105 0.06170392 0.08586783 0.05477126
 0.13154534 0.07207283 0.06170397 0.06170396 0.09131825 0.08444671
 0.06921084 0.08533181 0.08862673 0.061704   0.06025072 0.08787109
 0.09121854 0.06170396 0.04675221 0.07625197 0.05500709 0.06924618
 0.08422043 0.07629404]
tr_loss:[0.05440159 0.08356585 0.06939137 0.09756409 0.06636657 0.07121367
 0.06516661 0.07063305 0.06986795 0.06939138 0.06535661 0.06535658
 0.09994166 0.09604342 0.08811484 0.07710056 0.07710053 0.08367922
 0.08551173 0.07957336 0.05440157 0.07063309 0.06535662 0.07715125
 0.07710052 0.07063334 0.06535661 0.08357482 0.05461553 0.07707696
 0.09186347 0.0693914  0.09402941 0.07710047 0.07710052 0.07071257
 0.08215521 0.07709993 0.07121364 0.07710054 0.1330919  0.07726826
 0.0836212  0.13731456 0.08155201 0.06939138 0.06939141 0.06939138
 0.07709889 0.06535657]
tr_loss:[0.09714448 0.08665302 0.07701112 0.05944277 0.07988551 0.07380337
 0.08547581 0.0740979  0.07353643 0.05944277 0.10943468 0.09511272
 0.0866463  0.05944278 0.07701115 0.05946372 0.05944276 0.06238123
 0.07701112 0.08486976 0.0963682  0.05947379 0.0722958  0.07353643
 0.06238119 0.08202241 0.07353648 0.08666931 0.08693467 0.07740614
 0.10121977 0.09509816 0.07315394 0.08734132 0.08547582 0.07701195
 0.05916453 0.05944275 0.05944248 0.09631405 0.08380087 0.08667456
 0.07701112 0.08658565 0.08547585 0.09545763 0.05944272 0.07353644
 0.1342732  0.08682541]
tr_loss:[0.07999188 0.08153079 0.06507544 0.08004002 0.07999957 0.04285296
 0.06503411 0.08153079 0.06920613 0.08006307 0.08005894 0.08953442
 0.07029656 0.08153082 0.05009173 0.08152428 0.0692062  0.057393
 0.0573917  0.06920616 0.08025262 0.05009169 0.08010288 0.08026835
 0.08153081 0.08153078 0.05366285 0.09236663 0.06920619 0.09003612
 0.05008732 0.05366286 0.08037205 0.08009442 0.08995398 0.06920616
 0.06522395 0.06505267 0.06505252 0.08994231 0.05009121 0.0718867
 0.07659308 0.08805494 0.08139455 0.07802261 0.08153077 0.06505246
 0.08004784 0.06505252]
tr_loss:[0.07513363 0.08300927 0.07488648 0.06028874 0.06028489 0.10731821
 0.07491879 0.06023228 0.06023228 0.07935083 0.06028871 0.07714492
 0.07688365 0.08921276 0.06028583 0.07730712 0.04569359 0.06028875
 0.08816999 0.05379069 0.04688802 0.06028874 0.04267777 0.06028884
 0.11184718 0.0602323  0.06028871 0.07545579 0.06023227 0.07714494
 0.0602887  0.09135716 0.04569361 0.07483492 0.06028878 0.05391171
 0.07396994 0.07484041 0.04569351 0.04688802 0.05391172 0.06248116
 0.07714494 0.06028876 0.09237732 0.09153893 0.05759717 0.06028869
 0.046888   0.06028879]
tr_loss:[0.07897428 0.04758688 0.05736239 0.06309488 0.08908672 0.07938822
 0.05759362 0.05736239 0.07170285 0.04527891 0.07718354 0.04384742
 0.05653278 0.04384743 0.11215172 0.05736236 0.07938828 0.07171486
 0.07170779 0.05736234 0.05827443 0.08624968 0.05759367 0.06058489
 0.0719123  0.0565328  0.04754085 0.07169651 0.07784688 0.06311239
 0.07918344 0.04758692 0.05736236 0.06807102 0.07907526 0.04640307
 0.0475869  0.0631127  0.05653278 0.05736236 0.08184095 0.0888409
 0.07938445 0.07168899 0.04758693 0.05653279 0.05653276 0.05654004
 0.05735359 0.0793883 ]
tr_loss:[0.07027491 0.05739739 0.05739411 0.0810533  0.07017386 0.05557747
 0.07049152 0.07018679 0.04977911 0.07020971 0.05557749 0.08125132
 0.0810533  0.04962247 0.043077   0.05360378 0.05504933 0.0573941
 0.06568592 0.11099072 0.07262485 0.08105335 0.04977911 0.04977911
 0.06568585 0.05557743 0.07049909 0.08105336 0.06568592 0.05557948
 0.04307702 0.05739415 0.07016946 0.05739411 0.0497768  0.05739412
 0.06353639 0.05466599 0.05557749 0.05739411 0.04971933 0.06001397
 0.0497754  0.08105328 0.07701092 0.07993539 0.05739411 0.05557748
 0.05739412 0.05557741]
tr_loss:[0.06453806 0.04970125 0.07230086 0.06486697 0.07045688 0.0464053
 0.07248424 0.07248406 0.04969149 0.05375471 0.04968641 0.04707152
 0.04971541 0.06001996 0.08319469 0.08091798 0.07943901 0.06001996
 0.06001997 0.10990815 0.11590238 0.08686118 0.05320326 0.0496864
 0.0532032  0.04968639 0.05320321 0.07248421 0.05320325 0.04026816
 0.04968631 0.04968638 0.04707151 0.06896474 0.09057675 0.07248369
 0.04684597 0.08380848 0.06001996 0.05319236 0.03551837 0.04707148
 0.05375473 0.04968637 0.07248406 0.07241045 0.06002    0.0496867
 0.06402843 0.03551836]
tr_loss:[0.05544836 0.0470043  0.05478313 0.08137802 0.05863609 0.05543739
 0.0554374  0.06302484 0.06350768 0.06469543 0.05574108 0.04126254
 0.04108925 0.06972481 0.08407513 0.04116922 0.0411698  0.04106162
 0.07165922 0.06311725 0.04304012 0.05543739 0.04485705 0.04485703
 0.04485704 0.04700434 0.0602563  0.05863111 0.05543736 0.04108652
 0.07176939 0.05510335 0.04700832 0.06926889 0.05543744 0.0653257
 0.05571305 0.04484548 0.04485706 0.07430496 0.0661872  0.04700455
 0.04126151 0.05543741 0.07561959 0.04108924 0.0411692  0.0411692
 0.04117123 0.0554374 ]
tr_loss:[0.04227891 0.03514078 0.04143653 0.03206867 0.04103148 0.03202487
 0.05951007 0.04143652 0.03206863 0.04143655 0.03580774 0.03202872
 0.05139742 0.0636019  0.09716002 0.05063181 0.03206873 0.03206864
 0.05138398 0.09279347 0.04119012 0.04103047 0.04143656 0.03828498
 0.03184825 0.04143655 0.03580777 0.05858644 0.0382954  0.03826916
 0.03206864 0.0320249  0.0666376  0.05139498 0.03206866 0.04892523
 0.03829545 0.07723583 0.03206863 0.04103044 0.05139722 0.05139256
 0.04883449 0.03829543 0.03377574 0.04143651 0.05149717 0.05316023
 0.04143657 0.03829543]
tr_loss:[0.07362173 0.05292792 0.03963517 0.04985644 0.03755176 0.03895329
 0.03729425 0.0389578  0.05724071 0.04989013 0.03557206 0.04983302
 0.04983161 0.09468196 0.02454234 0.04875465 0.0643215  0.03656752
 0.06821889 0.04984801 0.03943298 0.05760382 0.04989683 0.03943294
 0.03943598 0.06033761 0.03755175 0.03895323 0.03597138 0.0358362
 0.0389533  0.03583617 0.03755171 0.06572027 0.03943291 0.03754994
 0.05245314 0.03583618 0.02454226 0.0635929  0.0541231  0.03583612
 0.02454227 0.06953965 0.03597095 0.06618752 0.03755175 0.03739565
 0.0245423  0.0498272 ]
tr_loss:[0.05713673 0.03908383 0.04354309 0.0416377  0.06140697 0.03675496
 0.04178765 0.03675499 0.02532454 0.036755   0.05627625 0.03675499
 0.03908383 0.04164924 0.03675501 0.05161317 0.07552999 0.03908383
 0.04162349 0.05161218 0.09534135 0.04353481 0.03908384 0.0447946
 0.05996836 0.03908382 0.04178767 0.03908296 0.04178765 0.05821751
 0.04353479 0.036755   0.04164917 0.04370504 0.02613318 0.02613321
 0.02613317 0.04164918 0.0261332  0.05169892 0.04164883 0.07201433
 0.04755272 0.04164916 0.03675504 0.04164924 0.03730267 0.04178767
 0.03896898 0.05998391]
tr_loss:[0.03723837 0.07678889 0.03463208 0.03611676 0.04338598 0.06339632
 0.0433225  0.0433225  0.05648891 0.04877002 0.03729906 0.05656312
 0.03779674 0.0433225  0.06524716 0.08049983 0.07055124 0.07109319
 0.08177601 0.03778606 0.06448157 0.05646599 0.03061649 0.08679051
 0.05647938 0.0433225  0.03061648 0.03780324 0.05646688 0.04402148
 0.03061647 0.05661713 0.05394359 0.05648087 0.03061638 0.04603585
 0.03061649 0.04332251 0.065145   0.07265808 0.0433225  0.04172153
 0.05648218 0.06038751 0.03780384 0.07151019 0.05646905 0.08045444
 0.04603587 0.07731868]
tr_loss:[0.0367416  0.0367417  0.0398711  0.03984976 0.03674155 0.05336918
 0.03674168 0.06647823 0.03095212 0.04058845 0.04068498 0.05295356
 0.03095211 0.05336948 0.07509391 0.0709966  0.03458963 0.03458966
 0.05336977 0.05031602 0.03103112 0.08636401 0.03674167 0.05336744
 0.05337458 0.0409044  0.04077861 0.03459036 0.05336872 0.07145859
 0.03466103 0.05336621 0.04090441 0.06538658 0.08583649 0.06135897
 0.04068501 0.04090437 0.06450403 0.08102807 0.04068498 0.05337024
 0.03095211 0.0730311  0.06569012 0.06597057 0.04090442 0.0649551
 0.04163573 0.04090443]
tr_loss:[0.03536579 0.03526452 0.03770829 0.02974312 0.03536566 0.05279471
 0.02974309 0.0726843  0.04050784 0.03668436 0.03526222 0.05261268
 0.02974314 0.03526483 0.07393224 0.07505244 0.06531828 0.06792283
 0.0768201  0.07631695 0.04050761 0.03520861 0.03526484 0.05270784
 0.04000316 0.05271459 0.03519858 0.05081285 0.07562909 0.02974309
 0.02974311 0.02974311 0.02976894 0.04210923 0.06012959 0.05274604
 0.03536563 0.07919132 0.06939068 0.05887368 0.03526485 0.04066823
 0.0379564  0.04050783 0.03536565 0.05272489 0.03526485 0.04210923
 0.07026269 0.0405078 ]
tr_loss:[0.04996173 0.0291903  0.03793366 0.03869189 0.02251915 0.0474685
 0.02774805 0.02715402 0.03812983 0.02774939 0.02919054 0.04998334
 0.0580969  0.03813374 0.03813367 0.02773475 0.06771874 0.0277495
 0.0381337  0.03674154 0.05000396 0.02919052 0.0277495  0.02919053
 0.05002344 0.02918702 0.0676678  0.06559987 0.05001928 0.03900349
 0.02447314 0.02919054 0.07636718 0.03674152 0.02251913 0.05809181
 0.02774929 0.04996405 0.02919306 0.07023317 0.02919056 0.02919053
 0.02919055 0.07181498 0.02251912 0.03813372 0.02774882 0.04996678
 0.0500768  0.03817959]
tr_loss:[0.05163039 0.06765477 0.02593552 0.03853352 0.08387414 0.04675622
 0.06895389 0.03956415 0.04941015 0.02432461 0.01871026 0.03939392
 0.02686111 0.01870559 0.02432461 0.08982258 0.01870563 0.02593554
 0.03955462 0.03072396 0.0423292  0.04304312 0.02593555 0.02593573
 0.02609396 0.03939291 0.0243017  0.01870643 0.02432463 0.03956447
 0.05283629 0.0187055  0.0187056  0.01870559 0.03956451 0.05829365
 0.02593555 0.02593556 0.09531824 0.06935431 0.04863161 0.02428116
 0.01870561 0.01870559 0.01870559 0.01870561 0.01870557 0.04871982
 0.06568049 0.02724598]
tr_loss:[0.02362447 0.03467987 0.06997262 0.04211392 0.02245606 0.01412136
 0.03413643 0.02075334 0.06536706 0.04937837 0.0141214  0.01412136
 0.01412135 0.04992314 0.04207804 0.02075334 0.0561815  0.02256293
 0.02075338 0.01412127 0.03777619 0.02245608 0.02072527 0.06679505
 0.0632948  0.01412136 0.05008726 0.06566261 0.03777621 0.05677319
 0.03777618 0.01412136 0.02262416 0.02362447 0.06118832 0.01413239
 0.02075273 0.06174747 0.03777617 0.01412135 0.02075337 0.01411408
 0.03777619 0.02056796 0.01412136 0.07084016 0.02075338 0.01412136
 0.05502786 0.02245608]
tr_loss:[0.02507636 0.02507887 0.03097008 0.03153639 0.03153639 0.01614162
 0.02507623 0.03970394 0.04495231 0.0250764  0.04339611 0.03973576
 0.03067422 0.06116633 0.02507635 0.02557648 0.03272383 0.02504644
 0.02217415 0.02217273 0.02507662 0.02557653 0.0733143  0.03874515
 0.02507637 0.03884339 0.07351365 0.02217416 0.02557653 0.03874071
 0.02217418 0.0464673  0.0315364  0.02507633 0.0397039  0.01614162
 0.02180518 0.04661516 0.02217406 0.0397042  0.03097004 0.05667828
 0.03875644 0.01614163 0.05560153 0.01614162 0.02507638 0.03097004
 0.03871534 0.02507635]
tr_loss:[0.0373992  0.02764846 0.0365338  0.04744972 0.05650876 0.05069368
 0.01988198 0.06560859 0.02644424 0.02644423 0.01988201 0.04503533
 0.02007004 0.02360427 0.02366209 0.0364382  0.01988198 0.02366296
 0.02644421 0.03969283 0.04809717 0.03477182 0.01988828 0.02641531
 0.02362048 0.04626269 0.02917266 0.02644425 0.03741309 0.03738476
 0.02366298 0.02644425 0.01988129 0.02644424 0.01988282 0.02918213
 0.019882   0.02623106 0.05796695 0.03726202 0.02366295 0.05813624
 0.02644424 0.02366295 0.04867373 0.02366292 0.03137563 0.03969703
 0.04297943 0.03738129]
tr_loss:[0.02138419 0.03882786 0.03714201 0.03800733 0.05301617 0.03680173
 0.0223086  0.02229594 0.02139161 0.02929432 0.02230861 0.0380073
 0.02230862 0.04779161 0.02369195 0.02388772 0.02332022 0.03672976
 0.02634881 0.0238352  0.02634883 0.03800745 0.02230859 0.03687138
 0.03685062 0.03800732 0.03694218 0.04836531 0.02634881 0.06315185
 0.02388762 0.02929434 0.03800732 0.03692243 0.03800748 0.04658964
 0.03802721 0.02138419 0.02230859 0.02929434 0.02634987 0.04067155
 0.02634886 0.02929435 0.03693163 0.03800733 0.03800734 0.03800731
 0.02388772 0.03800734]
tr_loss:[0.02553765 0.03426302 0.03549501 0.06480718 0.03639764 0.03730731
 0.03718436 0.03549502 0.03186125 0.04454064 0.0249741  0.03493776
 0.02824573 0.02553762 0.02553764 0.02824574 0.03549889 0.0504565
 0.03182492 0.03692671 0.02553762 0.03549504 0.05184903 0.06672631
 0.02824574 0.05977214 0.02553099 0.03186322 0.02390431 0.06646983
 0.03731819 0.02390431 0.02824574 0.02301293 0.02833685 0.05836825
 0.02553765 0.04918328 0.04969819 0.02553736 0.03553299 0.03580501
 0.03799878 0.02390429 0.03320373 0.02553765 0.03550271 0.03707537
 0.02390431 0.03186319]
tr_loss:[0.05914757 0.02535533 0.01998089 0.03195382 0.03475512 0.02152787
 0.05204377 0.03306228 0.02240961 0.03368784 0.03900786 0.02240958
 0.02535629 0.03776041 0.02845472 0.03522012 0.03309802 0.03236464
 0.03330249 0.02853438 0.02845469 0.02845468 0.03519941 0.01770617
 0.04494816 0.05724307 0.02240962 0.03438351 0.02536006 0.02844297
 0.01770616 0.07136848 0.02844825 0.02845469 0.04801153 0.03498744
 0.03835178 0.08548994 0.06906404 0.05035194 0.04710267 0.0350339
 0.07069154 0.05305371 0.04230866 0.02240961 0.02536006 0.0284547
 0.04503658 0.02240961]
tr_loss:[0.05890174 0.03153593 0.07434409 0.02793597 0.06101368 0.03184908
 0.04493968 0.03262749 0.01970816 0.03019221 0.02793958 0.0326822
 0.0324641  0.02462214 0.03268936 0.06648982 0.02793596 0.0691452
 0.01970816 0.03019163 0.03256813 0.01975664 0.0301919  0.04799387
 0.02501292 0.01807545 0.03268939 0.02793598 0.01970817 0.01807544
 0.02793649 0.01971261 0.01970818 0.01970818 0.02793598 0.04582925
 0.05248197 0.01970819 0.01807549 0.03268939 0.01807543 0.07100622
 0.02192108 0.02501295 0.01807542 0.03019221 0.01827676 0.03019219
 0.02838694 0.01805239]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1700 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1701, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1701 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1702, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1702 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1703, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1703 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1704, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1704 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1705, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1705 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1706, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1706 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1707, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1707 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1708, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1708 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1709, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1709 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1710, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1710 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1711, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1711 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1712, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1712 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1713, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1713 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1714, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1714 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1715, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1715 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1716, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1716 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1717, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1717 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1718, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1718 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1719, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1719 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1720, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1720 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1721, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1721 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1722, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1722 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1723, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1723 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1724, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1724 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1725, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1725 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1726, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1726 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1727, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1727 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1728, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1728 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1729, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1729 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1730, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1730 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1731, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1731 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1732, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1732 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1733, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1733 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1734, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1734 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1735, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1735 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1736, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1736 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1737, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1737 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1738, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1738 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1739, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1739 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1740, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1740 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1741, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1741 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1742, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1742 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1743, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1743 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1744, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1744 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1745, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1745 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1746, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1746 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1747, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1747 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1748, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1748 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1749, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1749 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1750, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1750 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1751, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1751 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1752, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1752 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1753, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1753 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1754, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1754 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1755, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1755 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1756, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1756 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1757, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1757 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1758, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1758 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1759, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1759 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1760, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1760 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1761, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1761 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1762, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1762 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1763, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1763 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1764, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1764 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1765, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1765 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1766, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1766 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1767, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1767 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1768, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1768 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1769, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1769 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1770, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1770 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1771, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1771 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1772, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1772 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1773, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1773 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1774, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1774 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1775, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1775 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1776, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1776 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1777, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1777 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1778, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1778 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1779, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1779 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1780, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1780 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1781, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1781 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1782, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1782 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1783, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1783 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1784, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1784 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1785, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1785 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1786, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1786 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1787, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1787 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1788, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1788 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1789, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1789 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1790, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1790 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1791, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1791 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1792, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1792 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1793, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1793 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1794, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1794 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1795, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1795 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1796, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1796 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1797, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1797 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1798, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1798 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1799, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1799 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1800, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-1700
text_input.shape
(1800, 14400)
learning_input_tmp.shape
(1800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1800, 80)
learning_output.shape
(750, 80)
Model: "sequential_37"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_37 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0322195  1.2406234  1.2483625  1.1603025  1.0680326  1.2304466
 1.2592866  1.0672086  1.2676523  0.9996023  1.1828749  1.2592871
 1.2406232  0.9912996  1.1505111  1.0716097  1.3534918  1.2592875
 1.2592871  1.0672225  0.96698713 1.3534877  0.98606616 1.296428
 1.3448135  1.2592871  1.2592869  1.1826191  1.2592869  1.2671788
 1.101371   1.259287   1.1505111  1.2671797  1.2406234  1.2671798
 1.2406232  1.0672467  1.2586606  1.1828747  1.1505113  1.2479868
 1.2930466  0.9961422  1.0718247  1.2406232  1.2417305  1.2592866
 1.2406232  1.2671806 ]
tr_loss:[0.6419865  0.588776   0.6723966  0.6187383  0.6746564  0.6939877
 0.7451141  0.56775886 0.61918247 0.64809954 0.57707214 0.64433366
 0.6184466  0.6200927  0.5204204  0.6307325  0.53560793 0.6191347
 0.55170274 0.5454407  0.5150723  0.67661417 0.59102696 0.61879957
 0.57662475 0.69398785 0.6307325  0.57529986 0.5802366  0.6200926
 0.61812174 0.67460316 0.5910268  0.64205045 0.61907953 0.67661417
 0.6419868  0.6188774  0.64077556 0.67710125 0.6939878  0.59102696
 0.6142387  0.6815571  0.57042825 0.641987   0.68111646 0.6419865
 0.63073254 0.69398767]
tr_loss:[0.40600032 0.38944915 0.38433748 0.3366378  0.34744316 0.4228193
 0.39116365 0.389457   0.3563847  0.4111364  0.37511197 0.34040967
 0.38943973 0.41113645 0.38943657 0.39595908 0.41113648 0.4034745
 0.35638466 0.38453478 0.38950208 0.38946787 0.38453525 0.3306121
 0.38902688 0.42282668 0.36383542 0.3845356  0.3845428  0.39931902
 0.4034853  0.3294317  0.40347475 0.3845349  0.41113633 0.42282686
 0.38453487 0.42352456 0.41113645 0.41113648 0.34015313 0.3845349
 0.38943034 0.38453624 0.38453498 0.3942603  0.3839013  0.38940996
 0.4234642  0.42281848]
tr_loss:[0.23186794 0.24997401 0.26773113 0.23910633 0.25219446 0.23366722
 0.25409183 0.2390879  0.23908786 0.25937945 0.23186703 0.25934
 0.2677311  0.24039678 0.23090677 0.251669   0.25938472 0.25219452
 0.23365748 0.2390879  0.24998435 0.2593794  0.2390881  0.25937942
 0.25219434 0.23808566 0.23570855 0.2677361  0.23186317 0.25167108
 0.22535637 0.21479838 0.26773113 0.22959356 0.20800953 0.25219446
 0.2593802  0.23665833 0.23117092 0.22535639 0.23366487 0.23895618
 0.22535631 0.25937945 0.26768428 0.26773113 0.23908786 0.25937945
 0.23908797 0.23908584]
tr_loss:[0.12927179 0.10642433 0.10662334 0.1319271  0.13766743 0.1283633
 0.13256642 0.11850263 0.13416831 0.11851247 0.11928792 0.12905604
 0.12906982 0.13813613 0.11323373 0.12852708 0.12501314 0.13766246
 0.11966052 0.13256478 0.1250131  0.12452023 0.13766739 0.14693086
 0.12378068 0.13209336 0.12935297 0.13256481 0.11851241 0.1283273
 0.14693132 0.10662339 0.13256481 0.10619831 0.11851237 0.13836968
 0.10662341 0.10650162 0.10649721 0.13766739 0.12501316 0.10649738
 0.11966053 0.13764544 0.13416858 0.13180597 0.1376674  0.12501311
 0.1196605  0.12901884]
tr_loss:[0.06545268 0.08863398 0.10199004 0.08196546 0.06545264 0.04631628
 0.08857377 0.09671973 0.0882386  0.09894093 0.06545266 0.0733549
 0.09868755 0.06545267 0.06430484 0.09501275 0.08846319 0.05865882
 0.09671967 0.09802086 0.09700068 0.06326511 0.06326511 0.05098475
 0.09872994 0.05865111 0.09595535 0.09671968 0.06549333 0.09523159
 0.06545267 0.09293769 0.09573311 0.0586511  0.0891478  0.09337308
 0.0922689  0.0632651  0.06430484 0.08857039 0.09671961 0.04691675
 0.09244785 0.08857372 0.05865113 0.09671968 0.06557415 0.08857374
 0.04630773 0.06430485]
tr_loss:[0.08299985 0.04714141 0.06815531 0.07625226 0.04439969 0.06970177
 0.0471414  0.0722198  0.08165856 0.04714143 0.05552419 0.05352532
 0.08313434 0.04714207 0.08265396 0.05352533 0.03248548 0.03303975
 0.08321556 0.06978489 0.04466629 0.04714564 0.06984905 0.05352533
 0.04714147 0.08623155 0.06768273 0.06970181 0.05352532 0.08617022
 0.08302855 0.06970187 0.06970181 0.05164148 0.03242539 0.06815545
 0.03233538 0.08276057 0.08180779 0.07781693 0.07806054 0.08379538
 0.04404246 0.06778112 0.05552418 0.05352535 0.06812718 0.06815539
 0.08297718 0.04929281]
tr_loss:[0.0427855  0.058829   0.07719128 0.07458286 0.05882903 0.04780155
 0.04775266 0.04903299 0.07442819 0.04775243 0.05883021 0.05324475
 0.04745705 0.05324477 0.05324476 0.08011965 0.04278553 0.04902684
 0.07466339 0.05506377 0.06736978 0.058829   0.05882905 0.06758983
 0.05310154 0.05324476 0.07405388 0.03918175 0.040036   0.04903338
 0.0391936  0.07443734 0.05925433 0.05882896 0.04761416 0.04775242
 0.04023513 0.04849651 0.05324478 0.08052397 0.04903328 0.04023514
 0.04903337 0.05194595 0.07163895 0.07444598 0.04005777 0.06530164
 0.05506381 0.05882894]
tr_loss:[0.05285979 0.05285976 0.04094638 0.03233111 0.05285979 0.05285979
 0.08233686 0.04866871 0.0486687  0.05350734 0.06694649 0.03482299
 0.04866872 0.05285981 0.03085866 0.04637327 0.05350731 0.0486687
 0.04866876 0.04866872 0.04457623 0.05285978 0.06923179 0.05350747
 0.06694059 0.04077247 0.04867252 0.05350726 0.04094637 0.06928884
 0.04866872 0.04094637 0.04867883 0.06909317 0.0688597  0.06955002
 0.03105407 0.07424124 0.03721485 0.04094637 0.03105407 0.06924337
 0.033059   0.04094638 0.03179735 0.08438469 0.05285978 0.0409154
 0.05285979 0.05285978]
tr_loss:[0.05054982 0.05054977 0.04133461 0.05054981 0.04424909 0.04133466
 0.03125529 0.04134636 0.04859324 0.04377108 0.04370994 0.04133464
 0.04133466 0.0656001  0.04427702 0.06748923 0.06999765 0.04370991
 0.04922342 0.04859319 0.04427698 0.06719033 0.05054978 0.05054976
 0.07493689 0.04427702 0.0505498  0.04064677 0.04922342 0.04133462
 0.03597524 0.05054982 0.05054977 0.05054975 0.06937669 0.04427675
 0.04136678 0.04922338 0.04879584 0.04922341 0.04133463 0.04230472
 0.04370995 0.04230484 0.04427166 0.02906441 0.09143424 0.06739964
 0.0290633  0.0698755 ]
tr_loss:[0.08628438 0.03938072 0.08003173 0.04327776 0.04686393 0.04961465
 0.04666836 0.06563016 0.04666836 0.06567656 0.0399973  0.04330848
 0.0461811  0.06574441 0.0399973  0.06570898 0.08461161 0.04618106
 0.0399973  0.03948088 0.04617842 0.03999736 0.04290037 0.04561163
 0.04961469 0.06560931 0.04618108 0.08654263 0.04961463 0.06618159
 0.04561163 0.04618109 0.04961466 0.03999731 0.05888983 0.04512295
 0.04666834 0.0353194  0.07974556 0.03108808 0.06601583 0.04666838
 0.04618096 0.06992128 0.04290073 0.04561167 0.04666894 0.04666837
 0.03999729 0.04618067]
tr_loss:[0.04334745 0.04334746 0.03521184 0.03187121 0.04004218 0.03567553
 0.03758704 0.06065563 0.04413393 0.04501272 0.04329602 0.03923491
 0.06074259 0.06716979 0.0450127  0.0317206  0.0392363  0.03758625
 0.04501272 0.04413393 0.04080129 0.057441   0.04501276 0.06070634
 0.0642225  0.03758623 0.05958783 0.03923486 0.03899327 0.03548067
 0.03758623 0.03521182 0.04413404 0.03758625 0.06069471 0.04501268
 0.03243528 0.07518726 0.06072559 0.06070951 0.05780093 0.06107098
 0.0317172  0.03321259 0.03794974 0.05744066 0.03765363 0.06071292
 0.04413388 0.06080992]
tr_loss:[0.02626615 0.03750106 0.02733515 0.05481674 0.03750285 0.03875409
 0.02733373 0.03519734 0.03749891 0.02733515 0.03734522 0.0387541
 0.05464153 0.02635675 0.02637262 0.02637256 0.0273352  0.03280027
 0.04038362 0.03519733 0.05502464 0.05472124 0.03734542 0.03734393
 0.0436856  0.02637262 0.03195029 0.06509963 0.02637262 0.0320082
 0.06739048 0.05481897 0.06142244 0.05497745 0.02733517 0.02733515
 0.05746142 0.03875409 0.03189959 0.02637263 0.02637259 0.03852578
 0.05540637 0.03247607 0.03733573 0.03734544 0.03734537 0.03734167
 0.05084829 0.06073565]
tr_loss:[0.02568211 0.03857851 0.05052333 0.05859716 0.02813982 0.03909035
 0.0382721  0.03576984 0.0679902  0.03685015 0.03892655 0.04241011
 0.02813981 0.03909039 0.05859189 0.03937037 0.07134242 0.02813979
 0.03705282 0.05608044 0.05854551 0.05899823 0.05855783 0.03703111
 0.05477218 0.05601751 0.04704976 0.05851348 0.06791703 0.02813981
 0.04705228 0.05543277 0.04704974 0.05516056 0.02568238 0.03909035
 0.0586411  0.03703113 0.03909036 0.03909041 0.02568208 0.02813982
 0.03856974 0.02568209 0.03943037 0.02813979 0.05531442 0.02568211
 0.06792203 0.03905855]
tr_loss:[0.0378935  0.06018939 0.03155575 0.02570727 0.04362945 0.03733666
 0.04907217 0.04088078 0.03229909 0.0347145  0.03154393 0.03229918
 0.03869877 0.03229921 0.05182995 0.02570727 0.03822231 0.05500038
 0.03824859 0.03229918 0.05108059 0.03398084 0.05213898 0.03229915
 0.0520116  0.03398087 0.04086897 0.05125148 0.04380127 0.05970347
 0.04039044 0.03154132 0.03229914 0.0382219  0.03229916 0.03674839
 0.05185277 0.03145952 0.04088077 0.03155571 0.05033965 0.06257173
 0.03471454 0.05204557 0.03627133 0.02569909 0.0515252  0.046839
 0.03155578 0.03465147]
tr_loss:[0.03026785 0.03964848 0.02850553 0.05227702 0.02405736 0.03043416
 0.04143636 0.03043413 0.03159318 0.04109062 0.03219672 0.03026786
 0.03043416 0.03026785 0.02850518 0.03159317 0.04345891 0.03026785
 0.0306417  0.03043415 0.04966804 0.05781262 0.03026784 0.02405687
 0.03678548 0.03159318 0.03045358 0.03039759 0.02834499 0.03195935
 0.03026783 0.03026786 0.0319282  0.03159466 0.03159315 0.02401243
 0.03159317 0.03199729 0.03043413 0.06300728 0.03131318 0.04587623
 0.03159318 0.05810361 0.04799065 0.03159318 0.03165339 0.03026785
 0.02851208 0.03026785]
tr_loss:[0.0329702  0.04520431 0.03284953 0.02338436 0.05211975 0.01988587
 0.03281163 0.04693381 0.05830307 0.02378247 0.02338435 0.02338433
 0.04824079 0.03280066 0.03313007 0.02143829 0.04057706 0.02143835
 0.03313008 0.0213735  0.02139435 0.01987998 0.02188634 0.02459035
 0.04633731 0.02464404 0.02115416 0.01986311 0.03287507 0.02338429
 0.03148938 0.02371901 0.04515549 0.02338434 0.03100259 0.0494219
 0.02299175 0.02143808 0.03100261 0.02143834 0.0329496  0.02037614
 0.03148941 0.0461284  0.02758687 0.02299175 0.03310214 0.03284681
 0.02054611 0.0331301 ]
tr_loss:[0.02625431 0.0247017  0.03147098 0.02822864 0.02712003 0.02550535
 0.03159832 0.03731905 0.03159829 0.01713295 0.02498237 0.02776264
 0.02818933 0.02033717 0.01601902 0.03159829 0.03731901 0.02498118
 0.0315983  0.02504539 0.02776266 0.0467627  0.0249822  0.0281953
 0.01716015 0.03731903 0.0532112  0.02625429 0.02825114 0.03159833
 0.01529039 0.02030591 0.02498233 0.02776268 0.0203059  0.02498229
 0.02801873 0.03159831 0.02030591 0.02497879 0.02030592 0.03159829
 0.02498231 0.02030589 0.02801534 0.0249823  0.02790539 0.01713407
 0.02805049 0.02498234]
tr_loss:[0.02916511 0.02934747 0.02361828 0.01702698 0.05219073 0.01702696
 0.0293565  0.0170283  0.0167695  0.02414025 0.017027   0.02360843
 0.04894039 0.01709741 0.03496544 0.02935017 0.02923347 0.01888751
 0.017027   0.0398213  0.02936858 0.05068965 0.01689828 0.05367591
 0.03982126 0.02235515 0.02361844 0.03982131 0.03159247 0.0223591
 0.0349656  0.03982129 0.03616368 0.02361826 0.02235908 0.03496549
 0.02338983 0.02413988 0.01703123 0.01867828 0.0241401  0.01702699
 0.01702701 0.03496551 0.02361823 0.04896894 0.01660322 0.02923474
 0.02930483 0.02361825]
tr_loss:[0.02343529 0.05217831 0.04448047 0.03437529 0.03429421 0.0154039
 0.04010069 0.01570567 0.02427517 0.04010262 0.03418569 0.01791568
 0.0396991  0.01791569 0.02304219 0.04897878 0.04611884 0.01789803
 0.0179157  0.02382161 0.05018599 0.04444738 0.034368   0.04403447
 0.02400147 0.02800919 0.02400838 0.01791569 0.01791571 0.02798621
 0.01988209 0.03409759 0.03343792 0.02376948 0.02208055 0.01540371
 0.02214802 0.02798625 0.02365123 0.02406887 0.02400867 0.01896767
 0.02798625 0.02400867 0.02241477 0.02419405 0.03969905 0.04010067
 0.04785712 0.0396991 ]
tr_loss:[0.0372139  0.05169405 0.03593747 0.01556175 0.02309159 0.01588956
 0.02804244 0.03579657 0.03569649 0.02624831 0.04280021 0.02624823
 0.01588956 0.03581793 0.06070568 0.02239779 0.01556957 0.04112602
 0.02725502 0.01556932 0.02227522 0.01617242 0.03568202 0.02227521
 0.02227523 0.04137444 0.03586487 0.01556958 0.03721392 0.03005579
 0.02624832 0.02804246 0.02486227 0.04039911 0.01588955 0.02502229
 0.02227521 0.01588956 0.03591951 0.01556956 0.035827   0.03721388
 0.02227522 0.04972065 0.03582118 0.02227522 0.04291932 0.02616614
 0.02681117 0.01556957]
tr_loss:[0.04103768 0.03115169 0.01842624 0.01632182 0.01842624 0.03317434
 0.01631848 0.01632184 0.03117251 0.02209351 0.0163218  0.02727313
 0.0523812  0.04474984 0.02209361 0.03578953 0.01842621 0.01842623
 0.02194426 0.0209094  0.0169746  0.03317446 0.02291275 0.04275464
 0.04757108 0.05750823 0.02699979 0.04506006 0.01697459 0.03071685
 0.01842576 0.03967664 0.03046318 0.02505071 0.03578952 0.03578952
 0.03113189 0.01944857 0.04397127 0.03114195 0.01933277 0.01632183
 0.01632182 0.01842163 0.02727293 0.01632184 0.01842624 0.02190381
 0.01632185 0.01842622]
tr_loss:[0.01968179 0.01935164 0.04381014 0.0305851  0.02345514 0.02672825
 0.03058506 0.01968173 0.01604476 0.02039859 0.01608783 0.0305851
 0.01935164 0.04825156 0.01608784 0.02039861 0.03144999 0.02925968
 0.02416998 0.03144997 0.01608783 0.01608783 0.02007144 0.02672395
 0.02569501 0.02329928 0.01608675 0.01608782 0.01607876 0.02672423
 0.02925968 0.01604821 0.02417017 0.01966242 0.04832821 0.01968034
 0.02285774 0.03144994 0.02671739 0.02039859 0.02756147 0.01608783
 0.02671866 0.0412261  0.02731541 0.02925973 0.0241903  0.02377907
 0.02416991 0.02039861]
tr_loss:[0.01879705 0.04009893 0.02078302 0.01521888 0.02078303 0.03035324
 0.02991177 0.01543125 0.02364025 0.02187805 0.03035327 0.01543121
 0.0264576  0.01543124 0.02362267 0.01543121 0.02378469 0.01543122
 0.02078303 0.02357896 0.04255632 0.01765269 0.04306164 0.02370912
 0.04457265 0.02085968 0.02226133 0.02187941 0.0320079  0.01987309
 0.02368581 0.02430662 0.01543121 0.02187943 0.03035327 0.03803844
 0.0303532  0.02187582 0.02354797 0.02051207 0.02187918 0.01879704
 0.02078306 0.03035325 0.02990891 0.02113133 0.02990896 0.03983931
 0.02705951 0.01869622]
tr_loss:[0.01915801 0.01813482 0.01944086 0.01650584 0.01813482 0.02454874
 0.02143514 0.01916796 0.01592391 0.02289615 0.02337888 0.01813483
 0.01650086 0.02944985 0.01813483 0.02454878 0.01944109 0.03426919
 0.02944985 0.0234129  0.02367495 0.01813482 0.02342847 0.02661288
 0.01944087 0.01813457 0.01898818 0.01813483 0.02944985 0.01936099
 0.02364671 0.03781168 0.01944087 0.03778155 0.01639235 0.04116278
 0.01650565 0.01650338 0.01650271 0.01944088 0.01625769 0.0236703
 0.01650585 0.01944088 0.01944088 0.01560426 0.04188453 0.02944983
 0.04768682 0.01650586]
tr_loss:[0.02665704 0.03015084 0.02666741 0.01446573 0.03011994 0.01756952
 0.01621986 0.02667028 0.02345601 0.02655671 0.03385354 0.03742478
 0.01414417 0.0267746  0.03644814 0.01414414 0.03862455 0.01414415
 0.01878742 0.01776055 0.01414416 0.01756954 0.01626132 0.02139629
 0.01355965 0.02140431 0.01870154 0.01414417 0.03011999 0.02671451
 0.01414411 0.01878897 0.02671286 0.01871084 0.02139609 0.02659028
 0.03011997 0.04818896 0.02371629 0.03015084 0.01756955 0.0301206
 0.01832387 0.02139636 0.023456   0.02905352 0.02668375 0.02907959
 0.01414417 0.01878493]
tr_loss:[0.01764734 0.03060256 0.02952874 0.02309239 0.03060254 0.0175225
 0.01908544 0.03855783 0.01750671 0.017527   0.02806398 0.03762756
 0.02774725 0.02947667 0.01565462 0.02952876 0.01992116 0.01992116
 0.0277977  0.03709165 0.01752708 0.01925813 0.03060254 0.02778003
 0.03060258 0.00970356 0.03703573 0.02817232 0.01752707 0.02295077
 0.01253327 0.03912547 0.02766814 0.03986956 0.01752687 0.03111737
 0.01752829 0.00970357 0.0136022  0.02050012 0.0093665  0.00970358
 0.02309423 0.00970356 0.03625242 0.01752705 0.01752706 0.03344021
 0.03435553 0.04357036]
tr_loss:[0.0394002  0.00690978 0.00690912 0.02660598 0.0175013  0.01246362
 0.01626662 0.03352962 0.01626658 0.04492552 0.01626661 0.01750575
 0.04999769 0.04654544 0.02621919 0.02650583 0.018988   0.00688009
 0.0162666  0.01881743 0.01760505 0.00690912 0.01897258 0.01626662
 0.023941   0.02621917 0.01675552 0.02927795 0.01751468 0.02927796
 0.01629624 0.01898795 0.01626661 0.01751964 0.01626708 0.00690912
 0.03566475 0.02927795 0.01705916 0.0175175  0.01751469 0.02621922
 0.01898799 0.01626662 0.02489291 0.00690912 0.02623279 0.04618915
 0.0262192  0.01246628]
tr_loss:[0.02544344 0.04533561 0.03588687 0.02846633 0.02243065 0.03308792
 0.01427332 0.04678103 0.01790369 0.01506075 0.0179036  0.02966948
 0.01450674 0.03788345 0.0483463  0.02546179 0.05334858 0.00761516
 0.0184802  0.02528735 0.02522429 0.01790366 0.00761555 0.04868673
 0.00761516 0.02243133 0.03540755 0.01506077 0.00761556 0.02243134
 0.01790283 0.0198834  0.00761555 0.02243133 0.02462284 0.01506077
 0.00761556 0.00761542 0.01790369 0.02545663 0.02243131 0.02846631
 0.00761555 0.01790334 0.04272238 0.00761555 0.01506075 0.01470982
 0.0367042  0.01789824]
tr_loss:[0.00992856 0.0279318  0.02746132 0.01708629 0.02133562 0.02267849
 0.02542019 0.00991893 0.04273767 0.00992857 0.01708638 0.02754415
 0.01708634 0.01524622 0.02549661 0.01811993 0.04711645 0.02564796
 0.01703232 0.02267851 0.02931857 0.0152462  0.0152461  0.02793184
 0.02746133 0.02558001 0.01811785 0.02793184 0.00992861 0.01708635
 0.02548263 0.03774393 0.0152462  0.02746133 0.01831742 0.03089812
 0.00992855 0.02793184 0.00992857 0.02267851 0.02128188 0.02267851
 0.01554671 0.01708634 0.00992856 0.02549715 0.01524621 0.02793186
 0.01524622 0.02758266]
text_input.shape
(1800, 14400)
learning_input_tmp.shape
(1800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1800, 80)
learning_output.shape
(750, 80)
Model: "sequential_38"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_38 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0240752  0.97106534 1.1040467  0.8644724  1.055752   0.91390973
 1.0367861  1.1086556  1.1086556  1.1086555  0.8485376  0.8715814
 0.9709446  0.9491445  1.0367862  0.86852247 0.91096085 0.9491447
 0.9615609  1.1000046  1.0240754  0.9108607  0.94914436 1.0240749
 0.90751684 0.94914454 0.94914454 0.9709406  0.9709407  1.1086555
 0.91080856 0.91099244 0.89499986 1.0367861  1.1088313  1.0240752
 0.8686268  1.0557519  0.953323   0.9709406  0.9722511  1.1001434
 0.9709406  0.94914436 0.9115566  1.1000344  0.9709407  0.9709426
 1.0118625  1.1487144 ]
tr_loss:[0.7188158  0.740369   0.7357391  0.7779506  0.73573905 0.72152543
 0.78228825 0.7403691  0.7443238  0.78781193 0.7215254  0.72528434
 0.71881634 0.72432536 0.7215254  0.61588585 0.6628106  0.660754
 0.57135046 0.7357391  0.66073835 0.71881634 0.72152555 0.7744874
 0.7760903  0.7186307  0.7357337  0.66073924 0.58984816 0.59005797
 0.7215253  0.72154415 0.7188164  0.77604115 0.77654785 0.7215255
 0.7215254  0.71881646 0.73573905 0.80520934 0.7215541  0.7760884
 0.66072863 0.55890876 0.7828109  0.7861942  0.7188163  0.7188164
 0.7188164  0.7760907 ]
tr_loss:[0.3898191  0.4595332  0.44546944 0.49780616 0.4176274  0.50013626
 0.49780473 0.38443232 0.4595341  0.49705762 0.45953554 0.50013626
 0.41833323 0.5019016  0.5256461  0.37222165 0.47362787 0.49780464
 0.4179941  0.41764373 0.45953313 0.43185455 0.47362795 0.41658598
 0.5007362  0.41833314 0.4179369  0.50013626 0.4805234  0.42055863
 0.50013626 0.48051825 0.47866058 0.50013626 0.47362787 0.5001344
 0.41791224 0.4183333  0.4595332  0.40670806 0.41740876 0.41783467
 0.5021233  0.41714326 0.5001306  0.5001363  0.41810054 0.41777286
 0.48051834 0.49780488]
tr_loss:[0.24382797 0.31031364 0.24035513 0.2823957  0.25681174 0.2823699
 0.26026845 0.24059543 0.24049044 0.30771357 0.25945884 0.30810615
 0.30802372 0.2939764  0.27377963 0.24662094 0.3077136  0.23548846
 0.2860396  0.2944476  0.30773026 0.23307452 0.30747876 0.28603953
 0.30802363 0.30771336 0.30802375 0.27377957 0.2861616  0.31256047
 0.23765317 0.24088287 0.28579754 0.246241   0.28315726 0.30802363
 0.25270855 0.237493   0.31031358 0.28908497 0.24088898 0.24103585
 0.30771366 0.23112652 0.30802375 0.26382384 0.24960709 0.24055362
 0.30771345 0.23307447]
tr_loss:[0.16962504 0.1696721  0.22888069 0.1922183  0.1890221  0.17893277
 0.15659057 0.18902335 0.21365479 0.16970938 0.16957596 0.1518619
 0.16878481 0.24227595 0.19330862 0.1687399  0.25052887 0.22841112
 0.18359746 0.21347955 0.18902202 0.22888073 0.22925332 0.16987686
 0.19540662 0.22888061 0.22888073 0.2288808  0.2288808  0.16942956
 0.2487083  0.24226789 0.21365476 0.18901917 0.16957797 0.18902202
 0.16740684 0.16878493 0.17861012 0.22888076 0.17709672 0.18902212
 0.158119   0.19205953 0.19221994 0.1687849  0.22888076 0.20267868
 0.16968878 0.21109924]
tr_loss:[0.14496705 0.12988493 0.08833034 0.11920412 0.10835638 0.08901862
 0.12974513 0.09819581 0.09175383 0.11152303 0.12976798 0.12696221
 0.15701847 0.12696217 0.11150694 0.11452663 0.11452667 0.102331
 0.129745   0.1477994  0.11452664 0.13765962 0.09520113 0.09520115
 0.1566815  0.15701815 0.10950359 0.12974504 0.12696214 0.10247197
 0.157167   0.11149659 0.11150692 0.1024733  0.09520116 0.10972685
 0.11452663 0.10246678 0.12974507 0.11452661 0.1297451  0.09079981
 0.14496703 0.1098026  0.11452665 0.11452661 0.09339871 0.126955
 0.11692286 0.11452663]
tr_loss:[0.07168242 0.08294138 0.06449504 0.09400474 0.0543586  0.08279155
 0.0543586  0.06729629 0.0827735  0.09389384 0.08654241 0.08264233
 0.06729906 0.06767718 0.08200288 0.06729625 0.0719564  0.06576782
 0.09389307 0.06001003 0.07196884 0.08214317 0.08201754 0.06449507
 0.06729628 0.08295438 0.06446366 0.09543879 0.08264042 0.0543586
 0.06028829 0.08265486 0.08528029 0.06449501 0.07273798 0.06729661
 0.05435854 0.07937664 0.05932014 0.06062818 0.08163229 0.08294912
 0.0672963  0.06483154 0.07117088 0.06729632 0.08979671 0.07195623
 0.0672963  0.05435862]
tr_loss:[0.06160611 0.04954914 0.07992697 0.06160613 0.06753527 0.08744051
 0.06337984 0.0605144  0.04954914 0.04928655 0.08746901 0.06753568
 0.09694545 0.05113679 0.04955444 0.04954915 0.06445123 0.04314778
 0.04954913 0.07078815 0.09297866 0.06450602 0.08739775 0.08756153
 0.0644512  0.08746783 0.05113678 0.06753571 0.08954532 0.0709101
 0.08210196 0.07033534 0.04954914 0.07032345 0.04954913 0.061535
 0.06445122 0.04955278 0.06160618 0.05824714 0.08748156 0.04954914
 0.0487408  0.06199016 0.08764753 0.06160613 0.06160615 0.06049539
 0.08764799 0.08740322]
tr_loss:[0.05530915 0.06716249 0.04741827 0.09681362 0.06718296 0.06403442
 0.06514077 0.06684877 0.05530918 0.0651408  0.08615887 0.05817701
 0.0581839  0.06719603 0.09322248 0.04706255 0.06706145 0.05818009
 0.05406489 0.04736687 0.09296238 0.09303317 0.06719345 0.04706123
 0.11685163 0.0909589  0.09045176 0.05406493 0.06719605 0.04741845
 0.06514077 0.09284721 0.04741844 0.09325138 0.0586602  0.06499311
 0.06719583 0.05866357 0.05817702 0.05406484 0.05406488 0.06514077
 0.06515439 0.0945878  0.08693766 0.06514069 0.09317087 0.06514072
 0.05852114 0.09422275]
tr_loss:[0.05116162 0.06933956 0.05116159 0.04475746 0.09268286 0.09143464
 0.05579432 0.06653771 0.04475742 0.04475742 0.05579433 0.05579432
 0.09446302 0.05516375 0.0665382  0.05887974 0.06712468 0.08544196
 0.08862782 0.05543536 0.06653807 0.06712636 0.05399952 0.06653818
 0.09309978 0.06712463 0.05116161 0.08969482 0.06712446 0.03926106
 0.10011945 0.05579428 0.04475747 0.09137668 0.05399949 0.04471293
 0.06712454 0.04760268 0.0906569  0.0409448  0.05116159 0.09315331
 0.10260098 0.06653826 0.06712462 0.11819901 0.05516378 0.04475744
 0.05380208 0.05399952]
tr_loss:[0.05247065 0.0498154  0.04446828 0.06493225 0.05172203 0.06493275
 0.04981548 0.09954181 0.04567405 0.0887995  0.0886058  0.08897989
 0.04075092 0.11372831 0.05632336 0.03913346 0.10860429 0.04448461
 0.05172481 0.06525636 0.05632334 0.06578317 0.0872625  0.1105309
 0.08642918 0.06199588 0.08891503 0.06578334 0.06493227 0.06380667
 0.06578334 0.0657834  0.06577092 0.0980529  0.06493236 0.06164143
 0.04075096 0.06577718 0.05247063 0.09262173 0.06575154 0.07180393
 0.0457209  0.06493224 0.04075097 0.06493229 0.04075092 0.09501028
 0.04075095 0.05172541]
tr_loss:[0.05722944 0.05982212 0.0548288  0.05465993 0.05722945 0.05751522
 0.05296917 0.08088399 0.08025212 0.04655687 0.05981775 0.04655686
 0.03707751 0.05722946 0.03927795 0.05305388 0.08139698 0.05465989
 0.07941887 0.06060731 0.03727254 0.04655681 0.08070248 0.03727253
 0.06169962 0.05723019 0.10755689 0.03727252 0.08233411 0.07796314
 0.08784518 0.04655685 0.04203119 0.07920493 0.1082978  0.05722936
 0.0546599  0.05981511 0.04185151 0.03727254 0.05924617 0.04783708
 0.05465993 0.03727249 0.05846596 0.08095833 0.03707797 0.05720298
 0.08113763 0.03707777]
tr_loss:[0.05940802 0.05350093 0.05791161 0.05791157 0.05900518 0.05789257
 0.08764911 0.05717446 0.05791134 0.04306003 0.04546497 0.05791161
 0.05791162 0.05717446 0.04448397 0.0447445  0.05717449 0.04306007
 0.05348279 0.05791156 0.05348275 0.05717447 0.04447812 0.05086492
 0.05360772 0.08956776 0.11616226 0.059408   0.04306003 0.04305999
 0.04674376 0.04306006 0.0445196  0.05791159 0.05021831 0.05348276
 0.07742325 0.05538575 0.05791155 0.05348351 0.04306002 0.05900545
 0.07568054 0.04673939 0.07733486 0.04306008 0.09171046 0.05900543
 0.05940804 0.10609613]
tr_loss:[0.06604944 0.04950976 0.04537428 0.04190884 0.05424639 0.04678219
 0.07370176 0.07368353 0.05195759 0.08898618 0.05196384 0.07172644
 0.05188451 0.05333912 0.04678219 0.05131831 0.07168344 0.04661763
 0.04676988 0.04541395 0.0533391  0.0419086  0.04661758 0.04678222
 0.04547057 0.07172309 0.05179749 0.0467822  0.07300457 0.05196378
 0.071747   0.04162668 0.05744991 0.04664509 0.04477017 0.0533391
 0.04678226 0.05196379 0.07290842 0.04200327 0.05333906 0.06922424
 0.0716894  0.05207624 0.0466176  0.04661757 0.04661758 0.04678243
 0.0467822  0.05196382]
tr_loss:[0.0488136  0.05147967 0.06963965 0.03981216 0.0543245  0.05432445
 0.09528779 0.05147965 0.06970246 0.04637958 0.04867773 0.06985801
 0.04930314 0.05147966 0.06942312 0.07610805 0.05717837 0.03981783
 0.04930307 0.05147965 0.08065585 0.03824494 0.04930316 0.03847682
 0.05147968 0.04637959 0.07477995 0.0494493  0.05147969 0.07342909
 0.05147969 0.05210317 0.06815823 0.07009794 0.05143045 0.04930314
 0.0514797  0.0493676  0.0543245  0.06971337 0.05143043 0.05143046
 0.0526737  0.05128462 0.04936737 0.06962406 0.04637957 0.06636386
 0.04148371 0.0543245 ]
tr_loss:[0.06891288 0.04541499 0.05614316 0.05459843 0.05011196 0.05614321
 0.0709727  0.03828127 0.03296635 0.05011189 0.04541502 0.04587336
 0.03247566 0.0500787  0.04587341 0.06619644 0.04628754 0.04544314
 0.04587337 0.06466101 0.03322123 0.04587341 0.06890567 0.05011069
 0.05614321 0.05614318 0.04541503 0.04587334 0.0501119  0.05614318
 0.05600683 0.045415   0.06416837 0.06574453 0.04541503 0.04541497
 0.03120736 0.06635962 0.05459841 0.03748462 0.0545984  0.04636202
 0.05614317 0.03120736 0.06914739 0.0738702  0.05011114 0.0380422
 0.0458734  0.06555828]
tr_loss:[0.04150109 0.03269979 0.03525046 0.03660687 0.03204767 0.06581701
 0.0414939  0.05204235 0.05204238 0.05030054 0.07753475 0.06626272
 0.05204239 0.04150123 0.03660683 0.06860302 0.0624583  0.0662225
 0.03660684 0.06481881 0.02621087 0.07199045 0.03661392 0.02840474
 0.05194552 0.06245822 0.04150119 0.06573369 0.04171463 0.06574329
 0.06598908 0.07687761 0.06215007 0.06245827 0.0624583  0.03660684
 0.04239813 0.04310132 0.0279599  0.05069859 0.0520418  0.05204212
 0.03662102 0.03660686 0.03270215 0.06245833 0.06245828 0.02621088
 0.02840417 0.06884001]
tr_loss:[0.03914899 0.03914901 0.06586312 0.02503914 0.03981035 0.02504091
 0.0296964  0.03981034 0.02969639 0.05288691 0.06777618 0.06346038
 0.06346035 0.03918976 0.03631002 0.06598343 0.06346038 0.03613813
 0.06617387 0.02553676 0.05288344 0.05288691 0.02767252 0.06981108
 0.02505211 0.03613843 0.02767255 0.03914901 0.05928908 0.03613824
 0.06346038 0.02969637 0.06877997 0.04064662 0.03914902 0.03614732
 0.065809   0.05288687 0.06582649 0.03622302 0.0722281  0.06346039
 0.02884041 0.03981035 0.06662554 0.03914902 0.06575585 0.05288684
 0.03914895 0.05288685]
tr_loss:[0.03657791 0.0335916  0.04663242 0.05944128 0.05243362 0.04284482
 0.03515838 0.02305414 0.02705388 0.05243363 0.05896691 0.02705253
 0.05925211 0.02305414 0.04592969 0.04592783 0.02774732 0.05928881
 0.02124442 0.04663241 0.07152522 0.03515835 0.03359165 0.05932252
 0.05907514 0.03657796 0.0590374  0.03359159 0.03515835 0.02505889
 0.05923429 0.02305415 0.03045436 0.06323951 0.02124635 0.0459298
 0.03669702 0.04590968 0.04592977 0.03657793 0.02305527 0.05243364
 0.02124633 0.02305415 0.02305454 0.02305414 0.0584325  0.06263914
 0.05914408 0.03657919]
tr_loss:[0.02533473 0.04393281 0.04526398 0.04279467 0.02529696 0.025297
 0.04383849 0.04134525 0.03974628 0.02545201 0.02596052 0.04526401
 0.06645995 0.04392572 0.0352521  0.03840153 0.04526397 0.03361099
 0.04526401 0.07458467 0.045264   0.03451349 0.05812335 0.0413708
 0.02529699 0.04321905 0.03931745 0.045264   0.02529696 0.05800299
 0.03451316 0.04121055 0.09078699 0.0439328  0.04393284 0.02525732
 0.0384563  0.10419378 0.04526399 0.07208516 0.045264   0.10457512
 0.07488175 0.05788793 0.03451366 0.08707563 0.04526399 0.02529696
 0.04121056 0.05808498]
tr_loss:[0.06824927 0.04048502 0.069288   0.0704565  0.02972668 0.0443274
 0.0277846  0.04366356 0.09798012 0.04507989 0.04048505 0.02974121
 0.04428302 0.05738536 0.02972667 0.10494888 0.05749022 0.05395756
 0.04432737 0.04043774 0.040485   0.05745987 0.09087677 0.06179874
 0.04502286 0.0443274  0.04502093 0.05997309 0.02772233 0.04414914
 0.05748377 0.0450229  0.04431866 0.04430992 0.03348496 0.04502292
 0.05700309 0.04046594 0.0297267  0.04432744 0.0422307  0.02778367
 0.04432566 0.05747688 0.04039774 0.02972666 0.02788794 0.04502293
 0.04048506 0.04048501]
tr_loss:[0.04132243 0.0413224  0.03901409 0.03901414 0.0296101  0.02595491
 0.03019097 0.03901406 0.04109729 0.04109729 0.02598776 0.04132237
 0.02283507 0.03585554 0.05346538 0.05927635 0.06742536 0.07119217
 0.03455812 0.04132243 0.04287318 0.08331485 0.04111866 0.03019419
 0.06733254 0.05860332 0.04132245 0.05360095 0.02961012 0.04287313
 0.04109728 0.03839167 0.05359657 0.04109729 0.06231805 0.02662
 0.05310709 0.04109721 0.03839167 0.06545601 0.08531871 0.03018998
 0.04132208 0.0654486  0.06216936 0.05382866 0.05292839 0.04109728
 0.02960988 0.09165715]
tr_loss:[0.03099613 0.0539438  0.05449384 0.05398437 0.04639759 0.02271735
 0.03099616 0.03775937 0.03937747 0.0623066  0.05406203 0.05180914
 0.05277956 0.03757351 0.05395708 0.03560438 0.05509668 0.03099617
 0.02762003 0.02271734 0.0377594  0.07993542 0.02676187 0.05400366
 0.02762176 0.04156581 0.05367146 0.03775936 0.03775939 0.0396696
 0.03572072 0.05625678 0.0377594  0.04098611 0.03572074 0.05399365
 0.04157533 0.02271738 0.03101304 0.03099617 0.02762212 0.04098611
 0.02672561 0.02676187 0.02498827 0.0347339  0.0750009  0.03099616
 0.02760547 0.05401172]
tr_loss:[0.03303945 0.05543929 0.0553901  0.06525825 0.03303941 0.03613032
 0.05545939 0.03613043 0.02956961 0.05517813 0.04368735 0.03613036
 0.05069808 0.04333391 0.03279771 0.02757596 0.03613159 0.02900872
 0.05545734 0.03674766 0.03303943 0.03437073 0.04290775 0.06666006
 0.04140686 0.04368733 0.03614866 0.03613039 0.05978284 0.04992588
 0.04290774 0.04368735 0.03613036 0.05441099 0.0429071  0.04290774
 0.02797381 0.06750073 0.04290769 0.03611534 0.03303937 0.0361304
 0.05552486 0.06259666 0.04290775 0.05548545 0.05535777 0.03303941
 0.04290115 0.05566118]
tr_loss:[0.03313681 0.04359609 0.0272047  0.0480171  0.03454906 0.04359636
 0.05373686 0.05368733 0.03248231 0.03313679 0.03313679 0.08221766
 0.04801709 0.03454904 0.02547542 0.0413693  0.02954601 0.02696174
 0.08046362 0.03313679 0.0536948  0.052274   0.03313677 0.01825017
 0.03248231 0.03454904 0.0411888  0.03250678 0.03313683 0.05367295
 0.02913885 0.04136761 0.05394534 0.02719984 0.03454905 0.05388432
 0.05360421 0.04801712 0.05282186 0.01825018 0.03248363 0.03314142
 0.03454904 0.0331368  0.05435354 0.0413693  0.04801708 0.03454906
 0.05370363 0.04359608]
tr_loss:[0.03180918 0.02410823 0.0318092  0.0318092  0.04346091 0.03180917
 0.04328971 0.05905068 0.02541245 0.04617092 0.06552075 0.05288829
 0.05259408 0.02703721 0.03180917 0.03181326 0.0194178  0.03366518
 0.03004857 0.02581937 0.02771469 0.04071301 0.05237292 0.05225586
 0.05875708 0.04071303 0.08503284 0.03180917 0.04071302 0.04346094
 0.05280384 0.07361941 0.0461709  0.03366519 0.04617094 0.0318092
 0.03396244 0.05758628 0.03366519 0.08077275 0.04390467 0.05253667
 0.03363812 0.04342313 0.04029578 0.02771572 0.03366519 0.03113392
 0.02897715 0.04067416]
tr_loss:[0.05181699 0.03805073 0.0252734  0.0317027  0.03986676 0.03984438
 0.0317027  0.02791331 0.03169196 0.04462544 0.03170266 0.04462543
 0.03151889 0.0199185  0.05052136 0.04462541 0.05184113 0.01991852
 0.03143572 0.03235141 0.05107041 0.03986238 0.0518023  0.05826845
 0.02152378 0.03235052 0.05368875 0.03986676 0.02003739 0.03986676
 0.05733288 0.04462538 0.03986676 0.05357212 0.02791334 0.02155023
 0.03986672 0.03170263 0.02791333 0.03170269 0.03170567 0.02791335
 0.02791333 0.05120982 0.03235052 0.02155    0.02520776 0.03986673
 0.04462538 0.01991851]
tr_loss:[0.05902136 0.05712736 0.09195092 0.03070822 0.04468151 0.07660566
 0.03075081 0.02497892 0.03190933 0.02806444 0.03070822 0.03190931
 0.01908262 0.09699102 0.02818607 0.0190673  0.03248151 0.04468153
 0.02497873 0.04680204 0.03697981 0.02497872 0.02802995 0.0446815
 0.02839984 0.03063587 0.02662959 0.03070825 0.03973442 0.02567148
 0.05349905 0.05343867 0.01907612 0.02798492 0.04025814 0.01985809
 0.04025486 0.02798851 0.04025816 0.03697387 0.03978376 0.03070825
 0.03697969 0.05313458 0.08817472 0.02555788 0.040258   0.0515531
 0.0402581  0.03190934]
tr_loss:[0.0417289  0.03515892 0.04172882 0.01905737 0.03153071 0.03153026
 0.02405038 0.03844396 0.03152973 0.03152974 0.02431208 0.05562035
 0.05573478 0.01905675 0.04172885 0.03152972 0.02431201 0.05474922
 0.02305759 0.04606442 0.0351589  0.02431208 0.03152963 0.09452926
 0.03239613 0.06166004 0.05869414 0.05461805 0.04172885 0.03152966
 0.05725507 0.02782348 0.06418228 0.05570237 0.0557307  0.0315297
 0.03152975 0.05565808 0.04157401 0.02431205 0.02431203 0.04172887
 0.04165269 0.02782352 0.04606438 0.03154352 0.05559017 0.03217223
 0.01885743 0.02788248]
tr_loss:[0.05267888 0.02502284 0.05273069 0.03875221 0.03359395 0.05267779
 0.02931608 0.0528476  0.02121502 0.03607399 0.02495259 0.02932195
 0.05500164 0.02121501 0.04070111 0.02932198 0.04070065 0.030506
 0.03988777 0.04070094 0.05303968 0.08637799 0.05233908 0.05495532
 0.05953059 0.02121501 0.04578786 0.05286721 0.02121506 0.02480691
 0.02256889 0.02121503 0.07232311 0.05302802 0.09620705 0.02121501
 0.04035888 0.02121501 0.02121503 0.01694291 0.01781667 0.04070112
 0.02121503 0.06412459 0.02121606 0.05214601 0.02373179 0.02121502
 0.02932198 0.06019448]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1800 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1801, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1801 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1802, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1802 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1803, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1803 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1804, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1804 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1805, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1805 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1806, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1806 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1807, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1807 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1808, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1808 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1809, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1809 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1810, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1810 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1811, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1811 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1812, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1812 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1813, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1813 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1814, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1814 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1815, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1815 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1816, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1816 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1817, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1817 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1818, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1818 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1819, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1819 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1820, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1820 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1821, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1821 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1822, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1822 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1823, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1823 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1824, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1824 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1825, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1825 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1826, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1826 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1827, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1827 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1828, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1828 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1829, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1829 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1830, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1830 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1831, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1831 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1832, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1832 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1833, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1833 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1834, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1834 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1835, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1835 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1836, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1836 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1837, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1837 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1838, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1838 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1839, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1839 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1840, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1840 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1841, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1841 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1842, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1842 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1843, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1843 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1844, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1844 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1845, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1845 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1846, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1846 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1847, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1847 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1848, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1848 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1849, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1849 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1850, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1850 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1851, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1851 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1852, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1852 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1853, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1853 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1854, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1854 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1855, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1855 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1856, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1856 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1857, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1857 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1858, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1858 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1859, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1859 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1860, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1860 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1861, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1861 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1862, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1862 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1863, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1863 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1864, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1864 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1865, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1865 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1866, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1866 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1867, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1867 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1868, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1868 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1869, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1869 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1870, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1870 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1871, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1871 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1872, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1872 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1873, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1873 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1874, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1874 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1875, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1875 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1876, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1876 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1877, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1877 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1878, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1878 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1879, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1879 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1880, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1880 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1881, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1881 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1882, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1882 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1883, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1883 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1884, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1884 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1885, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1885 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1886, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1886 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1887, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1887 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1888, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1888 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1889, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1889 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1890, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1890 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1891, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1891 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1892, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1892 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1893, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1893 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1894, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1894 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1895, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1895 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1896, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1896 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1897, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1897 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1898, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1898 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1899, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1899 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1900, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-1800
text_input.shape
(1900, 14400)
learning_input_tmp.shape
(1900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1900, 80)
learning_output.shape
(750, 80)
Model: "sequential_39"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_39 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1089419  1.3215631  1.1237379  1.1326151  1.3215631  1.1326149
 1.1087011  1.0997356  1.132615   1.132615   1.1478872  1.1691729
 1.1026818  1.3215631  1.3215631  1.1772597  1.3215631  1.1776165
 1.321563   1.1776165  1.207896   1.0985476  1.2375224  1.2465055
 1.0445846  1.1776164  1.3215631  1.2198719  1.100572   1.321563
 0.98990536 1.132615   1.2198426  1.210283   1.1776164  1.1018403
 1.2448012  1.0996792  1.2078959  1.2448043  1.3215631  0.9524194
 1.0995811  1.2448153  1.0998502  1.1312263  1.0997055  1.3215406
 1.1339394  1.1012819 ]
tr_loss:[0.6261843  0.6926605  0.6970967  0.64889556 0.6920339  0.69266045
 0.7831599  0.63708925 0.7831601  0.6926604  0.7831624  0.64779073
 0.7499443  0.6970967  0.6970967  0.77918637 0.64779073 0.74994415
 0.63706195 0.7831601  0.6370741  0.64779073 0.6370513  0.7499443
 0.6970967  0.69266045 0.7831601  0.70965135 0.6477906  0.63706636
 0.63692015 0.6934633  0.624514   0.69709677 0.72192603 0.63707244
 0.6456149  0.7192703  0.6370801  0.69266045 0.6477747  0.63342
 0.63706505 0.6970976  0.69266045 0.71927094 0.69266045 0.69584775
 0.66076756 0.66555226]
tr_loss:[0.3862322  0.4237314  0.37793803 0.35590515 0.4105888  0.42372084
 0.40047827 0.40047827 0.43922645 0.4155715  0.37793803 0.37706155
 0.38620138 0.43926686 0.43926686 0.4001724  0.3779005  0.35315844
 0.37779206 0.43926677 0.35316008 0.42382306 0.3779382  0.38620126
 0.4242888  0.42372355 0.4231902  0.39901    0.38620123 0.42372483
 0.43926677 0.4272317  0.33783507 0.3770616  0.35344014 0.42322668
 0.42379466 0.38620132 0.37793794 0.3779381  0.37706158 0.42319018
 0.37706155 0.38620192 0.43926677 0.39900994 0.3539117  0.40047836
 0.37793818 0.3770616 ]
tr_loss:[0.2238162  0.21075134 0.22851238 0.22743031 0.26035222 0.2527809
 0.22771688 0.23811384 0.22427945 0.22381659 0.22381616 0.21075138
 0.2528165  0.23813267 0.22722712 0.22759911 0.2548396  0.21075137
 0.24121332 0.24121985 0.2272776  0.21075138 0.2537151  0.22731383
 0.22381619 0.23442717 0.21084857 0.2381144  0.24645436 0.2528165
 0.21075284 0.23811392 0.25281653 0.21075165 0.21079215 0.24121983
 0.25281656 0.2528165  0.24749824 0.2528165  0.2375917  0.25423044
 0.21076086 0.22234711 0.23209934 0.2528165  0.21266451 0.22381596
 0.24121983 0.24749808]
tr_loss:[0.15060271 0.13013983 0.16807911 0.1515919  0.15863836 0.1698969
 0.16989736 0.16808005 0.16094045 0.13014004 0.13425125 0.15828435
 0.16094089 0.16094229 0.15775011 0.13436635 0.15775317 0.13434061
 0.15664527 0.16094196 0.15767749 0.15158257 0.1515826  0.17519686
 0.15863824 0.1343476  0.14934972 0.16091679 0.17110892 0.15622205
 0.17757289 0.13436851 0.15863836 0.13013987 0.15863809 0.1402928
 0.13431777 0.17519693 0.1519303  0.13013987 0.13610557 0.17519681
 0.17429847 0.1742985  0.15775004 0.16807905 0.15775008 0.1680791
 0.15905465 0.13024653]
tr_loss:[0.08993344 0.08044277 0.08656247 0.11419086 0.09680245 0.09931456
 0.09458828 0.07177834 0.08654563 0.08654565 0.09458826 0.07769681
 0.08065188 0.10493863 0.11029561 0.10269916 0.11517058 0.10004711
 0.08778057 0.08942357 0.07170959 0.07174164 0.08044275 0.09287705
 0.07171459 0.11517055 0.09458826 0.11424579 0.09458826 0.0712415
 0.09723382 0.07477406 0.0961001  0.09462734 0.11517058 0.08713041
 0.09387683 0.09609739 0.11419089 0.07742999 0.11517062 0.07742791
 0.0714509  0.10493869 0.10004711 0.07163554 0.09458828 0.09458826
 0.07743444 0.08654567]
tr_loss:[0.06380405 0.06683199 0.09822787 0.10278003 0.06380399 0.0725433
 0.0638056  0.06855943 0.0725521  0.10357557 0.09290852 0.07253827
 0.06683199 0.07540124 0.07255405 0.07247877 0.06429297 0.06380404
 0.07540124 0.06855956 0.0754013  0.08436596 0.09462814 0.09596219
 0.06683522 0.07255641 0.06729569 0.07539944 0.09490822 0.06683256
 0.06683199 0.09459779 0.10360408 0.07540129 0.06683399 0.08139341
 0.06855708 0.07253972 0.06855953 0.06684691 0.09460916 0.08599564
 0.09083553 0.07254742 0.09462728 0.09228214 0.07254083 0.07540125
 0.07540127 0.0638039 ]
tr_loss:[0.07311501 0.07082454 0.05659467 0.07064483 0.07641284 0.05468292
 0.07311606 0.05659468 0.05468311 0.05468317 0.05468311 0.08200465
 0.0627823  0.07068276 0.05898025 0.06940103 0.06713242 0.06713244
 0.06713237 0.07079469 0.08112242 0.08265307 0.06278229 0.07211494
 0.05566976 0.07311612 0.10468487 0.05468311 0.07078795 0.05468302
 0.07121432 0.05403746 0.07013781 0.08395278 0.05659466 0.0627823
 0.08302368 0.05469173 0.09916824 0.08201469 0.06278229 0.06713246
 0.0775774  0.07757743 0.05468313 0.06278227 0.05468311 0.07757739
 0.08175075 0.05659468]
tr_loss:[0.08168157 0.06340234 0.06800205 0.05891398 0.10678464 0.074719
 0.05370326 0.07430835 0.0670209  0.07018781 0.06962537 0.06962588
 0.06963132 0.05891401 0.07018784 0.05891399 0.05891401 0.07180127
 0.07916057 0.07456347 0.06962538 0.07310543 0.08347879 0.05464246
 0.05891399 0.08327431 0.07018787 0.08195683 0.06800221 0.06707782
 0.05891716 0.05891398 0.06962539 0.06962538 0.06722796 0.05891401
 0.07010061 0.06962539 0.07402814 0.07444672 0.07342366 0.05891399
 0.07886733 0.05891401 0.0556666  0.08905064 0.07353792 0.06962536
 0.07402842 0.05891398]
tr_loss:[0.06958294 0.06958312 0.07644226 0.07592422 0.0847543  0.06958271
 0.0759906  0.06958292 0.08454476 0.10829469 0.07542298 0.07534277
 0.07644223 0.05892729 0.10536797 0.07644286 0.07534276 0.08329854
 0.07534276 0.07596265 0.06393895 0.07592416 0.07534274 0.07498884
 0.09380462 0.07202596 0.0688208  0.0759242  0.07534062 0.07592426
 0.07607983 0.0794922  0.07592427 0.06958292 0.07785183 0.05892731
 0.06958284 0.07644223 0.08405877 0.08140576 0.06945986 0.07592424
 0.08404312 0.0759242  0.06962804 0.07492016 0.0589273  0.05892727
 0.09387579 0.08400144]
tr_loss:[0.05795743 0.06969678 0.07506362 0.07505639 0.07844589 0.07924132
 0.06735088 0.07155477 0.08218054 0.12386127 0.07448903 0.08212175
 0.07504838 0.08238245 0.07455285 0.0835435  0.06969671 0.08217597
 0.06969677 0.08220452 0.07710095 0.05795736 0.06983179 0.08222954
 0.07385455 0.07506426 0.07455277 0.07455284 0.07924135 0.05795737
 0.08219527 0.07455276 0.07506426 0.05795646 0.0579574  0.07138956
 0.07866633 0.07710095 0.07428604 0.05795841 0.06649274 0.07455283
 0.0745528  0.06969681 0.08064462 0.08214024 0.07506426 0.0745684
 0.07959966 0.07154024]
tr_loss:[0.06412175 0.06160095 0.05231838 0.05219573 0.07765305 0.07388895
 0.05231839 0.06809662 0.06809667 0.07799354 0.06412026 0.07299328
 0.07822561 0.07163948 0.0641205  0.08102851 0.06405846 0.06809666
 0.07305355 0.07426888 0.12231927 0.06423541 0.06809666 0.07765301
 0.07443192 0.0523184  0.05231838 0.07774454 0.07442217 0.06412051
 0.05231838 0.06081934 0.06410189 0.0641128  0.07799077 0.09326677
 0.07554429 0.06809665 0.05231763 0.07435751 0.07445456 0.09847496
 0.07724924 0.06809664 0.06081932 0.06812377 0.06809666 0.06405844
 0.07305323 0.05231849]
tr_loss:[0.07064438 0.07256441 0.06553236 0.06918943 0.05138355 0.11646228
 0.07256439 0.06553237 0.08297129 0.07256444 0.07256418 0.07222612
 0.05138355 0.06454141 0.07256447 0.11415287 0.07256444 0.0588018
 0.07239266 0.06553237 0.06454191 0.11359701 0.08096772 0.05138357
 0.07256363 0.06466283 0.06889778 0.05138351 0.06687011 0.07256436
 0.07190825 0.06687009 0.06454144 0.07081901 0.07074311 0.06454144
 0.06553237 0.05138355 0.07256441 0.07256441 0.05138355 0.05138356
 0.06497402 0.07256447 0.06454142 0.08096776 0.08096771 0.06454141
 0.06314941 0.06556295]
tr_loss:[0.06886803 0.06582338 0.05432954 0.06803881 0.11040032 0.07002657
 0.06886103 0.06803969 0.06546639 0.07000729 0.06296859 0.06587212
 0.0654664  0.05432953 0.06803925 0.06587215 0.08126142 0.06546641
 0.06587217 0.06587213 0.07002655 0.06546643 0.06547152 0.06546638
 0.06587212 0.07002662 0.05432951 0.05432952 0.05565225 0.07002623
 0.05432953 0.05432954 0.07002115 0.08092462 0.06587212 0.06550183
 0.06546638 0.06887136 0.07002656 0.06886927 0.07002657 0.08127031
 0.06546642 0.05432951 0.05432951 0.07065366 0.06554367 0.06546639
 0.05432952 0.06887563]
tr_loss:[0.07225539 0.06135299 0.06717114 0.09873352 0.06788554 0.06716976
 0.06482625 0.05606442 0.06349047 0.06717609 0.0634905  0.06716871
 0.0560644  0.06715902 0.06724198 0.056169   0.05615112 0.06529761
 0.0648263  0.06530918 0.07973878 0.06047102 0.06349044 0.07636259
 0.07973807 0.06803583 0.07175487 0.06482629 0.06482701 0.06809712
 0.06399944 0.0672311  0.05606441 0.0797381  0.07973813 0.06304757
 0.06349051 0.05606441 0.06809489 0.06809711 0.0634924  0.09775283
 0.05606442 0.05606439 0.0560644  0.06529764 0.06751857 0.05605079
 0.0671434  0.06349047]
tr_loss:[0.08551534 0.06133563 0.05729867 0.06319667 0.06353514 0.06133566
 0.06041486 0.06319578 0.06361805 0.05468856 0.06319628 0.05374069
 0.06361216 0.06219568 0.06369521 0.06357982 0.06133559 0.07182756
 0.06938741 0.06263279 0.06728342 0.08635982 0.0663299  0.05377411
 0.0626111  0.06263696 0.0613356  0.09499178 0.0537741  0.05719745
 0.06348477 0.0537741  0.06312972 0.07184019 0.06319666 0.06263659
 0.0631967  0.05719455 0.06859139 0.06111834 0.05964682 0.06632972
 0.06135285 0.06319295 0.07182758 0.06133565 0.05719457 0.06847004
 0.06133623 0.06257977]
tr_loss:[0.06406323 0.05647787 0.04801203 0.06328129 0.04813016 0.04813023
 0.05653669 0.05526137 0.05756606 0.04813018 0.04813021 0.08159164
 0.056632   0.05526136 0.05306296 0.05657442 0.0651794  0.06328131
 0.05737485 0.04813021 0.05309559 0.04813021 0.0485745  0.04801204
 0.04801202 0.0724227  0.06000489 0.0557048  0.05655491 0.05851942
 0.04813022 0.06406057 0.05526138 0.06000537 0.04801202 0.10222974
 0.04801203 0.05318564 0.0565382  0.04801203 0.05526131 0.0575989
 0.05526137 0.06517959 0.04813022 0.0873159  0.08965646 0.05526137
 0.05642096 0.04801203]
tr_loss:[0.07567962 0.05070471 0.05520321 0.05534947 0.07007428 0.08470201
 0.05851213 0.05068783 0.05945612 0.05517759 0.07041265 0.05070422
 0.05849661 0.0462657  0.05070424 0.0586803  0.07572865 0.05070419
 0.05848169 0.04626565 0.05517761 0.04626566 0.05660462 0.07041269
 0.05868066 0.05517761 0.05868034 0.05660461 0.05847918 0.05070422
 0.05070423 0.05070422 0.07041264 0.05877131 0.05847509 0.06782965
 0.05703738 0.05070423 0.04630078 0.05660466 0.05517759 0.04711416
 0.04626571 0.05518633 0.05847093 0.05517758 0.05847882 0.05660465
 0.07041266 0.04626568]
tr_loss:[0.05905672 0.05897727 0.05377994 0.09206619 0.05813263 0.06213348
 0.05377994 0.0727521  0.05710269 0.05813263 0.05909938 0.05894756
 0.07134282 0.07454807 0.07714389 0.06213342 0.05815924 0.08074682
 0.08297301 0.06213349 0.06213344 0.05377996 0.06294888 0.05813263
 0.05893863 0.08074468 0.08074121 0.07494044 0.07275209 0.04852067
 0.04850996 0.05705041 0.06149349 0.06213342 0.04104108 0.05813873
 0.06213345 0.09571965 0.05814756 0.07601853 0.05377992 0.06299879
 0.05377991 0.08257522 0.05964518 0.05377995 0.06213306 0.05893167
 0.08074468 0.10332762]
tr_loss:[0.04412565 0.04412572 0.05715026 0.05715024 0.07591274 0.0783938
 0.04793607 0.05715026 0.08256198 0.05134342 0.0783938  0.04950995
 0.04831737 0.08295351 0.04793607 0.07839383 0.04830558 0.07150118
 0.067899   0.04836536 0.05715024 0.04793608 0.04793607 0.0441287
 0.04950994 0.0571503  0.06758958 0.06604395 0.04950989 0.05134346
 0.05134345 0.05134849 0.08824927 0.04412574 0.04793606 0.07150116
 0.04793607 0.07150127 0.04950998 0.04793606 0.06140626 0.07150115
 0.04412577 0.05715026 0.07839377 0.05715017 0.06325943 0.05134664
 0.06164558 0.05134352]
tr_loss:[0.0576612  0.04373075 0.08806853 0.04604704 0.06022598 0.05107458
 0.04725782 0.04525381 0.04661069 0.04661069 0.09027332 0.04524973
 0.04507614 0.04520233 0.07006146 0.04661072 0.04661068 0.05007152
 0.05766125 0.05607231 0.05107347 0.07060466 0.04661069 0.04604695
 0.0466107  0.05007697 0.04532064 0.07011507 0.0452804  0.04526562
 0.04526099 0.07199378 0.04604698 0.04661069 0.07060463 0.04774591
 0.05766124 0.04525812 0.0452783  0.05107351 0.07352479 0.05766119
 0.04527153 0.07352477 0.04541604 0.04604694 0.0466107  0.05776386
 0.04604701 0.0706046 ]
tr_loss:[0.05498924 0.04595392 0.04595392 0.07016549 0.04764058 0.055246
 0.06990587 0.06994884 0.04594298 0.05857412 0.05521902 0.05622415
 0.08973166 0.05840011 0.04736915 0.05830295 0.05521869 0.05498928
 0.0459539  0.0804524  0.04595391 0.04737697 0.04595361 0.05841
 0.04702432 0.05829802 0.04595385 0.05829802 0.04702432 0.05498924
 0.04702436 0.05830484 0.05498923 0.05498615 0.05499128 0.05498916
 0.04702432 0.05499448 0.04595392 0.05498923 0.0459592  0.0475714
 0.04595301 0.06990591 0.06778981 0.04595392 0.04595391 0.0561315
 0.04698611 0.05829792]
tr_loss:[0.05433989 0.04590883 0.07608896 0.04696875 0.05066399 0.04226257
 0.04243057 0.04396797 0.04587391 0.04594858 0.04396794 0.05066399
 0.04596453 0.045951   0.0439679  0.07248384 0.04396791 0.05066399
 0.05244641 0.05337215 0.05434391 0.04594304 0.04396854 0.05427422
 0.04433947 0.06360145 0.05676955 0.04398948 0.06290005 0.05337212
 0.07180758 0.05066379 0.05066401 0.05607218 0.05470276 0.05319922
 0.05417862 0.03975527 0.05337212 0.06679111 0.05066397 0.06290261
 0.05535839 0.05097478 0.05424706 0.04617062 0.04396789 0.05676959
 0.06290006 0.05199553]
tr_loss:[0.04504846 0.06093263 0.0598387  0.05983865 0.04232819 0.0812297
 0.04657768 0.03533673 0.04657807 0.08288902 0.04657768 0.04657769
 0.05006172 0.04657769 0.05767262 0.04262837 0.05006166 0.05006173
 0.05009929 0.05767224 0.06093285 0.05118958 0.04232818 0.04259209
 0.04512477 0.04232818 0.04232818 0.04657768 0.06807577 0.0563852
 0.05865554 0.05865552 0.04672267 0.04478734 0.05865554 0.05006164
 0.05006173 0.04262838 0.05983865 0.0426284  0.04262837 0.045061
 0.04515156 0.04521881 0.0563908  0.05638521 0.04262843 0.04657769
 0.0426284  0.05700858]
tr_loss:[0.04520225 0.04941388 0.05919644 0.04767449 0.05736072 0.04142147
 0.05620625 0.04542726 0.05734779 0.05620797 0.05666914 0.04001037
 0.04142149 0.04036709 0.05855802 0.06868976 0.04769152 0.06502329
 0.05705534 0.0570551  0.04001034 0.04142148 0.04520224 0.04487722
 0.04205549 0.04001032 0.04277691 0.05620772 0.05635003 0.04767449
 0.04142147 0.04767449 0.04547743 0.04520226 0.04520227 0.0476745
 0.04542455 0.04142147 0.04001034 0.04520227 0.04142147 0.04767448
 0.04520224 0.04941271 0.04142148 0.04545435 0.0476745  0.04543241
 0.04490098 0.05897287]
tr_loss:[0.08034568 0.03887536 0.04808845 0.03887857 0.04235841 0.04566936
 0.05156467 0.04566949 0.03887535 0.042359   0.05406215 0.03973996
 0.03887652 0.04465282 0.04235842 0.05399773 0.06052089 0.04899241
 0.04008907 0.0563084  0.04469012 0.05635877 0.0563084  0.03887539
 0.04236346 0.04466511 0.05374752 0.0549453  0.03887536 0.04465482
 0.05376219 0.04559463 0.04240212 0.05473886 0.04008908 0.04465375
 0.05472391 0.05376995 0.04566949 0.04235844 0.0433103  0.07106288
 0.06215179 0.04466444 0.04008908 0.04235846 0.0437218  0.04008908
 0.04235846 0.04008908]
tr_loss:[0.04923511 0.04294693 0.04951492 0.04463477 0.05049429 0.04815933
 0.04463476 0.04815936 0.04817519 0.04631666 0.04462016 0.04815935
 0.03465506 0.04376981 0.05504497 0.03841079 0.04463477 0.04631669
 0.04376978 0.04951488 0.07468842 0.04631668 0.04376978 0.034655
 0.03465498 0.04631663 0.04463471 0.03465497 0.04590828 0.03465506
 0.04815933 0.04631664 0.04631672 0.05297411 0.04923501 0.04815926
 0.05172873 0.04815934 0.04070929 0.05223733 0.04101226 0.04463479
 0.04365259 0.04463478 0.03465589 0.05294993 0.04463455 0.04295057
 0.04376978 0.04815932]
tr_loss:[0.05338245 0.0344062  0.05254649 0.05048991 0.05048992 0.04675221
 0.05444369 0.0472941  0.0411467  0.04176206 0.04725023 0.08844703
 0.03444069 0.03440698 0.05254646 0.04232488 0.04729526 0.03440619
 0.05077387 0.04739568 0.04729525 0.05049279 0.0504899  0.05039964
 0.04175249 0.03826905 0.0493302  0.04180665 0.03440619 0.04739565
 0.04828315 0.05048992 0.04184216 0.04173302 0.04729524 0.03440621
 0.07442109 0.04729526 0.04739572 0.05048994 0.04731264 0.04739676
 0.04932745 0.05048992 0.05048994 0.05048988 0.05340736 0.06122327
 0.06892196 0.05254645]
tr_loss:[0.0551798  0.04122658 0.04365543 0.0469409  0.04365555 0.03653925
 0.0529628  0.07885939 0.04720998 0.05030346 0.04365555 0.03917723
 0.03666408 0.03653928 0.04692577 0.03681452 0.05032239 0.04481062
 0.03653926 0.04481065 0.05075531 0.0467488  0.04692576 0.03916053
 0.04481067 0.04365555 0.05314993 0.05025591 0.04692576 0.03653955
 0.03914385 0.05417697 0.03653947 0.03928895 0.04692578 0.04314142
 0.05032078 0.03917912 0.0384101  0.05047562 0.05029958 0.04365551
 0.0490213  0.05025589 0.04481179 0.03917962 0.04481067 0.04947545
 0.04692578 0.04692578]
tr_loss:[0.05240482 0.04287821 0.04314325 0.04997507 0.04052108 0.03635154
 0.06915276 0.03635808 0.04052116 0.06546265 0.04052107 0.04776043
 0.03635805 0.04287818 0.03671999 0.03646397 0.03727641 0.04405311
 0.04052107 0.03403201 0.04287822 0.0363581  0.07386151 0.03372274
 0.03635802 0.04287819 0.03635801 0.03719384 0.036358   0.03672782
 0.0405211  0.07718507 0.03671998 0.03352433 0.04052414 0.04052109
 0.03635807 0.03397803 0.04745653 0.03396993 0.03395497 0.0405211
 0.05614256 0.03671998 0.03385459 0.05248339 0.04287822 0.04287812
 0.03380661 0.03386652]
text_input.shape
(1900, 14400)
learning_input_tmp.shape
(1900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(1900, 80)
learning_output.shape
(750, 80)
Model: "sequential_40"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_40 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2691194  1.220779   1.2083076  1.2083024  1.0788677  1.0733861
 1.223401   1.3080599  1.1779922  1.1779922  0.9986294  1.1779922
 1.2691195  1.2691209  1.2121035  1.2691195  1.102358   1.0733527
 1.3642838  1.208307   1.1779982  1.2158846  1.0732248  1.2124478
 1.2691106  1.2691194  1.1792672  1.1962154  1.2691194  1.2125429
 1.3644361  1.2015836  0.98422116 1.2234285  1.208307   1.2082247
 1.1834707  1.2121345  1.1779925  1.2234012  1.1779923  1.1779921
 1.2083071  1.3642833  1.2083069  1.2083112  1.2015522  1.3642838
 1.2552154  1.2691195 ]
tr_loss:[0.8050004  0.733369   0.73365086 0.8049175  0.826042   0.76172984
 0.65656567 0.7336665  0.8263758  0.7336508  0.7688148  0.7336508
 0.8263756  0.81938523 0.6560184  0.8262571  0.8263758  0.7298545
 0.7398265  0.7850453  0.72973615 0.80491734 0.8263756  0.81841356
 0.78489584 0.7336508  0.6485761  0.63362664 0.6262218  0.8263748
 0.8263758  0.8263758  0.80493355 0.7336408  0.6561592  0.65743333
 0.6565243  0.80398196 0.8263758  0.7298071  0.8263758  0.7627333
 0.729736   0.7297359  0.785042   0.6557473  0.73365086 0.82627535
 0.65706396 0.72973585]
tr_loss:[0.39418006 0.39852968 0.36880207 0.36790156 0.41869926 0.4225998
 0.39415714 0.39416656 0.40958065 0.4225997  0.36908922 0.3941571
 0.41047382 0.36842138 0.3985294  0.42259973 0.41870433 0.3941571
 0.47428522 0.47428316 0.45802808 0.4225998  0.392945   0.47443715
 0.39415708 0.3941571  0.47428638 0.4225997  0.4605941  0.46059403
 0.47426143 0.36934876 0.36865854 0.38505945 0.39415798 0.46059284
 0.3784442  0.38505968 0.39815727 0.39846015 0.39415723 0.3987262
 0.36823875 0.3956933  0.44576398 0.36839622 0.39368552 0.4225996
 0.39469686 0.36826456]
tr_loss:[0.22853689 0.22399859 0.21486342 0.22619629 0.24178867 0.2183414
 0.23051839 0.2417887  0.24520512 0.24277839 0.22853689 0.22892213
 0.24178872 0.21469478 0.2242101  0.22883603 0.24438421 0.23318473
 0.23412505 0.22392364 0.24178872 0.22177772 0.22397919 0.24181926
 0.22044878 0.22044873 0.22044866 0.21946558 0.22393616 0.22916695
 0.24520504 0.24178872 0.24565509 0.21469331 0.24520512 0.24520512
 0.23937249 0.24520509 0.22892213 0.22892208 0.2056444  0.2238456
 0.2183414  0.24328093 0.22380301 0.24178872 0.22853315 0.2259585
 0.241708   0.22853613]
tr_loss:[0.16416052 0.1620698  0.16601706 0.16785972 0.16601701 0.16416058
 0.17126662 0.1712666  0.16005507 0.18464689 0.1641606  0.18233447
 0.18223605 0.1660171  0.16415396 0.18154243 0.1817846  0.17126659
 0.17126659 0.18674445 0.16601707 0.16601703 0.19392721 0.17633545
 0.18587953 0.17683879 0.18588045 0.16601694 0.17770799 0.17770794
 0.18173763 0.1688317  0.17126627 0.16416058 0.17126663 0.18172455
 0.19392014 0.16601698 0.1712666  0.16207093 0.16207084 0.18155591
 0.16598463 0.16207093 0.16416058 0.16571118 0.15264578 0.18208358
 0.17124802 0.1733517 ]
tr_loss:[0.1458596  0.11277176 0.12937458 0.144568   0.11279026 0.11386733
 0.13354973 0.10893098 0.11386728 0.12938234 0.10893097 0.13101456
 0.11386732 0.10890919 0.11019586 0.11019588 0.1083314  0.10893071
 0.13428342 0.10905097 0.11019595 0.10905101 0.10905101 0.11019592
 0.10820933 0.12109859 0.11019663 0.10869603 0.12826715 0.11278039
 0.11452154 0.13421825 0.10905099 0.10905097 0.12938592 0.13436879
 0.11197171 0.13429701 0.13266733 0.13429952 0.13113458 0.1342239
 0.10884758 0.13428608 0.10905097 0.11386733 0.11405561 0.11277673
 0.10646147 0.13364598]
tr_loss:[0.05666601 0.06211445 0.05689683 0.06553286 0.09137142 0.07716259
 0.06268711 0.06859846 0.06281479 0.06050523 0.06906085 0.06281471
 0.09144105 0.09144475 0.05666603 0.0756304  0.09146987 0.09138867
 0.05666561 0.06858786 0.06050523 0.07508521 0.06050522 0.09226991
 0.06859846 0.09132308 0.05666604 0.06906082 0.09138693 0.09143476
 0.07508686 0.0914175  0.06281431 0.06050625 0.09783066 0.0605052
 0.06279689 0.06281476 0.06859844 0.06281479 0.11573817 0.06281477
 0.09055115 0.06281475 0.06050516 0.07706004 0.07712283 0.09377044
 0.06281479 0.07175919]
tr_loss:[0.10624937 0.06346508 0.04704562 0.06124894 0.05275311 0.03541027
 0.05410188 0.0470483  0.06346504 0.05617577 0.07905214 0.07908218
 0.05821625 0.0634651  0.05821731 0.06335099 0.06346504 0.06346512
 0.05219331 0.03541025 0.06346508 0.07550512 0.04827192 0.0785445
 0.0470871  0.06346498 0.07889029 0.09963968 0.07633549 0.03540941
 0.04704816 0.03541024 0.07884058 0.03541026 0.05617582 0.05821623
 0.07886863 0.06346506 0.05617579 0.0470477  0.03540919 0.0527396
 0.07519688 0.05185736 0.05215997 0.05921762 0.06351858 0.08762502
 0.04827019 0.04682381]
tr_loss:[0.05142803 0.0695443  0.04189562 0.09717838 0.04189564 0.04093862
 0.10306456 0.04189559 0.05047948 0.0490102  0.05046161 0.04189559
 0.09240215 0.05785919 0.04189545 0.05254078 0.09426017 0.04964958
 0.0525407  0.05719314 0.05719376 0.06954434 0.05049567 0.06050535
 0.07964033 0.06975688 0.0418956  0.05719374 0.07969277 0.05719278
 0.05046164 0.05244685 0.04914436 0.0981712  0.06954429 0.05046164
 0.05719376 0.0418956  0.05046164 0.0605147  0.0605054  0.06952035
 0.05010863 0.05718737 0.04189561 0.04189561 0.0695443  0.05197655
 0.06954424 0.05719375]
tr_loss:[0.03594167 0.08004652 0.03594171 0.04128402 0.04128404 0.07996644
 0.04128399 0.04069244 0.10828242 0.06538649 0.05258775 0.05797479
 0.05735328 0.04169976 0.03594167 0.04069241 0.04003318 0.08015692
 0.0653863  0.08015957 0.08379034 0.03594166 0.04128401 0.08028171
 0.05145426 0.04128399 0.03594164 0.0501186  0.05791301 0.06538649
 0.08479342 0.03594166 0.03594169 0.06408913 0.06538644 0.04910243
 0.05258774 0.03594164 0.04910722 0.06884124 0.05797487 0.03594168
 0.06538647 0.04069239 0.04991613 0.03594171 0.05731323 0.03594166
 0.04128843 0.06321067]
tr_loss:[0.05487436 0.02847818 0.02847823 0.02847821 0.06056086 0.08468903
 0.06056088 0.04572114 0.0605607  0.08498748 0.03596677 0.02847813
 0.09001473 0.04959337 0.03596677 0.03596677 0.05487426 0.0605609
 0.03864068 0.03596676 0.05936208 0.06056089 0.0605606  0.0492177
 0.06055831 0.06052317 0.05487436 0.06052154 0.0605609  0.03596677
 0.06052295 0.057954   0.1073717  0.04572111 0.03915109 0.03596694
 0.08073084 0.060523   0.04704392 0.04704394 0.02847818 0.02847818
 0.02847821 0.06005157 0.05485538 0.03596678 0.08957758 0.04343812
 0.04704388 0.08560128]
tr_loss:[0.05724343 0.03688322 0.04786025 0.08478892 0.08611502 0.11053389
 0.08601791 0.05724387 0.03771013 0.04466979 0.05724348 0.04466972
 0.05724347 0.05966113 0.05724344 0.08563031 0.05724341 0.0572435
 0.08555844 0.03771012 0.05966111 0.02582216 0.0857135  0.04355515
 0.03969854 0.02582208 0.04804752 0.08596856 0.05724347 0.03756876
 0.0831937  0.08559181 0.03771017 0.02582218 0.03785048 0.04224464
 0.02582214 0.08598708 0.08141483 0.05966114 0.05966072 0.04466979
 0.05966111 0.02631757 0.05965583 0.05599381 0.04775937 0.03771064
 0.04085767 0.0377101 ]
tr_loss:[0.05528462 0.04512521 0.05528454 0.04237681 0.03949646 0.05452463
 0.02652434 0.08917099 0.03889374 0.02652435 0.0421673  0.02652729
 0.0807281  0.05286162 0.05545867 0.02652432 0.03949523 0.03949526
 0.05544527 0.08104201 0.05452467 0.06916475 0.08669128 0.05528461
 0.03949523 0.03949522 0.03889375 0.03949526 0.03772808 0.05511
 0.0394089  0.03949526 0.02652431 0.05452459 0.05528454 0.02652435
 0.03949526 0.04215368 0.03949527 0.0807893  0.03949527 0.04512548
 0.08074083 0.09386367 0.02652434 0.09046503 0.04215359 0.05541844
 0.05545866 0.04512503]
tr_loss:[0.10245377 0.04096899 0.02944251 0.05074886 0.05679747 0.05418207
 0.07601518 0.04588085 0.05484823 0.02944254 0.0358481  0.0294425
 0.02944254 0.05210697 0.05484821 0.0358481  0.05484823 0.02944251
 0.0358481  0.05484828 0.05061389 0.02944254 0.04096899 0.05074884
 0.0751661  0.02944251 0.07605773 0.02944252 0.04766154 0.04032599
 0.05074884 0.02944252 0.05074888 0.03702264 0.04096901 0.02944431
 0.10233846 0.03584812 0.07606097 0.05074887 0.05070556 0.05484961
 0.02944254 0.05484826 0.07603603 0.0294426  0.04096902 0.07610878
 0.05074469 0.07618263]
tr_loss:[0.0415964  0.0528812  0.03869183 0.07109158 0.04403    0.07119613
 0.04392657 0.08134432 0.05488705 0.03702874 0.02909774 0.03792539
 0.05104319 0.07113191 0.04107577 0.03579024 0.03505398 0.03505393
 0.05104319 0.05288116 0.05104315 0.051031   0.05139819 0.06810116
 0.0379254  0.07112889 0.03505398 0.02909775 0.06980677 0.06746065
 0.0920765  0.03469749 0.02909773 0.03868804 0.03792571 0.05288119
 0.04322987 0.09540017 0.03505399 0.0289022  0.07104063 0.0379254
 0.02909775 0.03776871 0.03793116 0.03792541 0.03792538 0.02909772
 0.08691809 0.03573909]
tr_loss:[0.03765858 0.0343415  0.03749222 0.02625257 0.03393095 0.04822653
 0.03566898 0.06594314 0.02625258 0.06575863 0.06582518 0.03749257
 0.04272537 0.04435139 0.06561318 0.02625257 0.03568468 0.02625312
 0.03780095 0.03109692 0.04555916 0.03109688 0.0660599  0.03747657
 0.03749257 0.04435143 0.0657791  0.05964414 0.06551794 0.03566898
 0.0443514  0.04433867 0.03561797 0.03746732 0.03109689 0.06596371
 0.03749252 0.03832684 0.03765426 0.03749253 0.03749252 0.04435141
 0.04822658 0.03109691 0.06581698 0.07925103 0.08427257 0.03474232
 0.02625259 0.02625257]
tr_loss:[0.03583839 0.03688312 0.06329157 0.04032347 0.02996767 0.04664711
 0.06295551 0.02647237 0.03363342 0.09359963 0.03712185 0.03583843
 0.02996733 0.04032367 0.02646281 0.04646237 0.06296957 0.04032348
 0.02996767 0.02996724 0.0382553  0.04502295 0.04439247 0.0403418
 0.0264628  0.0264628  0.04669196 0.02996766 0.02996771 0.03363283
 0.02948777 0.03817983 0.06268071 0.02646281 0.03583841 0.07502165
 0.0901184  0.06323867 0.04032348 0.02646281 0.02996766 0.03712108
 0.03479416 0.06032234 0.03749504 0.02996769 0.03800855 0.0358361
 0.03583658 0.02996767]
tr_loss:[0.04322489 0.05030053 0.03983766 0.02908308 0.04217077 0.04217078
 0.02908305 0.0421708  0.02910384 0.06327893 0.06334691 0.04217068
 0.0421708  0.04217077 0.09861052 0.06214276 0.04983014 0.04553083
 0.02908308 0.04177349 0.02908308 0.03966608 0.06316338 0.02908305
 0.04177349 0.04217081 0.02908306 0.06331876 0.04322469 0.03983768
 0.03983771 0.04217082 0.04216324 0.03264343 0.04260621 0.04217081
 0.04762526 0.0464255  0.02908308 0.03264344 0.06334301 0.04177349
 0.03264342 0.06325283 0.03264352 0.06373495 0.06326038 0.04217068
 0.04217076 0.04217074]
tr_loss:[0.03972967 0.10432617 0.03248952 0.03236351 0.04105144 0.05753886
 0.04072771 0.08434062 0.02770302 0.04078837 0.03236348 0.07559901
 0.0433832  0.04342186 0.03312699 0.02770302 0.03502481 0.04017027
 0.04105144 0.04105154 0.02770301 0.04555196 0.04078835 0.03502482
 0.03236354 0.06080461 0.04078835 0.04347137 0.03236353 0.03236351
 0.03437094 0.06006457 0.03968853 0.04243587 0.06068062 0.06039508
 0.02770301 0.06064998 0.02735412 0.04078835 0.08181841 0.03972279
 0.02990717 0.04078835 0.03502482 0.02769156 0.05913894 0.04078837
 0.02770302 0.08400194]
tr_loss:[0.04168867 0.02324039 0.03881757 0.04104713 0.03862138 0.02324039
 0.02942511 0.03352541 0.03881759 0.02324036 0.02324039 0.04003534
 0.03015691 0.03610045 0.04003538 0.03876942 0.02324039 0.02942507
 0.03881757 0.02826318 0.02324037 0.04100526 0.03881758 0.02324037
 0.05258375 0.02324037 0.02324012 0.05781507 0.03793865 0.03880627
 0.05785026 0.03871223 0.03610048 0.05783255 0.05792218 0.03622463
 0.0388061  0.02323669 0.03826821 0.05784212 0.02942508 0.05774002
 0.05760832 0.072474   0.03794526 0.02694055 0.02943    0.02861528
 0.05770382 0.03880628]
tr_loss:[0.02448338 0.05258975 0.0333235  0.02448338 0.0333235  0.03325794
 0.02448339 0.03199399 0.03466576 0.033342   0.01653648 0.01653652
 0.03208178 0.03325795 0.07624087 0.03466571 0.01653648 0.02448978
 0.03466574 0.05490469 0.02448339 0.02300913 0.03332349 0.0310671
 0.03332347 0.0550398  0.02448341 0.02450996 0.03461162 0.05503627
 0.03322703 0.0165365  0.02448338 0.03325788 0.03332369 0.05281905
 0.01644364 0.03332487 0.02407535 0.02448339 0.03231198 0.03325043
 0.03231489 0.03461667 0.0165365  0.03332347 0.05492226 0.03466579
 0.01653649 0.01653648]
tr_loss:[0.01560725 0.01560725 0.01560725 0.02605805 0.03103395 0.03104027
 0.03049384 0.03747027 0.05840376 0.06651261 0.03246987 0.02491665
 0.05837656 0.01560724 0.03104322 0.01560726 0.03104323 0.03104321
 0.02491617 0.0789303  0.06958892 0.02637357 0.02491613 0.02603759
 0.02491614 0.02491615 0.0582208  0.02491615 0.02491613 0.03104325
 0.05823977 0.02492126 0.02637341 0.03459698 0.03104325 0.03560274
 0.02441279 0.03104323 0.01560726 0.01560726 0.02491616 0.03560272
 0.0576257  0.03246989 0.05835667 0.01560725 0.02492503 0.02440202
 0.05778633 0.06806229]
tr_loss:[0.02726557 0.02971445 0.03255776 0.06092979 0.0306027  0.01555868
 0.01555867 0.02535755 0.06068252 0.02976956 0.02283073 0.029458
 0.03255779 0.0306068  0.01555869 0.01555867 0.03916971 0.02283071
 0.03820764 0.01555869 0.03255533 0.02972939 0.03820761 0.06149786
 0.02283071 0.02283072 0.01555914 0.06082519 0.02283072 0.03820766
 0.02283073 0.02283072 0.02283073 0.03060697 0.01555867 0.02283072
 0.04179068 0.04179069 0.03921478 0.03291268 0.01555868 0.06027859
 0.03060694 0.04405534 0.03060698 0.0382076  0.03124968 0.06038723
 0.03820763 0.0325755 ]
tr_loss:[0.03123328 0.05606472 0.01541251 0.01541251 0.03142493 0.03519029
 0.03329973 0.03123223 0.0351903  0.06047035 0.04193811 0.01541249
 0.06058343 0.05833285 0.03654266 0.06042857 0.04246805 0.03802551
 0.06035171 0.01568224 0.04193809 0.02056905 0.05677235 0.03051919
 0.0312333  0.03122789 0.06046863 0.02056905 0.01541252 0.03519028
 0.06868862 0.02053095 0.03123328 0.03519031 0.02056905 0.06043731
 0.06429576 0.0351903  0.0351903  0.03519028 0.06071662 0.02877535
 0.03123328 0.0351903  0.0154125  0.03519023 0.04175425 0.03519035
 0.02840387 0.02056904]
tr_loss:[0.05644606 0.01996407 0.01485256 0.03044505 0.04061243 0.05635235
 0.05648481 0.03555157 0.04061271 0.01485255 0.04061275 0.03790831
 0.06651326 0.02865515 0.05440943 0.03534921 0.03534919 0.03534915
 0.03814862 0.07827798 0.03052009 0.03534923 0.04061274 0.02964584
 0.0353492  0.09116625 0.01996403 0.03269421 0.02650465 0.0353492
 0.03022186 0.05659802 0.03269422 0.01995792 0.03052009 0.03878713
 0.01485254 0.03274707 0.03848105 0.0370989  0.01485254 0.01996406
 0.03709891 0.05433772 0.05871047 0.05632968 0.02651119 0.05603947
 0.05637807 0.01996406]
tr_loss:[0.03219446 0.03386328 0.0208156  0.03105223 0.07353512 0.03198547
 0.06043737 0.01410981 0.03386391 0.03219448 0.0208156  0.0208156
 0.05432449 0.05360655 0.03276225 0.03295598 0.03219435 0.03327863
 0.05430637 0.05428102 0.03219449 0.03193192 0.02081561 0.0525585
 0.01407875 0.0310522  0.03080815 0.02081563 0.05435653 0.03386331
 0.06755431 0.01410982 0.03105222 0.03081001 0.03219449 0.05436422
 0.03217849 0.03605022 0.02703227 0.06487766 0.01399533 0.03128784
 0.02703122 0.0141048  0.0530034  0.0141114  0.03219401 0.02081558
 0.03386334 0.0208156 ]
tr_loss:[0.02786932 0.02955834 0.02815873 0.02977009 0.02282293 0.02030684
 0.01349174 0.03218093 0.02330814 0.02816297 0.03187289 0.01349173
 0.01349173 0.0697605  0.03204297 0.02095972 0.05303935 0.02843986
 0.02811177 0.03187387 0.05995535 0.03432037 0.03464124 0.03464125
 0.01349169 0.02095969 0.05306344 0.03187389 0.03144794 0.03184754
 0.02787461 0.03187383 0.03186359 0.02819676 0.0280833  0.02789149
 0.05299697 0.02096084 0.06725661 0.02094144 0.01349175 0.07646608
 0.02841759 0.05307939 0.0530837  0.0209598  0.03187387 0.03218089
 0.07419263 0.03187386]
tr_loss:[0.02853335 0.02931476 0.04779238 0.02919207 0.02940718 0.01225523
 0.03035532 0.03283809 0.02005606 0.02657027 0.01225522 0.02005604
 0.06771097 0.0303553  0.02853126 0.02503246 0.047048   0.02002609
 0.0250305  0.03055016 0.06905188 0.02853312 0.05501233 0.01225523
 0.01225522 0.01225522 0.02931473 0.02912006 0.02853295 0.02687992
 0.02005607 0.03035602 0.02911986 0.02853367 0.0303553  0.03013865
 0.06393375 0.07898828 0.01225523 0.02881711 0.02881712 0.03283808
 0.02005605 0.05792921 0.02853372 0.05028441 0.02866032 0.05031807
 0.01225523 0.02881713]
tr_loss:[0.0503676  0.02318119 0.02152674 0.03482703 0.02995043 0.03482722
 0.03328743 0.0299504  0.02552376 0.02152575 0.03320557 0.02152574
 0.05018555 0.05067313 0.0332874  0.03482702 0.03328744 0.01397539
 0.05082522 0.02074434 0.02767723 0.0214479  0.03070673 0.02152574
 0.0276772  0.02995041 0.03170095 0.01397455 0.02995039 0.02995039
 0.02995041 0.02233127 0.02152574 0.02152569 0.06868688 0.02278856
 0.0653837  0.03592129 0.02999029 0.02146175 0.03657853 0.03189711
 0.03502262 0.02152574 0.05046223 0.01397459 0.02767721 0.05031694
 0.05079741 0.0227836 ]
tr_loss:[0.02643043 0.02643046 0.02643043 0.03301193 0.02578266 0.01261081
 0.02895293 0.02643045 0.02809708 0.02137737 0.02862337 0.05899677
 0.0629947  0.02582956 0.07800754 0.01261093 0.01261092 0.03301378
 0.02643046 0.02643039 0.0264142  0.05636554 0.02928073 0.0265498
 0.03301389 0.02570349 0.02862333 0.0197449  0.04936303 0.02642554
 0.02583327 0.02643042 0.02895295 0.04935407 0.02667486 0.01261092
 0.06429797 0.02137737 0.01261091 0.04921162 0.04966096 0.02927445
 0.02862337 0.01261093 0.02895293 0.04075801 0.02895323 0.02137737
 0.02137736 0.04945363]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1900 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1901, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1901 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1902, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1902 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1903, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1903 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1904, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1904 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1905, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1905 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1906, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1906 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1907, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1907 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1908, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1908 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1909, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1909 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1910, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1910 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1911, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1911 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1912, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1912 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1913, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1913 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1914, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1914 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1915, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1915 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1916, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1916 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1917, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1917 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1918, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1918 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1919, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1919 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1920, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1920 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1921, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1921 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1922, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1922 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1923, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1923 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1924, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1924 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1925, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1925 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1926, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1926 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1927, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1927 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1928, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1928 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1929, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1929 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1930, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1930 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1931, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1931 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1932, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1932 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1933, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1933 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1934, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1934 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1935, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1935 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1936, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1936 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1937, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1937 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1938, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1938 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1939, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1939 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1940, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1940 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1941, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1941 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1942, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1942 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1943, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1943 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1944, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1944 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1945, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1945 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1946, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1946 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1947, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1947 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1948, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1948 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1949, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1949 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1950, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1950 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1951, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1951 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1952, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1952 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1953, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1953 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1954, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1954 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1955, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1955 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1956, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1956 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1957, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1957 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1958, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1958 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1959, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1959 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1960, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1960 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1961, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1961 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1962, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1962 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1963, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1963 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1964, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1964 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1965, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1965 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1966, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1966 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1967, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1967 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1968, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1968 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1969, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1969 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1970, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1970 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1971, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1971 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1972, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1972 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1973, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1973 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1974, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1974 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1975, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1975 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1976, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1976 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1977, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1977 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1978, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1978 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1979, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1979 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1980, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1980 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1981, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1981 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1982, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1982 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1983, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1983 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1984, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1984 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1985, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1985 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1986, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1986 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1987, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1987 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1988, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1988 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1989, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1989 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1990, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1990 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1991, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1991 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1992, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1992 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1993, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1993 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1994, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1994 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1995, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1995 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1996, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1996 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1997, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1997 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1998, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1998 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(1999, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 1999 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2000, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-1900
text_input.shape
(2000, 14400)
learning_input_tmp.shape
(2000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2000, 80)
learning_output.shape
(750, 80)
Model: "sequential_41"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_41 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.138434  1.2345402 1.1774292 1.1116365 1.2386982 1.2346283 1.1311677
 1.1319185 1.2345403 1.1631144 1.1611364 1.1774309 1.2345397 1.1516231
 1.1516263 1.1516231 1.1324517 1.1509053 1.1762869 1.2386982 1.1516453
 1.1516287 1.1831623 1.117663  1.117663  1.151623  1.2386992 1.1311677
 1.1516231 1.1611321 1.0372488 1.2345403 1.1888139 1.1311677 1.2386984
 1.2386984 1.1311649 1.1611325 1.2345402 1.1288534 1.1315683 1.2368133
 1.1288536 1.1062378 1.1288536 1.1311674 1.1288524 1.1339848 1.1516231
 1.1311677]
tr_loss:[0.6344453  0.6400749  0.65442413 0.65442145 0.65799946 0.63444585
 0.71370375 0.7161093  0.63465786 0.71610916 0.63444525 0.64823043
 0.6875561  0.62803423 0.66331863 0.71370536 0.6772274  0.63444525
 0.65799963 0.63463855 0.63995016 0.6344464  0.6400814  0.65799963
 0.6579994  0.7161093  0.70829016 0.7137054  0.6344756  0.67227095
 0.6572336  0.7161093  0.7161093  0.71370524 0.6580031  0.6313438
 0.7137052  0.65442413 0.6623856  0.66238534 0.7137009  0.65446866
 0.6579995  0.64351827 0.6591712  0.68140316 0.66238534 0.71370524
 0.6579996  0.65910494]
tr_loss:[0.37982124 0.42621446 0.41956887 0.50587225 0.43914777 0.41182628
 0.41725102 0.41182643 0.38598108 0.4259553  0.5058722  0.4391478
 0.50587225 0.4595902  0.50587213 0.41935015 0.37960353 0.41182637
 0.43914777 0.43914786 0.34558424 0.34548122 0.42847142 0.43182144
 0.4391469  0.41613007 0.4174716  0.41182643 0.425955   0.43914586
 0.3796037  0.37960333 0.34555864 0.4172333  0.4877762  0.4259552
 0.34559923 0.4719329  0.50587225 0.41182643 0.4586439  0.4180425
 0.4391454  0.34551683 0.43914777 0.4172333  0.43962988 0.4118263
 0.380016   0.37960345]
tr_loss:[0.20087533 0.20087531 0.2265949  0.2196351  0.2009346  0.21575423
 0.17113331 0.20087528 0.20087528 0.19022448 0.21575427 0.16968055
 0.20087528 0.2542668  0.20289095 0.20331883 0.23953454 0.20087533
 0.22054787 0.2576415  0.17489943 0.22688024 0.17497595 0.20087531
 0.19022456 0.2542668  0.18020067 0.24600753 0.19022453 0.19022459
 0.20087524 0.20331761 0.19022457 0.21965083 0.21604478 0.21575423
 0.21596465 0.25426677 0.2033175  0.20087521 0.22669661 0.16972974
 0.22247012 0.16967642 0.2158082  0.22688016 0.2542668  0.17496446
 0.21963246 0.23985305]
tr_loss:[0.13760382 0.1336018  0.13148795 0.14800039 0.13760382 0.14726055
 0.14726046 0.12207581 0.14726046 0.13657112 0.13657105 0.13760379
 0.1479121  0.14725576 0.13646403 0.14655444 0.15598206 0.13760382
 0.1376038  0.13657105 0.13148797 0.12206753 0.1472605  0.136571
 0.13148795 0.14297509 0.15073843 0.13657111 0.13339493 0.14726049
 0.13657108 0.14800332 0.14537112 0.14726049 0.130269   0.14801866
 0.12205998 0.13760383 0.13148794 0.13794534 0.13339493 0.13161261
 0.11985518 0.14655444 0.14812604 0.13684213 0.13148797 0.13657114
 0.14935498 0.1367388 ]
tr_loss:[0.07292692 0.07292689 0.09586476 0.09730291 0.07597284 0.08940102
 0.07789119 0.07292693 0.10434377 0.07597286 0.0970265  0.10985132
 0.09116594 0.07597288 0.10320032 0.089401   0.07292693 0.12328069
 0.09082526 0.1232661  0.09730297 0.1031998  0.07292695 0.08803759
 0.12318034 0.08940099 0.08940082 0.08940103 0.10377948 0.07597284
 0.07986936 0.10377946 0.12326223 0.07597341 0.08940104 0.07597286
 0.09730296 0.09706749 0.10377951 0.08975246 0.10985217 0.07597286
 0.07597138 0.12298693 0.11246569 0.09705495 0.10377946 0.08940104
 0.07597226 0.10985227]
tr_loss:[0.0469559  0.08245979 0.08252691 0.08252664 0.10800834 0.0647101
 0.06741725 0.03345079 0.08245965 0.06469804 0.03345079 0.0469559
 0.09476118 0.03345079 0.08252688 0.07179185 0.09711035 0.04695116
 0.0469559  0.08632425 0.08252689 0.07514518 0.0334508  0.08252685
 0.0334508  0.04695592 0.06373049 0.08632429 0.08245958 0.0469559
 0.08632428 0.03345079 0.10800247 0.0647101  0.08632425 0.0469559
 0.0824596  0.08252691 0.06741617 0.03345079 0.09476107 0.0651422
 0.08252602 0.0825269  0.06472304 0.10801085 0.07172786 0.08246285
 0.03345079 0.08245957]
tr_loss:[0.04421942 0.02602836 0.07866926 0.10284368 0.05767228 0.0774319
 0.02602833 0.0774318  0.02602842 0.07668827 0.04439779 0.07743182
 0.07668821 0.04440546 0.04202918 0.02602836 0.05767222 0.07670321
 0.10296128 0.05766279 0.07743184 0.02602834 0.02602838 0.02602835
 0.06454416 0.02602839 0.05767221 0.02602834 0.02602839 0.05767218
 0.07669379 0.07668827 0.05767338 0.02602844 0.0579944  0.06707779
 0.07668823 0.0774319  0.05767228 0.10293481 0.05767221 0.10303422
 0.02602834 0.07668835 0.07668822 0.07668819 0.07668829 0.06060136
 0.04467214 0.02602836]
tr_loss:[0.054436   0.05443604 0.06915252 0.07365099 0.04851288 0.04851285
 0.07415648 0.07663828 0.03537993 0.0741565  0.05443604 0.07255673
 0.07255674 0.05230672 0.07418115 0.03537989 0.06915237 0.04851288
 0.04851288 0.04851288 0.07592698 0.063163   0.07255666 0.07415647
 0.06940497 0.06316163 0.03537994 0.03537993 0.07404105 0.0741565
 0.03537995 0.07404114 0.09806316 0.04851291 0.09803374 0.06939991
 0.06917343 0.07321537 0.0701388  0.05448794 0.09816056 0.03537989
 0.09820224 0.03537986 0.03537992 0.054436   0.07423531 0.07415647
 0.05443656 0.06940494]
tr_loss:[0.06003802 0.03938341 0.03942309 0.06047957 0.06003801 0.06401204
 0.05072208 0.03943367 0.06382073 0.06003798 0.05990435 0.06382099
 0.08819662 0.05067359 0.06382103 0.04477445 0.04471119 0.0591924
 0.07281397 0.06401202 0.07281415 0.06005286 0.05076411 0.08815169
 0.0447741  0.0881182  0.04477409 0.063821   0.06401205 0.08826163
 0.06382103 0.03942377 0.05076408 0.05076411 0.063821   0.0394231
 0.03942311 0.07281438 0.060038   0.06874206 0.07226126 0.08818522
 0.06381746 0.0619291  0.0687317  0.06003799 0.05076408 0.06003802
 0.04477404 0.0881702 ]
tr_loss:[0.05569647 0.04516217 0.05002983 0.03668947 0.05044916 0.04370094
 0.0504492  0.04516223 0.03404912 0.03668942 0.0707021  0.04749763
 0.05044919 0.04516251 0.04516222 0.05044918 0.03668945 0.04516223
 0.03667315 0.03501012 0.03138324 0.06254272 0.04370111 0.06271596
 0.05569648 0.06528562 0.03501011 0.0504492  0.05787824 0.03501174
 0.0706803  0.05044919 0.07079867 0.0474976  0.06113024 0.03668946
 0.04516221 0.03668944 0.05002983 0.05569644 0.06215449 0.04749158
 0.04697621 0.06271611 0.04749754 0.04516222 0.03669042 0.05569647
 0.04516224 0.04999421]
tr_loss:[0.03840479 0.03840333 0.04133612 0.03355952 0.02491185 0.03352921
 0.04364907 0.0384041  0.0496767  0.03862362 0.04371351 0.03855034
 0.03840333 0.03352923 0.03862366 0.06490155 0.02490564 0.0248819
 0.03843536 0.03862535 0.02490538 0.03800087 0.04375886 0.03840339
 0.02490729 0.04370551 0.03352923 0.04370555 0.03611743 0.03862364
 0.04356316 0.03352924 0.04370555 0.06003822 0.03862269 0.03353166
 0.02236821 0.03352924 0.04064525 0.0249056  0.03840335 0.04357958
 0.04670945 0.02490565 0.03352923 0.03795101 0.0249056  0.03855588
 0.02490566 0.03795098]
tr_loss:[0.03739814 0.03740528 0.04269778 0.0263262  0.03740539 0.04183066
 0.04902305 0.0380519  0.04192697 0.04420186 0.02632616 0.02795048
 0.04268988 0.01826847 0.02765445 0.01826848 0.02765433 0.06152757
 0.03805189 0.03740525 0.01826848 0.04152088 0.04268986 0.04149813
 0.03619504 0.04152071 0.04902303 0.01826846 0.03616797 0.03727611
 0.04152089 0.04269003 0.04440793 0.01803798 0.03616662 0.03616808
 0.04268985 0.03805232 0.04271507 0.02765234 0.0276531  0.04152091
 0.01826846 0.03740538 0.0415209  0.03805191 0.02632622 0.02624186
 0.04269053 0.02632623]
tr_loss:[0.0261158  0.03842768 0.04877306 0.01945894 0.04638255 0.03995888
 0.0218224  0.048773   0.06426807 0.04080961 0.01945898 0.03842801
 0.02182241 0.0261158  0.04007301 0.01947958 0.02917669 0.04004534
 0.04711928 0.02182238 0.04878787 0.04007314 0.02768013 0.04877488
 0.04128145 0.02613377 0.04638256 0.0218224  0.04005568 0.04007309
 0.02612709 0.02182239 0.04128146 0.02182241 0.01945834 0.04007312
 0.04007309 0.04510493 0.04007312 0.01945892 0.04128163 0.02611582
 0.01929637 0.04007313 0.0261158  0.0487731  0.04135229 0.04007313
 0.01881673 0.04477947]
tr_loss:[0.01826698 0.05010301 0.04304153 0.06301436 0.05010349 0.04007087
 0.05010309 0.02842027 0.02841946 0.04542754 0.04304155 0.05010513
 0.02766256 0.04046804 0.02841949 0.04188489 0.04188677 0.06300607
 0.04188749 0.02841945 0.02766256 0.01780364 0.03315737 0.03801107
 0.02766355 0.0418894  0.02841946 0.04007086 0.04304043 0.02766254
 0.04189022 0.05010306 0.0501044  0.04542794 0.06305278 0.04050018
 0.05045251 0.04180539 0.050103   0.05045236 0.04007085 0.02841946
 0.06301909 0.05053588 0.05045237 0.02766056 0.06292871 0.05045236
 0.06299138 0.04304158]
tr_loss:[0.02869482 0.03993299 0.03982837 0.02124446 0.03993303 0.0554109
 0.04476938 0.03982841 0.03798738 0.03982838 0.03982836 0.02883661
 0.02978662 0.04476955 0.03993297 0.02978662 0.02151119 0.02581963
 0.0286948  0.0447697  0.02154794 0.04476955 0.04475329 0.04476953
 0.03903319 0.03886756 0.03948855 0.03948853 0.0297866  0.02869481
 0.04476955 0.02869702 0.02154792 0.02154795 0.04476953 0.03993305
 0.02978662 0.02869482 0.02869477 0.03798737 0.04476953 0.02978662
 0.02556865 0.02208255 0.02978662 0.02978664 0.03352296 0.04475818
 0.0379874  0.02978663]
tr_loss:[0.03058916 0.04007104 0.04097926 0.04007104 0.04079836 0.03243158
 0.03216993 0.04079833 0.04007098 0.04079836 0.03243154 0.05384081
 0.05382089 0.04007194 0.03020109 0.03058914 0.05382214 0.03217336
 0.04007096 0.03217362 0.0303438  0.03913838 0.03153055 0.03153057
 0.03531486 0.04072205 0.04079764 0.03153054 0.040071   0.03243154
 0.04007137 0.03243139 0.03651889 0.03058916 0.03153056 0.04007098
 0.03651927 0.03772967 0.03058929 0.03153055 0.03772966 0.04079836
 0.04097927 0.0324315  0.0407983  0.0324315  0.0307882  0.0324315
 0.03772969 0.03651926]
tr_loss:[0.03726196 0.03212022 0.02546545 0.03212021 0.02546545 0.03697864
 0.02546468 0.02546543 0.04085262 0.03377404 0.03591697 0.03211942
 0.04085258 0.02958941 0.02546545 0.02943015 0.03736727 0.03270455
 0.03270455 0.05168571 0.05167798 0.03126706 0.03597968 0.03010787
 0.02546348 0.03270453 0.03005385 0.03695902 0.03698464 0.03263184
 0.02546542 0.03700772 0.03005387 0.03005386 0.03736724 0.04010274
 0.03799019 0.03736725 0.03005384 0.03270454 0.05168216 0.03212018
 0.03212018 0.03005384 0.03270452 0.0366242  0.03212022 0.03212019
 0.05167962 0.0313066 ]
tr_loss:[0.02211298 0.03490434 0.03171626 0.02453861 0.03104034 0.02211297
 0.02211296 0.03797233 0.02453589 0.03971761 0.03971542 0.03155413
 0.03467246 0.03445396 0.022113   0.03104032 0.03286056 0.02453861
 0.02787328 0.02453863 0.02211298 0.02984442 0.03171624 0.03170351
 0.03171625 0.02580966 0.02492292 0.022113   0.02580964 0.03171623
 0.0328607  0.02972889 0.02238087 0.03971542 0.02211296 0.02901434
 0.02580963 0.02453864 0.02580967 0.0397154  0.03797407 0.02580962
 0.03171623 0.04599584 0.02453863 0.02580963 0.02580946 0.03104031
 0.03892517 0.03042333]
tr_loss:[0.01937473 0.0490093  0.0251396  0.02842149 0.02794014 0.01937472
 0.02828086 0.02841299 0.02794018 0.02841994 0.025139   0.0193747
 0.03482841 0.01937464 0.02282938 0.02842158 0.02795675 0.03336029
 0.0281752  0.02513903 0.03412083 0.02514644 0.02800268 0.02282877
 0.03210437 0.01937471 0.0228288  0.02794016 0.0251406  0.0193747
 0.02445839 0.01937415 0.02794016 0.02513902 0.02513902 0.02842163
 0.02795698 0.01937527 0.02800095 0.03255825 0.0228176  0.0193747
 0.0193747  0.02794014 0.02513901 0.02842163 0.02842161 0.04896947
 0.025139   0.0490155 ]
tr_loss:[0.02991804 0.02603593 0.04519142 0.02904173 0.02991806 0.02991819
 0.02603593 0.02991807 0.03532656 0.02427261 0.02971789 0.02718095
 0.02603593 0.03209861 0.02603593 0.02909857 0.02971791 0.02971791
 0.02603595 0.02803471 0.03057579 0.02971792 0.02971789 0.02991804
 0.03938445 0.02909566 0.0375762  0.02971792 0.02422731 0.0149983
 0.02603595 0.03348471 0.03742235 0.02955874 0.02603593 0.02603592
 0.02909848 0.02968767 0.03530147 0.0305534  0.01499828 0.01499828
 0.02603593 0.03210348 0.03348472 0.02889979 0.01499827 0.01499829
 0.03529956 0.02903203]
tr_loss:[0.02449966 0.01201275 0.05253653 0.02905603 0.0371542  0.02785726
 0.02451908 0.02905604 0.03213859 0.02238522 0.03280895 0.02238522
 0.0343755  0.02449964 0.03353156 0.03279783 0.01201272 0.02449966
 0.02238523 0.02450047 0.02238524 0.02449313 0.02905602 0.01201274
 0.02238524 0.01201275 0.03837145 0.03726977 0.0244352  0.01130324
 0.02238523 0.03128715 0.03278979 0.05254151 0.03216596 0.01194414
 0.02785727 0.02449963 0.02785728 0.02905495 0.01201275 0.02238548
 0.05252602 0.02895204 0.02905466 0.01201275 0.02785726 0.02449966
 0.0327898  0.03130198]
tr_loss:[0.02196727 0.03581237 0.02843036 0.02903982 0.02903987 0.02391257
 0.01239282 0.033756   0.02391269 0.02391265 0.03304232 0.04992951
 0.02334128 0.02344691 0.03581404 0.02394842 0.02785307 0.01239145
 0.01239144 0.0263218  0.01993663 0.02903986 0.03581233 0.03566001
 0.03565999 0.02413575 0.02903968 0.0252152  0.02368402 0.02868724
 0.02903726 0.02400566 0.03581232 0.01993672 0.01239145 0.02391266
 0.01239142 0.01993665 0.04994165 0.02391268 0.0358124  0.02851061
 0.04989972 0.01239144 0.04996908 0.02903977 0.0499492  0.01993667
 0.01838625 0.03581232]
tr_loss:[0.03112124 0.01648914 0.02541788 0.04036716 0.04036715 0.04838492
 0.03906009 0.02163885 0.01818817 0.02541786 0.0240417  0.03111752
 0.04840082 0.02541788 0.01930126 0.04036739 0.03111137 0.03112121
 0.03906015 0.02355576 0.03112103 0.04036712 0.02541787 0.03112121
 0.03849804 0.02700334 0.03905703 0.04036885 0.04840636 0.03023542
 0.03111866 0.04839434 0.02541786 0.03112122 0.03838436 0.01420878
 0.02355565 0.02994575 0.03112083 0.01421738 0.04835151 0.02362015
 0.0403671  0.01420877 0.04036714 0.02373056 0.02355086 0.04036714
 0.0254179  0.02346967]
tr_loss:[0.04438289 0.01795803 0.028822   0.01304831 0.01795803 0.01756896
 0.0262809  0.01795804 0.02965803 0.0376573  0.02882203 0.01811001
 0.02641443 0.03851379 0.03847549 0.01944489 0.0443281  0.01945089
 0.02965805 0.01304831 0.02635598 0.02882202 0.02965803 0.02927021
 0.01815211 0.02917197 0.028822   0.01795803 0.04443049 0.028822
 0.02642028 0.03963467 0.04438656 0.01795896 0.01304834 0.01304828
 0.02964876 0.02926906 0.04433408 0.01795802 0.0292854  0.02926908
 0.02632942 0.01795803 0.03847551 0.02965603 0.02965795 0.0384755
 0.01304832 0.03751594]
tr_loss:[0.00939994 0.01633652 0.01633653 0.0320725  0.02740038 0.04217209
 0.03367228 0.01633653 0.02718143 0.03223717 0.02737682 0.03350841
 0.04209368 0.01544878 0.02718222 0.01428972 0.04208673 0.03223712
 0.01633654 0.03223713 0.01633655 0.0363976  0.0142916  0.01428314
 0.03636409 0.03223713 0.03223718 0.00939993 0.04733027 0.00939994
 0.03223716 0.00939397 0.01633654 0.01633664 0.04214739 0.00939994
 0.03223734 0.01540447 0.03223716 0.02853841 0.02738186 0.02717069
 0.03639761 0.02718223 0.03223711 0.02713014 0.01633657 0.03224199
 0.00939993 0.01633654]
tr_loss:[0.02666882 0.00730423 0.01630385 0.0272429  0.02635215 0.02635319
 0.01630917 0.04252559 0.03360271 0.02742462 0.01202771 0.02724385
 0.01394217 0.02742466 0.02666885 0.00730424 0.0242028  0.02742464
 0.02635772 0.02666885 0.01630917 0.03040989 0.04249753 0.00730423
 0.02635219 0.03023179 0.01397765 0.03360273 0.01630921 0.00730423
 0.01630918 0.02740841 0.01397719 0.04249562 0.02635219 0.00730425
 0.02666878 0.02360883 0.04179748 0.02742463 0.02666887 0.0274246
 0.02666882 0.04249964 0.00730423 0.00730423 0.0336027  0.02742464
 0.0425327  0.03360265]
tr_loss:[0.00801064 0.00801103 0.01722249 0.02153051 0.03809173 0.00801103
 0.02694325 0.01772991 0.02590201 0.03202727 0.00801103 0.04170344
 0.02610579 0.02290848 0.0177642  0.06062695 0.04171868 0.0215326
 0.01776414 0.02590192 0.02590199 0.00801103 0.02153263 0.02590199
 0.00801102 0.01776412 0.02603665 0.02153305 0.04171389 0.02153258
 0.00801103 0.00801092 0.02694326 0.02694323 0.02153257 0.04171199
 0.01718669 0.02690134 0.01776413 0.041721   0.02859781 0.02153276
 0.02045797 0.01693051 0.01574338 0.01574252 0.00801102 0.021546
 0.04173781 0.02685196]
tr_loss:[0.01815249 0.01920534 0.01920533 0.02167469 0.01022024 0.01920533
 0.02167473 0.02423909 0.02267843 0.02702964 0.02268871 0.02858394
 0.01680347 0.01015108 0.01680347 0.03700403 0.01015106 0.0226713
 0.01920187 0.01920533 0.01015106 0.01015107 0.03701209 0.02634663
 0.01680348 0.02702964 0.02423934 0.01013013 0.01015108 0.02381013
 0.02266908 0.01769596 0.02858389 0.01922514 0.03699862 0.02423905
 0.01887607 0.01920532 0.01015108 0.02858391 0.02700187 0.03214953
 0.01680346 0.01920534 0.01015107 0.01015108 0.03228224 0.02423903
 0.0270293  0.01680366]
tr_loss:[0.01884382 0.02391166 0.02024735 0.02391164 0.02391165 0.02809292
 0.02043463 0.03389909 0.03420771 0.02988319 0.02809242 0.03281216
 0.01582418 0.01287142 0.02391164 0.02988325 0.0133309  0.0158232
 0.02163043 0.02808791 0.01777558 0.02043462 0.01593718 0.0210102
 0.03284273 0.02854637 0.02809293 0.0280212  0.02809291 0.01972998
 0.02043463 0.01582322 0.0298864  0.02043464 0.03389911 0.0204347
 0.0158232  0.02391164 0.02026657 0.02043464 0.02988319 0.01613074
 0.02043464 0.02769183 0.03282864 0.01287142 0.02272007 0.01979727
 0.02809292 0.02043466]
text_input.shape
(2000, 14400)
learning_input_tmp.shape
(2000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2000, 80)
learning_output.shape
(750, 80)
Model: "sequential_42"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_42 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3381922 1.315176  1.4252608 1.3151758 1.2327185 1.3424464 1.2518984
 1.2996846 1.3163712 1.3005213 1.4071732 1.2327707 1.2134898 1.4071709
 1.3151758 1.2327182 1.3163712 1.4252609 1.2133888 1.3163694 1.3151759
 1.4252609 1.2327287 1.4252608 1.2327182 1.425261  1.232739  1.316371
 1.4252551 1.316371  1.316371  1.317117  1.2327182 1.3151758 1.3163712
 1.2364569 1.3163712 1.4071732 1.2518985 1.2980869 1.4071729 1.316371
 1.3005155 1.4252608 1.407173  1.2134823 1.407173  1.4252608 1.2520819
 1.315176 ]
tr_loss:[0.8273133  0.8811442  0.7670756  0.7479178  0.8215647  0.7478952
 0.79732335 0.85216266 0.82156694 0.88110673 0.8010146  0.88110256
 0.8811041  0.852163   0.82731324 0.8811064  0.82156676 0.80017644
 0.80017644 0.79732335 0.82156694 0.82156676 0.74810123 0.80017644
 0.80056924 0.7481538  0.80616474 0.8001763  0.8811065  0.8811064
 0.802203   0.79732335 0.80017626 0.88110626 0.88103426 0.82156694
 0.82854795 0.82156676 0.7977363  0.80220413 0.7838716  0.8273134
 0.88110626 0.8273134  0.80017644 0.8061681  0.80602634 0.7956648
 0.79737294 0.8215669 ]
tr_loss:[0.51821536 0.55339813 0.42973566 0.43792883 0.5059719  0.48285228
 0.42973384 0.55339813 0.5533982  0.48285237 0.51821536 0.4297338
 0.51208663 0.42973384 0.44029027 0.51821536 0.42973375 0.55837137
 0.55339825 0.4297337  0.5208976  0.42973384 0.52089787 0.43288136
 0.42973384 0.42203125 0.4379182  0.5291221  0.5294658  0.42973375
 0.42198816 0.5295701  0.4220175  0.5423059  0.43791813 0.5181902
 0.5120865  0.43791813 0.55339813 0.48285103 0.51821536 0.5208791
 0.4379182  0.5182152  0.479904   0.4219284  0.42198706 0.49546298
 0.5533982  0.5182153 ]
tr_loss:[0.26954588 0.29379097 0.23153397 0.2536147  0.26842397 0.23152837
 0.29263344 0.27217808 0.23101711 0.29343152 0.3134932  0.29263347
 0.27100453 0.27488273 0.21573114 0.2939883  0.23152366 0.23152657
 0.23152423 0.21359651 0.29263344 0.23100491 0.3134953  0.23101711
 0.2315236  0.23101708 0.23205177 0.23152366 0.29263347 0.27295145
 0.21359663 0.2647415  0.2826766  0.23101707 0.23101564 0.22917664
 0.23108645 0.23152366 0.27208868 0.23085508 0.29263344 0.27217805
 0.23152411 0.29263347 0.29263335 0.25358802 0.23101673 0.31349716
 0.2536173  0.31349722]
tr_loss:[0.10209205 0.10549009 0.10541914 0.1439689  0.12673482 0.1054192
 0.10193254 0.12673493 0.18023458 0.12152544 0.12159623 0.12166293
 0.18023688 0.1267349  0.13051096 0.12673493 0.18023458 0.19181612
 0.13157481 0.13619079 0.12145729 0.11865859 0.10209234 0.11650715
 0.13156515 0.13619089 0.13156514 0.13156521 0.13619082 0.1439691
 0.14396887 0.11867541 0.12053027 0.13156514 0.11867573 0.13156517
 0.13441241 0.18023458 0.13683343 0.12156785 0.10541918 0.12673485
 0.1303536  0.10168703 0.10541918 0.13064404 0.12673488 0.18030304
 0.12152791 0.18023458]
tr_loss:[0.09887671 0.11383075 0.09391633 0.13833185 0.09652157 0.12320103
 0.11383077 0.12318961 0.09248198 0.0939163  0.13786176 0.09246945
 0.11382759 0.098877   0.09391631 0.09887705 0.11383071 0.08284061
 0.09253021 0.13008569 0.08172311 0.11383064 0.09391631 0.13836934
 0.09391628 0.13827753 0.09887705 0.09881791 0.09391631 0.07928829
 0.13665238 0.09977211 0.1054527  0.09887697 0.0925933  0.13836275
 0.13836925 0.09887698 0.08284062 0.07652144 0.0939163  0.12321888
 0.09245893 0.0795043  0.07605144 0.10066327 0.07531412 0.07929348
 0.07531412 0.11383071]
tr_loss:[0.06443062 0.08202563 0.07391372 0.08202563 0.06876286 0.08081003
 0.08205508 0.11566558 0.08202727 0.11132982 0.07391374 0.08202566
 0.06766199 0.10687692 0.11505066 0.06876285 0.08588316 0.09612236
 0.09036881 0.06876285 0.07391372 0.08202567 0.08075429 0.10687055
 0.07271213 0.11039746 0.06247128 0.07409058 0.06531413 0.10687695
 0.0644307  0.06402943 0.11132865 0.08487359 0.10687689 0.06876414
 0.08202568 0.11566553 0.06876285 0.10687573 0.08202566 0.09612235
 0.08202566 0.08202569 0.08119686 0.11490836 0.06876282 0.11132984
 0.06876283 0.0820258 ]
tr_loss:[0.07642411 0.07856975 0.09500393 0.08520068 0.06083924 0.07144803
 0.07753242 0.07323188 0.08544257 0.08544254 0.06083922 0.06591304
 0.06591306 0.05956575 0.06083923 0.05901067 0.0953481  0.07188268
 0.0724103  0.05896912 0.08495389 0.08544258 0.06083921 0.07241033
 0.08544253 0.05895375 0.09534711 0.08495392 0.08495383 0.09500396
 0.08177932 0.08544244 0.06591303 0.05973176 0.06591304 0.08544252
 0.07159436 0.08542576 0.08600889 0.08544254 0.08495257 0.06591304
 0.07175095 0.08495391 0.07175121 0.08931726 0.06591305 0.05976518
 0.05896889 0.07241031]
tr_loss:[0.0617738  0.07584945 0.05505931 0.07584327 0.05505976 0.07004201
 0.07004198 0.05734087 0.06169769 0.06177356 0.070042   0.07137854
 0.0560237  0.05734084 0.05734084 0.05505974 0.06169774 0.07004197
 0.06177387 0.05505974 0.05734088 0.05505976 0.05734085 0.05734087
 0.07464181 0.07137849 0.06177393 0.07137855 0.06177393 0.0573412
 0.08501187 0.05505995 0.05734086 0.0616977  0.07581433 0.0713785
 0.07356487 0.07004198 0.07004192 0.05505974 0.05734087 0.05505975
 0.05734093 0.07403316 0.07137857 0.06169769 0.07585818 0.06992768
 0.06177396 0.0617739 ]
tr_loss:[0.05173882 0.05189127 0.04134258 0.04086734 0.05856271 0.0413426
 0.0413426  0.06552184 0.05343742 0.03117688 0.05558639 0.05856273
 0.05189129 0.05558642 0.05856355 0.05856244 0.05558643 0.0413426
 0.05558638 0.04134263 0.07484732 0.05189129 0.05558639 0.04134262
 0.03117686 0.03624795 0.07877985 0.05343344 0.0721304  0.03117716
 0.04134296 0.05558641 0.07877985 0.05173662 0.06525267 0.06552181
 0.05173599 0.0655218  0.04134264 0.05558641 0.05853249 0.07062773
 0.04947236 0.03124267 0.05534898 0.05189126 0.05558639 0.06050103
 0.05558638 0.0555931 ]
tr_loss:[0.04909221 0.0491076  0.02977889 0.05440917 0.04842145 0.01955037
 0.02864196 0.05342932 0.06515269 0.05342928 0.06515265 0.07133768
 0.05440732 0.01955038 0.06479643 0.04840174 0.06515244 0.06515267
 0.01955053 0.0195504  0.05440737 0.05442698 0.01955039 0.06742375
 0.05342932 0.07137576 0.06514009 0.06515247 0.06515264 0.07134524
 0.06715237 0.0528958  0.05339371 0.0660132  0.05921257 0.06693988
 0.06615832 0.06515265 0.04919465 0.02977888 0.04905732 0.01955038
 0.06694037 0.07134297 0.02977889 0.0490941  0.01955035 0.04956571
 0.05342937 0.0534293 ]
tr_loss:[0.0523487  0.06644947 0.05234868 0.0523487  0.0631354  0.02430711
 0.06644782 0.06641348 0.05242211 0.05736736 0.05151889 0.06644943
 0.06313537 0.02431218 0.04763602 0.02431219 0.0631356  0.06644936
 0.04896884 0.0631354  0.06313539 0.05234871 0.05771912 0.04897847
 0.06644739 0.06644931 0.06644817 0.02431218 0.0661916  0.06646408
 0.04897953 0.05234871 0.02431218 0.07094632 0.04938237 0.07092394
 0.04897835 0.02138065 0.02432549 0.0709476  0.07098183 0.06630383
 0.02138062 0.04895788 0.02138761 0.02138063 0.02431219 0.0523487
 0.02431765 0.0573414 ]
tr_loss:[0.06582034 0.04725707 0.01930425 0.04726    0.01781237 0.01781237
 0.06751613 0.04980953 0.0313862  0.0313845  0.06593264 0.04937091
 0.04937091 0.04725714 0.01781238 0.04343029 0.01781236 0.04937095
 0.057279   0.04948542 0.06738842 0.03138451 0.01786733 0.03138448
 0.03139014 0.05355899 0.01781237 0.06582042 0.05767126 0.06668118
 0.03138454 0.03138453 0.03142585 0.03138451 0.05593485 0.0472571
 0.03138481 0.04725715 0.04725713 0.04937091 0.06751619 0.05767127
 0.05767126 0.07402875 0.04537928 0.05355896 0.01781237 0.05391883
 0.0493709  0.06751619]
tr_loss:[0.05263896 0.0660585  0.04056516 0.05263896 0.07613804 0.04370724
 0.05263899 0.02747341 0.04056517 0.041346   0.01100256 0.01100256
 0.04056519 0.04056519 0.04370726 0.04704722 0.04370727 0.03340095
 0.04134603 0.06605823 0.05179473 0.07610495 0.06274191 0.05263982
 0.0437073  0.0525214  0.04056725 0.06601362 0.06598906 0.04495279
 0.05204775 0.05263896 0.04134599 0.04134449 0.05179478 0.06015835
 0.06422256 0.04958078 0.02796903 0.05271728 0.02847003 0.04134599
 0.01100256 0.06015373 0.04056527 0.04126569 0.07609681 0.03930692
 0.05263833 0.06015367]
tr_loss:[0.03200482 0.04539989 0.04034014 0.05605407 0.04881929 0.03825995
 0.04539991 0.0403401  0.07635961 0.05477421 0.04289674 0.07643615
 0.03131462 0.04033096 0.04539991 0.09037992 0.04539992 0.0453999
 0.03200663 0.03200488 0.03736149 0.04539991 0.01031211 0.04539996
 0.03736145 0.04539987 0.05578256 0.03949423 0.04539988 0.0453999
 0.03736146 0.05048466 0.03736145 0.06265388 0.05477516 0.07630876
 0.04539992 0.04034285 0.01031213 0.07635234 0.04678107 0.06265385
 0.05578325 0.01031214 0.06265385 0.04539994 0.07632001 0.05364076
 0.07645093 0.04034009]
tr_loss:[0.05109066 0.05723534 0.05293114 0.05293112 0.05723537 0.01254775
 0.04179289 0.05346068 0.04179287 0.03385354 0.05723533 0.05293105
 0.04179335 0.01122691 0.05723538 0.0417929  0.04179442 0.04582337
 0.04179288 0.05723531 0.03621458 0.01254777 0.05555086 0.03251044
 0.04179292 0.0388646  0.0349137  0.05109581 0.05109068 0.03385363
 0.01254774 0.041793   0.05026211 0.04589557 0.07261784 0.07264207
 0.03886454 0.01254632 0.05293107 0.04581737 0.01254774 0.03886459
 0.05719686 0.03886459 0.01254778 0.03886456 0.05293112 0.05723535
 0.05145112 0.01398664]
tr_loss:[0.05172335 0.04374587 0.04737897 0.06982176 0.04615324 0.05464053
 0.0546406  0.04737896 0.06982382 0.03846451 0.01526171 0.04737893
 0.03472317 0.03472317 0.04737896 0.05464059 0.01526169 0.06987437
 0.01526171 0.03312028 0.03846451 0.03846454 0.04673908 0.0152617
 0.03472278 0.03472317 0.04741731 0.04677774 0.04677797 0.04737896
 0.04737899 0.03846453 0.05260305 0.0152617  0.0384645  0.04126977
 0.05457845 0.04332132 0.06980093 0.06977441 0.01526173 0.03846453
 0.03472316 0.04737895 0.03472319 0.0461535  0.04677804 0.05463861
 0.06985925 0.04188867]
tr_loss:[0.03609851 0.01287332 0.05182631 0.04282773 0.02609746 0.09135693
 0.03491452 0.02609745 0.03609847 0.02609762 0.05213359 0.02609746
 0.01287332 0.04282777 0.01287332 0.03609848 0.0518127  0.05297435
 0.03538375 0.05568622 0.06790976 0.03609853 0.0360985  0.03609848
 0.05587392 0.05586073 0.05548986 0.04282115 0.01287332 0.04282779
 0.0678988  0.05599941 0.04126551 0.05151199 0.051886   0.05366835
 0.0679005  0.02609744 0.05599811 0.04241581 0.04282119 0.04446676
 0.02609751 0.05579584 0.04282919 0.05554531 0.05599602 0.03609845
 0.02609747 0.05477236]
tr_loss:[0.0348268  0.05419364 0.03482801 0.05180773 0.01018312 0.03482652
 0.0474225  0.06778237 0.05874132 0.04587518 0.03482653 0.04587522
 0.03482652 0.05874205 0.01018312 0.0677838  0.05042871 0.02088837
 0.05874209 0.01018312 0.03482652 0.01018388 0.03482652 0.04585247
 0.03256135 0.04587521 0.05867565 0.03482652 0.01018315 0.0212983
 0.04597303 0.05841957 0.05866145 0.02088838 0.03255672 0.01018313
 0.05869853 0.01018312 0.03555668 0.05804616 0.0541937  0.0458752
 0.02088884 0.05873954 0.01018313 0.04510815 0.04587514 0.02088835
 0.02088836 0.03875582]
tr_loss:[0.03238689 0.05542286 0.04910014 0.04687273 0.03678964 0.03676742
 0.0624055  0.03678892 0.01024547 0.06099014 0.03698489 0.07126526
 0.05542094 0.0367896  0.01024547 0.05342332 0.04517274 0.04910002
 0.0491001  0.01024548 0.04514317 0.0571484  0.01024196 0.02319618
 0.07123718 0.02319619 0.03678963 0.01024547 0.03678964 0.03679203
 0.04687278 0.01024546 0.04515734 0.07123055 0.03678963 0.03710492
 0.04687271 0.02319619 0.04944046 0.04687278 0.05542095 0.03431306
 0.0102341  0.01024547 0.07124762 0.03679401 0.05900396 0.03678963
 0.03678961 0.06240543]
tr_loss:[0.03570886 0.04111963 0.05953198 0.03570884 0.0088962  0.04866457
 0.04774453 0.04774447 0.03371281 0.03570884 0.07107732 0.05953195
 0.03491544 0.03284871 0.0088962  0.00889619 0.0259276  0.00889621
 0.00889621 0.07105207 0.03371404 0.0088962  0.03570884 0.03366468
 0.05198699 0.00922365 0.03282709 0.04773024 0.07109319 0.05953197
 0.03570885 0.04774448 0.0259276  0.0088962  0.05350782 0.05953198
 0.03363208 0.02593363 0.05953198 0.03570883 0.05198696 0.05198701
 0.05953199 0.00889618 0.07114152 0.05198701 0.00889619 0.05953194
 0.03371893 0.05952712]
tr_loss:[0.04882405 0.02921385 0.02921384 0.03819092 0.00770087 0.02921385
 0.04431585 0.04445872 0.03421356 0.04447171 0.05400216 0.03518305
 0.05397715 0.02921387 0.03900045 0.00774746 0.03790741 0.00774746
 0.00774745 0.02921383 0.00774741 0.0342136  0.00774746 0.02614124
 0.06991372 0.04933055 0.03348053 0.02921383 0.05400218 0.04447171
 0.00774745 0.00774744 0.04447288 0.04447172 0.07000738 0.0342136
 0.050024   0.02921385 0.04447174 0.00743836 0.05400217 0.03518307
 0.04446741 0.00774745 0.02921386 0.06992079 0.03077906 0.06996174
 0.02921387 0.02911779]
tr_loss:[0.05136218 0.03378692 0.03441485 0.04193997 0.05136222 0.03785285
 0.03278067 0.05126382 0.03440536 0.03052555 0.04194104 0.04193997
 0.03418539 0.03440533 0.051258   0.07052545 0.04232884 0.0344053
 0.04193997 0.05126382 0.03440534 0.04194003 0.03054612 0.04195284
 0.03052549 0.05126379 0.05126376 0.07052733 0.05126367 0.03052546
 0.03834174 0.04927809 0.03442811 0.00775371 0.00775373 0.03835244
 0.03834998 0.04193998 0.04194001 0.03268667 0.03895105 0.04923264
 0.00775372 0.03052549 0.03835397 0.07056377 0.03440533 0.03873909
 0.05126383 0.030527  ]
tr_loss:[0.05990983 0.03507195 0.04707094 0.02948692 0.03507198 0.03958987
 0.04902041 0.07007165 0.03656691 0.05116657 0.0511665  0.02948694
 0.05182077 0.03507196 0.0350918  0.0407926  0.00848095 0.00848094
 0.00848095 0.0701261  0.00848095 0.04290731 0.02948693 0.07007314
 0.04079259 0.03511455 0.03507201 0.00848095 0.04902044 0.04292195
 0.05115467 0.05116649 0.07004545 0.0407926  0.0511593  0.04079251
 0.03857625 0.02948692 0.02948694 0.02948693 0.03857612 0.03475858
 0.00848093 0.04079259 0.04057818 0.0407926  0.03507197 0.04079262
 0.04902036 0.03898451]
tr_loss:[0.03230386 0.03656791 0.04063847 0.06625783 0.02480867 0.04063849
 0.04063852 0.02480866 0.03855702 0.03424922 0.03424919 0.02480868
 0.04577387 0.03626223 0.00751519 0.04063851 0.03382214 0.02482581
 0.04063887 0.05141738 0.05141665 0.06632124 0.0075152  0.03938843
 0.00751521 0.03655882 0.03939425 0.04063854 0.03424924 0.05048992
 0.03568619 0.04716148 0.03424925 0.02481381 0.03597173 0.03669048
 0.04577387 0.00751527 0.02628748 0.03424922 0.05141733 0.04714981
 0.05141736 0.00760848 0.06637698 0.06631976 0.04483286 0.03113941
 0.04716342 0.05141741]
tr_loss:[0.03436316 0.04349397 0.05163623 0.04388436 0.03436315 0.03749638
 0.04309813 0.05159937 0.0318417  0.04388436 0.03804452 0.0343633
 0.03436319 0.03436315 0.00767257 0.03364068 0.03781779 0.04309815
 0.03364079 0.05163625 0.04388431 0.04388433 0.06247903 0.05163392
 0.05163628 0.04310124 0.04349397 0.04349396 0.06253441 0.05163584
 0.06246118 0.03755624 0.02034195 0.05163509 0.02034183 0.04388434
 0.00767256 0.03436316 0.02034193 0.04388428 0.02034182 0.03401052
 0.00767256 0.02165129 0.04309811 0.02831874 0.03364083 0.03436317
 0.03436678 0.04387707]
tr_loss:[0.05339805 0.04388887 0.05935175 0.03828835 0.04428389 0.03391897
 0.00866481 0.01949564 0.01949779 0.06201369 0.00865781 0.03436444
 0.05339807 0.0196781  0.05083802 0.00865849 0.04612257 0.00865849
 0.03372487 0.00865849 0.01740022 0.00865848 0.01951206 0.06201685
 0.03372489 0.05338944 0.04777341 0.05339805 0.0442839  0.05339807
 0.03521286 0.02998038 0.01949559 0.03372486 0.04612078 0.0533981
 0.04428394 0.04612085 0.05339804 0.03831702 0.05203455 0.03521167
 0.03356666 0.03372492 0.0442839  0.03501894 0.0442839  0.0528497
 0.05198104 0.01949579]
tr_loss:[0.03471647 0.0077303  0.03470698 0.04404022 0.04432611 0.05258585
 0.01971417 0.01970428 0.04403957 0.01970434 0.05011622 0.06149177
 0.03468919 0.03481909 0.04403955 0.01970431 0.03469174 0.04403954
 0.01970429 0.05258589 0.04616885 0.03757191 0.04616888 0.02868981
 0.03481906 0.00773028 0.00773029 0.0525854  0.0348191  0.01970484
 0.01970431 0.03758241 0.04507182 0.00773029 0.05258586 0.05258567
 0.03481913 0.00773028 0.05258589 0.02869518 0.04403956 0.01970428
 0.03481911 0.03022062 0.01970432 0.06148923 0.06148543 0.0077303
 0.03481992 0.0077303 ]
tr_loss:[0.0060586  0.05087414 0.02087801 0.03580337 0.02087799 0.02087799
 0.04830875 0.04830872 0.00605861 0.04602392 0.04006299 0.05088649
 0.02088955 0.04602387 0.03421065 0.03465262 0.03582821 0.04830869
 0.0060586  0.00605859 0.02088179 0.04828988 0.05088646 0.06090964
 0.0060586  0.05088649 0.02358596 0.04029218 0.03421066 0.00605856
 0.03314089 0.02087797 0.05088617 0.04006308 0.03412525 0.03465263
 0.02087969 0.02087801 0.03421067 0.03465262 0.02091577 0.05069541
 0.03216986 0.06090236 0.04602391 0.03226094 0.00606069 0.03465263
 0.00605859 0.0508864 ]
tr_loss:[0.0608461  0.03327946 0.03327926 0.00452777 0.05917178 0.03757972
 0.00452762 0.03324604 0.06082937 0.00442694 0.03537159 0.02204102
 0.0332793  0.03251978 0.00452776 0.04953582 0.02204191 0.03757977
 0.022041   0.03375114 0.04590817 0.03375106 0.03437541 0.02206721
 0.03697485 0.03371409 0.00452777 0.022041   0.03327927 0.03327927
 0.03070143 0.04759868 0.03327928 0.03757974 0.00452776 0.03754936
 0.02204102 0.03375159 0.0608316  0.03757973 0.03100753 0.04759836
 0.00452796 0.04522519 0.03757971 0.00452776 0.04955227 0.03757959
 0.04099686 0.06083958]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2000 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2001, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2001 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2002, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2002 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2003, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2003 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2004, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2004 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2005, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2005 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2006, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2006 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2007, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2007 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2008, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2008 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2009, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2009 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2010, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2010 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2011, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2011 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2012, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2012 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2013, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2013 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2014, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2014 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2015, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2015 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2016, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2016 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2017, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2017 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2018, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2018 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2019, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2019 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2020, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2020 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2021, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2021 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2022, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2022 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2023, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2023 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2024, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2024 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2025, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2025 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2026, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2026 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2027, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2027 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2028, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2028 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2029, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2029 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2030, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2030 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2031, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2031 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2032, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2032 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2033, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2033 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2034, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2034 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2035, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2035 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2036, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2036 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2037, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2037 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2038, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2038 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2039, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2039 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2040, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2040 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2041, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2041 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2042, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2042 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2043, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2043 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2044, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2044 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2045, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2045 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2046, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2046 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2047, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2047 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2048, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2048 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2049, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2049 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2050, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2050 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2051, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2051 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2052, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2052 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2053, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2053 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2054, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2054 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2055, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2055 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2056, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2056 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2057, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2057 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2058, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2058 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2059, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2059 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2060, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2060 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2061, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2061 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2062, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2062 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2063, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2063 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2064, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2064 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2065, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2065 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2066, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2066 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2067, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2067 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2068, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2068 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2069, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2069 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2070, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2070 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2071, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2071 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2072, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2072 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2073, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2073 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2074, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2074 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2075, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2075 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2076, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2076 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2077, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2077 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2078, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2078 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2079, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2079 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2080, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2080 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2081, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2081 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2082, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2082 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2083, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2083 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2084, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2084 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2085, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2085 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2086, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2086 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2087, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2087 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2088, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2088 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2089, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2089 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2090, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2090 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2091, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2091 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2092, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2092 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2093, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2093 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2094, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2094 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2095, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2095 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2096, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2096 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2097, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2097 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2098, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2098 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2099, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2099 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2100, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-2000
text_input.shape
(2100, 14400)
learning_input_tmp.shape
(2100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2100, 80)
learning_output.shape
(750, 80)
Model: "sequential_43"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_43 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0820373  0.9853846  0.9968772  1.1278324  1.1397845  1.1274357
 1.1398712  0.94145024 1.0845387  1.0820379  1.1351023  1.139872
 1.139872   1.1398718  0.98538464 1.0842613  1.0857805  0.98538435
 0.9436878  1.0817902  1.0261227  1.0820377  0.95158994 0.94149846
 1.0379863  0.98538446 1.139872   0.94145143 0.9898839  1.0379862
 1.0252032  1.0814716  1.1678722  1.0857805  1.0857804  1.139872
 1.0820379  0.980132   1.0433909  1.0820382  0.9894371  1.0802015
 1.1398718  0.98976725 1.1894766  0.941486   0.98976725 1.1710492
 1.0270962  1.1710606 ]
tr_loss:[0.68353605 0.6778044  0.6752361  0.65851945 0.6752365  0.6887814
 0.66779536 0.6752361  0.707809   0.65851516 0.67145157 0.6205589
 0.67523605 0.6205589  0.6754371  0.6689253  0.67582405 0.66892517
 0.68878126 0.68878126 0.67544043 0.6687481  0.66892517 0.6725534
 0.66892517 0.66892517 0.70866483 0.6574702  0.6752609  0.6599296
 0.6585152  0.6887813  0.6205589  0.6205589  0.6585153  0.62055856
 0.69751626 0.6689251  0.69535196 0.6887814  0.66892505 0.6759411
 0.7226841  0.6752359  0.6803374  0.6752361  0.6764618  0.6585165
 0.6897216  0.6844168 ]
tr_loss:[0.4075055  0.3940235  0.39334774 0.40749446 0.4019374  0.43070593
 0.39402312 0.39360425 0.39192072 0.39568123 0.40193748 0.40749446
 0.396715   0.4019374  0.42797828 0.4045189  0.3701431  0.4074939
 0.40745345 0.43066865 0.40721488 0.41173345 0.40749446 0.40749437
 0.39360434 0.43066865 0.4019374  0.40749446 0.40193734 0.4074944
 0.40193614 0.39402363 0.4019374  0.4306674  0.3701431  0.40732533
 0.39402354 0.4123512  0.39670977 0.41173333 0.3919019  0.3795858
 0.43066868 0.39666763 0.38385305 0.40749234 0.40193743 0.42440623
 0.39360434 0.3967108 ]
tr_loss:[0.20058218 0.20397596 0.19304302 0.20924468 0.21421024 0.20399833
 0.20924464 0.20399842 0.17231405 0.19923893 0.20058231 0.19923893
 0.19924316 0.17461634 0.20399837 0.17945048 0.21628344 0.19923887
 0.20399836 0.18769583 0.17864254 0.17857018 0.19372961 0.20924468
 0.18310305 0.20058222 0.20924595 0.20398287 0.18294375 0.17864266
 0.22424991 0.20924468 0.20924468 0.21629849 0.21420586 0.19923887
 0.2005068  0.20057869 0.20397589 0.20058227 0.17860232 0.18208963
 0.20399837 0.20924464 0.19514468 0.19923992 0.20924468 0.20397589
 0.20058218 0.20058219]
tr_loss:[0.13867974 0.11113571 0.11113568 0.10055753 0.11380114 0.16389461
 0.14421764 0.13360915 0.14530635 0.1189847  0.10078111 0.14530636
 0.10055753 0.10638907 0.14135818 0.13652375 0.10608814 0.14530627
 0.1005628  0.16694096 0.14530638 0.12737377 0.14421822 0.1111357
 0.10055752 0.10064471 0.10638925 0.11113572 0.1402108  0.14530638
 0.11380092 0.17280667 0.1111453  0.14530632 0.14421764 0.12737367
 0.16694103 0.14530635 0.13058493 0.11380111 0.14530629 0.12164285
 0.10621542 0.14421773 0.14530297 0.13181275 0.10055752 0.11380117
 0.14421761 0.14421749]
tr_loss:[0.1172653  0.09487097 0.09074873 0.10172427 0.09456678 0.1085168
 0.11195295 0.10851677 0.09104602 0.094395   0.077176   0.10172437
 0.13069654 0.1306965  0.09597899 0.13069654 0.10851683 0.09439498
 0.10172429 0.08049035 0.08252939 0.14645776 0.13069662 0.14645776
 0.10687777 0.0821634  0.08236513 0.11235155 0.08037595 0.07717594
 0.07729022 0.0803746  0.07717534 0.09069598 0.10771251 0.13069658
 0.10687618 0.1106175  0.09439492 0.10205412 0.10851681 0.10173507
 0.0803746  0.10172437 0.08037461 0.08037572 0.11230628 0.08037464
 0.1020123  0.08037464]
tr_loss:[0.07223943 0.0666092  0.06794463 0.08751946 0.06350405 0.06808046
 0.07265586 0.07440031 0.06808003 0.06957638 0.07878992 0.07229734
 0.07229732 0.0422248  0.06662471 0.07878989 0.10983594 0.07223936
 0.06662498 0.0677626  0.07944284 0.06735133 0.06351802 0.06350426
 0.0422198  0.08755474 0.09792863 0.10866012 0.06350704 0.0422248
 0.07223938 0.0422248  0.06350401 0.04222479 0.07250005 0.07529835
 0.04222478 0.08751978 0.04223738 0.06350896 0.063504   0.07223938
 0.07879236 0.08333769 0.06789671 0.08751993 0.07226504 0.06662161
 0.04222479 0.05447862]
tr_loss:[0.06327023 0.07618908 0.05667957 0.06406884 0.06034586 0.01672969
 0.04175471 0.04175469 0.05667954 0.06236366 0.04175469 0.07618907
 0.06034588 0.0566801  0.01672972 0.0603457  0.01672969 0.06886537
 0.07532718 0.07337898 0.05719952 0.05203759 0.06183282 0.05505521
 0.06043714 0.0603216  0.0167297  0.01769692 0.05243042 0.05667648
 0.04987406 0.06236306 0.05667952 0.04311705 0.0513443  0.06236303
 0.06034585 0.06509062 0.06360894 0.05667956 0.05240729 0.07074142
 0.07690068 0.06404977 0.05062762 0.07176562 0.06236305 0.04175469
 0.06324492 0.03732074]
tr_loss:[0.02030255 0.05782015 0.06849796 0.04624351 0.06460714 0.06604846
 0.04742943 0.08160514 0.02030256 0.05781134 0.02030256 0.05909228
 0.02030255 0.04126497 0.05923809 0.05782011 0.05782016 0.05782008
 0.04126634 0.04126499 0.05782012 0.05782015 0.0733218  0.08624234
 0.07385991 0.08961982 0.04126846 0.02030266 0.06849794 0.041265
 0.02030255 0.0574192  0.07332113 0.04126498 0.04126501 0.05782015
 0.02030254 0.02030255 0.07332113 0.04158354 0.02030255 0.04126497
 0.08160514 0.02030255 0.02030256 0.07332112 0.06612639 0.05989835
 0.07332112 0.04480843]
tr_loss:[0.07293796 0.06411741 0.07293798 0.07823949 0.08237185 0.06075245
 0.06389715 0.06075245 0.07291629 0.06083652 0.04807057 0.07028778
 0.05920339 0.04797035 0.06074756 0.05794131 0.06080003 0.05502929
 0.07813523 0.07813527 0.04807273 0.04806627 0.07364567 0.06801119
 0.02873571 0.06389713 0.07293799 0.07293799 0.02873951 0.07821824
 0.06968009 0.07289549 0.04806626 0.04808053 0.06831601 0.09067409
 0.06632257 0.05921563 0.0781352  0.04806622 0.04870159 0.08807558
 0.04806626 0.07813518 0.07813521 0.06244334 0.02873568 0.06387898
 0.07293733 0.07813515]
tr_loss:[0.04943812 0.04943815 0.04943808 0.03046723 0.07421789 0.07538923
 0.07545714 0.06278741 0.04943813 0.03046724 0.06160048 0.05711197
 0.06607747 0.04943816 0.04943806 0.07545711 0.07545065 0.04943813
 0.07420689 0.06328586 0.0627874  0.07545711 0.08135458 0.03046723
 0.03046721 0.07545716 0.05789964 0.07537205 0.07420681 0.06641278
 0.06328546 0.08635428 0.07420679 0.06279482 0.05251765 0.04943813
 0.03046724 0.03046724 0.03046724 0.03046723 0.07421352 0.07420678
 0.06278737 0.03046722 0.07423677 0.04943809 0.06278741 0.07420678
 0.03046726 0.0494381 ]
tr_loss:[0.06927475 0.06064682 0.06927471 0.05648482 0.05770857 0.06064678
 0.05119115 0.05377249 0.05119197 0.05771443 0.06927474 0.06082818
 0.06927466 0.02949202 0.05727704 0.07812602 0.05119193 0.06064686
 0.07793207 0.06927471 0.07741937 0.07798074 0.07812165 0.05777859
 0.02949203 0.02949202 0.07812619 0.02949214 0.06927474 0.04708081
 0.06064678 0.06927469 0.05308791 0.0606469  0.07812619 0.06064699
 0.04954201 0.05427674 0.07273559 0.02949204 0.05579797 0.07812615
 0.05398826 0.02949206 0.05469945 0.06927465 0.07812619 0.06927476
 0.07812619 0.02955728]
tr_loss:[0.05712529 0.07496598 0.05712513 0.0534911  0.05035767 0.0751781
 0.06500015 0.04759063 0.05392035 0.05035768 0.0503577  0.05774368
 0.05427563 0.0585898  0.05712533 0.07517806 0.05712531 0.0556611
 0.02570684 0.07514542 0.05427575 0.05774367 0.0503577  0.05566113
 0.07517812 0.05036317 0.04139493 0.02570687 0.02570684 0.05774368
 0.05392029 0.05774368 0.05774542 0.05711681 0.05493794 0.04798141
 0.04739438 0.02570685 0.05774364 0.05480462 0.07383423 0.0556611
 0.0257069  0.05592439 0.05035768 0.06985184 0.05261476 0.05035765
 0.05774365 0.05035768]
tr_loss:[0.05383454 0.02209051 0.04685247 0.06936571 0.0220905  0.04680096
 0.04838384 0.04242767 0.0637022  0.04905451 0.05930978 0.05483636
 0.0548364  0.04905451 0.04905612 0.06936821 0.05513566 0.04905453
 0.04905447 0.05423114 0.05483631 0.05483633 0.0220905  0.04904307
 0.05483649 0.04309361 0.02113873 0.04905451 0.06936821 0.0220905
 0.05483637 0.06046345 0.04905451 0.05423108 0.04312129 0.05483634
 0.05383439 0.02209049 0.05383236 0.04680096 0.05299063 0.04905454
 0.05301475 0.02209051 0.06936804 0.0490545  0.05483633 0.05483632
 0.05383449 0.06936814]
tr_loss:[0.04741219 0.0613481  0.06200673 0.01960796 0.04857174 0.04291362
 0.06493158 0.04500456 0.05773596 0.05370539 0.06200707 0.06396755
 0.03762922 0.05370323 0.04500451 0.0485718  0.0538337  0.05174055
 0.05370326 0.06200712 0.05370323 0.01960794 0.0541596  0.0410796
 0.01960794 0.04857179 0.05951449 0.04857181 0.05113237 0.06200712
 0.05370324 0.04857177 0.01960795 0.05366324 0.01960826 0.05126765
 0.06200203 0.02319925 0.04857289 0.06200584 0.05382712 0.04222379
 0.0537034  0.0538291  0.05162307 0.06200074 0.04500505 0.05370326
 0.06170238 0.05127322]
tr_loss:[0.04514972 0.05243551 0.05140965 0.05071132 0.05195557 0.05924252
 0.05071127 0.0524209  0.05362769 0.04987647 0.05936357 0.04859859
 0.03585426 0.04514974 0.05362773 0.05362769 0.04859389 0.01864215
 0.04531214 0.01871163 0.05262091 0.01864216 0.05129426 0.05362775
 0.05071126 0.05924259 0.05407353 0.04697425 0.05261432 0.05242841
 0.05639555 0.05071123 0.05239754 0.04584016 0.01864213 0.04697425
 0.05071134 0.04474515 0.01864214 0.05228113 0.04601154 0.04514971
 0.05071136 0.05071137 0.04835386 0.01864215 0.05243549 0.01864247
 0.04514968 0.04515681]
tr_loss:[0.0442906  0.04286073 0.04286775 0.0208654  0.04492349 0.04535251
 0.03991053 0.04233196 0.04268702 0.04054216 0.04428847 0.03947614
 0.02086539 0.02086538 0.02086539 0.02086542 0.04286061 0.06119382
 0.04286057 0.04429042 0.05322474 0.04910822 0.0428606  0.02087198
 0.04017415 0.04393297 0.03258631 0.02092566 0.02086539 0.04535253
 0.04491662 0.04429009 0.043933   0.04422428 0.02086537 0.04544387
 0.0490994  0.04535251 0.04429059 0.04535254 0.04535254 0.04535251
 0.0428606  0.04393295 0.03883729 0.04834964 0.0397132  0.04535256
 0.04492332 0.02086541]
tr_loss:[0.04803407 0.04523953 0.04584201 0.04802009 0.04806812 0.04808761
 0.04910488 0.04803161 0.06221831 0.06043953 0.04802009 0.06043955
 0.02237085 0.02243348 0.04802008 0.04218586 0.0248685  0.06221836
 0.02803122 0.04183261 0.04524    0.04910489 0.04523959 0.04523945
 0.03418061 0.03220968 0.0280312  0.0280312  0.04183222 0.02542239
 0.03253617 0.02803122 0.0471016  0.02803119 0.04525515 0.04523951
 0.0491049  0.0480681  0.04806805 0.04523862 0.02803122 0.04313388
 0.04523949 0.04189616 0.04805138 0.0491046  0.04024688 0.04683361
 0.04523948 0.0302155 ]
tr_loss:[0.04921806 0.03557596 0.01928333 0.0422605  0.02277477 0.04726899
 0.02277476 0.04726813 0.02277478 0.04711116 0.02277054 0.03049408
 0.04921795 0.03990357 0.02282386 0.03557557 0.0407864  0.04225956
 0.04225956 0.02277105 0.04698119 0.04078904 0.02572962 0.04921798
 0.05158188 0.03990375 0.04698119 0.03438041 0.04921801 0.04225955
 0.03267247 0.04027332 0.04078639 0.02277477 0.03022126 0.04921799
 0.03557595 0.04225954 0.03440259 0.02277478 0.04726889 0.03552922
 0.03437744 0.04726865 0.04921798 0.05638625 0.0407864  0.01926422
 0.03990337 0.02277478]
tr_loss:[0.03317054 0.03752081 0.02637406 0.03217015 0.02615229 0.03317057
 0.03317107 0.02753    0.04522426 0.01268334 0.04889348 0.02074189
 0.01268336 0.03404868 0.03752242 0.03317057 0.02222015 0.04152021
 0.03317057 0.04889346 0.01362191 0.0504814  0.03752077 0.04154851
 0.04154975 0.04150264 0.03317059 0.03752081 0.03752082 0.01268336
 0.02301455 0.03752083 0.03752081 0.04962556 0.0304159  0.0375208
 0.04520934 0.03897621 0.03317057 0.03317055 0.01706953 0.03204422
 0.04522325 0.04154998 0.04522512 0.04154812 0.01268336 0.04522329
 0.0452233  0.02892593]
tr_loss:[0.0405911  0.0338079  0.02785368 0.04122834 0.03035362 0.03638364
 0.03128798 0.04105722 0.0430724  0.02670209 0.04144392 0.01175205
 0.0316271  0.04096175 0.04307232 0.02750156 0.04122836 0.02795814
 0.02471025 0.04122833 0.04307234 0.01866552 0.0316271  0.03627781
 0.01175202 0.04065876 0.0430724  0.02665552 0.0412287  0.01175204
 0.01175202 0.01175202 0.03926744 0.03162707 0.01175202 0.04106007
 0.0351117  0.03721654 0.02401897 0.04307239 0.03434529 0.04307232
 0.0303534  0.04307237 0.02299485 0.03162708 0.02064304 0.02597797
 0.0372165  0.02656929]
tr_loss:[0.03875341 0.01456588 0.01456584 0.04412275 0.02888159 0.04149652
 0.04412273 0.03875261 0.01456584 0.01456587 0.04412274 0.01456585
 0.04029873 0.03875257 0.03875261 0.04412279 0.04406749 0.0351036
 0.03309312 0.03875257 0.03875263 0.02160489 0.01456586 0.03875263
 0.01456585 0.04171715 0.03510364 0.03880118 0.04406746 0.03500004
 0.04412273 0.01456586 0.03875261 0.04406717 0.03875326 0.03875258
 0.02945092 0.0351036  0.03309307 0.0217908  0.04069186 0.03510357
 0.03255668 0.01456444 0.04149652 0.02185231 0.03510361 0.04406743
 0.03875257 0.02634558]
tr_loss:[0.03871236 0.03983079 0.03983082 0.02735341 0.04561433 0.03983083
 0.04527512 0.02815413 0.03424285 0.01755246 0.0349746  0.01755244
 0.03871238 0.0482731  0.04827315 0.02584604 0.02273102 0.02734816
 0.04527513 0.04528835 0.02732404 0.04163125 0.02732446 0.01755581
 0.03983172 0.0342433  0.0398308  0.04480221 0.0461388  0.04827312
 0.04527509 0.02510802 0.03424285 0.03975006 0.03983083 0.04161457
 0.03497463 0.03424438 0.03983079 0.03871235 0.04827308 0.01755244
 0.03983079 0.04527537 0.01755244 0.04527513 0.03983102 0.04827314
 0.04527679 0.04561855]
tr_loss:[0.04828122 0.04182525 0.04827574 0.01672799 0.03948893 0.0426403
 0.04380191 0.0482812  0.03192834 0.04827    0.02784831 0.02277552
 0.03948719 0.02134803 0.03847486 0.03192655 0.01991064 0.03192653
 0.04668402 0.01672798 0.03274035 0.03847483 0.03948719 0.02134805
 0.04263414 0.01672797 0.0475534  0.03892443 0.01672795 0.02782013
 0.03123303 0.03193768 0.03942515 0.04668401 0.02836137 0.04828118
 0.03743574 0.01672797 0.03192655 0.03191575 0.03192658 0.02785239
 0.01666059 0.04209255 0.03780407 0.07594956 0.0482812  0.04828121
 0.04263665 0.0319269 ]
tr_loss:[0.04310773 0.03468275 0.02984308 0.02984307 0.03563578 0.03469263
 0.04333221 0.01388848 0.04321284 0.02984306 0.04333221 0.03408921
 0.03563578 0.03467552 0.04330386 0.01388849 0.03553651 0.04222202
 0.03467553 0.0138938  0.01388849 0.03563575 0.03190249 0.03567392
 0.02364896 0.02495569 0.04333226 0.03553298 0.02962227 0.01388849
 0.03563577 0.03192158 0.0346755  0.0356963  0.03941352 0.01388848
 0.04333221 0.01943178 0.03432506 0.03563572 0.03423679 0.01388848
 0.03563439 0.01700077 0.01388849 0.03942354 0.02381313 0.03467551
 0.01388847 0.03467552]
tr_loss:[0.04233024 0.05101507 0.01294578 0.01294566 0.03126714 0.03162151
 0.04233021 0.01294567 0.01294569 0.03022131 0.03721558 0.03180184
 0.03150663 0.0292248  0.03150753 0.02799638 0.03022133 0.03022133
 0.03808121 0.03022136 0.03188568 0.01294557 0.03808119 0.03188566
 0.03808121 0.01294569 0.0155918  0.0213735  0.01294567 0.0380812
 0.01836946 0.03188858 0.03022131 0.01840201 0.03124803 0.03162322
 0.01596031 0.03808124 0.03126713 0.03022134 0.03022134 0.03064612
 0.03677418 0.01294568 0.03808122 0.01776232 0.02914712 0.03188567
 0.01840202 0.02072444]
tr_loss:[0.0432914  0.03026034 0.04346003 0.02187464 0.04346005 0.027707
 0.03414836 0.02371881 0.03026035 0.03026032 0.02770699 0.02770706
 0.04329139 0.02770698 0.01249195 0.02558846 0.03026033 0.03415307
 0.03510327 0.03373054 0.03509564 0.03414556 0.03415306 0.03510337
 0.03026034 0.02515624 0.03415308 0.01249195 0.02426597 0.02770697
 0.03415307 0.0432914  0.0304548  0.03415307 0.02727388 0.03508203
 0.03996633 0.04329139 0.03907945 0.02770697 0.03415307 0.03533268
 0.02982303 0.03510333 0.02515588 0.02816033 0.03411692 0.02770695
 0.02770694 0.03026032]
tr_loss:[0.03685654 0.03266336 0.02940202 0.04078753 0.03685647 0.03346795
 0.02627116 0.03048738 0.04468627 0.029402   0.02940202 0.01356799
 0.04468624 0.03392342 0.013568   0.02627387 0.03266332 0.02940205
 0.02940202 0.03398035 0.02939008 0.03398033 0.02940201 0.03281417
 0.02940203 0.03398034 0.029402   0.04078754 0.013568   0.03398032
 0.03266201 0.013568   0.02527444 0.02942174 0.03397978 0.03398034
 0.03685649 0.03365787 0.03398035 0.03685649 0.03685654 0.04468628
 0.03398032 0.03685652 0.03266338 0.0245632  0.02940203 0.02940202
 0.03266335 0.02644393]
tr_loss:[0.01251416 0.03176057 0.0351887  0.02362033 0.03518867 0.02391328
 0.03518917 0.01251416 0.0351887  0.0351887  0.01251416 0.04756544
 0.03766625 0.03552453 0.03499397 0.03552449 0.03518867 0.03551023
 0.02773109 0.0354983  0.03179091 0.055984   0.03028303 0.03935043
 0.03518872 0.0351887  0.03935045 0.03518902 0.01251416 0.01251408
 0.03176177 0.03552431 0.03552455 0.03724782 0.03176056 0.03518868
 0.03583631 0.03171294 0.03551396 0.03176057 0.03523828 0.03626136
 0.03518871 0.03498201 0.0234214  0.03176056 0.03176055 0.03552452
 0.03659169 0.03518872]
tr_loss:[0.03123553 0.03493781 0.03398422 0.02803249 0.02521871 0.00981092
 0.03493681 0.03556548 0.03398422 0.00981091 0.04966488 0.03123553
 0.03398421 0.00981092 0.02621864 0.03388404 0.0292678  0.02803296
 0.03556679 0.03493377 0.03154928 0.03153511 0.03556821 0.03141832
 0.03123552 0.03398417 0.00981092 0.02477177 0.01832849 0.03554986
 0.01880791 0.04150737 0.02803245 0.03123551 0.02803249 0.01960869
 0.00981106 0.02803246 0.03556822 0.03564261 0.03556817 0.03236251
 0.00981092 0.03122562 0.0355682  0.03398421 0.02804728 0.02623501
 0.03556814 0.03129861]
text_input.shape
(2100, 14400)
learning_input_tmp.shape
(2100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2100, 80)
learning_output.shape
(750, 80)
Model: "sequential_44"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_44 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.194133  1.1705351 1.0899216 1.1335943 1.2283645 1.2537148 1.0682943
 1.1283033 1.0678428 1.2535001 1.2537149 1.1852537 1.1283033 1.1283033
 1.1478977 1.1283033 1.2289344 1.2289344 1.1418345 1.2537149 1.1852525
 1.1410353 1.2537147 1.1778233 1.0678428 1.155349  1.1415669 1.2537149
 1.0899217 1.1283034 1.1335999 1.0900118 1.0630289 1.2289343 1.1283032
 1.1852527 1.228934  1.0688317 1.0678428 1.0678475 1.1859992 1.2289343
 1.2537149 1.168849  1.0899216 1.2289343 1.1492745 1.2289343 1.1298383
 1.1415278]
tr_loss:[0.70220137 0.6275237  0.70220137 0.7139045  0.7137283  0.6795513
 0.72403234 0.70591915 0.7059189  0.7059189  0.71390426 0.679719
 0.6647109  0.6651001  0.70591885 0.7059408  0.7240018  0.7058715
 0.7124997  0.70591897 0.7014306  0.6651002  0.71390426 0.7328917
 0.67365324 0.71390027 0.70220125 0.67363966 0.67955124 0.7242026
 0.6740033  0.6742763  0.6650867  0.70220137 0.7127634  0.7059189
 0.7251626  0.7005034  0.7076342  0.70220125 0.70591927 0.67955124
 0.70219946 0.66510016 0.7139042  0.66510004 0.6650945  0.7059189
 0.7254058  0.67955136]
tr_loss:[0.50652343 0.46661863 0.47088966 0.4445177  0.4720133  0.4720133
 0.47232223 0.5046784  0.48509994 0.4875509  0.47232217 0.5065031
 0.47621292 0.4720133  0.47201318 0.45563507 0.48257798 0.44382778
 0.44118756 0.4762134  0.50650275 0.44451767 0.4445177  0.4762184
 0.4187633  0.4688301  0.4897337  0.47071066 0.45563498 0.44118738
 0.4762129  0.44118777 0.4671921  0.47201338 0.5066808  0.4851006
 0.47232217 0.4445177  0.50650036 0.44118777 0.47621292 0.506503
 0.4720133  0.44108796 0.47232217 0.49813032 0.4445177  0.47201318
 0.44118762 0.47232217]
tr_loss:[0.25763544 0.24318556 0.2429338  0.24824342 0.23998246 0.22605272
 0.2401894  0.24466734 0.23643413 0.22605272 0.24016762 0.2592972
 0.22605264 0.2592976  0.24318564 0.22716899 0.2429337  0.24418989
 0.22605276 0.22605264 0.24318568 0.2431856  0.25964457 0.24470058
 0.25929767 0.24267654 0.23643407 0.24470071 0.27024132 0.24470067
 0.26083252 0.24576679 0.25929755 0.24253723 0.2431911  0.27100396
 0.22605269 0.2356852  0.23669776 0.2528835  0.24318556 0.22605272
 0.25850487 0.25367182 0.25929755 0.2364341  0.25929767 0.2410285
 0.2432353  0.24468979]
tr_loss:[0.15748534 0.10329673 0.10329668 0.10329672 0.11089283 0.12792459
 0.1350117  0.1384283  0.14759655 0.10329642 0.1164367  0.12551141
 0.1384284  0.13500395 0.12551133 0.13500391 0.14872399 0.1574853
 0.13500406 0.11486719 0.11089293 0.15748492 0.12389491 0.12389461
 0.14554842 0.1416473  0.12388714 0.15748537 0.11089282 0.11581528
 0.11114039 0.12205146 0.12057134 0.10372408 0.11089396 0.15748525
 0.10329671 0.15100995 0.10322611 0.11089754 0.11089287 0.11089287
 0.11089285 0.15748535 0.1475958  0.09239803 0.10329676 0.135004
 0.10329673 0.13500397]
tr_loss:[0.06746808 0.06746814 0.06599037 0.09399777 0.06746814 0.04816326
 0.05590018 0.06746817 0.09400086 0.06746814 0.05342304 0.06512565
 0.05342302 0.04767317 0.0659909  0.06746818 0.05590793 0.05519947
 0.05014717 0.07332642 0.0476725  0.09400091 0.09400092 0.06599085
 0.05342301 0.053423   0.06746813 0.06746801 0.053423   0.05860593
 0.06746813 0.07331114 0.09400086 0.06599056 0.053423   0.04767265
 0.09400086 0.053423   0.04767319 0.05593724 0.06746791 0.06599077
 0.0940007  0.06517713 0.09400064 0.06716035 0.0674682  0.09412925
 0.05589968 0.09400086]
tr_loss:[0.05801006 0.03927105 0.05043652 0.03927103 0.07030734 0.05043654
 0.03927103 0.07030736 0.05476784 0.05614395 0.05801006 0.05709554
 0.05801002 0.05614392 0.05801003 0.05237607 0.03926713 0.0554303
 0.05043657 0.04326876 0.039271   0.05231103 0.04327932 0.05614389
 0.07030734 0.05043649 0.05301451 0.05481086 0.06282176 0.05614393
 0.05043632 0.03927103 0.05301373 0.03927103 0.04807005 0.07030735
 0.07030736 0.05043659 0.05328069 0.05475644 0.04327927 0.05236211
 0.05653784 0.05043658 0.06282173 0.05797713 0.0703144  0.05114947
 0.05060106 0.05614088]
tr_loss:[0.03378228 0.0382907  0.05574527 0.05533856 0.03996127 0.04867173
 0.04536423 0.03686889 0.03385286 0.04716907 0.04124097 0.07228573
 0.05347806 0.05845418 0.05538545 0.03378097 0.03385286 0.053478
 0.05538546 0.03255085 0.05274095 0.05347799 0.05954253 0.05538541
 0.03385286 0.05928807 0.05538566 0.05214145 0.05462188 0.05347803
 0.0399701  0.05533853 0.03615129 0.05955954 0.04144771 0.05955952
 0.06608691 0.03385284 0.05533851 0.05955951 0.05353874 0.0595595
 0.05955949 0.05460454 0.05533851 0.05312667 0.05538849 0.06098576
 0.03378196 0.03385286]
tr_loss:[0.02879965 0.05944961 0.05677374 0.05948834 0.05677375 0.05677963
 0.03211194 0.05677374 0.03211195 0.03211193 0.04839459 0.05779325
 0.07105682 0.02984677 0.03752276 0.0321237  0.03752318 0.05775381
 0.03068694 0.05773173 0.05948882 0.05677376 0.05677377 0.05719533
 0.05773178 0.05773675 0.05677374 0.04839479 0.05935543 0.03752278
 0.03752512 0.05659907 0.05948498 0.03632696 0.07105682 0.0566092
 0.03211192 0.03211195 0.04728993 0.03211192 0.05775284 0.05018041
 0.03068621 0.05663005 0.06642314 0.05948881 0.05621246 0.0566092
 0.05659348 0.03211191]
tr_loss:[0.05539735 0.07105911 0.06253053 0.05969515 0.04653751 0.03467035
 0.0339858  0.0615605  0.05433372 0.06156039 0.03398579 0.0339858
 0.03467028 0.07105912 0.06155996 0.06156052 0.03398579 0.06061392
 0.03467343 0.06270654 0.05977759 0.05969376 0.03467033 0.02293589
 0.05577253 0.06061393 0.03087859 0.03467035 0.06556942 0.05000794
 0.03467811 0.05969365 0.06156056 0.0346704  0.04614844 0.03398582
 0.05969562 0.04134409 0.059594   0.04131951 0.05573534 0.06422635
 0.03145344 0.05000566 0.06061394 0.05965785 0.03467032 0.04993019
 0.0346704  0.03467033]
tr_loss:[0.04603306 0.06202399 0.0278186  0.05963848 0.02783567 0.04613078
 0.05678028 0.03305966 0.06195169 0.05758148 0.0278186  0.05603801
 0.04318728 0.04325572 0.05428685 0.06202399 0.05602294 0.05602299
 0.02781859 0.06191187 0.06202399 0.04318724 0.05602303 0.06202397
 0.0630496  0.05602301 0.0432457  0.02781859 0.02087317 0.02781858
 0.0278186  0.06202406 0.05936459 0.03524794 0.02291472 0.04256732
 0.05559861 0.03302249 0.05602298 0.03302249 0.03511405 0.04318724
 0.02781862 0.02496903 0.05758166 0.03302258 0.02938991 0.02039353
 0.05602522 0.02540387]
tr_loss:[0.0499322  0.0494999  0.03904913 0.01843038 0.06636682 0.04949998
 0.04852059 0.04993222 0.04993217 0.03904953 0.03513054 0.03521549
 0.05876939 0.0499322  0.0261453  0.06635753 0.04197194 0.01677018
 0.04993217 0.01843039 0.01843038 0.06150339 0.06612343 0.04387851
 0.04141007 0.06150333 0.06624337 0.06628837 0.06636663 0.06636685
 0.04993219 0.04950986 0.06633657 0.05876936 0.05910505 0.01843042
 0.03790247 0.01842837 0.04993002 0.06263708 0.06636689 0.03904942
 0.02308301 0.04993216 0.06636683 0.04040132 0.06122991 0.04993347
 0.04993214 0.06636686]
tr_loss:[0.04764155 0.06360441 0.04764153 0.03206178 0.05022072 0.06927957
 0.05691799 0.06360447 0.05535466 0.05691801 0.03236531 0.04764155
 0.06360575 0.03236479 0.04764476 0.06400629 0.04193814 0.03230384
 0.06440877 0.04344114 0.06360444 0.03990691 0.06360447 0.06927957
 0.04851814 0.04030721 0.04111949 0.0692796  0.0476415  0.04764148
 0.06927953 0.05535468 0.05019562 0.0692796  0.01521041 0.0637812
 0.04765578 0.05036107 0.01521039 0.0152104  0.06926347 0.06358022
 0.06358811 0.04820845 0.03333683 0.03987244 0.0636045  0.05019562
 0.03793755 0.01520951]
tr_loss:[0.01478877 0.04527024 0.04527019 0.05679163 0.01478876 0.04963882
 0.0567968  0.0436768  0.04564112 0.05679152 0.06773051 0.06772673
 0.01478878 0.06212204 0.06212198 0.0398476  0.01478877 0.06701256
 0.05453957 0.05679154 0.01478879 0.04943815 0.06212201 0.06566048
 0.04007472 0.04527033 0.04124529 0.06636716 0.05453956 0.05434768
 0.01478879 0.04010473 0.06716767 0.05657578 0.03731506 0.03311117
 0.04527019 0.06212192 0.06212202 0.057554   0.0474251  0.05679154
 0.04742509 0.06773061 0.06717272 0.06773062 0.0668482  0.05679155
 0.05679153 0.04527018]
tr_loss:[0.01357396 0.04093299 0.04543691 0.06271647 0.04093706 0.05450866
 0.04530094 0.03627869 0.05810081 0.04812508 0.03621491 0.05810081
 0.05450597 0.06271646 0.03621021 0.05304226 0.04953084 0.05450723
 0.03239233 0.04331287 0.05810084 0.05810071 0.05450596 0.04543695
 0.05810084 0.06271641 0.0581008  0.04543693 0.05810077 0.05810078
 0.04331291 0.0409337  0.0627164  0.04093301 0.01357403 0.04331287
 0.06271604 0.05450599 0.05450599 0.05810082 0.06271647 0.04078152
 0.04331293 0.04093297 0.01357395 0.03621467 0.01362218 0.04093299
 0.05453216 0.05450602]
tr_loss:[0.04244211 0.05284886 0.01318004 0.03772304 0.03624071 0.01318005
 0.04140516 0.05643924 0.05643921 0.0562125  0.05182647 0.04691388
 0.0469121  0.05284884 0.01318004 0.04690475 0.01318003 0.04693947
 0.0564392  0.05284132 0.05643923 0.03623307 0.05743783 0.03623307
 0.0528489  0.03623306 0.0390742  0.04690482 0.03623302 0.04352263
 0.04573661 0.03623304 0.03432938 0.0564387  0.03623319 0.02977196
 0.01318002 0.03436925 0.05643923 0.04573541 0.01318003 0.03906747
 0.04690478 0.0742862  0.04573659 0.04658561 0.01318004 0.01318004
 0.05284888 0.05284889]
tr_loss:[0.05140767 0.04756146 0.04989352 0.03732603 0.03732546 0.05136856
 0.01286644 0.01286346 0.03654742 0.04497752 0.01286645 0.05140747
 0.03732579 0.03164861 0.03057053 0.02314336 0.01286643 0.02994998
 0.03547647 0.04496372 0.0495628  0.01286644 0.03732748 0.0475615
 0.03654743 0.05109183 0.01286644 0.05754435 0.04756147 0.05140753
 0.04496351 0.0308358  0.01286643 0.05140769 0.04956278 0.03732551
 0.0449627  0.0465035  0.05140768 0.04237925 0.03654737 0.03732548
 0.03732553 0.01286646 0.03531722 0.04756149 0.03459812 0.04237929
 0.02990941 0.02405282]
tr_loss:[0.04052589 0.04658638 0.03643344 0.05107318 0.03535313 0.03282128
 0.0405255  0.04053712 0.01605975 0.03579801 0.05882569 0.01582274
 0.04053012 0.04546869 0.0160586  0.04546868 0.04052577 0.03984688
 0.04256154 0.05120064 0.0160586  0.05119767 0.03945818 0.0405255
 0.03261573 0.03984218 0.0160586  0.04782508 0.03283821 0.01605859
 0.04546854 0.03282125 0.03282126 0.04583982 0.04052547 0.04052554
 0.0318438  0.05882571 0.03483728 0.04052548 0.03738113 0.01605861
 0.05119696 0.04546864 0.04658666 0.04052547 0.01605861 0.03150406
 0.0160586  0.03148686]
tr_loss:[0.04488843 0.04041078 0.0367294  0.01847012 0.02242153 0.03281904
 0.03672945 0.03420531 0.04985797 0.03420534 0.04786656 0.03420532
 0.02242156 0.02247633 0.04603678 0.04985791 0.03791431 0.03672943
 0.03228634 0.03514842 0.03420531 0.04979652 0.01835253 0.02242156
 0.03420532 0.03672939 0.04985315 0.03612339 0.04032298 0.04032177
 0.04445803 0.01847077 0.02242153 0.03673042 0.040323   0.04011091
 0.03993825 0.04980807 0.02242156 0.06335945 0.03420532 0.04985796
 0.07725932 0.04884087 0.04032298 0.02242158 0.06335946 0.03420534
 0.02242158 0.04050451]
tr_loss:[0.02979586 0.03803117 0.04942335 0.04112076 0.04942288 0.04942355
 0.02226905 0.02325466 0.0425836  0.02226879 0.02226879 0.02226879
 0.0411217  0.0304017  0.04622245 0.04622224 0.04942349 0.04112656
 0.02226879 0.04112078 0.03298723 0.04112078 0.05546235 0.04834381
 0.04942267 0.05546228 0.0407094  0.02728495 0.03937154 0.02255343
 0.03298721 0.04070942 0.02226857 0.03937159 0.04165649 0.04112078
 0.04942352 0.02226879 0.04622532 0.04112075 0.03040172 0.03040171
 0.04640514 0.02409211 0.04942338 0.04112079 0.02226873 0.02226876
 0.02996535 0.04070937]
tr_loss:[0.01991118 0.02511132 0.0408987  0.04089871 0.03030648 0.0358201
 0.03359067 0.04963299 0.04050576 0.03780187 0.01927627 0.04089915
 0.01991117 0.04050221 0.02848839 0.04963882 0.03564848 0.04427643
 0.05260872 0.04050218 0.03194468 0.03194471 0.0405022  0.03582012
 0.03030649 0.03971704 0.0358201  0.04050215 0.01354139 0.03030651
 0.0405022  0.06044476 0.0319447  0.04050221 0.04050218 0.04962384
 0.0303065  0.04089874 0.03582006 0.01991118 0.01991118 0.03030649
 0.01991118 0.04050218 0.05101104 0.02063425 0.03986413 0.03705902
 0.04402202 0.01991116]
tr_loss:[0.0340633  0.03406329 0.03412659 0.03150063 0.0315006  0.03946986
 0.03150062 0.03150154 0.03150132 0.03406331 0.03150062 0.03946988
 0.03944347 0.03946986 0.03874979 0.03150062 0.0315058  0.03406333
 0.03150067 0.03150101 0.014223   0.0291639  0.01422301 0.04931315
 0.03406329 0.04931312 0.04716909 0.03150058 0.02445623 0.0315006
 0.04615756 0.01422303 0.03150387 0.03318061 0.03946982 0.05213077
 0.04031129 0.03150061 0.02826318 0.03406329 0.03406333 0.03371673
 0.03150059 0.02580194 0.02826767 0.03946989 0.04931315 0.03946985
 0.01422301 0.03151752]
tr_loss:[0.02989433 0.03832337 0.01952547 0.04921063 0.03184908 0.03782778
 0.02748899 0.02607388 0.03289785 0.02925099 0.03810329 0.03782777
 0.04286363 0.03642155 0.031803   0.02153136 0.02925098 0.03281768
 0.02980443 0.04738832 0.04883724 0.03782776 0.03782776 0.03610856
 0.04854276 0.02925096 0.03782775 0.02748899 0.04921069 0.03229096
 0.02925099 0.03180545 0.03180293 0.03704419 0.02748902 0.03180293
 0.03810062 0.03781784 0.02211175 0.01111036 0.031817   0.04921062
 0.04919644 0.04921067 0.03642257 0.03281783 0.02878656 0.03180293
 0.02925097 0.02600018]
tr_loss:[0.04652504 0.02675443 0.03030218 0.04652505 0.02515967 0.02043596
 0.03144297 0.02856717 0.02568276 0.01874663 0.03568446 0.02454199
 0.00901948 0.04652507 0.04640295 0.0356854  0.01765466 0.04652508
 0.04343178 0.03568344 0.04431997 0.0156029  0.02674166 0.04082332
 0.04649438 0.04652504 0.03107447 0.03568446 0.03568449 0.03107446
 0.04296007 0.02088472 0.03595804 0.00766922 0.02856717 0.03568448
 0.0269775  0.03107448 0.01558634 0.0267688  0.03568448 0.01392061
 0.02668799 0.02675446 0.03397639 0.02697025 0.04546795 0.04652504
 0.03107509 0.03107445]
tr_loss:[0.02800066 0.04568335 0.01376786 0.0137692  0.0137692  0.02806559
 0.02806539 0.0361702  0.03263259 0.04279936 0.0428122  0.04554388
 0.03261896 0.04281219 0.02917091 0.01377581 0.02845283 0.03617021
 0.03263257 0.03609769 0.03683579 0.03638884 0.03045616 0.03333909
 0.01376921 0.03263263 0.03263261 0.04281017 0.04281214 0.03263285
 0.03610143 0.02792192 0.04281216 0.03045088 0.02917088 0.0326326
 0.02917086 0.03263264 0.02917092 0.02917088 0.04281219 0.04225807
 0.02917087 0.03263255 0.02917088 0.03151836 0.02896892 0.01376919
 0.01360044 0.03045434]
tr_loss:[0.02773573 0.02878407 0.01322965 0.02878422 0.03243561 0.03398571
 0.03400839 0.01322899 0.03398564 0.03937931 0.01322898 0.04436551
 0.03942258 0.03398571 0.038154   0.02809836 0.03046101 0.02878408
 0.03411949 0.03942324 0.02721749 0.03398569 0.0351328  0.02878406
 0.01324418 0.03398594 0.02756587 0.013229   0.02878407 0.02878406
 0.03046097 0.02651852 0.03599475 0.03398569 0.02778546 0.01733192
 0.03398567 0.03571473 0.03411967 0.03427151 0.03222788 0.03398584
 0.03429358 0.01322898 0.02878405 0.03942239 0.03413142 0.03941768
 0.03411856 0.03411855]
tr_loss:[0.02535987 0.0313933  0.03984771 0.01151229 0.03009609 0.02086106
 0.02808549 0.03984776 0.01151245 0.04325482 0.0300961  0.02086103
 0.03798985 0.04014749 0.03984773 0.03798987 0.03984775 0.03984773
 0.04325484 0.03798992 0.01151245 0.01151242 0.02985178 0.03139332
 0.01639418 0.01151245 0.0379815  0.01686191 0.03910992 0.03639706
 0.03013727 0.03009608 0.03798987 0.03798989 0.01151245 0.02673205
 0.01151244 0.01151243 0.03798994 0.02575242 0.03910993 0.02600528
 0.03798988 0.02419904 0.03639951 0.02417737 0.02417061 0.01151245
 0.02086108 0.02417276]
tr_loss:[0.02959771 0.02955464 0.02889287 0.0360706  0.03605245 0.03808404
 0.02959771 0.03808402 0.03186763 0.03808404 0.03075212 0.0384051
 0.03075216 0.00970296 0.02810286 0.03605237 0.03077245 0.03808399
 0.03605378 0.04168605 0.02448251 0.03075211 0.03075211 0.03841158
 0.00970295 0.03771041 0.03786218 0.03075216 0.0380838  0.03584441
 0.02289691 0.03075215 0.03605234 0.02631174 0.00970295 0.03075217
 0.03605244 0.03792567 0.0307521  0.00970294 0.00970295 0.03611606
 0.03753144 0.0307521  0.00970296 0.02833688 0.02840226 0.03840417
 0.03075211 0.00970294]
tr_loss:[0.0369436  0.03694157 0.02954586 0.03819977 0.03301007 0.0293657
 0.03692721 0.02512923 0.03694362 0.02954587 0.03045077 0.00941116
 0.04085891 0.02807823 0.02537084 0.03694361 0.03301004 0.03045256
 0.04173509 0.03045076 0.01813725 0.00941118 0.03045364 0.01336579
 0.03301007 0.0295459  0.02753811 0.03301006 0.03301002 0.02478537
 0.00941117 0.03301009 0.0295459  0.03588834 0.02884711 0.03688826
 0.02889867 0.03942979 0.0309221  0.03045081 0.02807822 0.03694361
 0.02954728 0.00941118 0.03694359 0.03947506 0.03824669 0.03301001
 0.0280782  0.02954587]
tr_loss:[0.00992548 0.0269075  0.036013   0.02690749 0.02984753 0.02582555
 0.02984732 0.02722699 0.00992547 0.0099005  0.02590915 0.020868
 0.02208759 0.0294524  0.03527453 0.03490108 0.02690748 0.00937494
 0.02688796 0.00992546 0.03601349 0.02690748 0.03596922 0.03785058
 0.03785058 0.02928857 0.0269075  0.00992546 0.02984734 0.02903004
 0.00992547 0.02558131 0.01325365 0.02468289 0.00992547 0.02086759
 0.02690749 0.00992547 0.03587823 0.03601065 0.03785061 0.02967906
 0.01044883 0.02690748 0.03601351 0.04048722 0.04048722 0.02310755
 0.02928862 0.00992547]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2100 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2101, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2101 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2102, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2102 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2103, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2103 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2104, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2104 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2105, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2105 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2106, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2106 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2107, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2107 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2108, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2108 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2109, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2109 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2110, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2110 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2111, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2111 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2112, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2112 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2113, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2113 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2114, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2114 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2115, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2115 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2116, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2116 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2117, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2117 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2118, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2118 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2119, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2119 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2120, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2120 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2121, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2121 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2122, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2122 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2123, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2123 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2124, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2124 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2125, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2125 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2126, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2126 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2127, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2127 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2128, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2128 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2129, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2129 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2130, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2130 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2131, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2131 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2132, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2132 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2133, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2133 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2134, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2134 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2135, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2135 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2136, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2136 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2137, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2137 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2138, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2138 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2139, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2139 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2140, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2140 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2141, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2141 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2142, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2142 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2143, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2143 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2144, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2144 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2145, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2145 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2146, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2146 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2147, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2147 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2148, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2148 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2149, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2149 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2150, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2150 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2151, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2151 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2152, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2152 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2153, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2153 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2154, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2154 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2155, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2155 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2156, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2156 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2157, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2157 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2158, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2158 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2159, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2159 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2160, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2160 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2161, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2161 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2162, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2162 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2163, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2163 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2164, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2164 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2165, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2165 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2166, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2166 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2167, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2167 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2168, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2168 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2169, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2169 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2170, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2170 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2171, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2171 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2172, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2172 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2173, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2173 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2174, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2174 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2175, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2175 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2176, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2176 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2177, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2177 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2178, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2178 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2179, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2179 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2180, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2180 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2181, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2181 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2182, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2182 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2183, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2183 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2184, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2184 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2185, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2185 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2186, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2186 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2187, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2187 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2188, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2188 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2189, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2189 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2190, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2190 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2191, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2191 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2192, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2192 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2193, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2193 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2194, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2194 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2195, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2195 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2196, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2196 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2197, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2197 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2198, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2198 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2199, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2199 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2200, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-2100
text_input.shape
(2200, 14400)
learning_input_tmp.shape
(2200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2200, 80)
learning_output.shape
(750, 80)
Model: "sequential_45"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_45 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2538719 1.253669  1.3634841 1.2860247 1.3122618 1.3633149 1.2923653
 1.3612156 1.3549674 1.285055  1.3549675 1.2536694 1.2850521 1.2850518
 1.2850035 1.2923654 1.3636259 1.3636268 1.3633206 1.4093345 1.3662844
 1.3636277 1.2860248 1.3633206 1.3549675 1.3824383 1.3549578 1.3636277
 1.3636278 1.328104  1.3824321 1.2860203 1.253669  1.3636278 1.253669
 1.3636277 1.3657191 1.2861195 1.3553014 1.3636277 1.253669  1.4125769
 1.4125768 1.2703753 1.3549674 1.3610374 1.4060552 1.3549675 1.2929571
 1.3633206]
tr_loss:[0.7071768  0.894873   0.6927967  0.7994825  0.8233932  0.7855824
 0.7071768  0.8473312  0.78392285 0.87864083 0.8207941  0.78392303
 0.7997998  0.69279695 0.783923   0.8786408  0.8957888  0.7998003
 0.69279677 0.8948782  0.83172387 0.8459587  0.7839331  0.82123786
 0.8317191  0.7681379  0.783923   0.7997589  0.69276875 0.8007332
 0.87864095 0.77071106 0.6927904  0.7998002  0.77139366 0.6927969
 0.87864083 0.8948782  0.83285314 0.78392303 0.87864095 0.70717686
 0.783923   0.8459854  0.8948782  0.7071768  0.87605697 0.8948782
 0.80314195 0.78348905]
tr_loss:[0.4282435  0.4768735  0.466755   0.4733544  0.38831633 0.46606246
 0.46584302 0.38831648 0.39650437 0.46815568 0.3965043  0.38831636
 0.4667549  0.4593988  0.40500623 0.47335428 0.47335428 0.39650434
 0.39650434 0.47335428 0.42915693 0.466755   0.4660624  0.42824346
 0.38831645 0.46653357 0.42824346 0.47273827 0.4667551  0.42824346
 0.466755   0.466755   0.46605554 0.46606246 0.39650434 0.48012248
 0.4683559  0.4667445  0.38831633 0.47335428 0.47308293 0.46675363
 0.46606237 0.4282435  0.47335434 0.42824355 0.39648652 0.39716655
 0.4593994  0.4329793 ]
tr_loss:[0.22736473 0.29072422 0.24027057 0.2886264  0.22846547 0.22144708
 0.24027057 0.22846551 0.2402852  0.22144714 0.21354994 0.24027061
 0.22144708 0.21868904 0.24027057 0.24778143 0.23353978 0.24027061
 0.28221902 0.23340285 0.24769919 0.24027061 0.29072434 0.22144708
 0.29072422 0.24772243 0.2333968  0.22846548 0.22846532 0.23340285
 0.22144715 0.22846548 0.29072374 0.2287242  0.23340258 0.25338575
 0.24027057 0.25832343 0.22144711 0.29143587 0.22846548 0.22144702
 0.22846408 0.24027057 0.24027054 0.23340282 0.23340292 0.22846548
 0.29072413 0.22846551]
tr_loss:[0.12662607 0.16718857 0.12959433 0.08873239 0.11927295 0.16719249
 0.14780568 0.0887324  0.16718861 0.10890295 0.11518951 0.16718863
 0.12662664 0.16718867 0.10906074 0.08873238 0.11518951 0.11518952
 0.08873238 0.12813649 0.10890298 0.10890295 0.10890289 0.10890295
 0.11518953 0.10890291 0.13444057 0.1278321  0.10890289 0.12662631
 0.16792783 0.12662622 0.08873633 0.13444057 0.11096071 0.13444062
 0.08873238 0.10890295 0.16718937 0.13444062 0.16719043 0.16478364
 0.11518951 0.14392708 0.10890293 0.12662624 0.16718927 0.12661836
 0.11659579 0.17624798]
tr_loss:[0.11423586 0.05552293 0.08771466 0.10623063 0.11423592 0.08769761
 0.05552293 0.06697589 0.06697591 0.08417042 0.08103073 0.11755089
 0.0997322  0.09974433 0.13415685 0.08103013 0.13119033 0.05552293
 0.07991913 0.11423592 0.08678687 0.09973216 0.08103012 0.09973226
 0.11423592 0.09973215 0.09973221 0.08103011 0.1142359  0.10260558
 0.06697588 0.08770701 0.09988737 0.05552296 0.09909464 0.10540564
 0.10147072 0.1030311  0.11423595 0.08103012 0.12549643 0.0669759
 0.0669881  0.1142359  0.11438207 0.11423589 0.09973224 0.08446243
 0.08028392 0.12668414]
tr_loss:[0.09593499 0.08668039 0.10061236 0.07327292 0.0980323  0.11481478
 0.09622072 0.07683893 0.04544563 0.04600622 0.10509963 0.07327295
 0.04600616 0.04600616 0.04547132 0.04600627 0.04600617 0.04547135
 0.04600616 0.07327296 0.08837591 0.08645935 0.08837592 0.07640792
 0.07638001 0.08837615 0.04547132 0.07327293 0.04547132 0.04547133
 0.09803239 0.04547132 0.04547131 0.0454713  0.07327293 0.08383118
 0.07655764 0.04600621 0.07638641 0.09252385 0.04600617 0.04600618
 0.0460062  0.0454713  0.08346704 0.07327295 0.09803237 0.04600621
 0.07251455 0.06746285]
tr_loss:[0.04186085 0.07031982 0.09889374 0.03546488 0.08330448 0.08330417
 0.04692131 0.08362782 0.0792518  0.08330445 0.03546488 0.07629268
 0.0988949  0.0880191  0.05830112 0.08371618 0.07893501 0.08615686
 0.07925182 0.08610256 0.08615687 0.07629566 0.07002296 0.04371654
 0.08610258 0.03546488 0.08610258 0.08579346 0.07925276 0.08330446
 0.03546489 0.07931222 0.04186096 0.04186093 0.05640275 0.08801897
 0.03546486 0.04670928 0.03546486 0.04186094 0.08330448 0.08615691
 0.03546485 0.03546488 0.0861569  0.08610258 0.08176396 0.04186093
 0.09902127 0.03546487]
tr_loss:[0.02716672 0.06064926 0.06231344 0.03929481 0.06526609 0.06882547
 0.06231338 0.03381603 0.06882552 0.02716672 0.0821271  0.03929482
 0.0392948  0.06000702 0.05004357 0.06730235 0.02716671 0.06231343
 0.03929482 0.06882552 0.06231342 0.06882614 0.07440315 0.05966041
 0.06231346 0.0744032  0.0392948  0.06231343 0.0623134  0.0366846
 0.05851171 0.07156769 0.07440322 0.03736352 0.03381842 0.06525941
 0.05648233 0.07441061 0.07440324 0.03929481 0.0271667  0.03929481
 0.05976804 0.03929481 0.07440324 0.03717331 0.0625748  0.02716673
 0.06871685 0.07390078]
tr_loss:[0.06527232 0.07116961 0.05870427 0.05224312 0.05271564 0.0851904
 0.06929715 0.05224315 0.05224315 0.05224313 0.08975671 0.05871505
 0.07034475 0.07830016 0.07613654 0.08975656 0.06527238 0.06527366
 0.07830007 0.05224316 0.05206863 0.07613654 0.07830013 0.07034481
 0.05870311 0.07000728 0.07778084 0.07613654 0.06527236 0.03595742
 0.05870304 0.08974724 0.06527235 0.07830004 0.07830014 0.07613651
 0.06431767 0.07237077 0.04216794 0.08252425 0.08923826 0.06471919
 0.07613654 0.07832755 0.07034553 0.07613657 0.05224315 0.07613652
 0.07613659 0.07034645]
tr_loss:[0.06147772 0.05938349 0.03396147 0.03396149 0.06236599 0.06236597
 0.06236737 0.04089894 0.03396147 0.07238026 0.06236597 0.03956954
 0.06236599 0.0761377  0.06721113 0.06236594 0.03396149 0.06236597
 0.06236596 0.07613691 0.06217538 0.06236597 0.03418478 0.06147772
 0.06236599 0.03396149 0.03396148 0.06399795 0.05847742 0.05188103
 0.07613617 0.07290695 0.05187323 0.04561179 0.05805852 0.06179457
 0.06236597 0.0723802  0.07238026 0.06399786 0.06147772 0.06236597
 0.06236599 0.06174652 0.06146288 0.08105898 0.07586609 0.05778704
 0.062366   0.05187315]
tr_loss:[0.04409073 0.07643239 0.07082678 0.08731382 0.06407466 0.05632166
 0.02750333 0.05632157 0.08645596 0.07082675 0.06267626 0.05359202
 0.05632166 0.07106509 0.03234515 0.05140226 0.05632172 0.05227119
 0.05637087 0.07568432 0.05632166 0.06478865 0.05227122 0.051697
 0.02750125 0.02750127 0.02750125 0.02739485 0.05632169 0.06407449
 0.02750125 0.02750125 0.0563217  0.0563217  0.02750126 0.05632165
 0.05792783 0.05482707 0.05542822 0.02750126 0.04243803 0.03234516
 0.04273093 0.0275015  0.07643243 0.07082676 0.07082678 0.04422623
 0.05792757 0.03234519]
tr_loss:[0.06107407 0.0346794  0.06183485 0.09171063 0.04169    0.08050965
 0.04169005 0.08107977 0.08107977 0.07755033 0.08782008 0.07489549
 0.02565317 0.02565314 0.02565314 0.02565317 0.06107408 0.02565316
 0.02565316 0.04168999 0.03467941 0.06107409 0.0775503  0.04169001
 0.07805935 0.06107405 0.06307062 0.03467941 0.06107408 0.07755028
 0.04861681 0.06107414 0.03467936 0.07755033 0.0346794  0.04169001
 0.08107975 0.07755263 0.0619719  0.05575163 0.04606451 0.06784879
 0.07755134 0.0810798  0.02565317 0.06107416 0.05917756 0.02565316
 0.06107413 0.08107977]
tr_loss:[0.06422634 0.04024773 0.04560975 0.04024812 0.06422053 0.06169438
 0.02708359 0.06422637 0.07297143 0.0402477  0.06422635 0.01980381
 0.05299951 0.04020973 0.02708362 0.06422637 0.07318684 0.06422635
 0.05301021 0.06229843 0.04024775 0.02708357 0.07126949 0.07297145
 0.07898222 0.0402477  0.07063015 0.04024773 0.07126957 0.04568004
 0.02708358 0.07912103 0.06422637 0.06422631 0.01980593 0.07128886
 0.02708359 0.04024773 0.02708358 0.02739913 0.07130526 0.07126947
 0.01980381 0.05320787 0.08346161 0.08346136 0.04024782 0.04024871
 0.02708356 0.08289989]
tr_loss:[0.01889654 0.01889535 0.06034192 0.04072692 0.04334685 0.02024257
 0.06329669 0.07633216 0.06035244 0.03979675 0.0202401  0.06329671
 0.01889653 0.060342   0.05816945 0.04744181 0.02024009 0.0202401
 0.03861169 0.04697923 0.03864779 0.06329674 0.06034206 0.06789571
 0.04744785 0.02024011 0.02024028 0.05816992 0.04596055 0.05816993
 0.06034197 0.03865047 0.06035846 0.05631964 0.06034198 0.06329673
 0.0487716  0.03932611 0.06034197 0.04545424 0.02024008 0.02024073
 0.01889654 0.0632967  0.03748362 0.06356496 0.04745458 0.0474478
 0.06329674 0.01889654]
tr_loss:[0.0387918  0.02482261 0.05949419 0.01989854 0.04578377 0.0484157
 0.04578378 0.02556342 0.06340914 0.07169204 0.01989766 0.02556342
 0.05920743 0.01989765 0.06340916 0.03702945 0.01989764 0.05150134
 0.03769305 0.01989762 0.05331822 0.03769293 0.05112125 0.02556343
 0.01989764 0.01989766 0.04626168 0.05225793 0.04578376 0.01989764
 0.01997754 0.05111353 0.04578373 0.05112111 0.06550547 0.04630478
 0.08339898 0.04578375 0.04844963 0.04578376 0.07181712 0.02556339
 0.05331834 0.04578376 0.05112127 0.01989765 0.0691639  0.02556338
 0.05331899 0.05920174]
tr_loss:[0.04237464 0.05136573 0.01471347 0.06211932 0.02570358 0.0500189
 0.06689022 0.06122522 0.0628372  0.03412911 0.05136574 0.05136574
 0.03405487 0.051367   0.05555083 0.05137629 0.05555099 0.05136574
 0.02570447 0.02570446 0.02570445 0.042376   0.04313874 0.04193119
 0.05136575 0.05136573 0.05136574 0.06122525 0.04983355 0.06123258
 0.04237497 0.02570447 0.06122525 0.05136572 0.0467056  0.04237463
 0.05057885 0.06689021 0.01471349 0.02569542 0.04237634 0.05100786
 0.05057759 0.05136573 0.01471347 0.02570446 0.02570445 0.0513624
 0.04813698 0.04237463]
tr_loss:[0.04640169 0.05060442 0.04599456 0.04587454 0.06345846 0.03422508
 0.05436535 0.0543365  0.05144888 0.02548053 0.07292525 0.05126363
 0.03422513 0.05433653 0.03038727 0.07292527 0.04707417 0.05111159
 0.05433653 0.01359957 0.03423239 0.06291284 0.05433651 0.06291281
 0.01359956 0.04613725 0.05660091 0.05433654 0.04594962 0.05433651
 0.05111251 0.07292529 0.05111245 0.05046679 0.01359959 0.03422508
 0.04576216 0.01359956 0.07292528 0.06331019 0.06291276 0.03422502
 0.02548052 0.04670954 0.01412934 0.01359957 0.07292527 0.05275749
 0.06291279 0.05426189]
tr_loss:[0.04709404 0.05793383 0.03718369 0.01512642 0.0187852  0.04505832
 0.03198507 0.01878519 0.0424004  0.0187852  0.05793383 0.03197974
 0.03197976 0.0431504  0.05791159 0.0579338  0.04505832 0.03206903
 0.03991272 0.05793379 0.0151264  0.01878521 0.03849421 0.03203412
 0.04505829 0.05793377 0.0551245  0.03267692 0.0319797  0.03689158
 0.0319797  0.04286956 0.0444673  0.03197972 0.04427416 0.05069394
 0.06772657 0.0677266  0.03197975 0.04314202 0.01512638 0.04234284
 0.02893841 0.05251159 0.03199074 0.04505831 0.03939638 0.05251158
 0.01512639 0.05793379]
tr_loss:[0.05524895 0.05920399 0.02136862 0.03772478 0.03634987 0.03287245
 0.02136863 0.06487237 0.03772525 0.07690164 0.05524895 0.02136862
 0.0312212  0.05524896 0.02136863 0.03737929 0.03808317 0.0365314
 0.06487238 0.05524896 0.01590536 0.03772479 0.02138348 0.0213686
 0.02136862 0.03840883 0.02136863 0.0373804  0.0648724  0.03723202
 0.05135238 0.02136921 0.03772498 0.02136861 0.03772477 0.01590535
 0.01590535 0.01590534 0.03772479 0.03632029 0.05524902 0.01590536
 0.03737806 0.0363203  0.04163817 0.05544726 0.02136864 0.01590535
 0.0331208  0.03632026]
tr_loss:[0.01800618 0.01197182 0.03308277 0.03573752 0.03738406 0.03274374
 0.03942918 0.03274375 0.01800614 0.04844411 0.04844408 0.03178061
 0.03942923 0.03186231 0.01800982 0.03275625 0.04844413 0.01800614
 0.03573341 0.03943033 0.06342973 0.03274371 0.01800615 0.06342973
 0.01197184 0.04844412 0.02654157 0.0307097  0.01800615 0.04005734
 0.01800616 0.03573765 0.01196967 0.04844414 0.03274372 0.01197182
 0.01197183 0.06342974 0.03274379 0.0357791  0.05943902 0.01197182
 0.0594107  0.01800613 0.03942947 0.01203857 0.03942916 0.06342975
 0.06342974 0.04842384]
tr_loss:[0.01492274 0.01195941 0.04671633 0.01492271 0.02763652 0.0119594
 0.0351705  0.05816275 0.03482336 0.01195939 0.0119594  0.01492275
 0.03922651 0.04550807 0.01195914 0.04675768 0.01195942 0.01195938
 0.03517054 0.0351705  0.01492271 0.05472418 0.06476521 0.04550814
 0.03917325 0.04659361 0.01195942 0.03519908 0.04456023 0.0647652
 0.04550814 0.04671632 0.01492271 0.01492272 0.01195212 0.04550812
 0.04584863 0.01492272 0.01492272 0.01492272 0.0541597  0.04550814
 0.03517052 0.04550813 0.03438685 0.04550808 0.04551705 0.04671634
 0.03512297 0.03438016]
tr_loss:[0.01322818 0.0507419  0.03849966 0.03152632 0.04769491 0.01322816
 0.04058105 0.06294908 0.04457758 0.04457604 0.04057108 0.03900752
 0.06294906 0.06294902 0.04792366 0.01855683 0.04457605 0.04769552
 0.0629491  0.06294905 0.01198168 0.0527161  0.03981179 0.06294907
 0.06294905 0.01322815 0.04769497 0.04250652 0.03900397 0.03849966
 0.03900742 0.04746029 0.0119093  0.03900395 0.0404743  0.04769499
 0.04803311 0.04769497 0.06294908 0.01322816 0.0435504  0.03739934
 0.04457601 0.01190623 0.01190623 0.04803402 0.01190624 0.04769497
 0.01322813 0.01190624]
tr_loss:[0.01424387 0.00992114 0.00992113 0.05140824 0.04006976 0.00992112
 0.04247453 0.04076951 0.04006421 0.04208989 0.04006422 0.04208977
 0.01424387 0.00992112 0.01620611 0.03574524 0.04082694 0.04208995
 0.01424386 0.04006429 0.04006424 0.01424386 0.04208993 0.00992113
 0.00992112 0.01622668 0.01424387 0.05140825 0.05773579 0.03380108
 0.04090217 0.03959677 0.04470672 0.04775202 0.03212305 0.0400642
 0.04208992 0.01159163 0.04208993 0.03637923 0.03521574 0.00992114
 0.05052971 0.02292385 0.01424387 0.05773578 0.04742169 0.01424387
 0.04208993 0.04006423]
tr_loss:[0.00863912 0.0400742  0.03418142 0.00863914 0.00863915 0.05433108
 0.02207637 0.01462079 0.03489607 0.05433103 0.05238036 0.01462082
 0.0341776  0.05433111 0.05247463 0.05238036 0.05433105 0.03418139
 0.05238032 0.04233394 0.03418137 0.0341814  0.03418137 0.00863914
 0.03418139 0.03076815 0.05238035 0.04233394 0.0523803  0.05433106
 0.05433105 0.033073   0.01697084 0.04073355 0.03183395 0.01462083
 0.03081577 0.01462082 0.05238029 0.03992192 0.04233392 0.04180496
 0.01462083 0.00863912 0.03939439 0.03418136 0.03418142 0.05238036
 0.03418138 0.01463597]
tr_loss:[0.05312202 0.03841849 0.0089611  0.03015724 0.01955784 0.02853278
 0.01590278 0.03559957 0.02346819 0.03983326 0.03942891 0.03419495
 0.04962166 0.0358353  0.01604193 0.03786693 0.02853278 0.0160419
 0.03983324 0.04443421 0.01604191 0.0378897  0.03007505 0.03661259
 0.02188938 0.02853276 0.0089611  0.05312198 0.04961437 0.04961962
 0.01604191 0.03987759 0.02853277 0.0399382  0.04961967 0.02853278
 0.01604193 0.02853441 0.04961965 0.00896109 0.03983325 0.03983327
 0.02346667 0.04614916 0.03820706 0.0500689  0.02853274 0.01604193
 0.053122   0.0160419 ]
tr_loss:[0.03923498 0.00989035 0.03729787 0.04777008 0.01652259 0.02665058
 0.02665282 0.00989036 0.03731234 0.01652258 0.04776381 0.03729789
 0.02665061 0.01652258 0.00989094 0.03804111 0.00989039 0.03730231
 0.03579153 0.03576501 0.0165226  0.04777002 0.01652258 0.03729786
 0.00989042 0.01652257 0.02665057 0.00989035 0.04777002 0.03729788
 0.01652259 0.02263768 0.04777004 0.03470321 0.04777002 0.02306919
 0.03728877 0.0363626  0.00989036 0.03853165 0.04776996 0.05124755
 0.01652258 0.01650962 0.02687648 0.05399407 0.04777009 0.0372979
 0.01652268 0.02665058]
tr_loss:[0.02631231 0.0340051  0.04438153 0.04438075 0.04438073 0.05469416
 0.05469415 0.04471617 0.01405369 0.04411865 0.03942288 0.04921209
 0.03344815 0.00966116 0.03831299 0.03924625 0.0324661  0.04438078
 0.00968397 0.03634931 0.04436477 0.03634939 0.03832597 0.01405367
 0.02588309 0.02630628 0.02628842 0.00966117 0.05469416 0.02628851
 0.00966117 0.03246498 0.03246497 0.04037877 0.036359   0.02628837
 0.01405369 0.01405369 0.02628845 0.04438129 0.02631701 0.04438075
 0.02628841 0.04921224 0.04438073 0.01405368 0.02628838 0.01405372
 0.01009655 0.00966118]
tr_loss:[0.02879178 0.02754692 0.04150063 0.03630421 0.04150017 0.03620823
 0.04286367 0.02879175 0.03909486 0.0320433  0.02548507 0.02097706
 0.04642304 0.04855766 0.02879165 0.01477424 0.05949532 0.02754694
 0.01020336 0.01152157 0.01152156 0.01152154 0.02544251 0.01152157
 0.02879177 0.04150018 0.01020336 0.02879176 0.02879177 0.01020336
 0.02754745 0.01152155 0.05533344 0.02879358 0.0415001  0.03329553
 0.03105598 0.04150013 0.01020336 0.01020337 0.01020336 0.04150014
 0.02879177 0.01152156 0.03204249 0.02754699 0.03309442 0.01020338
 0.0553334  0.02879179]
tr_loss:[0.02817357 0.04080577 0.01196177 0.03204746 0.01335244 0.04056643
 0.03280315 0.04080578 0.03218157 0.03716327 0.04080577 0.03203951
 0.04080576 0.05722475 0.03085395 0.02215122 0.0322657  0.04080568
 0.01197783 0.02817358 0.04080687 0.05722481 0.03203986 0.03225721
 0.02817376 0.03224541 0.02811708 0.01335244 0.02817358 0.01196251
 0.02811489 0.02785724 0.02817357 0.03203949 0.04080576 0.01196251
 0.02817393 0.01196252 0.01335283 0.05722481 0.02817358 0.01196251
 0.01196253 0.03637096 0.04080558 0.03226619 0.01335244 0.05722481
 0.03698149 0.01335244]
text_input.shape
(2200, 14400)
learning_input_tmp.shape
(2200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2200, 80)
learning_output.shape
(750, 80)
Model: "sequential_46"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_46 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0182043  1.0095522  1.1127201  1.0077932  1.029249   1.1133044
 1.0429895  1.055176   1.0095565  1.1025954  1.0262451  1.0425146
 1.1127201  1.0386826  1.0429925  1.1026028  1.0176147  1.0095564
 1.0032775  1.055176   1.0551752  1.0551758  1.1026027  1.0429922
 0.9972418  1.1127201  1.0175396  1.029249   1.0052564  1.0135822
 1.1133114  1.0260503  1.00099    1.1127201  1.0565922  1.1127201
 1.102603   1.0292488  1.0551758  1.1127201  1.0429926  1.0429924
 1.0095565  1.029249   1.0289488  1.0551758  1.1191282  0.99719703
 1.1127201  1.0551757 ]
tr_loss:[0.7041069  0.70836085 0.71015185 0.69504535 0.6368416  0.63700926
 0.7101519  0.6204726  0.6817226  0.6979105  0.64841616 0.6498987
 0.6817225  0.7296926  0.7208096  0.6817226  0.6958395  0.6144126
 0.68172264 0.6368417  0.7101507  0.72968704 0.6817226  0.69742477
 0.7296927  0.65056455 0.6368416  0.68172264 0.64374274 0.63700926
 0.63700926 0.68172354 0.71015185 0.6280687  0.729692   0.7296926
 0.6484175  0.7296926  0.71015185 0.6484161  0.6817226  0.64841604
 0.68172264 0.6817226  0.59804744 0.70167774 0.7101519  0.68745166
 0.71015185 0.6308857 ]
tr_loss:[0.33628064 0.3477545  0.32428056 0.31795597 0.38017184 0.38017172
 0.33380213 0.34775454 0.3801718  0.34775454 0.32475758 0.32095632
 0.34775454 0.37992784 0.33102527 0.38017178 0.34775463 0.3394022
 0.3242806  0.34926885 0.34775424 0.33380216 0.33379966 0.3307473
 0.34775454 0.3477545  0.3209564  0.32475397 0.32428053 0.32095638
 0.32428047 0.33380213 0.33102545 0.32428056 0.34775448 0.33380207
 0.3253565  0.33086306 0.34775457 0.34775448 0.3263151  0.33380213
 0.34775448 0.3400747  0.3338021  0.3209563  0.38017172 0.32428056
 0.33643454 0.33643442]
tr_loss:[0.20287661 0.20274386 0.19247887 0.17973705 0.16614293 0.1661429
 0.1661429  0.2028766  0.1660302  0.17973705 0.1756151  0.1756151
 0.19663993 0.1661429  0.20287657 0.18887798 0.19164318 0.20309548
 0.19247624 0.19164315 0.2028766  0.19164322 0.16614285 0.17973709
 0.20076367 0.17561515 0.1911242  0.17973708 0.19574675 0.18887722
 0.16827135 0.20287529 0.20076354 0.18298358 0.17973706 0.17973705
 0.19574675 0.18009658 0.20287657 0.18298365 0.17231937 0.19164321
 0.1780839  0.17973691 0.17561513 0.1924139  0.17972116 0.2028766
 0.16614285 0.20076394]
tr_loss:[0.10157503 0.13785705 0.12517965 0.12456895 0.10931184 0.09470882
 0.11597407 0.10928331 0.1129266  0.10931307 0.11889553 0.11597405
 0.11292664 0.12780307 0.10157504 0.11292173 0.11597397 0.12456898
 0.11291344 0.12456896 0.11597401 0.118897   0.11292662 0.11697815
 0.12661752 0.09470459 0.10931301 0.1310337  0.11889698 0.11889698
 0.11476575 0.1189122  0.11597405 0.1109815  0.11597407 0.11889696
 0.11292656 0.11292662 0.12456896 0.11889701 0.11602426 0.11889698
 0.12456892 0.10157503 0.12456894 0.12048409 0.11292662 0.12456896
 0.11292551 0.11602427]
tr_loss:[0.08171588 0.05424812 0.08403347 0.05577226 0.10062178 0.08171587
 0.05577226 0.08528304 0.08171603 0.0838082  0.08171585 0.0787639
 0.10062182 0.08171588 0.08577464 0.08171592 0.08380818 0.07876388
 0.05577286 0.0967168  0.10062177 0.05577227 0.08375409 0.07918674
 0.08770409 0.05686029 0.0772046  0.07876389 0.08380818 0.08380823
 0.08380822 0.05577223 0.05424807 0.0787511  0.08404034 0.05424811
 0.0787639  0.07876352 0.08380868 0.0834156  0.05577074 0.08171692
 0.07652915 0.08171581 0.05577226 0.07876392 0.08578563 0.09020786
 0.05577226 0.05424814]
tr_loss:[0.09235135 0.06430156 0.04035607 0.07792871 0.08473964 0.06895546
 0.04832584 0.08455187 0.0384809  0.07427804 0.06618147 0.06001973
 0.07065468 0.05999472 0.05687704 0.07792874 0.08410771 0.06618577
 0.07792872 0.0779287  0.07260419 0.03848089 0.03836813 0.09235134
 0.07792874 0.04035613 0.03848087 0.09235133 0.06618204 0.04037227
 0.0589984  0.04033095 0.07260422 0.06618184 0.07260424 0.06420694
 0.07279366 0.07280721 0.07792871 0.0661815  0.08456524 0.03848089
 0.03848089 0.09235138 0.07424968 0.07792872 0.09235135 0.07260422
 0.04035612 0.04035616]
tr_loss:[0.08320796 0.07969373 0.08115937 0.03855105 0.08898945 0.05429937
 0.03899512 0.07809687 0.07969377 0.07969376 0.07812817 0.07812823
 0.03899514 0.06039133 0.03899515 0.03899518 0.0781282  0.03750788
 0.07969373 0.03750785 0.076054   0.06621862 0.07647582 0.07969374
 0.08898948 0.0603913  0.04710395 0.06149166 0.07969373 0.06039128
 0.05262585 0.03750784 0.0889894  0.03899514 0.03899514 0.08898947
 0.07605396 0.07812816 0.07812819 0.08898944 0.03750784 0.03750782
 0.03750781 0.03899514 0.06039001 0.07605555 0.07969373 0.04694301
 0.06357951 0.06039127]
tr_loss:[0.08425678 0.05109709 0.0551815  0.08011398 0.03708472 0.03922383
 0.04758403 0.06444281 0.07270811 0.06444284 0.07270528 0.03708469
 0.0782882  0.03922383 0.05876778 0.07270533 0.06444278 0.05109782
 0.07270533 0.0657025  0.08224634 0.082213   0.06444266 0.06057642
 0.06368962 0.06444278 0.03707911 0.03922382 0.0370847  0.06442405
 0.06444284 0.08221296 0.08221298 0.05704539 0.03708468 0.04978342
 0.07832987 0.07276893 0.08364163 0.07270531 0.0727063  0.07292064
 0.05109412 0.06444265 0.06544362 0.08187128 0.082213   0.0392238
 0.07437764 0.08460565]
tr_loss:[0.06504154 0.03647871 0.0818403  0.04653964 0.06228403 0.06228399
 0.03181241 0.0353157  0.08174762 0.03531574 0.03531572 0.06504153
 0.06504152 0.06504153 0.062284   0.06524825 0.03531575 0.07707556
 0.06504151 0.07706601 0.062284   0.077067   0.06228402 0.08185898
 0.03181239 0.03353504 0.07697235 0.06228402 0.077066   0.06504278
 0.06895973 0.06376277 0.06504153 0.07782896 0.03181238 0.03531572
 0.0622822  0.03531572 0.03531573 0.06986715 0.0650415  0.06228293
 0.03347293 0.03252971 0.04209643 0.07133206 0.03181233 0.07177025
 0.06227567 0.07130034]
tr_loss:[0.05579972 0.01768923 0.04535916 0.06884474 0.05828539 0.06102489
 0.02303997 0.05984254 0.04502422 0.02985194 0.02303995 0.03439401
 0.0610249  0.06102492 0.02303998 0.03804116 0.0342685  0.02471816
 0.06596325 0.06600787 0.0582654  0.01768924 0.06884472 0.05579976
 0.04502436 0.0450248  0.05986812 0.06102487 0.06102487 0.01768924
 0.01768923 0.04502425 0.06102489 0.06102797 0.04419238 0.03663989
 0.0688447  0.06596176 0.04495696 0.05579972 0.03643811 0.06102485
 0.02303996 0.05933406 0.01768928 0.04054365 0.05592594 0.04503426
 0.04502426 0.06102489]
tr_loss:[0.01711633 0.01711631 0.04508035 0.01081659 0.0709918  0.03929096
 0.05257754 0.050435   0.05846945 0.05945226 0.05813498 0.05846944
 0.05186164 0.01081659 0.05846937 0.01081659 0.01081659 0.03393405
 0.01081659 0.01711681 0.05846949 0.02998669 0.05843843 0.01081657
 0.05846921 0.01711611 0.05846949 0.01081857 0.05139495 0.03384699
 0.01081659 0.01081721 0.01081659 0.03393408 0.01711632 0.01711632
 0.05813456 0.07099185 0.01081659 0.05139495 0.01711491 0.05813496
 0.04858566 0.05139493 0.03384696 0.03744721 0.05146606 0.05177097
 0.07099183 0.05139494]
tr_loss:[0.05364012 0.03222055 0.05377259 0.04655778 0.05374358 0.0156041
 0.01560411 0.01125354 0.04387783 0.01125355 0.01560408 0.04491207
 0.05310622 0.03344122 0.01125354 0.05045309 0.05377258 0.03344119
 0.01125353 0.04491204 0.05377258 0.0156041  0.04488879 0.01125354
 0.05373122 0.04335213 0.05377261 0.02970067 0.03344124 0.04805575
 0.06658464 0.0514078  0.04491212 0.0334454  0.06658462 0.01125354
 0.06658463 0.01125356 0.01560407 0.04491661 0.04652596 0.03349867
 0.04790178 0.01560408 0.0432134  0.03377741 0.03757148 0.03344116
 0.044912   0.0156041 ]
tr_loss:[0.04868848 0.06067199 0.04785665 0.04205454 0.01486319 0.04746968
 0.02955163 0.01542772 0.0148632  0.01511622 0.06067201 0.0148632
 0.04205448 0.03886085 0.01542773 0.02722411 0.03026744 0.0148632
 0.01545688 0.03886086 0.04866192 0.01486322 0.03886088 0.04997916
 0.04205522 0.04205455 0.03262206 0.03886086 0.07147637 0.04866191
 0.060672   0.04746728 0.06253432 0.01486319 0.04998573 0.03886285
 0.04206698 0.01542774 0.01542774 0.01486319 0.01486319 0.0475311
 0.03915361 0.04866192 0.04205457 0.0148632  0.01542773 0.01542773
 0.05495812 0.04857925]
tr_loss:[0.04840871 0.01886708 0.05058615 0.03382571 0.04966047 0.02119654
 0.04966052 0.04966054 0.04966053 0.0487453  0.04271687 0.02855827
 0.04601363 0.05301324 0.0496605  0.04457214 0.03278872 0.04457219
 0.04054968 0.06189261 0.03487708 0.01886707 0.03279848 0.04056876
 0.03379295 0.01886708 0.04457216 0.04011302 0.02119653 0.04457217
 0.01886709 0.02120009 0.02119571 0.06189262 0.04840868 0.04457215
 0.0238521  0.04841237 0.04840868 0.04457214 0.01886707 0.06189264
 0.0270097  0.05300877 0.04457214 0.02119656 0.0530133  0.04457219
 0.04457209 0.02119652]
tr_loss:[0.04492875 0.05364085 0.04755154 0.04942271 0.043678   0.05416954
 0.03484257 0.02203654 0.04755152 0.02203628 0.05033636 0.05345752
 0.04755158 0.01817326 0.05363746 0.043678   0.0182714  0.05100996
 0.04367795 0.03070113 0.04328796 0.04247984 0.043678   0.05364139
 0.0182714  0.04311983 0.04367799 0.01827141 0.04755158 0.02203653
 0.0536414  0.04329127 0.03264555 0.04755141 0.05444838 0.02203654
 0.01827141 0.03450577 0.03484306 0.04755153 0.06371872 0.04128518
 0.04329146 0.01827141 0.04867989 0.02203655 0.02453956 0.01827141
 0.04367803 0.06371872]
tr_loss:[0.01452943 0.08941637 0.02807338 0.04837545 0.04192255 0.04320288
 0.01452946 0.04320285 0.01452944 0.04320289 0.04772629 0.01452942
 0.04837537 0.04773095 0.04837537 0.06159868 0.0202276  0.01452942
 0.0426429  0.03797474 0.02019728 0.02019728 0.06159864 0.03797474
 0.03754476 0.01452944 0.04320287 0.06159864 0.06159869 0.02019726
 0.04837541 0.03014155 0.02443955 0.04320289 0.03797471 0.02019725
 0.04247189 0.06159865 0.02019725 0.04837539 0.03797476 0.04098417
 0.03803407 0.01452944 0.0432029  0.0379747  0.04323842 0.02033941
 0.02019725 0.01452943]
tr_loss:[0.04189751 0.03454787 0.03273024 0.0231943  0.04189581 0.01185632
 0.01185632 0.04121824 0.06390606 0.02319429 0.04190627 0.0118766
 0.01185631 0.04122031 0.03403573 0.02319431 0.0418975  0.02319427
 0.04121898 0.02193836 0.01185632 0.04511459 0.04121825 0.03418151
 0.02319436 0.0340357  0.02319431 0.0118552  0.04121831 0.0418975
 0.03447383 0.0231943  0.02319426 0.02326022 0.04189754 0.04189792
 0.03403569 0.04121822 0.03630371 0.03962778 0.01185632 0.01391549
 0.02319429 0.04588839 0.03403568 0.04841007 0.04189752 0.03087316
 0.02319429 0.01185632]
tr_loss:[0.01216188 0.01781607 0.02077226 0.03148293 0.03532373 0.01781607
 0.03140938 0.06248502 0.04757451 0.04683052 0.01216188 0.04197475
 0.04197586 0.01216189 0.02278779 0.03140942 0.03034422 0.03532171
 0.04757496 0.03140939 0.01217757 0.04197014 0.03017003 0.03532466
 0.03256747 0.03140942 0.03532168 0.03532171 0.03140942 0.06248497
 0.06248505 0.01781606 0.06248504 0.03532229 0.04197473 0.01781606
 0.03142349 0.04197476 0.01781605 0.03209842 0.062485   0.04761435
 0.03421227 0.0419747  0.03532172 0.01781607 0.03175297 0.03140943
 0.01781603 0.03027914]
tr_loss:[0.01977256 0.04076629 0.0180696  0.06058741 0.04341663 0.01766342
 0.0445037  0.02459121 0.01766343 0.01196415 0.0245911  0.0434166
 0.02459125 0.04341659 0.043398   0.02459111 0.01297449 0.01196415
 0.04843266 0.04076631 0.04076625 0.04383067 0.02459107 0.03550883
 0.02459113 0.06058743 0.01766344 0.04387771 0.06058739 0.04341654
 0.02459109 0.01766345 0.04843395 0.04076626 0.02014579 0.028114
 0.04483372 0.01196415 0.0212605  0.03244349 0.01766342 0.04550235
 0.04076626 0.02459381 0.0516787  0.03244345 0.04511322 0.0434166
 0.02460853 0.04076626]
tr_loss:[0.02081793 0.04364196 0.04922383 0.04356384 0.0492239  0.04356387
 0.04921428 0.0436427  0.02746299 0.05559079 0.03230299 0.04364192
 0.02961558 0.01217542 0.04356385 0.05003703 0.01217543 0.06113444
 0.06113443 0.0205799  0.01217864 0.05050397 0.0496906  0.01217545
 0.01217544 0.06113441 0.04356384 0.05286028 0.03500143 0.03483047
 0.04356385 0.02394725 0.04077621 0.04370906 0.02057991 0.04364195
 0.05316073 0.04356386 0.05259055 0.04888358 0.06113447 0.04356382
 0.04364197 0.01217543 0.03106312 0.04922089 0.04356432 0.04364227
 0.04356383 0.02394728]
tr_loss:[0.04026445 0.01867987 0.04479991 0.01277649 0.04512352 0.04063951
 0.0127765  0.04002295 0.02509109 0.0406395  0.04002295 0.03485275
 0.03549525 0.04102147 0.04085927 0.06001735 0.02586747 0.03354426
 0.04002301 0.0127765  0.03095529 0.04002299 0.01277651 0.02471401
 0.04009398 0.0127765  0.05419218 0.01739052 0.05392597 0.03127173
 0.02586673 0.01843033 0.0127765  0.05394569 0.06001728 0.02476875
 0.01951187 0.0127765  0.04063952 0.0600173  0.04512615 0.04602069
 0.0173906  0.01739059 0.01739059 0.04078414 0.040023   0.04063951
 0.01695464 0.04002864]
tr_loss:[0.01266062 0.0364571  0.01344802 0.05270962 0.01344801 0.02785664
 0.02785728 0.0278567  0.01618521 0.02785639 0.02785641 0.03387211
 0.03374698 0.03645711 0.0386156  0.013448   0.02785642 0.0583645
 0.0339848  0.02040701 0.01344902 0.03398482 0.05057137 0.05272415
 0.01344802 0.022862   0.02785636 0.03398483 0.03985167 0.03298468
 0.02360287 0.03139869 0.02479387 0.03645718 0.01344801 0.03398686
 0.01266063 0.01344801 0.0339848  0.03645716 0.01266063 0.01266063
 0.03644545 0.03645714 0.05270935 0.05836456 0.05218659 0.01266061
 0.0386171  0.02675606]
tr_loss:[0.01272901 0.012729   0.03399394 0.03117514 0.04569995 0.01272891
 0.03398704 0.03399397 0.03460845 0.00891862 0.03290663 0.03254774
 0.03460807 0.00891869 0.0341496  0.03117374 0.03460821 0.01617009
 0.01379619 0.01272901 0.03117367 0.02278388 0.02838169 0.00891778
 0.03399407 0.03117365 0.04561129 0.03399396 0.0339939  0.01675493
 0.05617582 0.03399394 0.03399395 0.00891869 0.03117367 0.00891869
 0.02738462 0.03117367 0.01272899 0.02838172 0.00891869 0.03399391
 0.05617589 0.00891869 0.04563234 0.04561125 0.03199411 0.03399394
 0.05617585 0.05617583]
tr_loss:[0.03518154 0.03376821 0.0128369  0.02569534 0.03145138 0.03886025
 0.02569542 0.02988159 0.02042352 0.02384079 0.03376822 0.00866892
 0.03376817 0.05249434 0.00866892 0.0338471  0.00866893 0.03083539
 0.00866892 0.0315302  0.01283693 0.0315302  0.01283686 0.00866891
 0.02040441 0.05249432 0.01283688 0.05249431 0.0337682  0.03153016
 0.0601779  0.0128369  0.05249432 0.0524943  0.0128369  0.00866892
 0.03396828 0.01283688 0.0395545  0.03153019 0.01283688 0.02569532
 0.05249434 0.02569535 0.03377693 0.01876798 0.03127053 0.01283689
 0.05249436 0.03153015]
tr_loss:[0.0359328  0.02950333 0.01040129 0.03425642 0.03591803 0.01953494
 0.02920881 0.01040131 0.04909161 0.03167043 0.01040129 0.02950334
 0.03425648 0.01040129 0.02950334 0.01433572 0.03425648 0.02952747
 0.02622183 0.03618421 0.0104013  0.01433566 0.03425691 0.03595798
 0.03359286 0.03410804 0.01040129 0.03425663 0.02950338 0.03593275
 0.0341082  0.02950334 0.01040083 0.01433567 0.03410823 0.02927121
 0.01644347 0.0104013  0.02950333 0.03425645 0.02873378 0.01037612
 0.0490916  0.03619159 0.02422911 0.03425712 0.03199589 0.01433751
 0.01973524 0.02622185]
tr_loss:[0.01689311 0.03602584 0.03153339 0.02791797 0.0484248  0.03515916
 0.02791796 0.01135968 0.02791795 0.01689312 0.02791795 0.02815281
 0.01135966 0.0168931  0.02791793 0.0315334  0.02791151 0.01800849
 0.03153339 0.03741307 0.03153338 0.01744168 0.01759576 0.03385654
 0.02791859 0.03152441 0.0315334  0.03153341 0.02791795 0.02194436
 0.02791794 0.02791834 0.03573583 0.03153508 0.01136617 0.03739795
 0.03153342 0.0315334  0.03153341 0.02783464 0.01135967 0.0279184
 0.02791796 0.02251714 0.03571258 0.03446639 0.0225192  0.03153339
 0.02738033 0.0168931 ]
tr_loss:[0.01794293 0.01098385 0.019251   0.02953857 0.01098459 0.05163477
 0.01794294 0.01794306 0.03050256 0.01794294 0.03050258 0.0305026
 0.01098454 0.0295691  0.03787382 0.02956909 0.01924704 0.01794293
 0.02956908 0.02956905 0.05163484 0.01098455 0.02545331 0.05163482
 0.01794293 0.02956908 0.03050255 0.01098456 0.03050258 0.02545356
 0.0363009  0.02794372 0.01794293 0.01098454 0.0254533  0.01794291
 0.03050258 0.03787467 0.01098455 0.0109795  0.03917199 0.02545327
 0.05163484 0.03974871 0.02956909 0.01098455 0.01794288 0.03136624
 0.02545328 0.01098455]
tr_loss:[0.03192673 0.05109972 0.03052672 0.0198684  0.0198684  0.01986871
 0.03401934 0.03052671 0.05109977 0.03984722 0.03715814 0.01407762
 0.01028085 0.0510998  0.01925572 0.05109981 0.0305267  0.03379012
 0.01986839 0.01028086 0.01411466 0.01028088 0.01407763 0.01028086
 0.01435188 0.01675509 0.01986839 0.05109976 0.03052671 0.01601912
 0.0161671  0.04602785 0.04388195 0.01763126 0.05109977 0.02540922
 0.02642035 0.03396874 0.0198684  0.04325368 0.05109974 0.01986839
 0.04309032 0.01407764 0.03379437 0.01028085 0.0305267  0.0305267
 0.01986839 0.01407764]
tr_loss:[0.02079048 0.00864404 0.04262789 0.01859696 0.03025177 0.03272892
 0.03168667 0.01187703 0.01187745 0.03245298 0.01187697 0.03245301
 0.01859662 0.03723289 0.032453   0.00819962 0.03245302 0.01459002
 0.01187699 0.01187699 0.02394017 0.04079611 0.03724797 0.03387373
 0.03245299 0.04004144 0.01187699 0.01187702 0.01859663 0.00864404
 0.01862678 0.01859662 0.00864404 0.00864404 0.03245302 0.03387355
 0.03728228 0.03244619 0.03015224 0.02653765 0.03387352 0.01352284
 0.01187696 0.01187699 0.01187699 0.01187698 0.03268584 0.03199927
 0.02394014 0.01859664]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2200 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2201, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2201 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2202, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2202 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2203, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2203 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2204, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2204 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2205, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2205 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2206, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2206 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2207, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2207 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2208, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2208 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2209, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2209 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2210, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2210 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2211, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2211 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2212, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2212 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2213, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2213 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2214, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2214 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2215, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2215 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2216, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2216 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2217, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2217 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2218, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2218 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2219, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2219 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2220, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2220 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2221, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2221 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2222, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2222 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2223, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2223 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2224, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2224 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2225, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2225 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2226, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2226 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2227, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2227 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2228, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2228 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2229, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2229 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2230, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2230 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2231, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2231 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2232, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2232 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2233, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2233 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2234, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2234 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2235, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2235 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2236, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2236 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2237, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2237 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2238, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2238 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2239, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2239 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2240, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2240 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2241, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2241 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2242, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2242 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2243, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2243 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2244, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2244 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2245, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2245 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2246, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2246 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2247, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2247 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2248, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2248 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2249, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2249 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2250, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2250 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2251, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2251 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2252, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2252 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2253, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2253 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2254, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2254 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2255, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2255 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2256, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2256 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2257, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2257 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2258, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2258 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2259, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2259 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2260, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2260 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2261, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2261 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2262, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2262 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2263, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2263 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2264, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2264 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2265, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2265 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2266, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2266 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2267, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2267 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2268, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2268 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2269, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2269 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2270, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2270 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2271, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2271 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2272, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2272 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2273, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2273 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2274, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2274 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2275, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2275 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2276, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2276 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2277, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2277 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2278, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2278 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2279, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2279 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2280, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2280 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2281, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2281 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2282, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2282 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2283, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2283 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2284, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2284 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2285, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2285 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2286, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2286 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2287, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2287 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2288, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2288 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2289, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2289 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2290, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2290 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2291, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2291 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2292, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2292 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2293, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2293 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2294, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2294 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2295, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2295 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2296, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2296 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2297, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2297 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2298, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2298 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2299, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2299 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2300, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2200
text_input.shape
(2300, 14400)
learning_input_tmp.shape
(2300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2300, 80)
learning_output.shape
(750, 80)
Model: "sequential_47"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_47 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.0985632  1.024319   1.024979   0.9866785  1.0502192  1.104893
 0.9866785  1.024979   1.0981567  1.034961   1.1000187  1.0188866
 0.9759428  0.9963417  0.9866785  1.0977254  1.0960577  1.1297334
 1.0977253  1.0243343  0.9860708  1.1021228  1.0977254  1.0977252
 1.0977252  0.9866785  0.97599775 1.0218346  1.100014   1.0249789
 1.1297334  1.1311896  1.0292488  0.97613585 1.0977253  0.9963415
 1.1021196  1.0277977  1.024979   0.9963415  0.9866786  1.0249785
 1.0977253  0.9963415  1.024979   0.9866794  1.1297334  1.0977253
 0.9866785  1.1297415 ]
tr_loss:[0.71885526 0.7188553  0.72507733 0.6453127  0.69071186 0.6482797
 0.6453127  0.7188554  0.7024991  0.72143304 0.71885616 0.71625787
 0.7188554  0.721433   0.5990671  0.5990671  0.6308726  0.5990671
 0.72143304 0.6482797  0.60676813 0.6059183  0.7250775  0.59906703
 0.6799308  0.7188554  0.5990671  0.65013975 0.6499097  0.6453126
 0.65014046 0.7216873  0.6308726  0.71885526 0.7216877  0.7186491
 0.6453128  0.68581724 0.7250774  0.72143304 0.6453127  0.72507733
 0.72507733 0.6308726  0.68252337 0.72507733 0.7105125  0.6940931
 0.6308726  0.6308726 ]
tr_loss:[0.36837286 0.34898    0.34898025 0.3765688  0.32881293 0.37979618
 0.34898    0.3682632  0.37656885 0.37028116 0.36828    0.3702811
 0.33622232 0.358992   0.3288129  0.33622238 0.3888959  0.37656885
 0.36827934 0.36842424 0.3702812  0.36828002 0.37027162 0.33983853
 0.35294914 0.35276312 0.34897995 0.36554104 0.3731616  0.38845092
 0.37028113 0.33622232 0.33622226 0.3702811  0.33622226 0.34937745
 0.37028116 0.37176067 0.33983856 0.3288129  0.3884569  0.37656888
 0.33622226 0.37656885 0.37656885 0.37028116 0.32881293 0.34898
 0.3702801  0.37039623]
tr_loss:[0.19154677 0.18458252 0.19818468 0.18458252 0.19553056 0.18329939
 0.19553055 0.18581295 0.20731108 0.19553056 0.18458244 0.18329886
 0.18584785 0.1858464  0.18329944 0.19147494 0.1955305  0.20163497
 0.19147368 0.18282174 0.19553053 0.1914737  0.1832994  0.18415019
 0.18458256 0.18415014 0.16718218 0.18458247 0.18261282 0.19553055
 0.18328051 0.21566825 0.18567319 0.19147365 0.1845825  0.18970123
 0.19552547 0.20117316 0.19676016 0.16718212 0.19147366 0.16718215
 0.19140232 0.19147363 0.19553052 0.1845825  0.17389782 0.19147366
 0.19149998 0.19147368]
tr_loss:[0.1249724  0.1243827  0.12500778 0.12442496 0.10940588 0.12193505
 0.11935784 0.14534137 0.14143325 0.15963688 0.1217391  0.12193497
 0.12173904 0.12442498 0.1188661  0.15955353 0.15115127 0.14939936
 0.12442505 0.12442507 0.14939925 0.11937793 0.12442498 0.12442501
 0.12193502 0.13056464 0.12193499 0.11580052 0.12188102 0.12203805
 0.11926715 0.14939933 0.12476422 0.14534137 0.12497187 0.14534052
 0.14939927 0.12497183 0.14939931 0.11935788 0.11824801 0.12497195
 0.12442503 0.11915988 0.14939933 0.12193503 0.14479561 0.12193503
 0.14939931 0.14939933]
tr_loss:[0.14346382 0.09730049 0.14346384 0.13571501 0.12755576 0.10671882
 0.10671888 0.12816703 0.11557625 0.11557628 0.12755582 0.09730051
 0.09730051 0.14346379 0.11557627 0.1405848  0.12755576 0.14346382
 0.11559763 0.1275558  0.14346392 0.11023508 0.12755601 0.10277939
 0.12127473 0.1184083  0.14300017 0.09729968 0.09730061 0.10671885
 0.14346388 0.12564549 0.1384809  0.14346386 0.13848084 0.11557621
 0.14028218 0.1418469  0.12755577 0.14346388 0.13889368 0.1275558
 0.1315516  0.11840566 0.12816744 0.14346385 0.13848083 0.13848086
 0.11557677 0.12761016]
tr_loss:[0.10480028 0.10025018 0.10025017 0.13631517 0.10819729 0.13185069
 0.09163246 0.12684663 0.09208757 0.11025433 0.11026426 0.10857622
 0.09163247 0.10935657 0.11025415 0.11025455 0.10025016 0.09518413
 0.11025405 0.12514618 0.11025511 0.13185072 0.11025405 0.1093566
 0.10935657 0.10975899 0.12684669 0.13185069 0.11026667 0.10935684
 0.10025015 0.12676804 0.09163271 0.10935658 0.1093566  0.12323041
 0.12684667 0.10955755 0.13138342 0.10935657 0.12686224 0.11692983
 0.11025409 0.12684664 0.10025017 0.1002502  0.12668352 0.09527723
 0.12684663 0.10024711]
tr_loss:[0.09891252 0.09727687 0.09574205 0.12461676 0.10028215 0.10900776
 0.09727689 0.13861097 0.10918756 0.09891274 0.10028219 0.12033176
 0.13861069 0.10028221 0.12461431 0.09998681 0.12461679 0.11937517
 0.1047251  0.10028221 0.12172113 0.10028219 0.09727611 0.09891276
 0.11106733 0.10920905 0.10028219 0.09891274 0.12959251 0.10028219
 0.09891268 0.12461674 0.10028218 0.12959252 0.11495527 0.12196296
 0.0989127  0.11226972 0.0987366  0.09891269 0.11363792 0.12461676
 0.14267814 0.09891276 0.11382409 0.10918589 0.14268634 0.09909068
 0.11936507 0.09888435]
tr_loss:[0.13611738 0.1330243  0.09678221 0.10899095 0.09957786 0.09710477
 0.09957788 0.09957785 0.13591929 0.09710481 0.09678219 0.1024956
 0.09710481 0.10527618 0.1320638  0.1252715  0.12527199 0.09727255
 0.09957724 0.08930965 0.13591924 0.09710477 0.13591932 0.10326171
 0.09710483 0.11551835 0.09958588 0.13591924 0.09957788 0.12529516
 0.13073282 0.10905641 0.13591921 0.12215643 0.09710482 0.09670107
 0.0925913  0.09957787 0.1359192  0.1221564  0.13591924 0.11504755
 0.09957783 0.1330181  0.12161019 0.13591924 0.13591981 0.10478638
 0.09952414 0.09984045]
tr_loss:[0.13038859 0.08670413 0.10689136 0.08915351 0.09608292 0.1164449
 0.11644223 0.08670411 0.13381994 0.13038614 0.08670411 0.11644437
 0.08910502 0.11630861 0.08911337 0.13038614 0.08910506 0.13038674
 0.11491034 0.12718931 0.08670044 0.082289   0.13038611 0.1303861
 0.0860639  0.12718934 0.08670414 0.13488898 0.08215149 0.08670413
 0.12718931 0.08910505 0.0861334  0.11556598 0.08910507 0.08225673
 0.09604551 0.12718934 0.1379431  0.11716847 0.10867651 0.08670412
 0.10021609 0.1164422  0.11556618 0.11643921 0.13038614 0.08660583
 0.11644222 0.09982357]
tr_loss:[0.0960194  0.09628947 0.11200748 0.06507195 0.11201419 0.11200871
 0.10422721 0.11600387 0.06928296 0.11361395 0.11009119 0.0667119
 0.11600395 0.06671191 0.0667119  0.06988198 0.06988195 0.11948372
 0.06669439 0.07400037 0.0777451  0.06500492 0.08330075 0.08256639
 0.0740004  0.1042272  0.06671166 0.0938734  0.09453833 0.1120075
 0.11158906 0.06988199 0.06988198 0.11200752 0.07903147 0.07400037
 0.10422723 0.10422717 0.09547065 0.1046472  0.10422716 0.0667119
 0.08163252 0.08208753 0.11600395 0.0762433  0.08331136 0.0667119
 0.1055949  0.0667119 ]
tr_loss:[0.07447387 0.11555073 0.07447384 0.07104781 0.10881911 0.08263469
 0.06888561 0.10881969 0.10471362 0.1155507  0.09902986 0.07104807
 0.06888559 0.10582881 0.10872994 0.08565611 0.10882249 0.10404666
 0.10881945 0.10404661 0.06962295 0.06962116 0.06888557 0.07447384
 0.06888561 0.10471383 0.10405731 0.10736418 0.10736319 0.10404672
 0.06888559 0.11555071 0.06889068 0.0856863  0.10882194 0.07104781
 0.07104783 0.10404667 0.11795671 0.10471387 0.10471386 0.10404666
 0.12045777 0.0710478  0.10404661 0.1006531  0.10407285 0.06888577
 0.0710478  0.10363362]
tr_loss:[0.0741298  0.11060991 0.09418385 0.13007721 0.1206347  0.08610917
 0.10183325 0.12063469 0.07686059 0.07412978 0.0741298  0.10571864
 0.07129365 0.11597478 0.07686058 0.07412979 0.1104116  0.07686047
 0.07412978 0.07686061 0.10572354 0.12063465 0.11060991 0.12070961
 0.07686058 0.07412918 0.11065123 0.1161163  0.11612113 0.11060989
 0.10620272 0.11060989 0.11618779 0.1206347  0.07130241 0.10183326
 0.10183327 0.10183332 0.11071311 0.12063469 0.07130238 0.0713024
 0.07129076 0.07161574 0.10621583 0.12063462 0.10183325 0.12603779
 0.07412979 0.07077803]
tr_loss:[0.11660714 0.10517043 0.07027131 0.11900122 0.09937658 0.0993707
 0.11712383 0.07289116 0.07289117 0.11880346 0.07407192 0.11038957
 0.09937046 0.11038957 0.11038952 0.07289127 0.11900129 0.10518012
 0.11609398 0.07289116 0.11709323 0.09945481 0.07407194 0.12377927
 0.07289116 0.11038957 0.07027132 0.09937047 0.09937049 0.08580967
 0.0740719  0.11038955 0.07407192 0.11022539 0.11038959 0.09938039
 0.07027201 0.07289118 0.11038959 0.1177872  0.0702713  0.11038957
 0.072888   0.11035148 0.11037705 0.07289116 0.12111552 0.07289116
 0.0699598  0.07404526]
tr_loss:[0.10519526 0.06797525 0.0679753  0.09146669 0.06797527 0.06614938
 0.06614783 0.11014271 0.0679753  0.06797531 0.11014833 0.10519526
 0.06614785 0.10519524 0.11385052 0.10519524 0.10519522 0.09550513
 0.06797528 0.09070265 0.06808314 0.09732051 0.11264078 0.06808312
 0.06614784 0.11256333 0.06589381 0.10405822 0.10020532 0.10519521
 0.06809781 0.06614785 0.11264884 0.10005877 0.11385065 0.06527434
 0.11264889 0.06797528 0.11385061 0.08816786 0.11264832 0.08301667
 0.08153637 0.11428164 0.06808312 0.11385063 0.11385059 0.10707381
 0.09146775 0.09732064]
tr_loss:[0.06701712 0.11156503 0.10476871 0.0987408  0.06513837 0.08485145
 0.06496381 0.11077575 0.06753244 0.1026607  0.08133833 0.08220553
 0.10054392 0.09401376 0.11172342 0.08508293 0.06660666 0.09247415
 0.06703301 0.10054089 0.0953003  0.10266117 0.11164572 0.1026607
 0.06753667 0.10266062 0.10056464 0.06742473 0.11135157 0.06753667
 0.11154573 0.10055415 0.1115467  0.06753705 0.06753246 0.10253044
 0.06703299 0.1005409  0.11157238 0.06753254 0.11172339 0.10266068
 0.1026607  0.06753669 0.10266068 0.09830327 0.06753244 0.10054088
 0.10054085 0.06753664]
tr_loss:[0.10542661 0.0710085  0.07058272 0.11501431 0.10542335 0.06962832
 0.10407813 0.10999296 0.07182296 0.1098047  0.07058265 0.12108879
 0.11416034 0.0710085  0.07058269 0.07182295 0.07058273 0.10542266
 0.10542266 0.10817508 0.10407816 0.0710085  0.07058273 0.09004898
 0.10762589 0.07100856 0.100947   0.11213428 0.07182298 0.10171871
 0.07100851 0.07182296 0.07182296 0.11501429 0.10407815 0.0710085
 0.11206267 0.07182069 0.10407815 0.07058273 0.0713729  0.10807562
 0.07182296 0.10407813 0.07058273 0.11501434 0.10762528 0.0710085
 0.0710085  0.1054227 ]
tr_loss:[0.11316238 0.06869198 0.06869645 0.06585883 0.11126886 0.0848393
 0.06869201 0.08060075 0.06585866 0.10797089 0.08995239 0.06585868
 0.1131624  0.10190575 0.06693224 0.06693225 0.10270441 0.09920706
 0.09913792 0.1019058  0.10190573 0.06856845 0.10598668 0.11316241
 0.10061636 0.06693223 0.06693222 0.10188695 0.1131624  0.10704686
 0.11718373 0.10643367 0.08257675 0.06585864 0.06585865 0.06585865
 0.06693224 0.06585868 0.06693225 0.10934275 0.06693223 0.10135795
 0.09668474 0.11038838 0.0675614  0.11316244 0.10061636 0.06693224
 0.06585866 0.06693222]
tr_loss:[0.10935185 0.06213115 0.06068412 0.09639602 0.06558375 0.0606841
 0.09726945 0.10823409 0.1093518  0.06222767 0.06226718 0.09641393
 0.06213114 0.09726946 0.06068411 0.10958146 0.10571142 0.06220959
 0.0606841  0.10935177 0.09726946 0.06429617 0.09724177 0.11703773
 0.06068411 0.096396   0.0621318  0.09727036 0.09034657 0.06068413
 0.10519161 0.09726944 0.09693936 0.06213113 0.10935183 0.06068411
 0.09726946 0.06213113 0.06213114 0.10523178 0.0958752  0.10824124
 0.0606841  0.09378231 0.07762981 0.06068408 0.09726946 0.10524891
 0.06213113 0.07684074]
tr_loss:[0.11018518 0.07728024 0.06572215 0.1197937  0.09561558 0.06572216
 0.09853556 0.0955605  0.11115648 0.09853552 0.06576012 0.09853552
 0.09853556 0.06127069 0.06450777 0.09853552 0.0614155  0.0614155
 0.09556058 0.09556041 0.10617361 0.11018515 0.06345171 0.06573218
 0.06450776 0.06572215 0.09853557 0.06572226 0.06450778 0.09853552
 0.09272198 0.06450778 0.09556041 0.11652897 0.10501932 0.09556039
 0.06345786 0.06141552 0.09853555 0.11115644 0.11130679 0.06450778
 0.10617308 0.09556238 0.09556048 0.11652873 0.09611175 0.06450777
 0.11114129 0.11018515]
tr_loss:[0.09941792 0.06349734 0.09520303 0.06349355 0.06349733 0.11109104
 0.08514535 0.09940584 0.0674337  0.0820459  0.10014139 0.06349733
 0.111091   0.06743319 0.06858154 0.09941785 0.06743316 0.06858156
 0.10148595 0.06743316 0.09520297 0.12112814 0.06743316 0.09520297
 0.11031044 0.06349733 0.11753614 0.11844443 0.09520294 0.06349733
 0.09941792 0.06349733 0.111091   0.08206453 0.11315882 0.12101866
 0.08517446 0.09520297 0.06349732 0.09883571 0.06349733 0.09520324
 0.06858154 0.06858154 0.09941768 0.06349734 0.09941795 0.09941796
 0.06707636 0.10627999]
tr_loss:[0.09794772 0.06464365 0.0701228  0.07012282 0.07012282 0.06737958
 0.06464422 0.09442904 0.10527961 0.0701228  0.06737969 0.09997281
 0.09051629 0.09641201 0.06464425 0.06630366 0.09863086 0.09794772
 0.06737971 0.09442908 0.11059397 0.09446099 0.10512239 0.09442912
 0.08842327 0.10719682 0.09794767 0.09442911 0.06464422 0.09442911
 0.0944291  0.06737743 0.06464413 0.06736548 0.06511974 0.06464423
 0.06464423 0.0701228  0.10467    0.09443395 0.1151847  0.09863097
 0.09443275 0.09431745 0.07012349 0.10467466 0.06464422 0.07012279
 0.09443019 0.06737968]
tr_loss:[0.09453493 0.08880724 0.1117409  0.06594879 0.09747683 0.08450665
 0.11420262 0.08536922 0.109496   0.07070951 0.06835361 0.10946115
 0.09453672 0.0659488  0.09747682 0.11311861 0.0659488  0.08884124
 0.10949604 0.1094961  0.09655509 0.09453491 0.07075448 0.08521347
 0.09747683 0.10310812 0.07051155 0.10949601 0.06770913 0.09593163
 0.09808751 0.06769896 0.06771079 0.09595279 0.09453485 0.11132821
 0.06594881 0.08603336 0.07075448 0.11141481 0.10949607 0.09453492
 0.09453495 0.09747677 0.10308582 0.06770912 0.09873568 0.10184579
 0.10305814 0.11616911]
tr_loss:[0.06414612 0.10874226 0.06739648 0.06414611 0.09550103 0.06414611
 0.09660792 0.06739648 0.08123495 0.11247082 0.10629785 0.06414612
 0.08777197 0.06739645 0.10594229 0.10874214 0.10205023 0.06581557
 0.10874259 0.0936015  0.06739648 0.09353384 0.06739646 0.09550102
 0.06739645 0.08111279 0.10875855 0.09922273 0.06739648 0.06739645
 0.11534886 0.06585442 0.09550105 0.09550102 0.10165693 0.09550102
 0.0793299  0.10221335 0.0936015  0.09550107 0.0801664  0.0657846
 0.09550099 0.09550103 0.095501   0.09550101 0.09360152 0.10629795
 0.10629785 0.06739648]
tr_loss:[0.10476051 0.1056591  0.10580909 0.06230981 0.09484942 0.07718506
 0.06321244 0.09004396 0.10509672 0.09433503 0.06335593 0.10509691
 0.09473088 0.06230981 0.06230979 0.09484947 0.09484948 0.06335591
 0.06335593 0.10408171 0.06463653 0.09484948 0.10408173 0.10622585
 0.09016407 0.10765073 0.10509677 0.06427638 0.0623098  0.06335593
 0.10408165 0.10408171 0.06335663 0.06222336 0.06335554 0.10873023
 0.10581094 0.10583428 0.10581088 0.06463654 0.0623098  0.1058109
 0.09434012 0.10043319 0.06463652 0.11483703 0.07655381 0.06463656
 0.10580646 0.06196499]
tr_loss:[0.07868741 0.06279131 0.06234849 0.10831241 0.07698201 0.11512295
 0.06234847 0.06234847 0.06271322 0.06234839 0.09728847 0.10549517
 0.06279133 0.06234848 0.06268106 0.06273428 0.06279131 0.06279132
 0.10512497 0.1083082  0.10830866 0.09643669 0.09653998 0.07865367
 0.10831008 0.06278523 0.06234849 0.06518334 0.0965318  0.09654
 0.06518336 0.062713   0.0627913  0.09728846 0.09654067 0.09652482
 0.10808065 0.06279131 0.10417445 0.09728839 0.06279133 0.09728843
 0.10208808 0.10417451 0.09728934 0.10829381 0.0627913  0.09653791
 0.09728874 0.06279133]
tr_loss:[0.07859621 0.07973523 0.06251057 0.07737982 0.09693352 0.06250676
 0.0920313  0.06438685 0.06244655 0.09655174 0.10615636 0.06244654
 0.09725268 0.10545605 0.09693352 0.09732816 0.10014307 0.06251059
 0.09728694 0.06251057 0.06251056 0.10451935 0.10451931 0.06251059
 0.0972525  0.06244652 0.06251059 0.06251052 0.09725274 0.06438684
 0.09162019 0.0969335  0.10764624 0.09693352 0.10451939 0.06438684
 0.0798919  0.06251057 0.06246081 0.09693347 0.11175753 0.09309687
 0.10451929 0.06438674 0.09725253 0.09693351 0.06248704 0.09693368
 0.10437484 0.06247882]
tr_loss:[0.10607624 0.10429503 0.0952826  0.08005193 0.09403849 0.06222825
 0.0636058  0.09528259 0.06281613 0.06351493 0.09528255 0.0636058
 0.09641727 0.06222824 0.09535456 0.06360582 0.10429502 0.09641729
 0.09641864 0.09528255 0.1006366  0.09528257 0.06360071 0.06351493
 0.09077586 0.09528255 0.06351496 0.10512695 0.09528255 0.0636058
 0.09641735 0.09641729 0.11328049 0.09528254 0.10607598 0.09641727
 0.09528258 0.06222884 0.07974785 0.09528256 0.09528254 0.10429494
 0.06222825 0.06360581 0.06351493 0.09581061 0.09641729 0.09596804
 0.09641729 0.09616866]
tr_loss:[0.09951045 0.0652423  0.06281634 0.06524248 0.09568264 0.09206833
 0.0652426  0.08395757 0.08045996 0.08395782 0.09568258 0.09206828
 0.10764803 0.09568264 0.06524251 0.06524251 0.09208298 0.08944219
 0.06281634 0.10318663 0.06281634 0.10842943 0.07069972 0.10760057
 0.09568256 0.10312982 0.10254753 0.08096845 0.09488855 0.09206827
 0.08955511 0.1031298  0.09567013 0.06281631 0.10312978 0.06369013
 0.06281634 0.0628145  0.10312982 0.06369024 0.09721233 0.09206827
 0.09568261 0.09568264 0.10254301 0.10312978 0.06355659 0.06281633
 0.10312976 0.10312977]
tr_loss:[0.08935345 0.10078681 0.06519928 0.08935315 0.0942631  0.0638337
 0.08936316 0.08323723 0.06271634 0.0893531  0.10058369 0.0942631
 0.06375717 0.10058359 0.08003451 0.09564331 0.08324157 0.06519932
 0.08935311 0.0637571  0.08935314 0.08935308 0.08935311 0.06383368
 0.0930265  0.06383345 0.06271635 0.06271634 0.1079973  0.10053885
 0.06271634 0.06271635 0.10427113 0.06271634 0.06476329 0.10145193
 0.06502579 0.08935308 0.09563891 0.0651993  0.06383367 0.06205687
 0.07757902 0.08853073 0.1094357  0.11557259 0.09426306 0.09244167
 0.06519932 0.06371395]
text_input.shape
(2300, 14400)
learning_input_tmp.shape
(2300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2300, 80)
learning_output.shape
(750, 80)
Model: "sequential_48"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_48 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.337626  1.3641384 1.2701437 1.3125669 1.2636745 1.3486834 1.3486836
 1.3392904 1.3886602 1.3489475 1.3489667 1.2636745 1.3029646 1.312868
 1.3486834 1.3372554 1.3125769 1.243165  1.2701439 1.3629963 1.3139985
 1.2892822 1.243165  1.348967  1.2701439 1.2431649 1.3489671 1.3124533
 1.2701439 1.3487034 1.2555546 1.2636744 1.2701436 1.2892992 1.3124247
 1.2701437 1.2431656 1.2636744 1.38865   1.3376255 1.3486835 1.2636745
 1.243165  1.2701575 1.2636744 1.3573517 1.2431649 1.2701437 1.3486834
 1.3886602]
tr_loss:[0.8479406  0.8479406  0.8155699  0.8479406  0.7853645  0.763944
 0.8155697  0.8049402  0.7739376  0.78747356 0.763944   0.8055803
 0.80166113 0.81340015 0.80090714 0.7455264  0.78367627 0.80355966
 0.7874735  0.8155699  0.77433836 0.84788245 0.80355966 0.84794027
 0.7836842  0.84793967 0.7874735  0.7465253  0.77387697 0.8155699
 0.7639439  0.82145584 0.8479408  0.7836762  0.8013304  0.81378
 0.8155697  0.78367627 0.74333274 0.76394385 0.78369033 0.8155699
 0.7785716  0.8051753  0.78123343 0.78747344 0.7874734  0.8036558
 0.7874733  0.84794027]
tr_loss:[0.374576   0.3803179  0.37457585 0.37887317 0.41962582 0.40932336
 0.3745758  0.41962585 0.41962585 0.37457585 0.39240065 0.3953129
 0.37457585 0.40628403 0.3745758  0.41962585 0.3745758  0.38002557
 0.39531294 0.3971755  0.37459105 0.3780493  0.3800171  0.3843991
 0.40628415 0.39668068 0.37457588 0.40628394 0.38002545 0.37940213
 0.37343603 0.39531302 0.39613277 0.40601555 0.41962576 0.3745798
 0.38440302 0.38002554 0.3800256  0.37828755 0.40628394 0.370849
 0.3745758  0.38439927 0.38002557 0.37457612 0.37914678 0.3800251
 0.41962585 0.37457585]
tr_loss:[0.2204422  0.18774593 0.20363355 0.20999579 0.21954532 0.20908904
 0.22146359 0.20737016 0.2081923  0.18830726 0.22043614 0.22043607
 0.22043641 0.18828651 0.21807651 0.19971025 0.18774594 0.21776518
 0.220436   0.21810004 0.1877449  0.220436   0.21810365 0.18742156
 0.22043605 0.220436   0.1911541  0.19109407 0.21776517 0.19003698
 0.2036335  0.18830721 0.18774597 0.22043607 0.20806146 0.1883077
 0.18869479 0.22923584 0.19109407 0.20363355 0.22554965 0.21907954
 0.22795832 0.2204442  0.21807027 0.20936677 0.22043595 0.19109404
 0.21809976 0.18802692]
tr_loss:[0.10796411 0.10975216 0.10796414 0.10976943 0.14889753 0.12135228
 0.14281276 0.13346298 0.133463   0.11456776 0.11452241 0.13479999
 0.1399782  0.10796414 0.10985913 0.14281268 0.14381054 0.10975363
 0.1097521  0.10796411 0.14381054 0.13343397 0.14271507 0.10975213
 0.13204023 0.13346295 0.10796411 0.13820866 0.11452246 0.13636944
 0.14381056 0.10796414 0.14381048 0.11036064 0.14070779 0.10975213
 0.14381073 0.11451833 0.13820826 0.10975218 0.10796416 0.133463
 0.1380312  0.10797081 0.13299471 0.10796412 0.14381059 0.10975216
 0.13338833 0.11452241]
tr_loss:[0.07114035 0.09737386 0.06046532 0.06447181 0.0604653  0.11888988
 0.09646957 0.1060429  0.06447179 0.09906821 0.09220169 0.11157898
 0.10018685 0.09894936 0.06046535 0.06046531 0.07119785 0.06046592
 0.09737393 0.09646961 0.09646954 0.09220213 0.06046529 0.09906812
 0.06454537 0.09646962 0.06046532 0.09646963 0.11495264 0.09906815
 0.09906973 0.06807569 0.09906814 0.09737392 0.06447174 0.07977426
 0.06046534 0.06447182 0.06447178 0.09906813 0.06046533 0.12244842
 0.06447177 0.11495557 0.11495256 0.09906816 0.09084791 0.06549628
 0.11894278 0.09646962]
tr_loss:[0.05827355 0.0834941  0.08349402 0.05829092 0.09941354 0.09005606
 0.10427497 0.10226576 0.11202963 0.10707135 0.11375856 0.09410325
 0.06022807 0.08507927 0.05829101 0.05121321 0.05829101 0.0834941
 0.08960577 0.09005602 0.06312905 0.08980386 0.058291   0.05121323
 0.07414404 0.09402058 0.08964831 0.09707163 0.06312902 0.06734987
 0.09005602 0.05944834 0.06312904 0.06312903 0.10705984 0.05121321
 0.06312899 0.05121319 0.06799829 0.05829099 0.06312633 0.09005602
 0.11203063 0.08960421 0.11378813 0.05829096 0.05121322 0.07414426
 0.05829098 0.08349409]
tr_loss:[0.05874455 0.06127463 0.109349   0.08110582 0.08110578 0.08904885
 0.05874456 0.09189478 0.05874455 0.06578531 0.05023708 0.08904884
 0.05023708 0.08904871 0.09189482 0.08904886 0.10975198 0.06571026
 0.05023707 0.09189481 0.08904886 0.08904888 0.05023709 0.06532491
 0.06578499 0.06578499 0.07203222 0.05874454 0.07098104 0.11257263
 0.06578503 0.08904881 0.08904882 0.05874454 0.09339152 0.08904889
 0.0502371  0.11243246 0.09511718 0.09189481 0.09388672 0.05023708
 0.09189482 0.09781313 0.09098041 0.05023707 0.06579158 0.06578483
 0.08904882 0.08110581]
tr_loss:[0.08510275 0.05702987 0.08924692 0.09104774 0.09170998 0.11060061
 0.0474195  0.05954971 0.10948334 0.11081269 0.06391493 0.09104766
 0.09104772 0.09104768 0.07018515 0.08924806 0.11083771 0.08924801
 0.11081229 0.08924807 0.05702989 0.08924802 0.05702989 0.08292069
 0.06392085 0.09786367 0.11070605 0.05702991 0.0603356  0.05702988
 0.07130597 0.05702827 0.09104766 0.05702989 0.05702989 0.09105428
 0.05778756 0.06033561 0.08292065 0.06819706 0.08914006 0.09104766
 0.10981166 0.09106831 0.04741949 0.08924802 0.09122702 0.1105878
 0.06033583 0.0684761 ]
tr_loss:[0.05322821 0.0835392  0.09127928 0.09127922 0.05782367 0.05568509
 0.05727509 0.0912792  0.0578237  0.06702491 0.08353792 0.09127921
 0.1148301  0.0835374  0.04447515 0.06630335 0.10519058 0.0444697
 0.10580766 0.05782367 0.04447513 0.08473644 0.06715681 0.04447513
 0.08388402 0.09127927 0.08693288 0.04447514 0.05322821 0.10579934
 0.05568048 0.05322821 0.04447514 0.0578237  0.08475111 0.11457257
 0.06942071 0.0532282  0.05782369 0.04447513 0.04447504 0.08693283
 0.04447513 0.09127922 0.05782353 0.1051896  0.05782372 0.05782371
 0.08353741 0.05322818]
tr_loss:[0.08629699 0.10498969 0.09046421 0.08860911 0.03947698 0.0886092
 0.08629701 0.0738352  0.09046622 0.07258252 0.0886067  0.04744181
 0.04090983 0.08860916 0.07645088 0.11087456 0.03947698 0.07383519
 0.08860377 0.08629702 0.0886091  0.05969177 0.11078864 0.08325068
 0.08629697 0.1049891  0.04744181 0.1105409  0.08629694 0.04744052
 0.06448273 0.04744179 0.03947479 0.04744181 0.065064   0.11087477
 0.09046404 0.08860914 0.04842469 0.03947699 0.08860914 0.03947698
 0.07384305 0.03947631 0.07645011 0.07383521 0.04744184 0.08629704
 0.09169429 0.06458803]
tr_loss:[0.07664187 0.03254599 0.0880447  0.04320908 0.03888472 0.03548916
 0.05344527 0.0649202  0.07523625 0.07523631 0.03590881 0.03590847
 0.06890716 0.06492017 0.03254599 0.06136908 0.03255863 0.08809806
 0.07523628 0.03254608 0.03888474 0.03590843 0.06492032 0.04097754
 0.06500398 0.03255217 0.03254598 0.07664193 0.08506542 0.07523626
 0.05344275 0.07523625 0.08804448 0.07523622 0.03888473 0.03888474
 0.03254599 0.06492019 0.0752363  0.03254653 0.0388848  0.03254601
 0.03590844 0.03888474 0.03590844 0.07523625 0.03327324 0.03254602
 0.03888473 0.03888477]
tr_loss:[0.05495555 0.05296328 0.03808752 0.04067488 0.05644839 0.05644841
 0.056449   0.05369266 0.0523249  0.08001156 0.05357236 0.02611412
 0.02612813 0.02496949 0.04065703 0.06703722 0.03974047 0.08001153
 0.06904356 0.02496947 0.02496945 0.02496946 0.02496998 0.05375307
 0.06800411 0.02953728 0.02496948 0.06271134 0.02496947 0.06944476
 0.05644835 0.06800412 0.04067484 0.0261141  0.0261141  0.02325808
 0.02518354 0.0261141  0.04158128 0.02325812 0.0261141  0.03806569
 0.05243651 0.02496947 0.0261141  0.06800441 0.0294396  0.02326919
 0.02496948 0.05645049]
tr_loss:[0.02891739 0.01927944 0.01927945 0.08851007 0.08851005 0.05365799
 0.07145365 0.06579878 0.04518216 0.01927946 0.05364063 0.04456378
 0.05538402 0.01990398 0.01990397 0.07145368 0.05365715 0.08851002
 0.06231599 0.02891738 0.07145365 0.05680881 0.01927947 0.0204749
 0.07108384 0.06090014 0.05718076 0.05282447 0.0291658  0.05366994
 0.02782382 0.06563729 0.01927947 0.05364063 0.05364152 0.0714566
 0.04397099 0.0536406  0.05680759 0.05681599 0.06563512 0.04838989
 0.04458637 0.02511805 0.05804136 0.06563396 0.02047508 0.04458189
 0.01927944 0.01927945]
tr_loss:[0.01967812 0.05014875 0.02408941 0.01966377 0.05735143 0.04382504
 0.06373788 0.07254802 0.0240899  0.0321842  0.03022169 0.04478271
 0.06015746 0.06517772 0.07254805 0.08795325 0.05014876 0.04291521
 0.01734759 0.06197342 0.0321842  0.06197463 0.08795319 0.07255028
 0.03024404 0.05014875 0.03218424 0.07254805 0.05014879 0.07254799
 0.05494139 0.05811159 0.0173476  0.03218421 0.07254802 0.07254803
 0.05018874 0.03218421 0.05964522 0.08795318 0.01740305 0.01734758
 0.07254807 0.07255515 0.05015218 0.01964803 0.07254805 0.0651664
 0.05014876 0.07242127]
tr_loss:[0.0547929  0.08380233 0.05807439 0.08380232 0.0700737  0.05859661
 0.05929326 0.0344049  0.05811451 0.02247503 0.06086827 0.06088175
 0.05464572 0.02247503 0.05464571 0.04766006 0.0515911  0.05492828
 0.03359003 0.02247503 0.02247503 0.05465299 0.07007649 0.07007296
 0.05464571 0.06080789 0.06086523 0.05464591 0.02158167 0.02247501
 0.03440577 0.02247503 0.05492789 0.07007301 0.07007302 0.05807447
 0.03440576 0.0838023  0.05791076 0.03440577 0.03440576 0.02513342
 0.0838024  0.03443892 0.05464647 0.03984907 0.07007302 0.07080881
 0.05859671 0.06086502]
tr_loss:[0.05826208 0.03303435 0.05826206 0.03636032 0.05826204 0.02552913
 0.06558342 0.02553009 0.02538343 0.03303437 0.03304756 0.06558345
 0.03303436 0.07685024 0.04175226 0.03583171 0.06324538 0.06558342
 0.05970999 0.05971093 0.05820491 0.02538341 0.05826204 0.02552911
 0.05826211 0.05826211 0.05930959 0.03303439 0.02552915 0.05826204
 0.03303435 0.0276266  0.03303431 0.05730877 0.07685026 0.06563275
 0.04770958 0.02538342 0.02538343 0.02574716 0.02538344 0.03303436
 0.07685026 0.0582621  0.02538342 0.03314501 0.07685017 0.0503973
 0.07685025 0.05825783]
tr_loss:[0.04398376 0.05201866 0.02652515 0.02256014 0.06345712 0.02445602
 0.0548987  0.07243726 0.02926604 0.02445601 0.02445612 0.0569483
 0.05489876 0.07243724 0.0634571  0.02445602 0.0590031  0.03201354
 0.04808082 0.07243721 0.02256017 0.0309475  0.03212857 0.02256014
 0.06135163 0.05087475 0.04911256 0.02256015 0.06345715 0.02256015
 0.0561345  0.06345715 0.04466744 0.05489875 0.06345895 0.05900265
 0.02926693 0.04218306 0.02445993 0.05489878 0.02926602 0.03753426
 0.02256015 0.05613006 0.06345714 0.02256014 0.04805603 0.05489876
 0.03824455 0.06345715]
tr_loss:[0.01922296 0.04902654 0.02646961 0.06459089 0.04902241 0.01922296
 0.07333127 0.07333127 0.03274994 0.01922297 0.05933688 0.06214897
 0.05933686 0.05966047 0.03574698 0.06459087 0.06459317 0.02178635
 0.0264696  0.03967412 0.02646958 0.02476428 0.04902241 0.05962075
 0.03691217 0.04902238 0.05466865 0.02646962 0.01922297 0.04902489
 0.0546687  0.04902248 0.04368987 0.02786135 0.07333128 0.05768198
 0.01922297 0.01922297 0.05916693 0.03274974 0.06459083 0.04902241
 0.04902242 0.06459372 0.01922296 0.05856832 0.05951633 0.06459089
 0.01922384 0.0264696 ]
tr_loss:[0.06271583 0.06369306 0.06728823 0.0170386  0.06728821 0.06728821
 0.0561635  0.03803409 0.02466188 0.05940384 0.02466192 0.02466192
 0.01918386 0.04363306 0.01703859 0.02632183 0.07745712 0.06514426
 0.04363278 0.06728824 0.01919    0.0170386  0.02801452 0.01919001
 0.04153992 0.06728826 0.0436326  0.02466194 0.05931379 0.01918999
 0.0598804  0.02466192 0.05999903 0.0170386  0.01703858 0.05615736
 0.05925618 0.0774571  0.06728826 0.06658261 0.03685172 0.06271742
 0.01765969 0.06728995 0.02466193 0.04363396 0.02466191 0.02466194
 0.02466192 0.04363261]
tr_loss:[0.01743353 0.0162027  0.07244893 0.07987386 0.07458755 0.03138191
 0.02382762 0.06478162 0.0162027  0.06902973 0.02382759 0.0690297
 0.02382762 0.0238276  0.02527381 0.06902973 0.06902973 0.05915026
 0.06832455 0.0162027  0.02526661 0.02382759 0.02365842 0.01620288
 0.01743353 0.03884691 0.02382761 0.0385402  0.06896929 0.02527359
 0.06892568 0.01631197 0.03791546 0.06902974 0.07987382 0.04115087
 0.04115088 0.07987384 0.02369366 0.04832151 0.04116667 0.06953106
 0.0238276  0.06902971 0.02382759 0.07987384 0.05915032 0.06833883
 0.0238253  0.04115112]
tr_loss:[0.03958446 0.06950703 0.0655644  0.04757143 0.06556316 0.06575862
 0.06576888 0.01412951 0.06576889 0.06631507 0.06505688 0.06576885
 0.01679389 0.07548483 0.06576888 0.01412954 0.06576888 0.06576888
 0.01439833 0.03958448 0.01374436 0.01374752 0.02114427 0.06576888
 0.0137444  0.01374449 0.07548489 0.01374439 0.02114429 0.01439811
 0.01412953 0.01419454 0.06544001 0.0754848  0.04757807 0.02114427
 0.01442038 0.07548489 0.07548485 0.02114426 0.05654152 0.01374437
 0.03429412 0.06632753 0.01412953 0.05671281 0.06552207 0.07548479
 0.05657082 0.02114427]
tr_loss:[0.04232597 0.05194626 0.01404139 0.02886179 0.01461755 0.05517134
 0.07131525 0.0423275  0.06409209 0.01461753 0.04232599 0.02187986
 0.01461753 0.05985327 0.0640921  0.042326   0.04232596 0.02188003
 0.01461753 0.05517129 0.02188005 0.04216676 0.01461754 0.07131527
 0.01461752 0.02188003 0.05181639 0.04485691 0.01415035 0.06409209
 0.05190192 0.01461834 0.04179494 0.0140414  0.04232634 0.01461754
 0.02954085 0.04232596 0.02962383 0.02903897 0.02964586 0.04234197
 0.02188003 0.01461754 0.01465088 0.02188003 0.02942364 0.0140414
 0.02188005 0.07131517]
tr_loss:[0.05367614 0.04933496 0.05284449 0.06443894 0.01426588 0.01426586
 0.04378948 0.01426588 0.01498785 0.04378954 0.02995536 0.01471545
 0.05367725 0.01473414 0.01498788 0.02418168 0.02463705 0.05758131
 0.05920591 0.02710203 0.0405549  0.07022268 0.06443898 0.0702227
 0.07022264 0.01426586 0.01424091 0.01424848 0.06443895 0.04748764
 0.06443898 0.02463702 0.01498786 0.05506639 0.04188835 0.02607914
 0.04379068 0.01498785 0.06443895 0.01855203 0.05506705 0.04380628
 0.01426587 0.07022269 0.07022269 0.07022265 0.02463703 0.02989395
 0.01498784 0.01426587]
tr_loss:[0.02379256 0.01736797 0.0612926  0.04202304 0.02400036 0.01308396
 0.04463039 0.05883886 0.04202304 0.02401533 0.04202307 0.04552672
 0.02401535 0.0515887  0.02401533 0.05113691 0.01737518 0.06128749
 0.01199283 0.04202302 0.04202409 0.01308397 0.04202303 0.06128749
 0.04202306 0.03195222 0.06128748 0.01199284 0.05113626 0.01308396
 0.02596658 0.01199282 0.02401534 0.05113897 0.01308396 0.01308397
 0.04911488 0.04202324 0.01198321 0.01308398 0.04202305 0.01308397
 0.04203688 0.05185169 0.01308398 0.01308396 0.05975554 0.06771334
 0.0612875  0.04202301]
tr_loss:[0.01301719 0.05110634 0.02516412 0.02903658 0.02516411 0.02516413
 0.06082683 0.04119796 0.02516413 0.02999786 0.04126254 0.04119793
 0.01301727 0.02517102 0.01478078 0.04119795 0.05111123 0.0689189
 0.06891882 0.02516413 0.01478077 0.01568967 0.05149983 0.06082684
 0.04761597 0.01478075 0.06080991 0.06082686 0.04119792 0.02516417
 0.04625788 0.0269865  0.04119891 0.01301715 0.04405481 0.02518621
 0.06891882 0.02818053 0.06082684 0.01478075 0.06082685 0.04119792
 0.04119793 0.01478075 0.01478074 0.05835057 0.03544449 0.05835038
 0.01301257 0.05163472]
tr_loss:[0.06054386 0.03716753 0.03558595 0.04001147 0.05111767 0.01439117
 0.01610309 0.0571294  0.0284853  0.04328988 0.04772093 0.02587906
 0.06117107 0.0510981  0.03729971 0.02335153 0.05901656 0.02587906
 0.04848165 0.03287579 0.04001151 0.04001146 0.06117054 0.01460256
 0.02848787 0.04001145 0.0519945  0.04001147 0.02587906 0.04001153
 0.02587906 0.01610777 0.04746816 0.02745033 0.05111272 0.02587905
 0.04671608 0.01610311 0.03235301 0.0588478  0.06117073 0.0161031
 0.02587906 0.01610312 0.04050908 0.03115444 0.05196514 0.07027384
 0.02587908 0.0629605 ]
tr_loss:[0.05908672 0.05908668 0.06807406 0.06807407 0.04862374 0.02734385
 0.04738153 0.05908675 0.03977031 0.05019384 0.01344608 0.06807409
 0.014011   0.03365619 0.01401098 0.05908672 0.03610907 0.03702047
 0.05908673 0.02369608 0.02369688 0.01343213 0.01401138 0.0236969
 0.04857552 0.0370219  0.01345215 0.02369687 0.03064129 0.01401098
 0.04220984 0.03740749 0.04419458 0.05908673 0.02369688 0.01401098
 0.05908672 0.05908673 0.01592463 0.03702044 0.06807409 0.02369687
 0.03145619 0.01580846 0.02369688 0.05908675 0.01401099 0.04298111
 0.01343743 0.01401099]
tr_loss:[0.01152861 0.02885647 0.04236304 0.0462511  0.02036457 0.01174496
 0.01174494 0.05534753 0.01667319 0.01174495 0.0212639  0.01152862
 0.04874433 0.02036503 0.04595466 0.03381801 0.03508509 0.0338277
 0.05534753 0.01152862 0.0459649  0.03381798 0.05534753 0.0461962
 0.06369977 0.05534754 0.03562253 0.06369971 0.02734709 0.05534749
 0.02036458 0.01152862 0.01152847 0.03259087 0.05534754 0.01152856
 0.04614332 0.04596494 0.01174494 0.03381799 0.01969697 0.01152892
 0.01152863 0.01297614 0.05534752 0.02423843 0.02036456 0.01303447
 0.02035446 0.04818049]
tr_loss:[0.06129895 0.01877677 0.05269806 0.03333725 0.01288943 0.01288944
 0.01288943 0.02756176 0.0512322  0.01877677 0.03197295 0.06129901
 0.03198566 0.03197268 0.04457697 0.02797836 0.01877679 0.01877677
 0.05269742 0.01288943 0.01291117 0.01112185 0.03198786 0.04851321
 0.05269741 0.01877677 0.01327597 0.04257833 0.05269735 0.01854679
 0.03197272 0.01026358 0.0319727  0.02756628 0.04755164 0.04755181
 0.0102629  0.04692159 0.01334578 0.06129903 0.04856549 0.01173305
 0.01405121 0.03197271 0.01854673 0.04755181 0.05269736 0.01877678
 0.0526974  0.03457152]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2300 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2301, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2301 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2302, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2302 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2303, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2303 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2304, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2304 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2305, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2305 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2306, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2306 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2307, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2307 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2308, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2308 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2309, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2309 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2310, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2310 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2311, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2311 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2312, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2312 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2313, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2313 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2314, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2314 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2315, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2315 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2316, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2316 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2317, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2317 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2318, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2318 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2319, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2319 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2320, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2320 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2321, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2321 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2322, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2322 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2323, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2323 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2324, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2324 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2325, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2325 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2326, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2326 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2327, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2327 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2328, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2328 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2329, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2329 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2330, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2330 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2331, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2331 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2332, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2332 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2333, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2333 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2334, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2334 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2335, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2335 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2336, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2336 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2337, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2337 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2338, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2338 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2339, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2339 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2340, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2340 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2341, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2341 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2342, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2342 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2343, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2343 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2344, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2344 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2345, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2345 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2346, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2346 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2347, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2347 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2348, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2348 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2349, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2349 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2350, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2350 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2351, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2351 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2352, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2352 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2353, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2353 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2354, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2354 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2355, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2355 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2356, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2356 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2357, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2357 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2358, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2358 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2359, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2359 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2360, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2360 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2361, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2361 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2362, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2362 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2363, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2363 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2364, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2364 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2365, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2365 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2366, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2366 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2367, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2367 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2368, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2368 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2369, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2369 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2370, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2370 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2371, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2371 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2372, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2372 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2373, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2373 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2374, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2374 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2375, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2375 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2376, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2376 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2377, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2377 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2378, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2378 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2379, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2379 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2380, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2380 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2381, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2381 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2382, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2382 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2383, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2383 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2384, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2384 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2385, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2385 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2386, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2386 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2387, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2387 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2388, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2388 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2389, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2389 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2390, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2390 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2391, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2391 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2392, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2392 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2393, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2393 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2394, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2394 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2395, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2395 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2396, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2396 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2397, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2397 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2398, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2398 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2399, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2399 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2400, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2300
text_input.shape
(2400, 14400)
learning_input_tmp.shape
(2400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2400, 80)
learning_output.shape
(750, 80)
Model: "sequential_49"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_49 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2753677 1.2753676 1.2651408 1.2193707 1.2193707 1.2193674 1.2532492
 1.2770334 1.3166692 1.3166692 1.2651409 1.2365429 1.2713921 1.2713921
 1.2479918 1.2475346 1.3122747 1.2753677 1.2811407 1.3844521 1.2753675
 1.2230551 1.2476733 1.2479906 1.3026102 1.2921546 1.2193701 1.2753676
 1.2193867 1.2811397 1.2479919 1.2848837 1.2193708 1.3166695 1.2528993
 1.2651409 1.3060427 1.3160174 1.2479919 1.3041394 1.3161421 1.2753675
 1.2511008 1.2479917 1.3094689 1.2753679 1.3100173 1.312344  1.2330645
 1.2782013]
tr_loss:[0.9494163  0.83644074 0.834823   0.83650666 0.8001391  0.83644086
 0.83302706 0.8001391  0.82615566 0.7493674  0.7493674  0.7869832
 0.7943284  0.8402678  0.83302706 0.80013907 0.72740966 0.83644074
 0.8332802  0.7691367  0.81128806 0.7729624  0.8113718  0.76186436
 0.80013925 0.8331197  0.83644086 0.83311975 0.836445   0.83311975
 0.80013925 0.7493676  0.75699186 0.83310825 0.72507143 0.83311975
 0.8238457  0.8330269  0.7463559  0.833027   0.81925803 0.83644074
 0.80013907 0.77871335 0.83302706 0.83160096 0.7787452  0.80987656
 0.84027135 0.83302706]
tr_loss:[0.4270784  0.405435   0.415178   0.4289891  0.41840935 0.41501117
 0.39266005 0.4335413  0.4516377  0.41582337 0.39266044 0.408708
 0.40681475 0.45161954 0.4129228  0.4516375  0.4386608  0.41842642
 0.44759044 0.5410185  0.4087081  0.4068161  0.4087081  0.41361064
 0.45163757 0.408708   0.44947928 0.40870804 0.41061148 0.4087081
 0.41840926 0.4516375  0.40535635 0.42492    0.40680337 0.4272384
 0.411693   0.44434047 0.4087081  0.4272852  0.4184093  0.42581925
 0.408708   0.42408687 0.408708   0.53281724 0.4516375  0.41841084
 0.41840926 0.45163745]
tr_loss:[0.30786186 0.29757026 0.26179644 0.28002506 0.29756993 0.3098146
 0.30351713 0.26107848 0.26107845 0.29805762 0.28839964 0.25547415
 0.2952039  0.2610785  0.30362436 0.29761165 0.3011439  0.29756984
 0.2554732  0.29757    0.27493763 0.30114383 0.25547412 0.29756987
 0.26107845 0.3136754  0.25265208 0.28318554 0.31130546 0.27480823
 0.2748083  0.35291657 0.26107845 0.2975796  0.2982741  0.29756993
 0.274439   0.2877597  0.28375387 0.2748083  0.2975699  0.25547403
 0.29826555 0.25547403 0.26107842 0.25547433 0.29478666 0.25563902
 0.28840604 0.297571  ]
tr_loss:[0.17257929 0.1699864  0.20365599 0.15240923 0.1699864  0.20851111
 0.2070454  0.23723659 0.23724048 0.2025818  0.14773257 0.21470359
 0.16998644 0.14539182 0.17257586 0.17584607 0.1699864  0.19028911
 0.17584601 0.17257576 0.17257577 0.15240929 0.2025752  0.20407104
 0.17259507 0.2397772  0.15240669 0.15240921 0.16998643 0.15240923
 0.17257592 0.1768612  0.20249204 0.19803712 0.14773254 0.14773253
 0.16998638 0.14793387 0.14773254 0.18585601 0.15240952 0.1699864
 0.16998641 0.14773247 0.1572568  0.20258173 0.17257571 0.15240924
 0.14772569 0.19265644]
tr_loss:[0.08946092 0.10540649 0.10750781 0.15342203 0.1415379  0.17327791
 0.09419654 0.10540643 0.15871993 0.1341951  0.10540644 0.14153765
 0.1075078  0.14034545 0.14498565 0.14034545 0.10540649 0.09419654
 0.09419655 0.10541365 0.09419656 0.15872209 0.14497563 0.09419654
 0.10750781 0.08945759 0.13440804 0.13635972 0.10631175 0.14034548
 0.10540648 0.17327914 0.11287729 0.10540648 0.11550792 0.09419658
 0.14139244 0.09419656 0.14034547 0.13417025 0.1075078  0.14034545
 0.13636567 0.10750778 0.10862134 0.1403454  0.09419578 0.10540648
 0.08946089 0.12572923]
tr_loss:[0.08658861 0.09488644 0.0746619  0.07442508 0.08998577 0.08998574
 0.12209813 0.11211614 0.08229315 0.08998577 0.08998576 0.08998579
 0.08043953 0.07606132 0.11747129 0.07442506 0.08226509 0.0822651
 0.08998575 0.12415413 0.07442509 0.07442509 0.07442506 0.12209819
 0.10945282 0.08226518 0.10785785 0.13494001 0.0822651  0.12531011
 0.08226512 0.12589432 0.0746619  0.07442507 0.08998574 0.08226509
 0.08226508 0.08043846 0.07442506 0.09864447 0.07442506 0.12209813
 0.07450553 0.07442509 0.0822659  0.08043885 0.07442509 0.08209161
 0.13494006 0.08998577]
tr_loss:[0.10442896 0.09897753 0.05392943 0.05391483 0.07543603 0.075596
 0.05899286 0.05902662 0.07559602 0.06701856 0.05899366 0.05391481
 0.05933667 0.07559597 0.07470582 0.075596   0.06278287 0.10945169
 0.05391488 0.06529247 0.06253725 0.075596   0.05899292 0.06528671
 0.08103409 0.1094517  0.09885262 0.10945167 0.08865836 0.07569442
 0.06701855 0.06701853 0.07559596 0.0650676  0.07559604 0.06846358
 0.05391503 0.05391484 0.075596   0.07882868 0.05391536 0.06528671
 0.10346057 0.05391481 0.06528676 0.07933604 0.05391483 0.06100198
 0.11732231 0.08994831]
tr_loss:[0.03414611 0.03656825 0.05724339 0.04739184 0.04739182 0.05971603
 0.0846524  0.08005671 0.04860105 0.0344435  0.08464906 0.03414614
 0.08503683 0.03569473 0.08002531 0.05724486 0.08275509 0.08005248
 0.08878952 0.03569474 0.03444389 0.07095092 0.03569471 0.08878952
 0.0343238  0.03454694 0.0357338  0.03569464 0.08878954 0.05725173
 0.03414611 0.0887895  0.04740769 0.03444389 0.06155044 0.03414613
 0.04739186 0.0887895  0.03640563 0.07299159 0.03454656 0.04739182
 0.03569477 0.05724337 0.08004986 0.03444104 0.05293046 0.08005054
 0.03414615 0.08990301]
tr_loss:[0.02564781 0.02359755 0.02579201 0.04618705 0.05984142 0.03037602
 0.06989096 0.06595286 0.02579198 0.05500223 0.02579201 0.0303711
 0.06470089 0.02406802 0.02564782 0.02568747 0.07825978 0.0495428
 0.02579198 0.02490478 0.02981854 0.05381856 0.06354158 0.05984143
 0.06686504 0.02579199 0.02011451 0.03037667 0.0598443  0.03037575
 0.06319594 0.06989107 0.02564778 0.02564779 0.05984146 0.03037604
 0.06909449 0.025792   0.06989101 0.0610703  0.03281771 0.06918356
 0.02579202 0.06980698 0.02512899 0.06113157 0.02988683 0.06330967
 0.05119627 0.04088733]
tr_loss:[0.02740178 0.0253377  0.06410493 0.0279199  0.02640016 0.02458153
 0.0824929  0.02640015 0.02638688 0.02740182 0.06635217 0.02640016
 0.06635215 0.02640014 0.0640138  0.06307687 0.02507755 0.0274018
 0.05653625 0.0274018  0.06307687 0.05643446 0.0279199  0.06411591
 0.02640017 0.03123352 0.06102179 0.05634987 0.06307689 0.06680883
 0.02740181 0.02468737 0.02640017 0.02773971 0.06795579 0.06307686
 0.02320975 0.06635214 0.07256699 0.05653624 0.02640016 0.06644699
 0.06145072 0.02791987 0.06146438 0.02640015 0.05819696 0.02334325
 0.0361784  0.06307684]
tr_loss:[0.02317746 0.0667425  0.02775419 0.02800514 0.06674259 0.07167431
 0.02421698 0.05712518 0.09883899 0.07314906 0.02775426 0.06674258
 0.06507697 0.06674258 0.02585454 0.06507708 0.06495849 0.02617928
 0.02905265 0.06674293 0.02905269 0.03010716 0.06615225 0.06674256
 0.06498624 0.02905266 0.02421708 0.06084371 0.02905265 0.04144274
 0.02905267 0.02905265 0.0280053  0.06507693 0.02585443 0.08687872
 0.05972385 0.02421698 0.02585939 0.06677888 0.05947965 0.06934921
 0.07504446 0.05998971 0.06674258 0.06508539 0.05972388 0.06674255
 0.06674496 0.06674258]
tr_loss:[0.05813041 0.06231618 0.10445078 0.05813039 0.06195052 0.05610409
 0.05813034 0.0457085  0.05813035 0.02610398 0.07351385 0.09012819
 0.02782809 0.05813039 0.02385776 0.05430027 0.07843771 0.02630431
 0.07229556 0.05813038 0.0238681  0.07843653 0.05743167 0.0237026
 0.02409395 0.02527623 0.04475088 0.05430153 0.02403549 0.0655321
 0.02370263 0.02610399 0.02370261 0.02385882 0.02527625 0.03130611
 0.05813037 0.02370261 0.05433154 0.0262026  0.05571983 0.05813036
 0.05406854 0.02610399 0.05584558 0.05318709 0.05741242 0.05741245
 0.02610399 0.04575311]
tr_loss:[0.07410119 0.05982805 0.05429526 0.05574162 0.02108916 0.01594638
 0.05659182 0.04798911 0.02443391 0.02451273 0.07918546 0.02271236
 0.04798909 0.02271237 0.05659183 0.04837814 0.02326354 0.02153041
 0.02108916 0.0737501  0.02326353 0.06097377 0.02271238 0.02271384
 0.05449104 0.02406437 0.02153036 0.05458448 0.08896105 0.02326351
 0.04798906 0.02231215 0.05659179 0.02327145 0.07375014 0.10099302
 0.04425959 0.02479633 0.02108913 0.03655903 0.02443228 0.0565918
 0.02326351 0.02443228 0.0481707  0.06106707 0.04425068 0.04810485
 0.02108915 0.02479632]
tr_loss:[0.05494443 0.01363915 0.0620438  0.0573657  0.01989517 0.05023796
 0.02124761 0.0630307  0.05627248 0.01895112 0.02124762 0.04180061
 0.06217953 0.08495786 0.02558457 0.0226541  0.0212476  0.04445875
 0.01515119 0.09335366 0.04180386 0.02558454 0.04977303 0.06369773
 0.02318362 0.01363919 0.04469411 0.04977301 0.06204408 0.0620438
 0.04604537 0.06216654 0.0591024  0.02558454 0.04180057 0.02558458
 0.02558455 0.02558435 0.01375917 0.04180063 0.06008629 0.05910243
 0.02558457 0.02124763 0.02558456 0.06320601 0.04180057 0.0255843
 0.02558456 0.02124761]
tr_loss:[0.03881316 0.02748213 0.02093842 0.03881348 0.03882528 0.0893968
 0.02093842 0.02666997 0.02747896 0.03884609 0.02093842 0.03897348
 0.03881357 0.06187264 0.01869338 0.02093842 0.03957561 0.01897919
 0.01869038 0.03881317 0.02093844 0.03881451 0.08939681 0.01897919
 0.0189792  0.02093843 0.02100091 0.02747896 0.01915918 0.01869038
 0.02747895 0.02102921 0.03710818 0.04101462 0.02747897 0.06151052
 0.03881903 0.06151055 0.04101317 0.06151054 0.01257772 0.01897917
 0.06260227 0.02102922 0.06272409 0.06151054 0.01897921 0.01869038
 0.01897919 0.04015191]
tr_loss:[0.06503202 0.02240379 0.02336403 0.03046174 0.02331429 0.05742885
 0.02331429 0.05744825 0.01472222 0.02331429 0.05875754 0.02331427
 0.05535897 0.04006987 0.05312426 0.03046173 0.05874026 0.02336906
 0.0304617  0.02111711 0.01472028 0.06183855 0.06603177 0.06146193
 0.02331714 0.04006743 0.03955268 0.06183853 0.02331426 0.05747495
 0.03046173 0.02085067 0.06183858 0.0400674  0.06183854 0.09225537
 0.02615408 0.02331428 0.03045427 0.02331426 0.04006744 0.02336364
 0.05676473 0.02623861 0.0400674  0.03046173 0.02331429 0.05676537
 0.06503186 0.04698849]
tr_loss:[0.03604225 0.05207459 0.05606661 0.02103965 0.05541705 0.02127073
 0.02553581 0.09562571 0.01842673 0.05618444 0.04922197 0.01231064
 0.0255358  0.06118768 0.0409272  0.0409272  0.04092717 0.04092719
 0.01877952 0.05533838 0.05219717 0.0409272  0.05429043 0.0255358
 0.02795616 0.04003572 0.0255358  0.06116424 0.02553577 0.04092719
 0.04176979 0.08910921 0.02553579 0.02553579 0.02103962 0.01250119
 0.01835994 0.05353307 0.08910929 0.02126438 0.05803528 0.02553579
 0.02553579 0.05618443 0.04092716 0.02799464 0.02553579 0.06148414
 0.01842663 0.02103966]
tr_loss:[0.02730537 0.01731711 0.05221225 0.04878854 0.05221225 0.05221221
 0.02076583 0.0452311  0.01966466 0.05540473 0.04526309 0.05833773
 0.05605258 0.01966466 0.05221222 0.01966465 0.08602463 0.01966465
 0.05221223 0.05251314 0.05314892 0.06027889 0.02076583 0.01966462
 0.01967353 0.02076585 0.04204757 0.02076584 0.01966462 0.01966462
 0.01966462 0.01966463 0.05821385 0.04907779 0.0452222  0.01767104
 0.04158334 0.0522122  0.0583388  0.0452222  0.07691046 0.0452222
 0.02076584 0.05342103 0.0173171  0.05930262 0.05221222 0.04158251
 0.02076584 0.01966461]
tr_loss:[0.04707013 0.01886715 0.04938229 0.01894853 0.01896986 0.05662913
 0.01896986 0.01896988 0.03715678 0.04730345 0.05018447 0.01886699
 0.04946692 0.05663367 0.01886699 0.05816411 0.08652176 0.01896987
 0.01894989 0.01706524 0.04733501 0.04763972 0.06259809 0.01894818
 0.01715954 0.05663325 0.05018447 0.05673573 0.04938228 0.01896985
 0.018867   0.04719078 0.05018447 0.01894815 0.01896987 0.0171777
 0.05018447 0.01896986 0.0189528  0.01896988 0.01896989 0.02813891
 0.04763975 0.01896986 0.01897048 0.0471217  0.01717769 0.01896989
 0.01717768 0.01895534]
tr_loss:[0.01902017 0.04926969 0.05349842 0.06805056 0.02764463 0.05119103
 0.050005   0.01852657 0.05068253 0.04752452 0.02492905 0.02500229
 0.05068276 0.01889911 0.0188991  0.04999813 0.05068257 0.05068258
 0.01704984 0.01890191 0.06130219 0.03658549 0.01852659 0.02492903
 0.02013708 0.01889871 0.01902016 0.01889895 0.05349114 0.01852654
 0.01889908 0.05580737 0.01864258 0.02766148 0.01852708 0.04961475
 0.04961476 0.05068256 0.02020357 0.05582324 0.01856761 0.05068254
 0.02492902 0.03661536 0.05220829 0.04961476 0.01889909 0.06003133
 0.02013662 0.05187318]
tr_loss:[0.03306656 0.01866761 0.03621862 0.0460365  0.04863276 0.01847383
 0.0213264  0.0191135  0.04600912 0.05467199 0.01866644 0.04714884
 0.01866642 0.01866643 0.04600913 0.04793411 0.05817726 0.01942933
 0.05360062 0.07681562 0.04600915 0.01887359 0.01866644 0.07681561
 0.06429285 0.0184738  0.04600908 0.05492245 0.01949087 0.0519139
 0.01956687 0.0134348  0.06431638 0.01866641 0.06378864 0.01342312
 0.01942804 0.05487454 0.05829688 0.03424463 0.04600912 0.05191396
 0.01866643 0.04601272 0.0253745  0.01866642 0.04600916 0.01942933
 0.08377983 0.0185206 ]
tr_loss:[0.01965071 0.01984367 0.04950409 0.01984365 0.05039407 0.01802426
 0.04950408 0.04787029 0.0479295  0.05046117 0.02074625 0.01984366
 0.04950904 0.01984366 0.04950906 0.01984364 0.01802428 0.0428264
 0.01389713 0.01969775 0.01965074 0.01802428 0.05844197 0.01984326
 0.04000479 0.04662009 0.04950402 0.0196505  0.04580592 0.01785216
 0.01802429 0.04950406 0.01796849 0.01965069 0.0495091  0.01965068
 0.04813464 0.01802427 0.01984364 0.07877792 0.0400049  0.04000475
 0.01998228 0.05045456 0.01984404 0.04950908 0.04623998 0.04948864
 0.01802426 0.01965081]
tr_loss:[0.01257379 0.03328637 0.03546938 0.03546936 0.05143797 0.03546939
 0.04981323 0.01936121 0.03864498 0.02174323 0.04739376 0.0490601
 0.02174322 0.01814651 0.03546936 0.01935931 0.01737317 0.01737314
 0.02174323 0.01737314 0.04741637 0.01760488 0.01936123 0.02174321
 0.05347102 0.04741252 0.01933182 0.01936123 0.02174321 0.03546942
 0.04010972 0.03546937 0.04981323 0.01936083 0.0217432  0.03546937
 0.03547236 0.02174324 0.03546948 0.0194053  0.03546936 0.04981325
 0.08010397 0.03949099 0.0454637  0.02174323 0.03546939 0.01809001
 0.03949089 0.08010101]
tr_loss:[0.03270171 0.02419366 0.03684939 0.02419432 0.05236014 0.05236075
 0.02419367 0.01770882 0.03270119 0.03939898 0.03270085 0.0437694
 0.01917884 0.04915748 0.03278646 0.09259631 0.01098825 0.01770884
 0.03739854 0.03733014 0.04332872 0.01542125 0.02419367 0.01544176
 0.04221413 0.05174503 0.01147596 0.05019305 0.01917801 0.0498421
 0.01725894 0.01917802 0.05174505 0.02075901 0.0177088  0.03274602
 0.01917802 0.05357351 0.01770907 0.01542125 0.0327023  0.0403003
 0.01770881 0.03270083 0.09259635 0.0441597  0.03270093 0.03891587
 0.01770884 0.02419366]
tr_loss:[0.01983299 0.05320628 0.03207966 0.02707693 0.01633911 0.03686013
 0.02707696 0.01921737 0.04310931 0.02707697 0.01983303 0.05141263
 0.04311094 0.05305127 0.01983303 0.01983301 0.0513868  0.03209393
 0.01983302 0.01921737 0.03207966 0.03210514 0.01923465 0.03207964
 0.03207963 0.0320802  0.02707697 0.01921736 0.03207964 0.01907874
 0.03207963 0.0428309  0.02934291 0.02199409 0.04105423 0.01921701
 0.02121909 0.02121917 0.01983303 0.04487829 0.0532105  0.04098438
 0.02707697 0.05142961 0.05179932 0.03687602 0.04411095 0.05179938
 0.01907759 0.08549881]
tr_loss:[0.02059525 0.05412738 0.01858429 0.03558659 0.03275056 0.05290711
 0.01763159 0.02059525 0.02059528 0.01814673 0.02411425 0.02813946
 0.0185979  0.01858426 0.02018046 0.03275057 0.02059528 0.01762071
 0.01137287 0.08467473 0.04584334 0.0185843  0.0327506  0.05685765
 0.0205953  0.09474373 0.02059529 0.01160281 0.02813947 0.0241143
 0.01762062 0.09469728 0.03275057 0.04310061 0.04469582 0.0185843
 0.05475058 0.01962811 0.04355602 0.03613207 0.02813948 0.03275055
 0.04685924 0.03275059 0.02903936 0.02059528 0.02813947 0.01858432
 0.01136989 0.03517362]
tr_loss:[0.02343667 0.04952839 0.02343668 0.03310006 0.02343667 0.0476932
 0.01607952 0.04952838 0.01798612 0.047199   0.01707172 0.04809897
 0.02278585 0.01707173 0.01707173 0.04952839 0.01803063 0.03739052
 0.00909094 0.04298867 0.03987938 0.01597234 0.01518115 0.01498437
 0.03309417 0.04809898 0.03709091 0.02343668 0.01518114 0.01707172
 0.02585502 0.01518116 0.03597205 0.05228276 0.01517673 0.01652797
 0.05227219 0.04739591 0.03225257 0.02343665 0.05216268 0.0232914
 0.01522859 0.04980783 0.01518113 0.0234367  0.04300026 0.04952841
 0.02339246 0.04727738]
tr_loss:[0.07532035 0.07532035 0.02220984 0.0141335  0.04699423 0.05197166
 0.01861467 0.01488269 0.02116646 0.03523258 0.03300359 0.03523111
 0.03976827 0.01413355 0.0305477  0.01487931 0.02127233 0.04699422
 0.04639766 0.03068632 0.0358213  0.01861469 0.01487933 0.00895578
 0.01550973 0.01861466 0.03532743 0.04699424 0.01279532 0.03523105
 0.01758218 0.04689921 0.04409124 0.01550978 0.01550973 0.05051189
 0.03307807 0.08365002 0.02126986 0.0518677  0.01861465 0.01253985
 0.01487934 0.04705951 0.01861467 0.01488523 0.08304709 0.02883862
 0.03523103 0.07531108]
tr_loss:[0.0166099  0.04644161 0.07452945 0.04644158 0.04587123 0.04644164
 0.01548768 0.01642415 0.01548765 0.0385932  0.01548765 0.01642415
 0.04644162 0.04851518 0.05355189 0.03859317 0.01914846 0.01548767
 0.01654997 0.05105769 0.01642413 0.01548767 0.03859939 0.03859317
 0.05353916 0.01548768 0.04644163 0.03859361 0.07412487 0.04644161
 0.03652192 0.0187826  0.01642547 0.01642561 0.02279819 0.01642542
 0.01642415 0.04849998 0.01642433 0.04644162 0.01548767 0.01642547
 0.05353267 0.01548874 0.02011723 0.01548765 0.01641534 0.04587124
 0.01548768 0.05221941]
text_input.shape
(2400, 14400)
learning_input_tmp.shape
(2400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2400, 80)
learning_output.shape
(750, 80)
Model: "sequential_50"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_50 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.5375326 1.3493292 1.4606106 1.5079756 1.4886119 1.4508483 1.5375279
 1.5103769 1.4577901 1.4885931 1.41386   1.4842355 1.4883752 1.4886115
 1.5486395 1.5103769 1.5476849 1.4138601 1.4577891 1.5115502 1.5103768
 1.5375278 1.4886116 1.5726726 1.4541281 1.5081381 1.4878128 1.5674016
 1.45779   1.4755294 1.5103768 1.5375278 1.4883753 1.5375365 1.4886116
 1.3497233 1.4577901 1.46061   1.5405178 1.5328904 1.4883753 1.4138601
 1.537528  1.4498012 1.4886115 1.4577901 1.5103769 1.5097296 1.5622938
 1.4138601]
tr_loss:[0.70371705 0.7694322  0.7515571  0.7503839  0.7458459  0.7694322
 0.75038385 0.71984106 0.77670133 0.7694323  0.7789599  0.7570267
 0.7037233  0.73092425 0.8959651  0.88519907 0.723287   0.71468306
 0.7150315  0.72887886 0.72328705 0.76550514 0.76956004 0.7309259
 0.7232871  0.75038385 0.76867497 0.7624378  0.76140374 0.750384
 0.76973736 0.7198356  0.7191807  0.7694322  0.75574386 0.7351943
 0.7309243  0.72328705 0.7539172  0.7503494  0.8851837  0.755744
 0.7037381  0.77683777 0.73092437 0.7503838  0.7354095  0.75574374
 0.7309245  0.70253503]
tr_loss:[0.4475395  0.43477765 0.4627057  0.44062695 0.43945107 0.47990847
 0.4253512  0.46546292 0.4475398  0.43945104 0.4475395  0.4253506
 0.44062686 0.43384877 0.46296367 0.47990656 0.43477768 0.4498436
 0.46547684 0.45012617 0.48474208 0.48468438 0.4406268  0.43477765
 0.47115898 0.44062692 0.42535073 0.4654789  0.4406011  0.4488155
 0.45216322 0.43477756 0.43716222 0.4654749  0.46547684 0.505082
 0.479914   0.44753957 0.425354   0.46768445 0.44062686 0.5050825
 0.44062692 0.46515933 0.42535073 0.48259774 0.42535067 0.46661568
 0.44062692 0.4394599 ]
tr_loss:[0.2664101  0.29957694 0.2664098  0.32749972 0.26641014 0.34135404
 0.26641005 0.28095603 0.3807601  0.2664101  0.30585557 0.33561754
 0.31945658 0.2995771  0.23463163 0.30620453 0.3807912  0.3171332
 0.29957694 0.29957694 0.29957694 0.26641005 0.299577   0.29568526
 0.2664101  0.3026174  0.26641002 0.29957694 0.298695   0.3194279
 0.29957694 0.31191945 0.29957694 0.29957697 0.28550526 0.28828087
 0.29957697 0.2915546  0.2676471  0.2919803  0.29918134 0.26639202
 0.30261734 0.37128973 0.28438497 0.30585545 0.26641    0.32480726
 0.3119194  0.3119194 ]
tr_loss:[0.17509189 0.18087265 0.18451394 0.13728137 0.19950669 0.13727972
 0.16128926 0.1858741  0.16128714 0.27452034 0.23286292 0.16825956
 0.16128922 0.16883054 0.17327185 0.1808726  0.16128927 0.13728115
 0.16671167 0.1732718  0.18087263 0.1661021  0.15129817 0.15876071
 0.25932962 0.17327183 0.16128924 0.18147185 0.18087262 0.20338039
 0.16825955 0.16883059 0.1645746  0.18516989 0.16363136 0.13726011
 0.23191798 0.16128926 0.1995054  0.16128922 0.13728133 0.16266724
 0.20283823 0.17327185 0.18331675 0.16883047 0.1793929  0.1594264
 0.14920722 0.17327185]
tr_loss:[0.14555094 0.1024667  0.10246669 0.10685513 0.09363101 0.09658764
 0.09441163 0.11614835 0.06798446 0.08539192 0.09658767 0.10052893
 0.09581953 0.10662746 0.09502582 0.0944116  0.08086748 0.06798398
 0.06798464 0.09355529 0.10246663 0.10229962 0.06798397 0.10053337
 0.07941113 0.10015027 0.10053198 0.12819023 0.08347615 0.06798392
 0.09441161 0.07218173 0.08540948 0.10295282 0.1258498  0.07501093
 0.09670307 0.09213667 0.07218148 0.17937289 0.09441154 0.08137552
 0.07857762 0.10673509 0.09446393 0.07218146 0.08135525 0.07953694
 0.08095736 0.0944116 ]
tr_loss:[0.08179794 0.06490882 0.08179794 0.09799837 0.0596882  0.0817979
 0.05968819 0.04545849 0.03615775 0.06309153 0.04559047 0.06490913
 0.04545835 0.07637872 0.08179791 0.09376998 0.06490878 0.04391507
 0.09453833 0.03615653 0.08179791 0.04545837 0.04463387 0.03615773
 0.03615773 0.12324914 0.07637228 0.05968823 0.03615772 0.09891842
 0.06490883 0.04545837 0.05968825 0.05968818 0.04450152 0.13006027
 0.1228626  0.04545833 0.09829685 0.0944588  0.04450095 0.04545834
 0.0596882  0.03615776 0.05827369 0.08179791 0.06515111 0.04545837
 0.07974941 0.03615775]
tr_loss:[0.09678715 0.03353345 0.06451998 0.09202629 0.0476861  0.08968048
 0.09625275 0.03962388 0.07103353 0.04578311 0.11343775 0.03353346
 0.09513236 0.08481828 0.04770306 0.07486192 0.09202451 0.04578274
 0.05709656 0.03353344 0.06452364 0.05709634 0.07427432 0.03962386
 0.06576165 0.10275684 0.0918212  0.0476867  0.06311859 0.0476861
 0.05709655 0.04010879 0.09617863 0.047756   0.08481829 0.06239197
 0.05709656 0.08481828 0.03962386 0.0716765  0.05319204 0.08481827
 0.03353344 0.03962387 0.06313862 0.05709658 0.03353348 0.06357434
 0.03962391 0.08963521]
tr_loss:[0.04024296 0.08069561 0.04024294 0.05365131 0.05353006 0.05373993
 0.09504794 0.04024295 0.02610304 0.02623475 0.02610299 0.05365131
 0.08362761 0.04037566 0.03090804 0.0308766  0.08642945 0.0842187
 0.05367128 0.09467087 0.08421125 0.04025197 0.05497883 0.0536513
 0.03090813 0.05363619 0.05365128 0.0536513  0.03110798 0.08421336
 0.08997963 0.04974888 0.08423315 0.04024298 0.04024306 0.05373973
 0.09504768 0.026103   0.04299104 0.09108396 0.06120808 0.05365126
 0.02610299 0.05340877 0.08659457 0.09037409 0.06828769 0.03090817
 0.08069558 0.03090817]
tr_loss:[0.0516646  0.06426436 0.12504494 0.05143367 0.06408989 0.04377849
 0.05143367 0.04095681 0.0325552  0.04583767 0.06408991 0.04095612
 0.0790766  0.04373493 0.07452537 0.06408988 0.06693629 0.03255522
 0.07026371 0.05128343 0.04095311 0.04095349 0.04372784 0.06409323
 0.03487911 0.061659   0.04252731 0.03487911 0.04095315 0.05822873
 0.06408937 0.0786229  0.04095311 0.03254959 0.06165992 0.03487912
 0.08323626 0.0325552  0.08078726 0.06408987 0.06362373 0.10660803
 0.06408988 0.0325552  0.05796523 0.0325552  0.04097306 0.07907661
 0.07862341 0.06408992]
tr_loss:[0.06449501 0.02901873 0.05130605 0.04768107 0.06449504 0.06785721
 0.05127164 0.02952155 0.07851703 0.07851436 0.11886068 0.064495
 0.06449501 0.06781534 0.06111413 0.05380827 0.06522946 0.03186427
 0.06449503 0.08156621 0.06449501 0.06449503 0.07488661 0.0411956
 0.02902411 0.10502183 0.08156618 0.02901871 0.02952157 0.06449501
 0.02952155 0.07851703 0.02952161 0.0815661  0.02952159 0.08156618
 0.06449501 0.04119619 0.02952155 0.02952156 0.08563127 0.06111849
 0.04119616 0.06449504 0.04119616 0.05139773 0.06448166 0.05731454
 0.04586462 0.02939316]
tr_loss:[0.04130136 0.04939361 0.05326008 0.02800048 0.08071379 0.10995007
 0.02800051 0.06158606 0.02466705 0.02466705 0.06696922 0.02800048
 0.08071379 0.06032082 0.06367793 0.0280005  0.06032084 0.04130147
 0.0807138  0.04130138 0.06158607 0.04130138 0.02466705 0.06032083
 0.06032082 0.05744248 0.06158667 0.02466706 0.06158604 0.04130139
 0.08071379 0.04130137 0.04759968 0.07581842 0.06032082 0.05934928
 0.06158605 0.07719767 0.06032081 0.06158606 0.06565665 0.07818375
 0.07456861 0.04105907 0.07494184 0.0807138  0.06032143 0.07302316
 0.02466706 0.06032084]
tr_loss:[0.05029795 0.0680639  0.03646388 0.05185657 0.05185783 0.01988307
 0.02653863 0.05185808 0.01988305 0.05033641 0.02654053 0.07955553
 0.08970736 0.04581725 0.0518581  0.07565505 0.03646055 0.03646054
 0.06101943 0.03651791 0.05147658 0.05033638 0.0503364  0.05729286
 0.04710808 0.07955553 0.07230891 0.07780959 0.05033637 0.07955553
 0.07545898 0.06527952 0.05036412 0.04692072 0.0208712  0.01988394
 0.02653891 0.05677764 0.05739266 0.02234944 0.07955551 0.08522578
 0.047071   0.05033641 0.04693305 0.07565059 0.02193856 0.01988188
 0.05033641 0.03646752]
tr_loss:[0.04651284 0.02235096 0.07723159 0.05097261 0.05055671 0.05504057
 0.02160532 0.02235097 0.04722951 0.07723813 0.04651455 0.03511984
 0.04651285 0.03511981 0.02235095 0.07969342 0.04508612 0.02167144
 0.06243084 0.03511985 0.08834523 0.02264357 0.03512654 0.02235099
 0.04508764 0.04651285 0.0216053  0.06951239 0.02235096 0.0465121
 0.03511987 0.02160531 0.07725803 0.10519717 0.03511983 0.05504171
 0.08003668 0.079789   0.02235346 0.02235095 0.04651285 0.07723145
 0.04651284 0.0215595  0.02235096 0.03520542 0.02160701 0.04194909
 0.03511983 0.02235098]
tr_loss:[0.05363542 0.05363467 0.02446635 0.08376064 0.05007106 0.07935528
 0.02446547 0.07376411 0.07637889 0.02380649 0.0237969  0.04469811
 0.03330396 0.06383386 0.07715543 0.06041172 0.04792054 0.0333041
 0.04469811 0.0244655  0.03044589 0.02446547 0.0238065  0.02446547
 0.07373887 0.07844292 0.0446981  0.04469805 0.02380649 0.02446548
 0.0743345  0.02446549 0.023963   0.04469811 0.07376702 0.07373885
 0.03330398 0.03330397 0.02446547 0.03330399 0.07715543 0.02396306
 0.03330566 0.03330395 0.02446548 0.04469811 0.04287404 0.02380657
 0.06041172 0.03044915]
tr_loss:[0.04346288 0.03928722 0.04377648 0.04258754 0.03928702 0.04220004
 0.03397863 0.03352937 0.02570352 0.06377918 0.04589388 0.04289817
 0.063969   0.06377918 0.02572012 0.03099544 0.07233572 0.02390812
 0.02875346 0.0675766  0.06296991 0.04289826 0.06345426 0.02367218
 0.05704514 0.04347902 0.0257035  0.02570354 0.03917714 0.04346285
 0.02570354 0.04289817 0.04289817 0.04289823 0.03099542 0.09783998
 0.03099543 0.06757662 0.04443947 0.04432407 0.05739189 0.04289817
 0.04432416 0.03099544 0.06381381 0.02485674 0.0428982  0.0679711
 0.02485671 0.02390318]
tr_loss:[0.05046023 0.03318985 0.0562529  0.03318536 0.02204351 0.02204353
 0.03318986 0.03634524 0.02204356 0.03634524 0.03319018 0.03091883
 0.02840502 0.05046026 0.03634524 0.02282319 0.03319367 0.02282311
 0.0425287  0.05625283 0.02840508 0.02886165 0.03634521 0.03634524
 0.02204354 0.03634526 0.03409771 0.03650493 0.03318987 0.03770686
 0.02204355 0.03318987 0.03009663 0.03318987 0.04315571 0.03318989
 0.05895674 0.046386   0.03620747 0.02204356 0.03634525 0.04988413
 0.0463046  0.05255692 0.03093848 0.02840504 0.02852235 0.11130454
 0.03635701 0.04823711]
tr_loss:[0.02775848 0.0653313  0.02199869 0.05402492 0.04478503 0.02327556
 0.02432422 0.0232756  0.04498207 0.02327559 0.02956383 0.02432421
 0.02432423 0.03724853 0.04654579 0.0363735  0.04504334 0.02327561
 0.04478499 0.03055293 0.03786212 0.02327562 0.10628597 0.04944002
 0.02199871 0.04478503 0.06531985 0.02430144 0.03822269 0.03934519
 0.02432422 0.0269328  0.04478501 0.0540207  0.02327558 0.10628589
 0.04614709 0.04478503 0.02155369 0.0232756  0.02432421 0.0342962
 0.02775854 0.03799225 0.06531981 0.02432423 0.0232756  0.0243242
 0.06505585 0.03723333]
tr_loss:[0.02280095 0.02311532 0.10248504 0.023437   0.04283979 0.06469245
 0.0231445  0.04059955 0.05800287 0.04439673 0.02343702 0.02343703
 0.02311533 0.04439672 0.07371836 0.04064839 0.0272028  0.04439672
 0.0443967  0.02343703 0.02265624 0.04578872 0.0737185  0.04301311
 0.0271985  0.04060166 0.05929682 0.04439673 0.03104438 0.03105117
 0.02311532 0.04051849 0.0461134  0.05971958 0.02344372 0.06209641
 0.02343701 0.07371785 0.03644496 0.02777199 0.04060118 0.03105222
 0.02311564 0.02343699 0.06135213 0.10248379 0.03743932 0.04206426
 0.04615037 0.02343701]
tr_loss:[0.0733908  0.02898056 0.04294592 0.02244007 0.02912373 0.04262366
 0.0442154  0.0217204  0.0264411  0.07339074 0.02643954 0.02244007
 0.02244007 0.02912412 0.07339085 0.02656354 0.02172088 0.02644109
 0.03482987 0.0264411  0.03471596 0.07339106 0.02244006 0.02172087
 0.02244005 0.02244006 0.02244007 0.05324831 0.02666944 0.02898058
 0.06704591 0.0264411  0.02172088 0.02244008 0.03476167 0.05325527
 0.02169462 0.02244007 0.04296411 0.02172087 0.07339072 0.02244008
 0.04293849 0.03381967 0.04066212 0.02821062 0.02172086 0.09138978
 0.07045472 0.04293849]
tr_loss:[0.06787132 0.01894568 0.03198804 0.05513226 0.02323969 0.04080666
 0.01894568 0.0232391  0.02007061 0.05248075 0.02007801 0.04080588
 0.06789674 0.0189457  0.04058515 0.02039809 0.02039936 0.01894568
 0.02877101 0.01894655 0.02799341 0.05510427 0.09157634 0.04070891
 0.05336824 0.01894567 0.04075373 0.0444703  0.06827871 0.02399373
 0.01894568 0.06787135 0.01894653 0.02323879 0.06787133 0.06787135
 0.02039694 0.02039696 0.06749351 0.01894566 0.04549554 0.02324222
 0.01894568 0.02309397 0.02008126 0.02392485 0.03829926 0.02039694
 0.02323912 0.02323909]
tr_loss:[0.05710925 0.01939614 0.01806466 0.04252527 0.02021419 0.02567322
 0.02565924 0.05710945 0.09387878 0.02027087 0.01806467 0.01919197
 0.01806467 0.04062586 0.019192   0.02543734 0.01806467 0.02775311
 0.08491147 0.0193251  0.06302946 0.03322376 0.02983557 0.05710923
 0.03735804 0.02636374 0.01939618 0.06348632 0.0193962  0.01919197
 0.05710921 0.05711703 0.05710921 0.0419281  0.01806467 0.01939617
 0.01806467 0.0585392  0.05710924 0.05710924 0.03382018 0.01806783
 0.01806468 0.01806467 0.04769326 0.019192   0.01939618 0.02543769
 0.04664701 0.03735716]
tr_loss:[0.04753853 0.0350036  0.01268661 0.02405423 0.04026993 0.04756609
 0.04026987 0.04682735 0.03853165 0.04028038 0.04845402 0.04385044
 0.03946692 0.04026992 0.04026991 0.04026996 0.01268897 0.04879649
 0.01268975 0.04026987 0.04027604 0.02307469 0.02790288 0.02406193
 0.02979395 0.04026994 0.01616382 0.0230747  0.02889682 0.04027276
 0.04845539 0.05549563 0.01482773 0.01268911 0.02405409 0.02307469
 0.02982123 0.04176789 0.01439042 0.02307467 0.0240541  0.0402699
 0.0417679  0.01439044 0.04176791 0.01439043 0.0240541  0.03500167
 0.04753833 0.04176789]
tr_loss:[0.02386281 0.02384103 0.04634948 0.01210382 0.04634945 0.03413251
 0.01444941 0.02413261 0.01210382 0.02386324 0.01210382 0.01212956
 0.04634948 0.10391334 0.03413246 0.04888197 0.05251424 0.0144494
 0.0144494  0.05239189 0.0144494  0.0341325  0.04962492 0.02818266
 0.01444939 0.05245205 0.04634947 0.05251381 0.02383954 0.01210382
 0.01444939 0.01213905 0.05023645 0.04634948 0.08989932 0.04634947
 0.01210383 0.02818265 0.01210382 0.04889322 0.03413248 0.03596061
 0.05351783 0.02410976 0.04888413 0.04899253 0.04888871 0.0320896
 0.05389013 0.03549664]
tr_loss:[0.01333142 0.03607895 0.04819385 0.04694317 0.02730649 0.01335124
 0.02155286 0.04819384 0.03187569 0.01434551 0.01434542 0.02952327
 0.0273065  0.01785632 0.03032494 0.02831399 0.05257951 0.0136156
 0.03173145 0.0318767  0.03681019 0.02134115 0.03266758 0.03445793
 0.0143454  0.01434544 0.04819382 0.03446113 0.01335122 0.01335146
 0.03445791 0.09145811 0.04819385 0.0326676  0.05519138 0.02730649
 0.02730652 0.04819382 0.05279023 0.02749196 0.01785691 0.01335123
 0.03446041 0.03187693 0.02730649 0.03445794 0.01361572 0.02730649
 0.09909227 0.04995478]
tr_loss:[0.01436071 0.09096907 0.01436134 0.04473582 0.05149928 0.09439699
 0.04467807 0.02307383 0.04473526 0.02307382 0.01553635 0.02014378
 0.09440631 0.04409181 0.02286668 0.02307382 0.0143939  0.03843407
 0.03843219 0.03843214 0.04546743 0.01436069 0.02307382 0.02286856
 0.02248084 0.04805908 0.02081995 0.01553633 0.01529553 0.01553634
 0.01436071 0.03843204 0.09092046 0.03843223 0.05013777 0.02993094
 0.03843206 0.04472494 0.05000959 0.03815974 0.09439733 0.01553634
 0.02284837 0.01493264 0.08984104 0.02014337 0.03843207 0.02138335
 0.03843204 0.02307406]
tr_loss:[0.01696121 0.02011125 0.03756045 0.01466641 0.04432589 0.04633806
 0.04432586 0.04374155 0.04432607 0.04440144 0.01806839 0.03495331
 0.0180684  0.04437047 0.02011138 0.02011141 0.04433253 0.03062795
 0.01466641 0.04759697 0.04759694 0.01806822 0.02248838 0.0146664
 0.0173043  0.01806837 0.02198361 0.08652985 0.0146664  0.01806238
 0.02091469 0.04432585 0.04436881 0.08811206 0.02077816 0.01876488
 0.0180684  0.02011139 0.02011139 0.0520866  0.02011141 0.02203505
 0.05520939 0.02384015 0.04759697 0.02011138 0.01467888 0.02091502
 0.03019848 0.04633773]
tr_loss:[0.03949664 0.04440232 0.04398034 0.03319437 0.04234792 0.04170964
 0.01792246 0.01830139 0.0264288  0.01280056 0.04395711 0.04395714
 0.04440232 0.01280057 0.02156447 0.07974509 0.04394574 0.02212388
 0.03216053 0.08103476 0.05200665 0.01280056 0.04234642 0.02993015
 0.04440228 0.01993965 0.04395721 0.01654335 0.01280057 0.03018182
 0.0439572  0.01585134 0.04402442 0.01280056 0.01280059 0.04394556
 0.04394404 0.01654335 0.04440231 0.04245418 0.04395762 0.0444023
 0.04440231 0.02214914 0.01280058 0.01831    0.04440233 0.04440235
 0.02922498 0.04397879]
tr_loss:[0.04012321 0.01412089 0.01124407 0.03914041 0.04374922 0.01890971
 0.01124407 0.01370631 0.01890971 0.03913967 0.01890971 0.03913968
 0.04012319 0.01948407 0.01124406 0.03913967 0.04024041 0.0189097
 0.01124406 0.01124407 0.0402455  0.01124407 0.01890969 0.0391397
 0.02318529 0.03916915 0.01148432 0.0138877  0.01384883 0.03916608
 0.02906086 0.0189097  0.05176479 0.0141209  0.01124408 0.03520015
 0.01890971 0.04012322 0.02957187 0.03913969 0.03043917 0.0189097
 0.0189097  0.01890969 0.0141209  0.01412084 0.02318065 0.04697406
 0.0801509  0.03920532]
tr_loss:[0.08451651 0.03607872 0.04215747 0.01237814 0.0580304  0.03607623
 0.04347471 0.02208386 0.03607626 0.01237814 0.03607622 0.03607623
 0.05802945 0.08376354 0.04336183 0.03607697 0.0304037  0.04599418
 0.02502111 0.04637264 0.01237814 0.08420266 0.0215947  0.01237812
 0.05490202 0.02159467 0.01237813 0.0214758  0.05000522 0.04625244
 0.02161276 0.01388023 0.03877609 0.04216265 0.01237812 0.02147579
 0.04172203 0.01237813 0.03828621 0.02147581 0.02965032 0.04336278
 0.02159467 0.03040379 0.02893853 0.01237812 0.03877611 0.04988763
 0.01237812 0.01359232]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2400 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2401, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2401 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2402, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2402 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2403, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2403 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2404, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2404 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2405, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2405 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2406, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2406 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2407, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2407 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2408, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2408 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2409, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2409 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2410, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2410 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2411, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2411 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2412, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2412 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2413, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2413 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2414, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2414 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2415, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2415 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2416, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2416 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2417, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2417 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2418, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2418 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2419, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2419 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2420, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2420 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2421, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2421 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2422, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2422 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2423, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2423 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2424, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2424 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2425, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2425 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2426, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2426 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2427, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2427 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2428, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2428 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2429, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2429 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2430, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2430 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2431, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2431 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2432, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2432 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2433, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2433 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2434, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2434 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2435, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2435 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2436, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2436 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2437, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2437 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2438, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2438 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2439, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2439 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2440, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2440 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2441, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2441 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2442, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2442 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2443, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2443 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2444, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2444 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2445, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2445 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2446, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2446 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2447, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2447 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2448, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2448 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2449, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2449 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2450, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2450 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2451, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2451 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2452, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2452 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2453, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2453 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2454, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2454 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2455, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2455 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2456, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2456 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2457, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2457 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2458, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2458 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2459, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2459 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2460, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2460 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2461, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2461 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2462, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2462 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2463, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2463 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2464, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2464 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2465, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2465 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2466, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2466 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2467, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2467 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2468, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2468 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2469, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2469 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2470, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2470 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2471, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2471 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2472, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2472 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2473, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2473 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2474, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2474 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2475, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2475 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2476, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2476 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2477, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2477 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2478, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2478 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2479, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2479 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2480, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2480 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2481, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2481 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2482, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2482 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2483, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2483 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2484, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2484 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2485, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2485 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2486, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2486 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2487, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2487 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2488, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2488 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2489, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2489 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2490, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2490 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2491, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2491 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2492, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2492 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2493, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2493 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2494, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2494 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2495, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2495 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2496, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2496 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2497, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2497 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2498, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2498 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2499, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2499 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2500, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2400
text_input.shape
(2500, 14400)
learning_input_tmp.shape
(2500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2500, 80)
learning_output.shape
(750, 80)
Model: "sequential_51"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_51 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.5710205 1.5606883 1.5352848 1.5698564 1.5352849 1.5667118 1.4858078
 1.5102553 1.4858022 1.5637403 1.4858067 1.5352848 1.4858079 1.5352848
 1.5352848 1.6068401 1.6068401 1.5352848 1.5698258 1.5710207 1.6069591
 1.4680796 1.6068401 1.5709499 1.37069   1.535285  1.5766133 1.5667661
 1.6095806 1.6068401 1.5698259 1.5606904 1.5352848 1.4425116 1.5352848
 1.4565885 1.5438855 1.5430644 1.485453  1.5352848 1.6068401 1.4058874
 1.5109644 1.5637449 1.5352848 1.5698258 1.5352849 1.5352848 1.4467653
 1.3714154]
tr_loss:[0.86280614 0.86280525 0.84241754 0.80981266 0.86280537 0.8424155
 0.8592278  0.85922784 0.88153267 0.8184134  0.8692128  0.8981169
 0.8692131  0.8016127  0.84241754 0.8104601  0.8692129  0.8104725
 0.88153297 0.86280537 0.8692129  0.8692129  0.8548336  0.89817584
 0.8941026  0.86280537 0.8628052  0.81949794 0.8941914  0.8651005
 0.84241754 0.84241754 0.89419097 0.85925275 0.8033797  0.8158468
 0.8815328  0.8456752  0.86921275 0.8583819  0.82210237 0.8412117
 0.85922796 0.85925466 0.88153285 0.86404496 0.88153285 0.8597946
 0.8458414  0.81677043]
tr_loss:[0.42668217 0.42272902 0.42260274 0.41662756 0.42669263 0.41672397
 0.39935938 0.4123188  0.39935946 0.41231877 0.43540525 0.4112772
 0.4123188  0.42272907 0.43551332 0.4166276  0.42144704 0.41695365
 0.4529234  0.419221   0.42360172 0.4529234  0.421012   0.40820527
 0.39937285 0.42272893 0.4151226  0.41663092 0.42272896 0.38932163
 0.3895614  0.44145632 0.44143057 0.3989635  0.3989933  0.41662756
 0.41530862 0.4112648  0.42247027 0.42197496 0.39935917 0.4172452
 0.44145554 0.41662765 0.45292765 0.44608194 0.39936304 0.39935938
 0.4166286  0.42272893]
tr_loss:[0.20377271 0.24798378 0.18862191 0.19797489 0.22227797 0.23962489
 0.20377274 0.2374082  0.22148864 0.18881932 0.2037727  0.2333894
 0.23960216 0.19798687 0.24798384 0.20377271 0.21345726 0.19798693
 0.20377266 0.24798381 0.2311792  0.20377278 0.19691242 0.19691822
 0.19798684 0.22563915 0.24092455 0.25411028 0.1884124  0.19798687
 0.2407475  0.20370364 0.18841238 0.25156417 0.18841235 0.23122005
 0.22566053 0.27978313 0.2277741  0.22552657 0.225637   0.22037125
 0.20373067 0.2796836  0.20351711 0.22563705 0.19798687 0.18883535
 0.20377274 0.23059645]
tr_loss:[0.10659708 0.10189545 0.10667568 0.10667564 0.12901363 0.13683929
 0.15604882 0.10518675 0.10667567 0.10945594 0.1066757  0.13111813
 0.10518672 0.10687785 0.10189547 0.10189547 0.10259155 0.15604873
 0.15589961 0.10418739 0.1471582  0.15604874 0.10910366 0.10518672
 0.13875769 0.14628431 0.15604869 0.11909957 0.10189543 0.10667566
 0.10667562 0.10259154 0.1356174  0.10382327 0.10667565 0.10259154
 0.1357727  0.12785986 0.10668757 0.10667565 0.10518674 0.10955721
 0.10189541 0.10667565 0.10259156 0.1091027  0.10577758 0.16142456
 0.13134162 0.1066849 ]
tr_loss:[0.04582214 0.0524608  0.07291032 0.08442236 0.05059715 0.09182139
 0.09182139 0.0524602  0.04987438 0.0522692  0.04548289 0.09182134
 0.05246024 0.09095635 0.04548285 0.04481362 0.05749286 0.0522692
 0.04486802 0.09182143 0.0918235  0.09182151 0.05059718 0.05059717
 0.05246023 0.09182145 0.05226914 0.09182139 0.05059715 0.0448625
 0.05059715 0.09182147 0.04582217 0.0764563  0.05058843 0.05059714
 0.08383349 0.05128209 0.08352019 0.099143   0.0591898  0.09215809
 0.05059716 0.08236279 0.0524602  0.04987434 0.04548287 0.05226919
 0.04795008 0.05246024]
tr_loss:[0.04727712 0.03583857 0.06135749 0.06839967 0.04581579 0.07942233
 0.03559075 0.04786269 0.07628211 0.08855756 0.06016833 0.03637448
 0.07018793 0.0523271  0.03335346 0.03932558 0.03381632 0.06016836
 0.03381632 0.05419001 0.05232707 0.0601684  0.05261631 0.03932541
 0.03559462 0.05692768 0.03690573 0.0478627  0.03637448 0.03637452
 0.03381633 0.03934451 0.08855754 0.03766715 0.03637447 0.0608516
 0.03551755 0.04766904 0.06016847 0.03716002 0.0601813  0.03381636
 0.03381632 0.03381632 0.06016837 0.03559076 0.04786271 0.04738196
 0.07872335 0.03932548]
tr_loss:[0.0394632  0.03536929 0.05360562 0.03536906 0.03820916 0.0344607
 0.03610393 0.05648777 0.03569237 0.03569236 0.05648778 0.03569238
 0.03641731 0.03536918 0.05648779 0.03569236 0.05648776 0.03610391
 0.03569237 0.04131475 0.09510733 0.05191638 0.05191637 0.07229374
 0.05360566 0.09510715 0.07960396 0.05648774 0.03569237 0.03947503
 0.03569236 0.03610391 0.03580504 0.09510498 0.03446051 0.06980386
 0.03569238 0.03569238 0.05191638 0.03569237 0.03610393 0.05647499
 0.05648784 0.03610391 0.03610393 0.03947515 0.05648773 0.07061054
 0.03610452 0.03947502]
tr_loss:[0.0489123  0.06160076 0.03285932 0.0523935  0.03216182 0.04891235
 0.05280156 0.09109661 0.03285934 0.03559956 0.06798788 0.03216182
 0.09398782 0.03559963 0.0621465  0.0489123  0.04891232 0.05285548
 0.03381447 0.03216201 0.03342404 0.06802206 0.03516887 0.03285931
 0.06815107 0.03285934 0.07772738 0.07715104 0.03285934 0.03417021
 0.04723538 0.04719377 0.05285264 0.03216183 0.03436846 0.04510368
 0.03561922 0.0355995  0.07772211 0.03216182 0.03328196 0.04891234
 0.06815101 0.03216181 0.03559952 0.06814242 0.03216181 0.03216254
 0.04891235 0.04891232]
tr_loss:[0.03862638 0.03862641 0.02823555 0.02752491 0.02594232 0.05508516
 0.08186065 0.05509081 0.03862641 0.05508521 0.02828118 0.02562897
 0.02562898 0.06273456 0.05318861 0.02594231 0.02630882 0.02562899
 0.02562896 0.02562896 0.06191281 0.02608776 0.05508528 0.02920215
 0.04851306 0.02652144 0.02722729 0.0382769  0.02562897 0.0618273
 0.02594234 0.05318917 0.0550855  0.06273259 0.02562896 0.0550852
 0.029216   0.0386264  0.05508522 0.0259423  0.02667207 0.0550852
 0.0292173  0.0292173  0.0550852  0.0292173  0.06273022 0.05508564
 0.02562898 0.02562898]
tr_loss:[0.0587497  0.02702937 0.02863849 0.05055577 0.05753879 0.03696221
 0.02702939 0.05753663 0.02444285 0.08667023 0.03029985 0.03380704
 0.02320541 0.03302513 0.0330222  0.02617378 0.05850197 0.05753643
 0.03302513 0.02702932 0.05753728 0.05753646 0.08880384 0.02335333
 0.02322804 0.05858405 0.08837526 0.06571548 0.05753647 0.03029986
 0.03302532 0.02277506 0.02444284 0.02703229 0.02499919 0.0575365
 0.02320538 0.08837526 0.02320541 0.08669999 0.04894437 0.04894473
 0.02623457 0.02320543 0.03302513 0.05187412 0.02444283 0.02527967
 0.02444285 0.06307192]
tr_loss:[0.05237944 0.08635511 0.02474942 0.02533292 0.0292406  0.02471459
 0.04770374 0.02446007 0.02924062 0.02474559 0.02233433 0.06006513
 0.08781065 0.02295633 0.04497357 0.02446434 0.02216213 0.05995866
 0.08840571 0.0223342  0.03090901 0.0599586  0.08732396 0.02924135
 0.06181746 0.03034769 0.05607067 0.02474561 0.02233422 0.02233421
 0.02924063 0.05995844 0.02233423 0.02619935 0.07052773 0.02233422
 0.02233422 0.0223342  0.02233419 0.08724961 0.04737034 0.03090907
 0.02295634 0.05995593 0.02233421 0.05995863 0.02474503 0.02924139
 0.06184478 0.06753031]
tr_loss:[0.02046408 0.05658969 0.01930691 0.02458171 0.02458173 0.05658977
 0.02715172 0.05658216 0.05658974 0.02137745 0.04370545 0.03706398
 0.02458171 0.05658751 0.03079532 0.05881371 0.08628031 0.05658972
 0.04201268 0.05658973 0.06163056 0.02715171 0.02046408 0.02137747
 0.01933786 0.05658972 0.0225286  0.03079536 0.02137744 0.02137747
 0.05639942 0.05658976 0.05658974 0.0565889  0.02310055 0.02458171
 0.05999833 0.02715171 0.02458173 0.02458174 0.02137748 0.01937312
 0.02137728 0.03079533 0.05660077 0.02685013 0.0271517  0.02046394
 0.02458173 0.02137746]
tr_loss:[0.02586258 0.03205136 0.04386921 0.09432246 0.03205135 0.02358744
 0.03584818 0.03205137 0.02696376 0.02327635 0.02696375 0.06696993
 0.04953127 0.02086588 0.03205136 0.04953128 0.02586261 0.02696376
 0.01996753 0.02035496 0.0258626  0.05118037 0.04312534 0.04953124
 0.0258626  0.02696375 0.02586261 0.04953128 0.02035498 0.03769724
 0.04449883 0.03205137 0.02035498 0.02586262 0.0258626  0.02696375
 0.06106132 0.02035496 0.02257076 0.03840356 0.02586261 0.03205138
 0.05626647 0.02035498 0.02586261 0.04390307 0.03205135 0.04953126
 0.02696378 0.02696376]
tr_loss:[0.02206487 0.0251851  0.03052262 0.03052251 0.0305218  0.02518508
 0.03490347 0.02513882 0.03052033 0.02206485 0.03610697 0.03052253
 0.02206484 0.0536854  0.04420832 0.03052251 0.02206483 0.05848843
 0.04420827 0.03052253 0.05711294 0.04420831 0.03052251 0.04420765
 0.045893   0.03411935 0.05963446 0.02518508 0.03411999 0.02206684
 0.02206485 0.02518509 0.0442083  0.04428372 0.04234407 0.0442083
 0.06650032 0.02518511 0.02206483 0.02049455 0.02206484 0.02518592
 0.02206484 0.0423388  0.0251851  0.01975175 0.09708526 0.02993169
 0.01975178 0.01975222]
tr_loss:[0.0178007  0.03362279 0.02074087 0.022916   0.03245607 0.01780069
 0.03245712 0.01923953 0.02734349 0.02074065 0.02291599 0.01783849
 0.04946126 0.01780068 0.02291599 0.0593299  0.01780069 0.04054802
 0.02291601 0.09346552 0.02825784 0.01780069 0.03193045 0.04282568
 0.02734349 0.01780069 0.02734349 0.01798554 0.04282574 0.04282568
 0.04480866 0.03213973 0.02291601 0.04062008 0.02734346 0.02734347
 0.02339304 0.02734446 0.0178007  0.02291601 0.0178007  0.04282568
 0.0577499  0.02821497 0.04282568 0.05939372 0.02074068 0.04282566
 0.02074067 0.01780069]
tr_loss:[0.03939438 0.02870972 0.02870972 0.0287097  0.02135579 0.02137957
 0.05368051 0.02870974 0.08136123 0.04132574 0.02336079 0.05507401
 0.02731926 0.02031235 0.02234747 0.02871641 0.04261877 0.02870975
 0.02346944 0.01706243 0.02731925 0.02870973 0.09073403 0.02135579
 0.0426183  0.05509467 0.02135579 0.01706242 0.04261819 0.02870663
 0.0213297  0.04984427 0.02870972 0.02352139 0.02135578 0.03740906
 0.02870974 0.08136124 0.0277882  0.02199429 0.04215132 0.02072609
 0.06584203 0.02871537 0.02731947 0.03740879 0.02135578 0.02870972
 0.04261878 0.04261873]
tr_loss:[0.04414322 0.02457348 0.02258013 0.01983673 0.03119657 0.01983575
 0.0245634  0.0550824  0.01983664 0.01761504 0.04414324 0.04414322
 0.03119658 0.02669518 0.03119658 0.05130339 0.08012767 0.01983667
 0.0225801  0.03119659 0.01761503 0.03354518 0.04387077 0.02456213
 0.04003393 0.01761503 0.02258013 0.04466694 0.04414324 0.03405812
 0.04279615 0.0556471  0.06613268 0.01761504 0.06701091 0.08778016
 0.03119658 0.02350189 0.03119658 0.02258012 0.04406589 0.03284059
 0.08014727 0.01983664 0.03214177 0.01761504 0.0441432  0.03119659
 0.01983668 0.03382667]
tr_loss:[0.03948563 0.04536181 0.02395767 0.0206593  0.02634526 0.01931304
 0.02756435 0.04309627 0.04536175 0.04536179 0.05646403 0.03118523
 0.02065929 0.02065931 0.03441333 0.03441535 0.04369692 0.02065931
 0.01931305 0.02714314 0.02369537 0.02714403 0.0206593  0.03441537
 0.078816   0.02065917 0.04536138 0.03441535 0.04211063 0.02369384
 0.01931294 0.02637221 0.01931226 0.0453618  0.0237368  0.05388107
 0.03341964 0.04536175 0.03441536 0.03441537 0.04212134 0.01931305
 0.08631005 0.04536176 0.02395768 0.03580913 0.04536178 0.0239577
 0.078817   0.03426119]
tr_loss:[0.01889287 0.01831194 0.0438651  0.01834618 0.0333338  0.01889286
 0.04159007 0.02090602 0.01889286 0.04158596 0.08505697 0.0208962
 0.03333418 0.02324824 0.04326916 0.02323871 0.07773709 0.03193713
 0.01889287 0.02564757 0.02089621 0.02089652 0.08354139 0.01889286
 0.07773618 0.03107369 0.02324826 0.07768973 0.03265135 0.04158897
 0.01889286 0.06885939 0.03333418 0.04158895 0.04158896 0.01889289
 0.04158897 0.01889288 0.05440024 0.03333418 0.03333417 0.02085677
 0.04519608 0.04256164 0.03333417 0.0694228  0.0592387  0.0208962
 0.0208962  0.05439583]
tr_loss:[0.0195544  0.08308195 0.04090299 0.0195544  0.02254762 0.02086253
 0.02086253 0.03838721 0.02978351 0.03838723 0.0225529  0.03838722
 0.03915295 0.08308244 0.0297835  0.03504844 0.03838722 0.02220916
 0.02086501 0.02255289 0.0511414  0.02086253 0.01955441 0.0225529
 0.04305356 0.03504811 0.06320298 0.04101876 0.03838724 0.02978351
 0.02086365 0.02086253 0.0297835  0.02978351 0.0186483  0.08442216
 0.02256412 0.03838723 0.01864839 0.08308192 0.02978351 0.03838724
 0.03562985 0.04101883 0.02079744 0.0195544  0.01994926 0.02978352
 0.02255267 0.02086252]
tr_loss:[0.02082244 0.04663021 0.02065153 0.01987559 0.01864888 0.03595809
 0.03017899 0.03774036 0.01948611 0.01944992 0.03595745 0.02916951
 0.02065153 0.05946475 0.02581515 0.0194861  0.02082537 0.02082181
 0.03775182 0.02082172 0.02581511 0.0194861  0.03791394 0.08419872
 0.01948612 0.02286338 0.03595806 0.01948613 0.03985599 0.01948612
 0.02916946 0.02046844 0.03790358 0.02065151 0.02065151 0.03595806
 0.01948613 0.04038043 0.03595809 0.02082176 0.02052571 0.02082176
 0.02099705 0.02581512 0.03093201 0.02065151 0.02117412 0.03210784
 0.02082174 0.03595792]
tr_loss:[0.02248732 0.0353145  0.03531431 0.02413148 0.01781018 0.02158555
 0.02378394 0.02722323 0.0327461  0.02158554 0.01781018 0.03657215
 0.01781017 0.02413147 0.0353145  0.02158553 0.01788068 0.01787994
 0.02158554 0.03531448 0.01540577 0.01781019 0.03531449 0.04127734
 0.03656914 0.02158553 0.02733609 0.02413146 0.01787614 0.04968757
 0.02378304 0.03399744 0.02158554 0.08384834 0.01813915 0.01813702
 0.0181083  0.0189149  0.02413163 0.02158554 0.08540113 0.02831752
 0.02158552 0.02413147 0.04851143 0.01781018 0.02158553 0.04996743
 0.018137   0.02413148]
tr_loss:[0.02461942 0.02813095 0.02461934 0.02246116 0.02461942 0.01687511
 0.03893124 0.0504808  0.02246114 0.02246119 0.01791147 0.02462113
 0.02461942 0.03893294 0.0189212  0.02461942 0.01960221 0.05523416
 0.01800541 0.02461941 0.01892123 0.02246074 0.02114552 0.02246115
 0.03893291 0.01892122 0.02461941 0.02246116 0.03441074 0.05843189
 0.01791144 0.02246115 0.03271189 0.03893295 0.03707284 0.02246115
 0.01887949 0.03408678 0.01708662 0.033857   0.01892123 0.01791147
 0.02578688 0.0246194  0.02461942 0.05655335 0.01892122 0.01892122
 0.02461941 0.02461942]
tr_loss:[0.01990118 0.02382614 0.02812784 0.02382613 0.0201916  0.04112459
 0.04118226 0.02991853 0.01990118 0.04118227 0.03800143 0.04117987
 0.05527516 0.07636975 0.04765419 0.02812783 0.02019161 0.05752488
 0.02382613 0.02019161 0.01839545 0.01990117 0.01990118 0.01990116
 0.05752713 0.04441952 0.0183954  0.01990117 0.01839331 0.01528261
 0.01990119 0.02381297 0.03178944 0.01602206 0.01991166 0.01937022
 0.03528064 0.01614866 0.01659453 0.02019161 0.03784866 0.02676231
 0.02019165 0.04118191 0.01610256 0.02691346 0.02676122 0.01772725
 0.04118229 0.01839796]
tr_loss:[0.01622044 0.05144072 0.03981129 0.01496243 0.01864422 0.03981132
 0.03980647 0.05127794 0.01622043 0.02730077 0.08228546 0.03650943
 0.07565782 0.01989112 0.0518821  0.01864422 0.01715649 0.02637363
 0.02652432 0.03981132 0.02832511 0.01864423 0.02327589 0.07520257
 0.01989109 0.0149657  0.02832269 0.01622751 0.01864419 0.01622044
 0.02079471 0.02219367 0.02951719 0.01989111 0.01989113 0.03981131
 0.01622043 0.0350103  0.01622044 0.02327591 0.03884362 0.01622044
 0.01622043 0.02471314 0.01864422 0.02832649 0.0232759  0.02912964
 0.02327591 0.07565884]
tr_loss:[0.04984046 0.04605856 0.0372919  0.02556994 0.01849706 0.03890042
 0.02460608 0.01972959 0.01709567 0.0246061  0.01377842 0.05727835
 0.01377843 0.01377842 0.05724441 0.01377842 0.04605884 0.02906898
 0.02557531 0.01972959 0.01359458 0.01972959 0.02460613 0.01972963
 0.01376982 0.03722116 0.01972959 0.0197296  0.01972959 0.01869926
 0.02580431 0.02075346 0.029069   0.0197296  0.02556664 0.04889445
 0.01972961 0.02392209 0.0197235  0.01377842 0.01377842 0.0197258
 0.03729185 0.01377842 0.02075506 0.04697297 0.0197296  0.01377845
 0.01377842 0.04991063]
tr_loss:[0.02086158 0.02830504 0.0357274  0.03572874 0.01360572 0.01935778
 0.01360571 0.05928318 0.05707384 0.01952633 0.0500019  0.02660064
 0.0226688  0.01898417 0.01360572 0.01952634 0.03572751 0.02660064
 0.02271397 0.02660063 0.04158933 0.03578961 0.01360572 0.01360572
 0.03959879 0.01982164 0.01952632 0.04760977 0.04357684 0.0265971
 0.01812364 0.02429744 0.01952633 0.02660064 0.01946444 0.02401518
 0.02237487 0.03369293 0.03572744 0.03572744 0.05704515 0.01952634
 0.02267057 0.02660063 0.03572742 0.02660063 0.02271399 0.01923998
 0.02660065 0.02401515]
tr_loss:[0.02801755 0.03486431 0.02103651 0.02655485 0.01975521 0.02108941
 0.02102938 0.02125485 0.03486379 0.01829997 0.01976321 0.02125862
 0.0280414  0.03486344 0.02010217 0.03486345 0.01994025 0.01461591
 0.03486428 0.03486346 0.01937234 0.06050646 0.02607789 0.02127491
 0.01922165 0.01461557 0.02655479 0.02555298 0.01461591 0.03486349
 0.01461591 0.03126068 0.01976323 0.03486351 0.03126065 0.01976321
 0.02655482 0.08104877 0.01937235 0.03486344 0.02655481 0.03486344
 0.0197632  0.03097416 0.03486346 0.03802976 0.04680822 0.05637818
 0.01461591 0.02435082]
tr_loss:[0.03362627 0.02087471 0.01856977 0.03362633 0.02684422 0.01620015
 0.01618183 0.0196495  0.01920806 0.01920805 0.02056794 0.01620013
 0.03362632 0.01967171 0.0368365  0.02882885 0.01920805 0.01620015
 0.02684421 0.01620014 0.03362632 0.01942449 0.02684422 0.03359658
 0.02228674 0.01920805 0.02056806 0.02056798 0.01788141 0.01920804
 0.01920805 0.02684422 0.01920805 0.03362631 0.01620013 0.03048258
 0.02684422 0.0196495  0.02909691 0.01920805 0.03901603 0.02173803
 0.01928295 0.01920805 0.02796794 0.0336263  0.04534877 0.01788146
 0.06147934 0.02882882]
text_input.shape
(2500, 14400)
learning_input_tmp.shape
(2500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2500, 80)
learning_output.shape
(750, 80)
Model: "sequential_52"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_52 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3231696 1.2144712 1.2799242 1.2455127 1.3328388 1.2788836 1.2145509
 1.3015236 1.2745556 1.214551  1.2145509 1.3215227 1.2846798 1.3328388
 1.2799246 1.2675254 1.2145607 1.3489631 1.2024188 1.2455336 1.3215227
 1.3328388 1.2046688 1.1918211 1.3328388 1.3328388 1.2772052 1.2764934
 1.3328388 1.2799245 1.2846798 1.1941848 1.2798033 1.2846819 1.2799245
 1.214551  1.3215227 1.2145507 1.214551  1.3228862 1.2846799 1.2177825
 1.2145495 1.2029182 1.2817997 1.3215226 1.3215225 1.3489627 1.2131064
 1.214528 ]
tr_loss:[0.78393865 0.81975496 0.83655185 0.85377836 0.8592798  0.9031733
 0.8592798  0.8338025  0.7736176  0.86183566 0.83240235 0.93783665
 0.78755605 0.86183566 0.90317327 0.86257    0.90317345 0.7726191
 0.9031674  0.86412317 0.83240235 0.7197453  0.85927975 0.8324022
 0.86183566 0.8438223  0.86183566 0.7838029  0.9031733  0.90317345
 0.8324022  0.9203644  0.86572105 0.7832897  0.8618356  0.9031733
 0.9031733  0.83167297 0.8647348  0.9031733  0.83168966 0.83240235
 0.85377824 0.90317345 0.8324022  0.8324022  0.90363085 0.8592798
 0.7197277  0.78380275]
tr_loss:[0.61914396 0.5847101  0.504066   0.5571495  0.5491282  0.5510702
 0.58470994 0.55112725 0.5571493  0.6862958  0.55525196 0.5017334
 0.5592259  0.57396734 0.5086265  0.5739665  0.5571493  0.55257034
 0.5481081  0.58129025 0.6024917  0.5847144  0.5739498  0.53831065
 0.6660527  0.5571493  0.52546227 0.52874833 0.60249186 0.55714935
 0.5373739  0.5175216  0.5809372  0.49840227 0.55706006 0.51215094
 0.5962718  0.5827423  0.5510701  0.5525463  0.55199254 0.5510718
 0.51034856 0.55107015 0.5571494  0.55107015 0.60249174 0.55714923
 0.57111657 0.58371097]
tr_loss:[0.36865407 0.32410592 0.41594464 0.37832206 0.35369307 0.3686491
 0.3207035  0.36865377 0.43684512 0.32581288 0.34918302 0.378322
 0.32410592 0.35339266 0.3578847  0.32409427 0.37832204 0.36865407
 0.36902323 0.37832204 0.4159457  0.3508764  0.359759   0.3013169
 0.32409924 0.37832206 0.35341907 0.29167107 0.36865416 0.2889243
 0.3398394  0.37832206 0.353409   0.37833807 0.36865404 0.41585612
 0.35340896 0.30412906 0.3398167  0.36865407 0.3686541  0.35344666
 0.32410592 0.32410583 0.40682235 0.30890974 0.3494059  0.36865407
 0.35854405 0.35340896]
tr_loss:[0.2011222  0.20112221 0.23035197 0.189943   0.2192053  0.1848759
 0.19456527 0.17854385 0.21647969 0.1945653  0.18223551 0.2514487
 0.19443563 0.19084443 0.1944974  0.2239627  0.20112221 0.23664927
 0.19456531 0.18487592 0.2365559  0.19716556 0.2011222  0.23358707
 0.23672195 0.24772353 0.20112224 0.19084448 0.19439428 0.23847087
 0.19603518 0.2121664  0.1908444  0.18225217 0.19549045 0.20367137
 0.18487594 0.18997264 0.17769802 0.2012016  0.19084445 0.19956136
 0.19461259 0.19084445 0.19456527 0.18487604 0.19546525 0.19603518
 0.19084446 0.24665399]
tr_loss:[0.10503219 0.11959176 0.12204438 0.12348155 0.15803322 0.10444725
 0.11394266 0.14369431 0.10648938 0.12199786 0.16296154 0.1065563
 0.13247308 0.10501163 0.11959179 0.12348151 0.10195391 0.12489533
 0.1626591  0.12992558 0.10503221 0.10196042 0.13871835 0.11959176
 0.10655709 0.13003027 0.10195391 0.11959176 0.15482196 0.14979209
 0.10433201 0.10655711 0.10655711 0.14894119 0.11959174 0.11959176
 0.10503218 0.10655703 0.14041725 0.11361325 0.11941986 0.15266788
 0.12200029 0.11959171 0.11959176 0.12348153 0.11937334 0.15423337
 0.10195367 0.10655703]
tr_loss:[0.08151844 0.08242624 0.14098683 0.10689632 0.09495733 0.08055986
 0.12874994 0.12328549 0.08056015 0.12552826 0.10180935 0.11861179
 0.11634861 0.10200913 0.11330001 0.08740246 0.11809228 0.11809234
 0.11809232 0.08151846 0.09842209 0.1180923  0.08151845 0.08151842
 0.08242625 0.10971539 0.08242626 0.09495881 0.08151837 0.08242626
 0.08740243 0.12567696 0.11809234 0.09495739 0.0815184  0.09264746
 0.08242624 0.14098717 0.08151845 0.09496355 0.08242626 0.08056029
 0.1254982  0.08151811 0.08182462 0.08242624 0.1180923  0.1163703
 0.14098719 0.12876873]
tr_loss:[0.08450449 0.08450449 0.12351523 0.08450449 0.07086127 0.07095753
 0.06834631 0.11288118 0.07095753 0.07629408 0.11286996 0.12337042
 0.07629596 0.13002285 0.07291807 0.11731295 0.07095752 0.08450449
 0.07629338 0.12945092 0.07227875 0.07227869 0.09947959 0.07303394
 0.11302839 0.07291807 0.12352254 0.11286996 0.07291809 0.07095752
 0.07291809 0.08450449 0.07028691 0.08449233 0.11286993 0.07291807
 0.07291809 0.07095753 0.07291807 0.07629595 0.11287534 0.09738643
 0.07095753 0.07227869 0.11286988 0.09737803 0.1027871  0.0845045
 0.07291806 0.07227872]
tr_loss:[0.07784116 0.11502542 0.07278363 0.07279362 0.13171823 0.10044795
 0.08177449 0.07800264 0.07381779 0.07313357 0.08177449 0.11494782
 0.13171783 0.08150105 0.07784121 0.1370074  0.08177454 0.11494784
 0.1045032  0.10374974 0.08177451 0.07235815 0.07278367 0.10993212
 0.08177443 0.07313373 0.09164989 0.13171817 0.07794122 0.07278368
 0.07048959 0.07048956 0.08177447 0.07278378 0.07543299 0.07048957
 0.14366646 0.07048957 0.0817745  0.07048957 0.07991178 0.12109097
 0.07048955 0.07318213 0.07313365 0.1263806  0.07991172 0.07048959
 0.09299373 0.07278366]
tr_loss:[0.07987833 0.10438533 0.07577898 0.14421666 0.07987835 0.07419831
 0.11632042 0.08119436 0.13164538 0.07419831 0.07419832 0.07398359
 0.07419829 0.13631387 0.07674671 0.07398356 0.0906949  0.1163203
 0.07577915 0.13342658 0.0741983  0.13066314 0.07457081 0.11632053
 0.12837933 0.07987831 0.11632033 0.07987832 0.07675556 0.07915602
 0.11312604 0.11048504 0.07419832 0.11632092 0.07419828 0.0739836
 0.11632049 0.12682818 0.07674821 0.07398357 0.12870722 0.07987834
 0.12837279 0.07987832 0.07419829 0.10560862 0.11634029 0.09069487
 0.12837091 0.07419833]
tr_loss:[0.11110232 0.07918779 0.07302256 0.07924895 0.10751126 0.07918781
 0.0791878  0.07419641 0.07427742 0.07412674 0.07296703 0.11110236
 0.10870846 0.07427744 0.07302163 0.07307258 0.11279819 0.07918782
 0.10054853 0.07296705 0.08829568 0.07368648 0.10919819 0.13003042
 0.13741896 0.07412674 0.11110727 0.10920574 0.08023803 0.13051462
 0.12608738 0.07296706 0.10548858 0.07296705 0.08180498 0.07427746
 0.07296707 0.07630748 0.07427744 0.07918777 0.11110238 0.0791878
 0.11110232 0.07296703 0.07918779 0.07427742 0.11110866 0.08032681
 0.1331914  0.13497922]
tr_loss:[0.10682328 0.07026383 0.06888791 0.07859115 0.10167976 0.12842706
 0.10172322 0.08770454 0.08053705 0.0688879  0.06867872 0.10232797
 0.13535622 0.07026383 0.08043322 0.10182017 0.06858556 0.07859118
 0.10168068 0.08043329 0.06778447 0.1277366  0.08043321 0.10167976
 0.06888787 0.07026385 0.10167974 0.10180621 0.13148475 0.07026384
 0.0688879  0.07026383 0.0688879  0.10168137 0.07026383 0.0688879
 0.10260633 0.06839162 0.0804332  0.06867291 0.1292731  0.0688879
 0.06888791 0.11873557 0.10169198 0.06867295 0.06834362 0.08043323
 0.10167974 0.11877368]
tr_loss:[0.08718821 0.06936507 0.06752199 0.06936754 0.09452989 0.08718824
 0.06560778 0.10149904 0.08654594 0.09497256 0.06936763 0.08718828
 0.13583913 0.06560776 0.06752198 0.06936765 0.087189   0.06567848
 0.06560779 0.13851796 0.08716736 0.13296059 0.0768928  0.06936667
 0.06597741 0.10516401 0.0831281  0.08718702 0.06560776 0.09497099
 0.06936765 0.08312809 0.10402626 0.11560444 0.06560861 0.08312811
 0.06936766 0.08718824 0.08718825 0.08718823 0.10039189 0.08718821
 0.06512871 0.06560682 0.06638493 0.08718826 0.08718822 0.06752195
 0.13743047 0.06936765]
tr_loss:[0.08626229 0.09419826 0.09419824 0.06852616 0.07299292 0.09419826
 0.08758825 0.08628748 0.06852618 0.0856429  0.09900537 0.11478214
 0.06886323 0.07299293 0.11040608 0.0941997  0.08208956 0.08570358
 0.06852616 0.06722961 0.07299291 0.10147715 0.08119631 0.11040606
 0.06718148 0.11676015 0.0962396  0.08556865 0.08758828 0.0942084
 0.12468326 0.07299291 0.06852614 0.08570789 0.08758828 0.08570357
 0.09419845 0.08217563 0.06852616 0.08556751 0.0816961  0.10870437
 0.09419825 0.09419861 0.07258134 0.08573797 0.08758825 0.06722967
 0.06852615 0.06722963]
tr_loss:[0.07362959 0.09314177 0.0690377  0.09314013 0.07068969 0.08118669
 0.07362958 0.07362957 0.12475146 0.06903791 0.09314013 0.09314018
 0.08167343 0.08987006 0.08757187 0.07362959 0.06871702 0.12097095
 0.09107194 0.08054575 0.12096708 0.06903769 0.12097925 0.08054577
 0.12469049 0.08054576 0.06738446 0.08054575 0.09314011 0.06903769
 0.07362957 0.09314008 0.07356582 0.08054575 0.09314014 0.08054575
 0.07362957 0.06903769 0.06871681 0.08736588 0.09314013 0.07362958
 0.0736296  0.08054574 0.06703961 0.06903935 0.06871682 0.0931517
 0.0736296  0.0690377 ]
tr_loss:[0.07234688 0.12033232 0.12956497 0.08203194 0.08201808 0.07569508
 0.07046663 0.07046662 0.06766721 0.08203031 0.07569511 0.07569508
 0.0756951  0.07549609 0.07061833 0.06935241 0.07046661 0.07569508
 0.09438328 0.07569507 0.07569505 0.07234688 0.07234689 0.08203199
 0.0756951  0.10266723 0.10399085 0.09429672 0.08937611 0.08394535
 0.08904718 0.07569507 0.07575332 0.08090112 0.07234689 0.07046665
 0.07569508 0.09438153 0.09438153 0.07046663 0.07046665 0.10386632
 0.0943815  0.07046664 0.09440582 0.12061827 0.12757353 0.07569508
 0.07046662 0.07046664]
tr_loss:[0.06995021 0.07288662 0.07249531 0.0724953  0.08080359 0.07293034
 0.11143421 0.07143399 0.06995023 0.0975183  0.06995022 0.09751816
 0.13397905 0.09751985 0.10848358 0.0712531  0.0698403  0.0724953
 0.0724953  0.07292825 0.09552778 0.11865057 0.07143398 0.07376856
 0.12809166 0.07143398 0.07121632 0.07249531 0.07801537 0.09751894
 0.09751818 0.09851638 0.07143398 0.07130577 0.09751816 0.07121633
 0.13397989 0.0707546  0.08430227 0.07143261 0.07143401 0.09159692
 0.06997733 0.0712163  0.09751819 0.09851636 0.07250194 0.09751815
 0.09851637 0.06995699]
tr_loss:[0.06678097 0.12647915 0.10754018 0.12049071 0.10535159 0.07229409
 0.09532348 0.06827642 0.09532344 0.08344752 0.06827641 0.06824356
 0.12177857 0.06994218 0.09585709 0.07229408 0.08512172 0.06678072
 0.0682764  0.08478545 0.09053725 0.06678075 0.09532347 0.07229395
 0.06827641 0.09532345 0.06827635 0.09455957 0.09053744 0.07229339
 0.06827642 0.09041537 0.08478551 0.0668027  0.09478585 0.10950315
 0.12100589 0.09379832 0.09381277 0.06827284 0.1042342  0.07884192
 0.06678072 0.09381227 0.06827641 0.0953235  0.12878208 0.06994219
 0.06827641 0.09968042]
tr_loss:[0.07225804 0.09162457 0.10798307 0.0916419  0.10369913 0.10205396
 0.13334492 0.09282897 0.06785563 0.0880879  0.09162429 0.08481992
 0.07225806 0.06383853 0.10818817 0.06785562 0.0848915  0.06785563
 0.08363275 0.06591338 0.07225806 0.07225806 0.07225803 0.06591337
 0.06384434 0.08491824 0.06785562 0.09162428 0.10795909 0.09370927
 0.06785563 0.09802771 0.10369918 0.06383848 0.07225803 0.09800583
 0.0678556  0.06383848 0.06394637 0.09481369 0.10532627 0.11051665
 0.06383848 0.09162425 0.12735675 0.06383847 0.07815133 0.0950751
 0.06300686 0.07084148]
tr_loss:[0.08936621 0.08515714 0.11854575 0.06862645 0.06273461 0.08466138
 0.0627346  0.07443495 0.09673658 0.08711915 0.07801986 0.08946782
 0.12320349 0.06358601 0.07868992 0.06862641 0.11908307 0.09446216
 0.09444673 0.06862644 0.08466139 0.08466138 0.08470592 0.06050961
 0.0636836  0.06358598 0.11854751 0.1185024  0.06358601 0.063586
 0.063586   0.063586   0.06273461 0.06862644 0.07105221 0.0627346
 0.063586   0.09682886 0.06273462 0.06273462 0.06358598 0.06273461
 0.06273463 0.06862645 0.07868989 0.07801991 0.08466139 0.07801986
 0.09202798 0.06274031]
tr_loss:[0.06680875 0.06148853 0.04924646 0.06221094 0.0492465  0.06953846
 0.05250837 0.04924646 0.059435   0.0525084  0.06953846 0.06924316
 0.07295634 0.04948641 0.05979159 0.06953849 0.04948602 0.05649533
 0.06007522 0.07541676 0.04924644 0.07080559 0.06406798 0.06954089
 0.072959   0.04821903 0.06953847 0.05898406 0.07720282 0.05676579
 0.04948699 0.10363881 0.04924644 0.07565101 0.04924644 0.06953849
 0.05250839 0.10767406 0.06007792 0.04924644 0.05628024 0.09369469
 0.10604279 0.05936105 0.04924646 0.04924646 0.0695385  0.0565177
 0.04924646 0.05651773]
tr_loss:[0.03358171 0.0323827  0.04314207 0.02627281 0.08448183 0.07905656
 0.0286584  0.02627281 0.06728671 0.0304817  0.03358168 0.04623943
 0.0304817  0.02627279 0.0462498  0.02627271 0.04630718 0.04623948
 0.03048168 0.03048171 0.05706863 0.03238622 0.03192227 0.02473375
 0.02627276 0.03339749 0.02742897 0.02626981 0.03358171 0.04184655
 0.04624029 0.03367472 0.07829383 0.02716857 0.04270345 0.08579797
 0.04623948 0.02742899 0.02627277 0.03238269 0.03232567 0.03048169
 0.05698424 0.02627279 0.07829412 0.0335817  0.02742898 0.03358171
 0.03048167 0.03236397]
tr_loss:[0.07581478 0.03902193 0.02120537 0.02120537 0.01879993 0.0390219
 0.07581862 0.02120538 0.02387946 0.07581812 0.01879994 0.01880271
 0.02389227 0.02120537 0.06663455 0.01536099 0.02387946 0.03902193
 0.03697023 0.02120538 0.01879994 0.03902233 0.07581838 0.01879994
 0.01465616 0.01536108 0.03275914 0.05540807 0.01539263 0.02387945
 0.02387946 0.03907087 0.03902194 0.03902195 0.0207294  0.04044872
 0.02498554 0.01879995 0.02387945 0.01536099 0.02387946 0.08640008
 0.02387947 0.02120537 0.03902194 0.01536098 0.02120538 0.01880042
 0.02387949 0.03902192]
tr_loss:[0.02796026 0.02257405 0.01746994 0.01465199 0.01360009 0.02795738
 0.03477003 0.02929022 0.06400661 0.07966244 0.06830498 0.01746994
 0.04945625 0.02624386 0.01466296 0.0232312  0.02795736 0.01297697
 0.03808525 0.01297697 0.03797543 0.04880639 0.07930903 0.03797496
 0.03797493 0.07047572 0.01465198 0.01297766 0.01465228 0.0425269
 0.01358998 0.02257405 0.0174698  0.01746994 0.03797527 0.03797504
 0.01297695 0.01746682 0.03639295 0.01297694 0.02257405 0.01746994
 0.014652   0.03670623 0.01465196 0.03797494 0.01413148 0.07930722
 0.05467566 0.01465197]
tr_loss:[0.01463053 0.04746855 0.03418616 0.02956587 0.03945346 0.03940581
 0.03318831 0.03730746 0.03940586 0.01709997 0.04059934 0.02201701
 0.04147058 0.01329254 0.01177058 0.02201701 0.01709996 0.03631913
 0.03940583 0.04128523 0.01709994 0.07707866 0.01709995 0.02201701
 0.022017   0.05006437 0.01311245 0.07419662 0.02201702 0.03940583
 0.07423577 0.05435546 0.05228423 0.02201708 0.03941061 0.02201703
 0.03940583 0.02201702 0.01709993 0.02201701 0.01329245 0.02956589
 0.01709994 0.07842735 0.02847506 0.05008946 0.01311297 0.01177146
 0.01329248 0.01709994]
tr_loss:[0.06425298 0.03510018 0.01218793 0.01700735 0.0185193  0.03754336
 0.06805632 0.01274267 0.0112902  0.0185276  0.01852763 0.0185276
 0.0371809  0.01700735 0.01700735 0.07449038 0.03987543 0.02682474
 0.01852789 0.06879883 0.01700735 0.06805036 0.075275   0.01700735
 0.01700735 0.01218794 0.01218793 0.03986909 0.01854056 0.03077132
 0.01277177 0.01852761 0.03453362 0.01218795 0.01218793 0.01277176
 0.03077148 0.01700735 0.01691141 0.03986897 0.04835185 0.01852762
 0.05570519 0.01852761 0.01852762 0.02685612 0.03718068 0.0377446
 0.03986353 0.07086418]
tr_loss:[0.0129872  0.01808856 0.0343249  0.01338319 0.03430619 0.0162345
 0.0248371  0.01338317 0.01298721 0.05140776 0.06429981 0.05314045
 0.04200456 0.03590099 0.02759244 0.03590101 0.03391528 0.01808856
 0.01338321 0.01444194 0.01808855 0.05152532 0.04202764 0.04200459
 0.04201325 0.01808857 0.01808857 0.0162345  0.01818791 0.01808855
 0.01179154 0.04200459 0.01623449 0.01779296 0.02755806 0.01623449
 0.03503953 0.033804   0.01298719 0.01807598 0.05259202 0.03818427
 0.01808856 0.02927502 0.01623451 0.04200456 0.02319039 0.01623478
 0.05658581 0.01338321]
tr_loss:[0.03587838 0.01188178 0.04330519 0.03740186 0.01425655 0.01839971
 0.02737847 0.01425655 0.01425655 0.0183997  0.01347443 0.07808992
 0.01839971 0.01347443 0.0118765  0.01425654 0.01187625 0.01425654
 0.02738075 0.01681712 0.01425654 0.01425655 0.01425655 0.0183997
 0.04330626 0.0168171  0.01839957 0.01347443 0.04806553 0.03436062
 0.01425655 0.01839969 0.01681712 0.01425655 0.06655731 0.043309
 0.0183997  0.0183997  0.04777762 0.02971168 0.04330522 0.07200925
 0.04330519 0.01628131 0.0433052  0.03654879 0.04330523 0.01839971
 0.01435483 0.01832567]
tr_loss:[0.02844922 0.01339318 0.01820344 0.01425225 0.01965594 0.01339344
 0.07723337 0.01656619 0.02974241 0.03084085 0.04097536 0.01425224
 0.06727906 0.01820346 0.01189614 0.0347289  0.04095864 0.0372315
 0.04095846 0.01057885 0.03129854 0.01656619 0.01189615 0.04096065
 0.03395097 0.06720135 0.02974234 0.01425355 0.01820344 0.05732139
 0.01656619 0.03384555 0.01820345 0.05713025 0.034804   0.01820344
 0.01425225 0.07238172 0.05350328 0.04095845 0.01189625 0.03723177
 0.02980327 0.0486972  0.04095853 0.01656619 0.04807901 0.01820346
 0.01425225 0.02845055]
tr_loss:[0.01487848 0.01599178 0.0148785  0.03602159 0.01203248 0.01599179
 0.01203237 0.01487851 0.05174102 0.0289721  0.0148785  0.03946461
 0.01526938 0.01970925 0.01487849 0.0106828  0.04610256 0.01599178
 0.01487852 0.01599178 0.01971071 0.02909455 0.01969726 0.03946463
 0.01970982 0.02897212 0.01599118 0.01487849 0.03176464 0.02057429
 0.01599178 0.03510027 0.03946454 0.03946466 0.03013224 0.03173194
 0.01487851 0.01075607 0.01970982 0.07645677 0.0120232  0.02897209
 0.01487851 0.04160156 0.02542793 0.01970981 0.03001435 0.05559416
 0.01970983 0.06691724]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2500 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2501, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2501 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2502, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2502 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2503, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2503 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2504, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2504 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2505, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2505 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2506, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2506 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2507, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2507 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2508, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2508 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2509, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2509 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2510, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2510 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2511, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2511 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2512, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2512 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2513, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2513 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2514, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2514 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2515, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2515 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2516, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2516 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2517, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2517 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2518, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2518 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2519, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2519 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2520, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2520 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2521, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2521 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2522, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2522 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2523, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2523 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2524, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2524 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2525, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2525 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2526, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2526 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2527, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2527 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2528, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2528 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2529, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2529 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2530, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2530 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2531, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2531 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2532, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2532 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2533, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2533 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2534, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2534 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2535, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2535 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2536, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2536 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2537, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2537 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2538, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2538 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2539, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2539 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2540, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2540 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2541, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2541 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2542, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2542 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2543, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2543 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2544, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2544 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2545, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2545 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2546, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2546 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2547, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2547 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2548, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2548 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2549, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2549 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2550, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2550 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2551, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2551 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2552, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2552 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2553, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2553 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2554, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2554 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2555, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2555 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2556, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2556 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2557, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2557 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2558, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2558 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2559, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2559 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2560, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2560 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2561, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2561 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2562, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2562 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2563, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2563 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2564, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2564 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2565, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2565 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2566, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2566 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2567, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2567 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2568, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2568 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2569, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2569 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2570, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2570 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2571, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2571 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2572, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2572 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2573, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2573 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2574, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2574 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2575, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2575 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2576, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2576 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2577, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2577 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2578, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2578 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2579, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2579 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2580, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2580 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2581, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2581 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2582, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2582 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2583, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2583 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2584, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2584 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2585, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2585 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2586, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2586 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2587, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2587 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2588, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2588 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2589, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2589 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2590, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2590 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2591, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2591 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2592, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2592 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2593, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2593 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2594, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2594 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2595, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2595 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2596, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2596 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2597, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2597 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2598, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2598 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2599, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2599 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2600, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2500
text_input.shape
(2600, 14400)
learning_input_tmp.shape
(2600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2600, 80)
learning_output.shape
(750, 80)
Model: "sequential_53"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_53 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.03443    0.9845505  0.97697943 0.9422801  1.0554303  1.03443
 0.988567   1.0865405  0.94228    0.97800887 1.0344299  1.0950333
 1.0554277  0.98867494 0.9422792  0.9422757  1.0344301  1.03443
 1.0554343  0.98360217 1.0344301  1.0551596  0.9885662  1.0923556
 1.0865402  1.0055908  1.0865402  1.0344299  0.94228    1.0950334
 1.0398142  1.0344299  1.0580314  1.0600986  1.0398144  1.0528696
 1.0865418  1.0865402  1.0865402  1.0344301  1.0538439  1.0497502
 1.0344299  0.94228    1.0878408  1.0950333  1.0398142  0.9422801
 1.0865451  1.053937  ]
tr_loss:[0.5702604  0.5763384  0.57995254 0.53294325 0.60651386 0.4917361
 0.5329431  0.49362803 0.57899696 0.5713064  0.52893704 0.5614862
 0.5332885  0.5742067  0.57027894 0.5702604  0.5702604  0.49167386
 0.5702604  0.491736   0.5270939  0.5742067  0.48887378 0.49173617
 0.5799524  0.49173436 0.57420665 0.4760293  0.57700336 0.5799525
 0.47568536 0.48893088 0.6592773  0.5799445  0.57062167 0.5799524
 0.49172974 0.5599326  0.6067868  0.5787996  0.57035416 0.57420665
 0.5614532  0.5702604  0.560073   0.4759837  0.53275335 0.4937714
 0.6065199  0.49172792]
tr_loss:[0.3023185  0.32935762 0.32935768 0.32935768 0.3516764  0.32941908
 0.28904596 0.32941905 0.28149202 0.29241642 0.35048145 0.292917
 0.3205685  0.32935768 0.30782813 0.30782813 0.32749647 0.32056868
 0.3246195  0.3305763  0.31058723 0.32067275 0.3078281  0.30782813
 0.3172299  0.29278404 0.32471356 0.3246196  0.30457824 0.35048154
 0.281492   0.3205685  0.28149197 0.30458122 0.28146243 0.30782816
 0.3246196  0.32461968 0.28149205 0.32056865 0.30782813 0.3205685
 0.29330364 0.32056847 0.29291704 0.29291698 0.32461947 0.307828
 0.31305802 0.31348   ]
tr_loss:[0.18491259 0.1539582  0.16199797 0.16180012 0.15339145 0.16199799
 0.15395816 0.15395817 0.1533916  0.15339157 0.15339153 0.16199782
 0.16649792 0.16647418 0.18904391 0.22531052 0.15395819 0.17906731
 0.15339161 0.18491258 0.17176107 0.15051086 0.1533916  0.15395817
 0.16638103 0.18092588 0.17906728 0.17345516 0.16648808 0.16372338
 0.17906731 0.15339157 0.1539582  0.17906907 0.18094188 0.15395817
 0.1849126  0.15395819 0.17906733 0.1664979  0.16197827 0.16228649
 0.16431892 0.16199799 0.1620225  0.16649792 0.16211595 0.17207232
 0.1854641  0.16199747]
tr_loss:[0.08087812 0.08202565 0.11616564 0.10431866 0.10189052 0.08079894
 0.08285947 0.08893752 0.11616568 0.11616566 0.08079892 0.08997452
 0.08293714 0.08893763 0.10656567 0.08997453 0.08997454 0.07867719
 0.09154016 0.08087827 0.08293716 0.08997454 0.08893763 0.08893759
 0.08293717 0.08997452 0.11616568 0.134614   0.08087835 0.08293714
 0.08997457 0.11697817 0.08079894 0.08892929 0.09180588 0.09296878
 0.08079904 0.09395502 0.08997469 0.11010922 0.0829371  0.0829371
 0.08893759 0.0922543  0.08293712 0.08893764 0.0863153  0.0893878
 0.08997453 0.0829372 ]
tr_loss:[0.07112776 0.10651519 0.07112776 0.06572195 0.05981385 0.08460736
 0.10827484 0.05869657 0.0920857  0.07112774 0.05981385 0.09208565
 0.0598139  0.07112777 0.05981383 0.07434581 0.07434585 0.08777536
 0.09158964 0.07434581 0.08777561 0.0583243  0.05869658 0.05832428
 0.05981373 0.09102304 0.07032389 0.06880821 0.07434583 0.05869658
 0.05832993 0.10419907 0.05869661 0.05981391 0.05811719 0.07112775
 0.09208572 0.10073231 0.10106792 0.07112774 0.07112772 0.05869656
 0.05981383 0.0743458  0.07434579 0.05832423 0.07112788 0.07112774
 0.0920857  0.07112771]
tr_loss:[0.08054531 0.05516899 0.09842747 0.07635596 0.08873808 0.08873807
 0.06198968 0.07513933 0.08873805 0.11166952 0.07696215 0.10410388
 0.08054528 0.08054532 0.08054529 0.05885123 0.08054528 0.06134272
 0.08873808 0.05885123 0.05516898 0.06195679 0.05885122 0.08818237
 0.06195734 0.08762522 0.05516898 0.07465646 0.05885123 0.06128854
 0.0585341  0.05779435 0.07509782 0.05885125 0.0950024  0.07513934
 0.05853403 0.06184766 0.05516898 0.0751393  0.05885123 0.0588512
 0.0887381  0.08646814 0.07864495 0.09842755 0.08090081 0.11595508
 0.05516898 0.07513925]
tr_loss:[0.06157902 0.05565047 0.06883144 0.11380284 0.08060242 0.05833213
 0.06883149 0.05780407 0.08818698 0.08843188 0.10726435 0.04640214
 0.05833272 0.05788357 0.10320614 0.0805856  0.05565047 0.07972938
 0.0688315  0.05996771 0.06883149 0.0578836  0.08125    0.05788357
 0.0578836  0.05780391 0.0856783  0.0688315  0.05565045 0.08910656
 0.04499857 0.06884758 0.04641778 0.06154657 0.08756834 0.06041958
 0.05565047 0.05565044 0.08056545 0.06883148 0.08967859 0.06884242
 0.05788356 0.05565048 0.06008453 0.10103504 0.06883149 0.05455797
 0.05565049 0.08056536]
tr_loss:[0.05892595 0.07787947 0.05892592 0.06204309 0.09592523 0.05864901
 0.05673847 0.077904   0.07788218 0.09242154 0.09242152 0.07791895
 0.04516094 0.09592519 0.07787961 0.09242155 0.05892595 0.06704793
 0.06446432 0.07787952 0.07787945 0.05673847 0.07946448 0.06072854
 0.09914002 0.05892592 0.05332483 0.06071526 0.09592258 0.05673848
 0.05892591 0.06041247 0.06071522 0.09242154 0.09485664 0.05892595
 0.07787945 0.09913667 0.06204164 0.07623436 0.06203771 0.07787947
 0.05864897 0.07013311 0.09242155 0.09769361 0.05673848 0.05673849
 0.07506698 0.07826921]
tr_loss:[0.06041851 0.06128195 0.07747583 0.06302354 0.06044477 0.07500001
 0.0630236  0.09935733 0.09840839 0.06302358 0.06128193 0.0984084
 0.06303093 0.07747579 0.06041854 0.06509212 0.06302355 0.06041852
 0.06516908 0.06302357 0.06128197 0.07876089 0.06302357 0.06550335
 0.06128191 0.06302357 0.09840839 0.04935122 0.06128196 0.06041852
 0.07747579 0.05925043 0.07747594 0.06041865 0.06128316 0.09694667
 0.06128192 0.0612819  0.108899   0.06302354 0.06550347 0.06128192
 0.07874973 0.06550332 0.06128194 0.06128194 0.07790055 0.07044732
 0.06302357 0.07747583]
tr_loss:[0.06007353 0.0610908  0.0614845  0.06092343 0.06387027 0.07528859
 0.06387033 0.09679573 0.0600867  0.09679575 0.06007354 0.06148332
 0.06148446 0.07770543 0.06396612 0.06264549 0.07534601 0.07534876
 0.07528887 0.0614842  0.06148443 0.0986001  0.06007353 0.06148444
 0.06387031 0.07534597 0.09323381 0.09679572 0.07545163 0.09395876
 0.07534596 0.08801258 0.06148444 0.06139231 0.06294966 0.07534701
 0.075346   0.09370923 0.06092338 0.09860084 0.06148385 0.06007354
 0.06007377 0.05060235 0.09679574 0.06762961 0.06146408 0.07534599
 0.08358643 0.06092343]
tr_loss:[0.0635537  0.06032234 0.09068339 0.10645156 0.06355368 0.06280167
 0.09440695 0.07211599 0.07511037 0.06008422 0.05533762 0.06355368
 0.07211637 0.06008416 0.0594293  0.06355369 0.09068308 0.08408741
 0.06355368 0.06280527 0.10912113 0.06355369 0.05326654 0.08085072
 0.0721176  0.06008418 0.05360103 0.0759881  0.06106068 0.06766307
 0.06280168 0.0618203  0.06359459 0.06355365 0.06355371 0.06290656
 0.06280168 0.06551591 0.05616794 0.06355368 0.09437048 0.06280168
 0.06355366 0.06709715 0.0610607  0.07211773 0.06280642 0.09437048
 0.05931996 0.06355367]
tr_loss:[0.04888014 0.04888014 0.04888015 0.084287   0.05357331 0.08600078
 0.04888016 0.05315455 0.05889157 0.0860008  0.06484257 0.07169968
 0.05311594 0.06484145 0.07978368 0.07169965 0.04894968 0.07169971
 0.07169969 0.04888015 0.04888015 0.04888016 0.05443854 0.04888015
 0.05263178 0.05312925 0.06484117 0.06688297 0.0531163  0.09445597
 0.0968136  0.08428695 0.05315457 0.06484145 0.0531546  0.04888014
 0.10009927 0.10587154 0.04888016 0.04888016 0.05315456 0.09683622
 0.10596726 0.06483842 0.08277304 0.07169974 0.09453608 0.0797838
 0.05315285 0.10208861]
tr_loss:[0.05647627 0.07672381 0.05368261 0.07672384 0.08642797 0.05368264
 0.09993315 0.06846411 0.08138038 0.05647568 0.0686671  0.04781373
 0.0536826  0.07672383 0.05368261 0.04217988 0.04781374 0.10753516
 0.05368261 0.04781374 0.05336392 0.05368266 0.084174   0.11060059
 0.07672332 0.10959005 0.04817958 0.05336393 0.07672387 0.06815817
 0.0483316  0.11402788 0.07439841 0.04781373 0.04781373 0.04781374
 0.06805491 0.04781373 0.07967617 0.05647618 0.04832474 0.04827374
 0.05368262 0.05368258 0.09167372 0.067082   0.08417398 0.07672381
 0.05336394 0.05336084]
tr_loss:[0.05039306 0.06451774 0.04973093 0.07942957 0.0497309  0.07904615
 0.07904399 0.05118875 0.06451775 0.0790441  0.07905114 0.0911013
 0.07133196 0.05118874 0.05118871 0.05393449 0.06735091 0.04973091
 0.06451794 0.05212802 0.04973096 0.09982479 0.06451772 0.05118876
 0.05212804 0.07942958 0.05212809 0.04973092 0.04973092 0.04959451
 0.06451774 0.05118873 0.05212803 0.06264307 0.08199833 0.05212804
 0.1067299  0.10672531 0.07942955 0.07127062 0.06451795 0.05118874
 0.08134784 0.06452058 0.07942958 0.07904406 0.06451773 0.07829416
 0.06451774 0.05213612]
tr_loss:[0.04486936 0.06587504 0.04511848 0.04469665 0.04217689 0.07965579
 0.05967926 0.0448694  0.04511848 0.05033909 0.06587502 0.07965587
 0.04511846 0.0447034  0.0950346  0.06587501 0.05033905 0.07965587
 0.04470337 0.06587502 0.08981965 0.05975565 0.04520129 0.0731503
 0.04511845 0.05033907 0.06587504 0.04212966 0.05048425 0.06761783
 0.04470335 0.04212988 0.05809081 0.04626691 0.0447034  0.04488496
 0.07966267 0.04511848 0.04486939 0.04511849 0.05033944 0.04511848
 0.06587504 0.04628067 0.07828061 0.0447034  0.05975555 0.04453739
 0.04511847 0.04486941]
tr_loss:[0.03401048 0.04982702 0.047469   0.06669164 0.04641078 0.05395208
 0.05395211 0.09159672 0.04505119 0.04975647 0.04641084 0.03659051
 0.04982354 0.04641082 0.04641083 0.03737444 0.0464108  0.04641081
 0.03737438 0.09479122 0.04973952 0.09479115 0.09423134 0.0474673
 0.04618239 0.09479116 0.03644864 0.04982303 0.03661718 0.04641082
 0.04975637 0.05395212 0.03708545 0.06714816 0.0497701  0.04982702
 0.0948175  0.04982703 0.08162399 0.05256536 0.09237919 0.03426658
 0.03644881 0.04549562 0.09479111 0.04982706 0.04641084 0.04866478
 0.05395211 0.09006654]
tr_loss:[0.05747418 0.10129418 0.05254655 0.03625184 0.10129416 0.05122247
 0.03625183 0.05747417 0.08006244 0.11516388 0.05747335 0.05122297
 0.03625104 0.04487809 0.05121876 0.05783224 0.05780669 0.05254654
 0.05747416 0.0362518  0.04725711 0.05747413 0.10129409 0.0985077
 0.10129418 0.05993883 0.03625182 0.05780672 0.05254655 0.03625178
 0.05450992 0.05254655 0.09230626 0.09029601 0.04329257 0.05783151
 0.04487782 0.05747414 0.05254652 0.03625184 0.05747415 0.05747417
 0.09850784 0.0512221  0.1012941  0.05747414 0.05453739 0.05747419
 0.0663344  0.0326081 ]
tr_loss:[0.05238646 0.089498   0.05798795 0.09922908 0.05606908 0.05798794
 0.03380579 0.05597462 0.09922938 0.09922893 0.08908025 0.09920949
 0.07810581 0.09922938 0.08532574 0.03093597 0.05798795 0.05489758
 0.05609276 0.05798795 0.09922936 0.05238647 0.05546043 0.044809
 0.03394555 0.09922924 0.03394557 0.05576532 0.07762162 0.05798793
 0.07723893 0.05529758 0.03394557 0.04508032 0.0333343  0.05238715
 0.03394557 0.05798792 0.05529762 0.03394557 0.05798795 0.03333143
 0.05798795 0.06382836 0.05199707 0.0993788  0.0523872  0.05238648
 0.05238647 0.05489846]
tr_loss:[0.05781331 0.09612028 0.05018665 0.03272011 0.04747213 0.09197307
 0.04955267 0.03259661 0.05018662 0.04250936 0.03272543 0.09611942
 0.09612023 0.08403473 0.05121306 0.05781328 0.09197239 0.06889301
 0.05070476 0.04964696 0.09199133 0.05121307 0.0436925  0.05018663
 0.05266    0.05018668 0.04323628 0.09169346 0.04378603 0.0425014
 0.05018672 0.09612066 0.04254784 0.03272007 0.05018663 0.05018665
 0.05266004 0.05266004 0.05018666 0.04955234 0.09197305 0.05266044
 0.09197309 0.05121303 0.05539103 0.05121303 0.0495543  0.05121302
 0.05121302 0.03271898]
tr_loss:[0.08339795 0.04606269 0.04991373 0.07157518 0.03377495 0.04441558
 0.07741172 0.0337831  0.07741024 0.04448804 0.03378315 0.04441559
 0.04469784 0.06330816 0.06330547 0.04448803 0.04552713 0.07741021
 0.07741019 0.07741023 0.07741021 0.0553023  0.0833805  0.04606267
 0.04606267 0.04448804 0.07741398 0.05863686 0.07741024 0.04441559
 0.06288792 0.03181489 0.04982138 0.05863686 0.06695624 0.04441553
 0.07741027 0.04441557 0.04538842 0.04315873 0.07741024 0.07741021
 0.0444156  0.04441559 0.0444156  0.04441743 0.07741022 0.04441559
 0.06330825 0.0368984 ]
tr_loss:[0.0444212  0.0359573  0.04363703 0.0444211  0.06855503 0.04397889
 0.04397888 0.05658036 0.04397888 0.04199841 0.04397902 0.06855538
 0.04397889 0.05337159 0.07200099 0.04398565 0.04483818 0.0444215
 0.08370754 0.04013486 0.05256587 0.04312689 0.05492295 0.04440513
 0.08046903 0.04442111 0.04442111 0.06837596 0.04397886 0.06354337
 0.04483814 0.04483813 0.07964738 0.05720177 0.04578884 0.0533716
 0.0476928  0.08046892 0.04442112 0.04389292 0.0685585  0.06855497
 0.04483815 0.04397891 0.06837598 0.06855506 0.04397889 0.04440522
 0.04440513 0.07371255]
tr_loss:[0.0446154  0.04351407 0.03609914 0.04504777 0.04504778 0.04205118
 0.07924248 0.04982346 0.04982351 0.04351402 0.04491465 0.03915431
 0.04982347 0.04813518 0.04504775 0.049819   0.04491464 0.04500189
 0.06696367 0.04504776 0.04491457 0.04351404 0.04982347 0.0450478
 0.0449146  0.04349333 0.06038786 0.06696373 0.04491464 0.04504775
 0.04504774 0.04982346 0.04351404 0.04491463 0.06529918 0.03811371
 0.07265869 0.04982349 0.07896484 0.04982345 0.04491464 0.03916395
 0.0726587  0.04456433 0.04982243 0.04504775 0.06038809 0.04491446
 0.06696371 0.06317542]
tr_loss:[0.0410087  0.08531399 0.08456475 0.04456521 0.08137365 0.05138928
 0.05140166 0.04891277 0.04115669 0.04115481 0.06619318 0.05137593
 0.07403841 0.05140167 0.04456522 0.04456522 0.05140168 0.0410087
 0.0410087  0.04453143 0.06696068 0.05140166 0.04456522 0.08531482
 0.08100421 0.04456523 0.06695148 0.05501727 0.04456523 0.04091949
 0.04482368 0.04456524 0.07403843 0.04456521 0.06424925 0.04891033
 0.04456522 0.04453136 0.04456521 0.0445248  0.05677151 0.08806501
 0.06695145 0.04456525 0.07503089 0.04100871 0.04453137 0.04456522
 0.05140161 0.06711154]
tr_loss:[0.06582088 0.06595677 0.04430218 0.03977993 0.03899818 0.04250744
 0.04731825 0.07653608 0.04430202 0.07260897 0.03899592 0.04731816
 0.07732682 0.06595677 0.04731825 0.04337407 0.03899817 0.07653298
 0.0659568  0.04731823 0.04250581 0.03899819 0.04252756 0.04031754
 0.07109024 0.07260895 0.06590091 0.06083977 0.04731821 0.04250742
 0.07260898 0.03899819 0.04731826 0.07108787 0.08673046 0.06595642
 0.04337399 0.06595672 0.07260896 0.04341058 0.03899816 0.09597418
 0.04731823 0.07260896 0.04757848 0.03899818 0.04731826 0.03899819
 0.06084611 0.0787199 ]
tr_loss:[0.08844778 0.04126863 0.04126824 0.04278492 0.05913204 0.03996383
 0.04126825 0.04126823 0.06777932 0.04656759 0.05235624 0.04126821
 0.04877871 0.04278488 0.06778425 0.04126823 0.04541916 0.05228263
 0.07116343 0.04126818 0.03792538 0.08742505 0.04126822 0.06777932
 0.04126821 0.06777932 0.04882101 0.07135974 0.06777928 0.04126826
 0.04321412 0.06895024 0.03982592 0.04126825 0.06895022 0.06895025
 0.04161985 0.04161982 0.04126824 0.04161983 0.03993805 0.0640402
 0.06777932 0.04278487 0.03995011 0.04161982 0.03982592 0.0858845
 0.0423153  0.03982589]
tr_loss:[0.04258157 0.04191301 0.04191301 0.03533009 0.08403995 0.04191303
 0.07225841 0.06983997 0.07225847 0.04256793 0.03533009 0.04618679
 0.06222451 0.04494902 0.03814527 0.0709232  0.04229293 0.08724059
 0.04191304 0.07225448 0.03533008 0.04191303 0.04258158 0.03533008
 0.03533009 0.05235107 0.04191302 0.06409837 0.03533008 0.05409035
 0.06222448 0.0722585  0.03532876 0.03533009 0.04258158 0.04229293
 0.03530506 0.04191303 0.07225848 0.04618677 0.04192723 0.04191307
 0.04191303 0.03532975 0.06222454 0.04191292 0.04191301 0.06222452
 0.04229295 0.03532964]
tr_loss:[0.05551518 0.07138513 0.04205975 0.076712   0.076712   0.06646437
 0.04329659 0.03090083 0.04203657 0.03688229 0.04344545 0.04433537
 0.07353032 0.03090083 0.04344543 0.04344544 0.04203654 0.05551519
 0.04344545 0.03241058 0.04066579 0.03241057 0.076712   0.05357049
 0.04344543 0.0434455  0.04632128 0.05551521 0.05551519 0.07671195
 0.04344543 0.06072118 0.07361629 0.076712   0.04033845 0.07671201
 0.03241057 0.03241058 0.04203657 0.04469983 0.04203655 0.07774079
 0.07671203 0.07671192 0.0555152  0.05130534 0.04203655 0.04203657
 0.03187796 0.07671197]
tr_loss:[0.07985228 0.03399024 0.03294522 0.04314946 0.03400553 0.07985225
 0.04603949 0.07985224 0.04603947 0.04315638 0.04678463 0.05485403
 0.07985254 0.03399024 0.0798523  0.03399025 0.04283757 0.04314946
 0.04314948 0.05318202 0.07985222 0.08175214 0.03399025 0.04678463
 0.0460395  0.0433137  0.07985229 0.04603946 0.07985228 0.04314949
 0.06497802 0.03399025 0.04941298 0.04603948 0.03385413 0.05318199
 0.08248422 0.08248451 0.07985223 0.04258963 0.07842428 0.03399025
 0.06453882 0.04603948 0.04314942 0.07985229 0.03399023 0.04603947
 0.03399021 0.02685162]
tr_loss:[0.04597985 0.03518914 0.07812893 0.03518916 0.0529098  0.04314994
 0.07005952 0.04695586 0.04694945 0.04597984 0.07851124 0.04694947
 0.04597982 0.07851095 0.07375947 0.04597982 0.04321248 0.03528226
 0.03518917 0.03518913 0.03518888 0.04314994 0.04378445 0.0431499
 0.04379458 0.07851101 0.04694947 0.04597984 0.04597979 0.04314991
 0.07851108 0.04379458 0.03395908 0.07963871 0.07943239 0.07851098
 0.04597982 0.06594177 0.04892031 0.04315222 0.04314992 0.04342474
 0.03384088 0.03505936 0.06594183 0.08642057 0.04543433 0.07851094
 0.03518958 0.08026556]
text_input.shape
(2600, 14400)
learning_input_tmp.shape
(2600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2600, 80)
learning_output.shape
(750, 80)
Model: "sequential_54"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_54 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3645833 1.3419356 1.3780453 1.378041  1.1001436 1.3419354 1.1001433
 1.3780453 1.3780454 1.3780454 1.3900738 1.3646094 1.1001436 1.3646231
 1.3016493 1.3138909 1.3931328 1.1001434 1.3419356 1.3114798 1.3191226
 1.3780454 1.3645833 1.1289688 1.1001482 1.3419355 1.368282  1.3108523
 1.301892  1.3643407 1.3680252 1.3419355 1.3016493 1.3016493 1.3900979
 1.3645833 1.3917799 1.3636532 1.1186769 1.3191228 1.3138604 1.3419355
 1.3780453 1.3191228 1.3191226 1.3645833 1.3407052 1.3780454 1.3191227
 1.1001434]
tr_loss:[0.78975147 0.789972   0.8483661  0.825843   0.82580453 0.82778895
 0.7987784  0.8436607  0.84268457 0.8827966  0.85234165 0.84366053
 0.80020696 0.84366053 0.7897516  0.7897515  0.81936044 0.81936044
 0.81164473 0.84371567 0.8193606  0.7897515  0.8008195  0.8277971
 0.84366053 0.7985978  0.81936055 0.7897516  0.8258034  0.78974855
 0.85574996 0.82775843 0.84366053 0.856815   0.84366053 0.8116396
 0.8432247  0.80340326 0.84366053 0.8468092  0.83284634 0.811619
 0.84366053 0.7897481  0.81936055 0.80020124 0.8866617  0.8437727
 0.82956046 0.8515786 ]
tr_loss:[0.50363356 0.50816345 0.50816345 0.4915077  0.5036335  0.5036486
 0.4967299  0.49453717 0.52100563 0.49144658 0.5579082  0.5210056
 0.49150762 0.49672994 0.4967299  0.49927694 0.45972452 0.4619914
 0.49553147 0.5036335  0.5081636  0.5210055  0.49684125 0.49150777
 0.49672526 0.5210055  0.52522755 0.5401304  0.49150777 0.50816345
 0.5401281  0.5579098  0.52534884 0.49669427 0.47142488 0.50816345
 0.5081635  0.49672985 0.48320103 0.53451616 0.4915077  0.49150783
 0.49150744 0.49672985 0.50363266 0.54819036 0.49672985 0.46387196
 0.49672985 0.5036349 ]
tr_loss:[0.2989114  0.33452418 0.33259842 0.29152346 0.29152393 0.28687266
 0.28689212 0.29152393 0.291524   0.40449086 0.30925602 0.29814792
 0.33560315 0.309256   0.2989114  0.3042954  0.29510158 0.3042938
 0.29868555 0.29152393 0.3284443  0.28687268 0.28687263 0.2869349
 0.2969416  0.3006549  0.29821563 0.28687274 0.28687912 0.309256
 0.2868727  0.29152393 0.309256   0.28183126 0.309256   0.3319007
 0.2913912  0.30925608 0.33190078 0.30925602 0.29152387 0.33190078
 0.29820395 0.28858    0.29152393 0.32845485 0.309256   0.28687266
 0.2982157  0.33546942]
tr_loss:[0.18202183 0.21325664 0.18417612 0.20240287 0.18202183 0.19468231
 0.21431872 0.18202187 0.19468233 0.22999167 0.1913888  0.22528534
 0.20349681 0.18856943 0.2023977  0.19853541 0.18617499 0.18865468
 0.18278435 0.22528538 0.22527318 0.19853544 0.30795518 0.1960211
 0.1861749  0.28226218 0.18383558 0.18856938 0.18202186 0.19468231
 0.22895952 0.19853544 0.19602141 0.2290512  0.20240322 0.22528538
 0.19853537 0.18202184 0.19853655 0.22528537 0.22528537 0.18856941
 0.19853546 0.19468229 0.19118676 0.19853547 0.20240942 0.21432042
 0.28226238 0.22528538]
tr_loss:[0.11654206 0.10442457 0.13945761 0.13059646 0.12669928 0.09719128
 0.10716651 0.11686815 0.10442463 0.13061611 0.1271405  0.19923308
 0.13761814 0.10716651 0.10287426 0.12082835 0.13761812 0.1169521
 0.13569377 0.11531719 0.13761851 0.13761811 0.10710742 0.13001677
 0.12097426 0.12669967 0.10716651 0.10709993 0.10442458 0.09719133
 0.09719135 0.13761806 0.10716657 0.10287426 0.10175206 0.1071679
 0.10442458 0.10442454 0.13957138 0.19765262 0.1376181  0.14408803
 0.09719129 0.1028743  0.14210305 0.13957289 0.13593844 0.09719133
 0.1376175  0.13059631]
tr_loss:[0.05865529 0.04906642 0.0628233  0.03898049 0.05886219 0.10077234
 0.04443676 0.05875925 0.04443048 0.04906638 0.10077234 0.05209243
 0.06216523 0.04443049 0.05965067 0.10077231 0.04530615 0.10851927
 0.05984464 0.10077896 0.0576907  0.10701667 0.08333237 0.04854154
 0.05984464 0.0389805  0.05909278 0.04906642 0.0444305  0.04443053
 0.04489161 0.03898054 0.0490664  0.04443048 0.10077231 0.03898052
 0.0444305  0.03898051 0.04489162 0.11384486 0.03898048 0.05984464
 0.05984466 0.10077228 0.10077234 0.10077231 0.10077548 0.04443051
 0.04854488 0.04443052]
tr_loss:[0.03712293 0.0327496  0.03274962 0.03718684 0.01731749 0.03296429
 0.10090543 0.03710032 0.03968769 0.03712296 0.01731138 0.03703896
 0.03274961 0.01731749 0.11087871 0.03712294 0.03712296 0.03712295
 0.03331709 0.01731747 0.03290107 0.10649081 0.01731747 0.0173175
 0.05396107 0.03274959 0.03733545 0.01731749 0.03274959 0.03712327
 0.09602812 0.03712296 0.03712301 0.06098517 0.03712183 0.03290103
 0.03274955 0.09602807 0.03835914 0.0960281  0.09622636 0.0329011
 0.03756665 0.01731747 0.09602813 0.03712296 0.11556733 0.09641061
 0.06128973 0.05195842]
tr_loss:[0.07182557 0.09375159 0.09107072 0.09258784 0.03815433 0.0904602
 0.09219647 0.09045183 0.03749986 0.07034214 0.05237705 0.07055449
 0.07055618 0.02324139 0.09044345 0.05237705 0.03637801 0.03815435
 0.05643457 0.03751848 0.02323853 0.03751845 0.0381555  0.03815434
 0.03815431 0.03591054 0.05643458 0.03751851 0.03760607 0.09508734
 0.0232414  0.09044351 0.03815432 0.05643377 0.02324141 0.03815436
 0.05237703 0.0904435  0.09052993 0.11700962 0.07182622 0.03815431
 0.05237706 0.03751849 0.03819809 0.03776148 0.07055616 0.03749406
 0.09044348 0.09044351]
tr_loss:[0.03898131 0.03809387 0.04096355 0.04219077 0.02800187 0.11847478
 0.08451466 0.02795197 0.04149853 0.06105172 0.07379927 0.10220279
 0.04024478 0.04149854 0.04219079 0.04024473 0.06105172 0.02800175
 0.07586858 0.12146175 0.03898131 0.04149853 0.0389813  0.02800187
 0.08451571 0.0906889  0.0410045  0.0610517  0.06105169 0.09437557
 0.04149855 0.04149853 0.03362677 0.12146257 0.08429028 0.02970852
 0.02800189 0.04219078 0.10305204 0.04219075 0.10654651 0.0389813
 0.03898131 0.0610517  0.04149852 0.03898126 0.05955204 0.08442076
 0.08455306 0.04149855]
tr_loss:[0.08023356 0.02116444 0.03189107 0.0212725  0.02127252 0.04065318
 0.0212725  0.05386097 0.02127252 0.08021486 0.03957196 0.08021478
 0.03566945 0.08215608 0.02127253 0.03566945 0.03243756 0.08021478
 0.02127251 0.09292962 0.02127251 0.10481846 0.11035273 0.05414144
 0.03566944 0.08021477 0.03573244 0.08021476 0.03566945 0.10291562
 0.03243757 0.03243754 0.0324376  0.07090552 0.03957197 0.02127253
 0.03566942 0.08021476 0.08021481 0.09752478 0.03957196 0.05414142
 0.03566939 0.0212725  0.10573585 0.11129487 0.10542582 0.05386097
 0.0356953  0.03957195]
tr_loss:[0.0395451  0.03955416 0.03955416 0.09461993 0.03094095 0.09707822
 0.04332391 0.06091171 0.10323916 0.01520719 0.03955414 0.03046927
 0.01558314 0.01684633 0.03046929 0.03955416 0.01558341 0.02678834
 0.09461816 0.03333751 0.08434842 0.08114641 0.04836898 0.03955417
 0.0155834  0.0710002  0.08114666 0.0155834  0.03046927 0.0826141
 0.02678837 0.03046927 0.04332397 0.10848536 0.03955417 0.08114641
 0.11019285 0.04332393 0.04164808 0.09440691 0.03979763 0.03897101
 0.04094457 0.10324778 0.09457733 0.04332394 0.0155834  0.03955729
 0.08114716 0.03335635]
tr_loss:[0.01667096 0.04025523 0.08414503 0.03820532 0.08414502 0.03067327
 0.04025529 0.11090279 0.03484927 0.0404797  0.02637314 0.08414502
 0.08414495 0.02620248 0.01667098 0.01667096 0.02784973 0.0402553
 0.03067336 0.04025527 0.01667097 0.0402553  0.03067329 0.09818299
 0.01667096 0.01667097 0.0263741  0.08415101 0.08414508 0.06551989
 0.02637427 0.04226568 0.0813932  0.04226571 0.0402553  0.11658643
 0.04311124 0.01667096 0.02717604 0.03820532 0.0382053  0.03067329
 0.0402553  0.03067325 0.0306733  0.01664876 0.0263741  0.04025528
 0.08414499 0.08412454]
tr_loss:[0.03156507 0.01728564 0.01728564 0.07425503 0.01728565 0.0243935
 0.01728565 0.03711069 0.02652427 0.01599014 0.09845322 0.0441112
 0.03444326 0.02429814 0.07262297 0.07427169 0.0272736  0.074255
 0.07425541 0.03710991 0.07425566 0.01728564 0.01728565 0.0172585
 0.02570056 0.09684253 0.03711067 0.02652426 0.07425794 0.01728565
 0.01728565 0.03711069 0.03711069 0.07606075 0.0968522  0.07425509
 0.0243935  0.02570495 0.03285209 0.07425684 0.0371107  0.03444325
 0.01728564 0.02652426 0.03711067 0.03711069 0.02652426 0.0371107
 0.03771981 0.09516785]
tr_loss:[0.02633714 0.09341613 0.02641784 0.02631825 0.08945725 0.0670376
 0.03709349 0.0370935  0.02770468 0.06043758 0.03642632 0.10229512
 0.02223052 0.04135329 0.02223325 0.03548128 0.02421443 0.03023087
 0.02783267 0.0604376  0.0370935  0.06153636 0.02223326 0.06587134
 0.04135018 0.10229324 0.03709351 0.02429328 0.02223324 0.06043758
 0.02421439 0.02770467 0.03642633 0.02223325 0.02941868 0.03642631
 0.02392519 0.03709348 0.02421441 0.02223326 0.0364263  0.09341782
 0.02763502 0.02421441 0.03709364 0.09900466 0.02421439 0.03172985
 0.02421437 0.0242144 ]
tr_loss:[0.02560902 0.05641128 0.06489925 0.0302357  0.03776192 0.03779666
 0.0564113  0.03993849 0.10221656 0.025609   0.03293258 0.02607378
 0.04202824 0.02760364 0.03067336 0.03124345 0.02560901 0.03778687
 0.03023567 0.02823571 0.07069248 0.03583543 0.03779671 0.10323533
 0.0341739  0.0399385  0.02560901 0.03993849 0.03780168 0.03993848
 0.02823541 0.03779626 0.06533259 0.03779671 0.06076243 0.02823573
 0.03023389 0.0282357  0.05641125 0.03779667 0.03779673 0.04091443
 0.04202824 0.0282357  0.0409118  0.03779671 0.05641126 0.0316474
 0.02560903 0.03023572]
tr_loss:[0.03037755 0.02587332 0.02587332 0.04554363 0.02902636 0.02902636
 0.03871857 0.0340992  0.09395367 0.03713017 0.07157681 0.02931587
 0.02902636 0.02902636 0.03255218 0.02587333 0.03169269 0.03409838
 0.0258733  0.07156758 0.03871857 0.08948469 0.02980916 0.0370912
 0.05973188 0.1042737  0.03073222 0.03465052 0.03710798 0.08747891
 0.02587332 0.09377582 0.03413775 0.03169271 0.02902636 0.03703909
 0.02587331 0.03409836 0.10427272 0.05973188 0.05973183 0.08747896
 0.07157689 0.05973186 0.02587333 0.05973776 0.05973191 0.05973187
 0.05558112 0.05823241]
tr_loss:[0.06622256 0.03064515 0.06411398 0.02461306 0.05699968 0.06622991
 0.02502565 0.02874063 0.07299755 0.02686492 0.02502564 0.02461271
 0.02874063 0.06622259 0.03071189 0.06622257 0.0284447  0.02502563
 0.03383268 0.03383268 0.03113245 0.02502563 0.03104261 0.03074627
 0.06704106 0.09532507 0.05220305 0.02502529 0.0529285  0.02628613
 0.02502565 0.02461277 0.03167193 0.0287387  0.03071123 0.06622256
 0.0896502  0.0287407  0.02502565 0.02874062 0.02502566 0.02878162
 0.03071032 0.0287406  0.05734211 0.06799658 0.03104167 0.02543553
 0.03090636 0.02874061]
tr_loss:[0.09612287 0.02481125 0.07201551 0.08173507 0.02022487 0.02022736
 0.02481006 0.05744061 0.02723223 0.02560608 0.02945614 0.09723548
 0.02481006 0.02724016 0.07488877 0.02017393 0.02022736 0.02779023
 0.09590616 0.02723852 0.02724122 0.07488877 0.07495536 0.02481007
 0.02478618 0.07228412 0.02478618 0.02478621 0.02970845 0.02481011
 0.01999773 0.02022735 0.07488894 0.08173542 0.09606282 0.02970848
 0.02715589 0.02824733 0.02478622 0.0294619  0.07488871 0.0277955
 0.02945547 0.02970845 0.02480993 0.02970847 0.07573332 0.02481006
 0.02481006 0.02478622]
tr_loss:[0.02340805 0.02914061 0.09493872 0.07971068 0.02340805 0.07970956
 0.07970984 0.07973375 0.02828136 0.02612117 0.01752357 0.01752357
 0.02612114 0.02341623 0.01752359 0.07589346 0.07971204 0.10407616
 0.05676401 0.02612117 0.02612117 0.0281616  0.07975681 0.02914061
 0.01753054 0.03229387 0.02914059 0.02340806 0.07970949 0.02914062
 0.07970949 0.02720833 0.07970951 0.0283444  0.02914061 0.01752359
 0.01709466 0.02612115 0.02514734 0.02914061 0.02834431 0.07862623
 0.01752356 0.07970954 0.02340806 0.07473134 0.07970953 0.08389084
 0.02612111 0.02781312]
tr_loss:[0.02317911 0.07598284 0.02531874 0.07598311 0.02667561 0.07598274
 0.10402326 0.10654765 0.02390905 0.07653309 0.07598273 0.07598275
 0.07598279 0.07598329 0.09125114 0.02972849 0.0270987  0.02576696
 0.02531878 0.02318095 0.02972848 0.02531877 0.08461249 0.0264509
 0.02011144 0.02318094 0.01480999 0.02576693 0.01481002 0.02318093
 0.02559852 0.0265721  0.04866533 0.09424001 0.02531877 0.0297285
 0.07405061 0.02355462 0.02318095 0.01481003 0.02556735 0.02531877
 0.07598288 0.01481    0.02576697 0.02972851 0.02801891 0.07598274
 0.02531882 0.02331026]
tr_loss:[0.0135768  0.03228876 0.03228877 0.02244771 0.02602243 0.01357658
 0.0135768  0.02312183 0.0592288  0.06632559 0.0135768  0.02351435
 0.02481379 0.02602032 0.0135768  0.03228877 0.01357679 0.02351435
 0.09537466 0.02633414 0.02481381 0.02548007 0.02413039 0.06632904
 0.02351435 0.10272364 0.02312274 0.02244872 0.06634502 0.01357679
 0.05682299 0.09165887 0.02481497 0.02328027 0.02312184 0.05277029
 0.02351435 0.0916507  0.06633489 0.02723031 0.01357679 0.08165204
 0.02481379 0.02658314 0.07038041 0.02750907 0.0931831  0.0248141
 0.01357679 0.02245838]
tr_loss:[0.0231596  0.05257118 0.02856704 0.02398576 0.01514404 0.02530589
 0.01514402 0.02398577 0.06012023 0.02821099 0.0239858  0.02468408
 0.03632238 0.02821098 0.09344824 0.03013529 0.02398575 0.0231596
 0.02315961 0.06005247 0.10172762 0.09456395 0.01514403 0.02794209
 0.02821097 0.0239858  0.01514402 0.09432824 0.02380802 0.03632242
 0.02821099 0.09148168 0.06853455 0.02398578 0.02315959 0.02292049
 0.05790532 0.0363224  0.02821098 0.02315958 0.02327292 0.09325524
 0.0242256  0.06006826 0.0363224  0.02472646 0.02398579 0.09971613
 0.01514403 0.02821086]
tr_loss:[0.09806613 0.0377607  0.02552778 0.06680145 0.02397278 0.09721393
 0.03776069 0.05680835 0.06717131 0.02600267 0.06770678 0.02764093
 0.01695236 0.09717397 0.02397278 0.05680372 0.02552728 0.03128697
 0.02397389 0.03128697 0.03128698 0.0568037  0.07394198 0.08817993
 0.0169523  0.01695235 0.03128697 0.01695237 0.05680371 0.02571186
 0.03776069 0.01695236 0.03130196 0.05700326 0.0568037  0.056936
 0.07902482 0.05680371 0.02382579 0.06806514 0.01694772 0.03128695
 0.03776069 0.05680365 0.05680372 0.02397411 0.02397278 0.03128697
 0.03128699 0.09721255]
tr_loss:[0.03198346 0.0566286  0.05865749 0.05811633 0.03198401 0.0338462
 0.03198618 0.02402451 0.05733404 0.02480875 0.0859976  0.05541498
 0.09481895 0.01858445 0.01858443 0.03198399 0.03384617 0.01858446
 0.02402449 0.03738795 0.09472837 0.03738796 0.02402478 0.02480873
 0.02402454 0.03222117 0.03198398 0.07758825 0.02480875 0.0546236
 0.01858445 0.02578721 0.08200333 0.02480874 0.10085672 0.01858444
 0.05744102 0.03043024 0.03198397 0.02480871 0.03738795 0.06538435
 0.05744825 0.02402451 0.07227387 0.03198414 0.08699474 0.09564683
 0.01858445 0.01858443]
tr_loss:[0.01839805 0.02699482 0.02921105 0.0235724  0.05637608 0.02608859
 0.05637393 0.01839804 0.02956774 0.05766897 0.0235724  0.02931389
 0.05637388 0.03452216 0.01839806 0.02527842 0.02500433 0.03001074
 0.05542747 0.02931388 0.02474487 0.02930703 0.02357712 0.01839804
 0.02445916 0.01839805 0.02357241 0.01838418 0.03160744 0.02474488
 0.02823791 0.07636257 0.05637386 0.02497461 0.01839806 0.05676755
 0.08332038 0.05637385 0.02931386 0.0235724  0.01839805 0.0894518
 0.02931387 0.05640795 0.05637404 0.02357237 0.09536153 0.02931386
 0.05637487 0.05650825]
tr_loss:[0.05855443 0.02562664 0.05867856 0.02295232 0.05855439 0.02562665
 0.02418719 0.03133302 0.01706978 0.05242413 0.02445993 0.02295231
 0.02562666 0.05855457 0.02295233 0.02562663 0.0229523  0.02562665
 0.05856656 0.06708192 0.02562664 0.01707308 0.01707311 0.03133302
 0.02295233 0.02562665 0.05855439 0.03133302 0.02295233 0.02562665
 0.02249171 0.05855434 0.02295231 0.02445994 0.01707311 0.02300004
 0.08950523 0.02295232 0.03133303 0.02295229 0.07568492 0.08662878
 0.10284245 0.01707311 0.02295232 0.05855441 0.02295232 0.02295232
 0.02295231 0.03133303]
tr_loss:[0.02506931 0.0609166  0.02226062 0.05021637 0.06084698 0.02506914
 0.02295882 0.0231086  0.02226066 0.02310859 0.01588605 0.01436569
 0.0222696  0.02092431 0.0279671  0.02506931 0.01588605 0.02282127
 0.06093006 0.0231086  0.02226065 0.02226063 0.0250693  0.02226066
 0.02310858 0.0906534  0.02226067 0.02235569 0.02905921 0.01588607
 0.02905921 0.01588605 0.02793348 0.02590098 0.02506962 0.10178888
 0.01588606 0.0231086  0.02282128 0.0765887  0.02226064 0.02203305
 0.06572856 0.02310858 0.02310858 0.06084691 0.0250693  0.01416572
 0.02346875 0.06004145]
tr_loss:[0.0892584  0.02594525 0.02133624 0.09369044 0.01561294 0.02264314
 0.02133627 0.09084036 0.01561293 0.02874944 0.02594525 0.10150975
 0.01561293 0.06351403 0.02083551 0.05198216 0.02133626 0.02874945
 0.06706336 0.06355574 0.02264314 0.02626575 0.06351408 0.06351405
 0.02264313 0.01561292 0.02594523 0.02133626 0.02134045 0.06351403
 0.02029234 0.05333234 0.01561295 0.04027467 0.06724455 0.09590987
 0.06351398 0.02874948 0.02027629 0.01561295 0.02133625 0.02594521
 0.05497618 0.01561295 0.02874945 0.02594524 0.09369048 0.01561294
 0.02133625 0.02594526]
tr_loss:[0.02333856 0.02333853 0.07596076 0.01478159 0.02684792 0.02554639
 0.02362148 0.0263076  0.02333855 0.01574825 0.01574827 0.09315737
 0.02083343 0.06487446 0.02333852 0.02333853 0.01574825 0.01566569
 0.02630856 0.01574827 0.01574825 0.08975116 0.02333854 0.06487429
 0.02029127 0.02639141 0.01574828 0.02333857 0.01574824 0.06487429
 0.02677861 0.02984958 0.0208143  0.02984959 0.06487433 0.09319286
 0.0648758  0.02083341 0.02083344 0.02083342 0.0234674  0.07326765
 0.0208334  0.02083345 0.02083344 0.02677851 0.06487496 0.06487431
 0.01574827 0.02629543]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2600 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2601, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2601 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2602, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2602 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2603, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2603 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2604, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2604 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2605, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2605 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2606, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2606 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2607, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2607 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2608, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2608 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2609, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2609 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2610, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2610 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2611, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2611 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2612, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2612 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2613, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2613 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2614, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2614 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2615, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2615 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2616, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2616 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2617, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2617 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2618, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2618 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2619, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2619 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2620, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2620 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2621, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2621 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2622, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2622 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2623, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2623 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2624, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2624 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2625, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2625 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2626, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2626 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2627, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2627 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2628, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2628 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2629, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2629 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2630, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2630 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2631, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2631 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2632, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2632 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2633, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2633 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2634, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2634 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2635, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2635 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2636, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2636 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2637, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2637 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2638, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2638 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2639, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2639 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2640, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2640 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2641, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2641 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2642, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2642 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2643, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2643 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2644, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2644 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2645, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2645 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2646, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2646 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2647, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2647 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2648, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2648 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2649, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2649 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2650, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2650 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2651, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2651 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2652, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2652 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2653, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2653 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2654, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2654 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2655, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2655 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2656, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2656 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2657, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2657 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2658, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2658 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2659, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2659 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2660, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2660 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2661, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2661 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2662, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2662 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2663, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2663 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2664, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2664 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2665, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2665 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2666, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2666 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2667, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2667 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2668, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2668 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2669, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2669 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2670, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2670 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2671, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2671 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2672, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2672 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2673, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2673 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2674, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2674 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2675, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2675 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2676, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2676 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2677, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2677 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2678, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2678 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2679, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2679 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2680, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2680 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2681, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2681 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2682, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2682 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2683, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2683 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2684, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2684 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2685, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2685 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2686, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2686 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2687, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2687 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2688, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2688 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2689, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2689 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2690, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2690 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2691, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2691 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2692, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2692 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2693, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2693 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2694, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2694 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2695, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2695 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2696, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2696 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2697, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2697 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2698, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2698 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2699, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2699 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2700, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2600
text_input.shape
(2700, 14400)
learning_input_tmp.shape
(2700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2700, 80)
learning_output.shape
(750, 80)
Model: "sequential_55"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_55 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1181989 1.2083071 1.2027344 1.1700366 1.2377704 1.1188546 1.2378546
 1.2325194 1.1700363 1.1700363 1.2017736 1.2378523 1.2378513 1.2143596
 1.229603  1.1224444 1.21777   1.21777   1.2028066 1.1700363 1.1700363
 1.1159945 1.2388636 1.1941656 1.1209133 1.21777   1.1700363 1.21777
 1.2177703 1.2027615 1.1700363 1.2177699 1.1270604 1.2027344 1.2027342
 1.1700364 1.1700364 1.2392781 1.2290136 1.2027342 1.1700363 1.2027342
 1.1387608 1.2290219 1.2378523 1.1174732 1.2378527 1.2378446 1.2466637
 1.2289855]
tr_loss:[0.83010215 0.81208974 0.81208974 0.802029   0.77730054 0.7892028
 0.81208974 0.6785697  0.6785697  0.71901524 0.6785696  0.81208956
 0.8143469  0.71951795 0.81208974 0.7756793  0.7980505  0.82697934
 0.7889787  0.81208974 0.78394157 0.7195131  0.7976414  0.80990714
 0.81793964 0.7204531  0.78505594 0.7773003  0.785056   0.81208974
 0.8003233  0.81208974 0.8302854  0.7839834  0.88441145 0.7850559
 0.72045916 0.7980504  0.79804647 0.7980505  0.77730054 0.7806906
 0.7980506  0.78505605 0.81206864 0.81209296 0.7850772  0.82671916
 0.77730393 0.6785697 ]
tr_loss:[0.5207942  0.44739968 0.43735418 0.5207942  0.39168698 0.5545658
 0.39168692 0.42898044 0.46976995 0.4697655  0.42898092 0.46711302
 0.5213953  0.5207943  0.5207942  0.45274296 0.52708465 0.5207942
 0.5207943  0.46713695 0.43053454 0.43721175 0.4697701  0.42468196
 0.46711302 0.5207941  0.5207942  0.39168692 0.5207941  0.46711308
 0.5207943  0.46711308 0.47359285 0.53897136 0.46976995 0.5207943
 0.43279472 0.5207943  0.5207944  0.538973   0.4697644  0.5207943
 0.55456525 0.46711296 0.5207942  0.5207942  0.4246768  0.42465806
 0.5207943  0.52078587]
tr_loss:[0.33839962 0.32547727 0.28821468 0.3254772  0.25021848 0.25340918
 0.3254773  0.3254772  0.28078088 0.27959752 0.26690516 0.2807474
 0.29073933 0.32547727 0.2907393  0.32547718 0.26690513 0.3383996
 0.2907394  0.2646938  0.3242932  0.28821468 0.2591732  0.25340915
 0.28079194 0.27812427 0.32547724 0.32547727 0.26690513 0.28821468
 0.33839995 0.32547727 0.2534091  0.3254773  0.25019905 0.3329332
 0.32174596 0.28821468 0.26600736 0.32547724 0.32548416 0.3254773
 0.2806873  0.28821474 0.32547724 0.26690516 0.3254772  0.32547727
 0.25593227 0.29073924]
tr_loss:[0.18873066 0.14849214 0.13696834 0.15843332 0.17092001 0.15843332
 0.18588355 0.14849208 0.19141015 0.1887315  0.18588352 0.18588348
 0.18588355 0.14172885 0.17326781 0.14849105 0.14750604 0.13662699
 0.14750603 0.19026954 0.15843329 0.14849208 0.18588369 0.17220293
 0.18876152 0.15843332 0.14849213 0.18588357 0.1484921  0.14849213
 0.15843336 0.18588355 0.14750616 0.18588354 0.18873163 0.14172934
 0.18588354 0.14849208 0.1484921  0.1484921  0.17327039 0.15843332
 0.17243035 0.14849205 0.17326827 0.15843329 0.18588354 0.13295779
 0.17228329 0.13001461]
tr_loss:[0.1038569  0.10385649 0.10559938 0.10385691 0.09985473 0.09985475
 0.12913282 0.10007737 0.09656441 0.10333809 0.13434997 0.09620664
 0.14273658 0.0890479  0.14073303 0.10010801 0.10385691 0.11823462
 0.10385688 0.1038569  0.10323401 0.10385688 0.09656442 0.1038569
 0.1038569  0.10385688 0.10266036 0.10385688 0.10385686 0.13786896
 0.10454221 0.08669826 0.1038569  0.09985474 0.08904695 0.10385688
 0.09656441 0.1038569  0.08904795 0.11228295 0.12944049 0.08904795
 0.09985477 0.1038569  0.0965644  0.10385688 0.1044382  0.08904798
 0.12704107 0.11514676]
tr_loss:[0.07103337 0.06421081 0.07103533 0.06894319 0.06694336 0.0704538
 0.07103334 0.09788489 0.07045383 0.0689432  0.07103722 0.07103339
 0.06894319 0.07103336 0.07045385 0.06894325 0.0711012  0.06422623
 0.10457982 0.07508035 0.07045379 0.07096721 0.11666286 0.07103337
 0.09788488 0.09152742 0.07045384 0.078927   0.06541458 0.07045385
 0.07103334 0.10614105 0.07045387 0.09788492 0.07103337 0.12518217
 0.10625967 0.07103337 0.07279365 0.07462086 0.07103336 0.07103337
 0.07103334 0.07045386 0.07103334 0.06894319 0.06894322 0.07103334
 0.0642296  0.07105024]
tr_loss:[0.04389609 0.03773637 0.04254125 0.04389613 0.04254127 0.04389614
 0.03773638 0.0377364  0.07965942 0.10233746 0.10338996 0.03861671
 0.03861671 0.04254125 0.06312175 0.04254128 0.04389612 0.0440765
 0.08017899 0.04389609 0.03773641 0.0377364  0.07885862 0.07885866
 0.0377364  0.03773642 0.07954135 0.07885862 0.0448203  0.03861672
 0.04254126 0.04254139 0.06206457 0.03780444 0.0377364  0.04389613
 0.06658281 0.04254129 0.04389613 0.04389613 0.0438961  0.04254127
 0.03773639 0.04578409 0.03815453 0.04389612 0.04389612 0.03152004
 0.03809318 0.03773639]
tr_loss:[0.08541743 0.02901386 0.0222231  0.01642063 0.0610318  0.01946158
 0.05933264 0.02762539 0.02762667 0.02739804 0.02222775 0.05585705
 0.08542962 0.02711322 0.01946158 0.02469171 0.02762565 0.08772556
 0.01946157 0.02566868 0.02902529 0.02222314 0.02762538 0.06857455
 0.02318337 0.02741083 0.0276254  0.02721624 0.02762541 0.01904786
 0.02902234 0.02762539 0.0276254  0.0276254  0.02740082 0.0276254
 0.02762541 0.02762539 0.01946156 0.01946157 0.02762539 0.01946159
 0.02762539 0.02318338 0.02471644 0.02762539 0.02762206 0.02222313
 0.02318334 0.02762542]
tr_loss:[0.02973821 0.02719588 0.02998235 0.03329464 0.02543737 0.07312257
 0.06408502 0.02973822 0.02998234 0.063852   0.02973846 0.02543736
 0.02829504 0.02719564 0.02719587 0.06234054 0.02998236 0.06640266
 0.07312097 0.02719587 0.02973822 0.08289369 0.10665784 0.02719585
 0.02973821 0.02973814 0.03333108 0.02973823 0.09148302 0.02543736
 0.02543736 0.02719587 0.1095806  0.02973821 0.02719574 0.02719586
 0.02998173 0.0297382  0.06840666 0.02543739 0.02973823 0.05950298
 0.02992773 0.02973823 0.05950302 0.0664123  0.0285012  0.05950297
 0.06636403 0.08471517]
tr_loss:[0.05988594 0.05988596 0.11120002 0.11190648 0.08971912 0.02814925
 0.03003079 0.02814928 0.02978809 0.03003079 0.06891326 0.0297881
 0.02824734 0.11336325 0.0300308  0.08876874 0.02978809 0.03500269
 0.02724907 0.0297881  0.02762719 0.0598859  0.02814925 0.02978809
 0.03816164 0.03003081 0.06891633 0.05988595 0.03003081 0.03273467
 0.05988596 0.03003081 0.08434079 0.06395753 0.03003084 0.03273464
 0.02978807 0.03273465 0.05988597 0.02814926 0.02814927 0.11336388
 0.02978808 0.02814925 0.06141598 0.03003082 0.0297881  0.03300679
 0.02701119 0.02994221]
tr_loss:[0.02570787 0.02570567 0.02521837 0.02521839 0.07685415 0.02570887
 0.03336601 0.02521839 0.02570789 0.01889499 0.05807335 0.02521842
 0.02283907 0.0257079  0.02570789 0.02559232 0.02570789 0.02730997
 0.05719976 0.02304503 0.031526   0.02570787 0.08459576 0.05652374
 0.02570788 0.02733221 0.02604223 0.05807333 0.02570791 0.05807339
 0.02521839 0.05862298 0.02559221 0.02570788 0.05807336 0.02303341
 0.02889729 0.02521837 0.02820832 0.02570791 0.05807337 0.02570788
 0.02746833 0.02304505 0.05807338 0.0580734  0.02011653 0.07243331
 0.02067395 0.02521841]
tr_loss:[0.02490582 0.08515575 0.02423064 0.02490579 0.02359496 0.06137282
 0.02366894 0.02366846 0.02359495 0.02366855 0.04808861 0.01634266
 0.02587498 0.02490581 0.02423067 0.06831755 0.06137279 0.02359489
 0.02155169 0.02366891 0.01668372 0.02426185 0.0249058  0.02366895
 0.06137276 0.02366892 0.01665028 0.02490581 0.02490583 0.02353766
 0.01948728 0.07396353 0.06137281 0.06137279 0.02366892 0.02366891
 0.02468907 0.02366893 0.0194873  0.02359482 0.02490582 0.04974728
 0.04793734 0.02366893 0.02366895 0.02492314 0.02490582 0.02436409
 0.01666633 0.02366893]
tr_loss:[0.02464303 0.02564474 0.02755385 0.02464299 0.02668113 0.02464234
 0.02337066 0.024643   0.0247163  0.02337068 0.02464299 0.08161874
 0.02464299 0.02564924 0.024643   0.01959512 0.02464301 0.02668112
 0.024643   0.0250908  0.02668113 0.07805353 0.02337063 0.02464303
 0.07627968 0.02464301 0.07805356 0.02872611 0.024643   0.06853651
 0.02337064 0.02337063 0.0601298  0.06017641 0.02464301 0.07127654
 0.0266811  0.02464301 0.0266811  0.02464298 0.02564046 0.02564921
 0.02998642 0.02189147 0.02337063 0.02756323 0.02982996 0.02325377
 0.07130821 0.02564922]
tr_loss:[0.02532427 0.07252859 0.06247296 0.0274998  0.02766327 0.02766329
 0.02766331 0.02362548 0.02749979 0.02868645 0.02808641 0.02532424
 0.02532426 0.06884964 0.02808643 0.02532426 0.02532423 0.02809176
 0.02766326 0.02766329 0.02532427 0.02766328 0.02532426 0.02532427
 0.02532422 0.02532426 0.02532426 0.02766328 0.04354843 0.02533093
 0.02766326 0.062473   0.02766329 0.08980668 0.02519388 0.0622891
 0.02766326 0.02766329 0.02532423 0.02766327 0.02532426 0.02766326
 0.03053691 0.06030975 0.02532427 0.02754523 0.02808644 0.02765779
 0.02749978 0.07252854]
tr_loss:[0.02438346 0.07972706 0.02295769 0.0228638  0.06741451 0.02438346
 0.02523621 0.08444396 0.02295768 0.08527447 0.02523615 0.06741448
 0.02205077 0.02438347 0.02578428 0.02295789 0.04885811 0.02343663
 0.02295769 0.0249043  0.02295766 0.02577083 0.0484181  0.04723368
 0.02414941 0.02295766 0.02295768 0.02490432 0.0229577  0.02523614
 0.02490433 0.02490428 0.02295766 0.02523611 0.02490431 0.02295769
 0.02438348 0.0797425  0.02295761 0.02523616 0.02523612 0.02490428
 0.0249043  0.0249043  0.0249043  0.02490428 0.02800361 0.06741443
 0.02665488 0.05829288]
tr_loss:[0.05764771 0.02072809 0.02028559 0.02072808 0.03856207 0.01733013
 0.02576162 0.02067569 0.06977009 0.0204088  0.02067569 0.01903801
 0.06857099 0.02068772 0.02067575 0.01903802 0.01903802 0.02072806
 0.019038   0.02072808 0.02072811 0.02072771 0.0206757  0.06111484
 0.0207281  0.0207281  0.05764773 0.02072811 0.02233036 0.019038
 0.08984087 0.01903802 0.0204088  0.0207281  0.02072138 0.0206757
 0.02067569 0.02072873 0.0207281  0.02072811 0.0204088  0.02073061
 0.0204088  0.05764772 0.0207281  0.02040879 0.02067568 0.0207281
 0.02072873 0.0206757 ]
tr_loss:[0.01822869 0.02369788 0.02369229 0.0182288  0.02115517 0.05307596
 0.07552417 0.05307595 0.0182288  0.01822877 0.02844571 0.0236923
 0.02159267 0.07072818 0.01822878 0.02115517 0.0236923  0.0236923
 0.02195447 0.08834632 0.0236923  0.02115517 0.05307596 0.08834631
 0.02115517 0.07072303 0.02369229 0.02383408 0.02115517 0.02369232
 0.02027375 0.02115514 0.02369229 0.05307601 0.02379227 0.02048119
 0.02369255 0.0202468  0.02315248 0.02361106 0.02027376 0.02116292
 0.05962384 0.04711486 0.02029308 0.01822878 0.01628836 0.02369229
 0.0182288  0.0236923 ]
tr_loss:[0.02065167 0.02137366 0.0187988  0.02728129 0.01877482 0.01879881
 0.02240186 0.07029241 0.07800919 0.05373278 0.02137365 0.09272079
 0.01700307 0.02864063 0.01683174 0.07029214 0.0272813  0.05411786
 0.02728126 0.09270584 0.02728129 0.09409154 0.05656813 0.0187988
 0.02728126 0.02240186 0.03218621 0.02469237 0.02728129 0.01879879
 0.0702924  0.02831385 0.02728128 0.02240184 0.02728128 0.01875231
 0.05373279 0.07029097 0.03101118 0.02789662 0.05656805 0.02137366
 0.02728126 0.05373284 0.02137422 0.02240188 0.02240188 0.02728129
 0.02728125 0.02240185]
tr_loss:[0.02570599 0.02570597 0.02037226 0.02573002 0.01676753 0.023544
 0.02570599 0.05571793 0.025706   0.02570602 0.01676756 0.01676755
 0.01676754 0.025706   0.01993146 0.02590308 0.02037224 0.07172632
 0.02037225 0.05885021 0.02037226 0.05480481 0.025706   0.01676751
 0.02580889 0.01676751 0.02590303 0.01477329 0.01477478 0.0146945
 0.019929   0.02037224 0.025706   0.05480479 0.02570601 0.01990515
 0.01977902 0.05480481 0.09047387 0.02077178 0.02037225 0.05571768
 0.02037226 0.01676752 0.02037226 0.01998984 0.025706   0.025706
 0.025706   0.02605289]
tr_loss:[0.02413053 0.05725069 0.06455715 0.02413054 0.0241305  0.08126973
 0.04679861 0.019322   0.02413052 0.04733618 0.02413053 0.01556011
 0.01612513 0.0241305  0.05725069 0.02380731 0.01610466 0.01612513
 0.07262181 0.02413054 0.02413052 0.02154674 0.01933227 0.01923704
 0.02413051 0.02364164 0.05134772 0.01932199 0.04732854 0.05386598
 0.07262918 0.01931215 0.01362918 0.02413052 0.01612512 0.01913109
 0.02325061 0.01612514 0.01932162 0.01923705 0.02380505 0.05725063
 0.0241305  0.01923706 0.01923704 0.02413336 0.01612511 0.02001623
 0.01612514 0.07570316]
tr_loss:[0.0227201  0.04878856 0.01881478 0.01881476 0.02272011 0.05813658
 0.05133855 0.0227201  0.04883547 0.0169798  0.04855917 0.01881478
 0.0227201  0.014621   0.02181222 0.02272012 0.02272009 0.01697982
 0.01697981 0.08206674 0.02272007 0.05813659 0.06475285 0.01990415
 0.01932843 0.06493112 0.04387686 0.02272012 0.05182645 0.07856927
 0.02275878 0.0581366  0.02272082 0.04735866 0.0218158  0.04406241
 0.01435847 0.0227201  0.05509825 0.07941459 0.0227201  0.01881478
 0.01881835 0.0227201  0.07670679 0.01881478 0.01697981 0.01697978
 0.02272009 0.02181224]
tr_loss:[0.01839362 0.01925981 0.01925981 0.05650955 0.02125334 0.01925981
 0.01970251 0.05424183 0.02259338 0.02125335 0.0192598  0.07887858
 0.01839449 0.0192598  0.0183945  0.02532882 0.04879367 0.08183237
 0.08007103 0.02125333 0.01623793 0.01839448 0.01970252 0.07887862
 0.02125334 0.0788781  0.02125039 0.02214282 0.04883238 0.0225934
 0.01929899 0.01925979 0.02027448 0.0210039  0.01717013 0.01839448
 0.0225934  0.01836375 0.01839448 0.02125333 0.02027228 0.05369018
 0.02125331 0.08209391 0.02213264 0.01925981 0.0183945  0.02125334
 0.01542773 0.02259336]
tr_loss:[0.07857089 0.02281472 0.0213476  0.02100246 0.01556228 0.02100247
 0.02100244 0.02100246 0.02100245 0.04673987 0.01980493 0.01790356
 0.07724764 0.02146534 0.07956836 0.06711806 0.04027566 0.02100245
 0.01716218 0.02100245 0.02100246 0.05540688 0.02100247 0.01980492
 0.02345375 0.02100243 0.02100244 0.02100246 0.02100245 0.02082773
 0.08107388 0.05540682 0.02345122 0.02146533 0.02082773 0.08105908
 0.02100244 0.0228148  0.05540688 0.08107385 0.02146534 0.01980491
 0.01980494 0.02100243 0.0208277  0.04335838 0.05540688 0.02106855
 0.02100243 0.02145218]
tr_loss:[0.02266607 0.05528613 0.02105547 0.0219778  0.08136318 0.07850751
 0.0237413  0.02105549 0.05528613 0.02264037 0.02105551 0.02457509
 0.02105549 0.03867893 0.02105545 0.02105548 0.02374129 0.02105547
 0.02105549 0.02374132 0.02197771 0.02105549 0.02105548 0.0237413
 0.02072107 0.0520493  0.02105547 0.02105548 0.02105547 0.02105549
 0.02105549 0.02374127 0.05528615 0.02086971 0.02105547 0.02105547
 0.02105548 0.02072107 0.02139433 0.02374131 0.02374129 0.02105548
 0.0450982  0.04438265 0.05528615 0.02105546 0.02164208 0.02358485
 0.02105549 0.01758194]
tr_loss:[0.0564873  0.06703223 0.08357114 0.05413298 0.02628401 0.02105653
 0.01972603 0.0263072  0.04042601 0.01991308 0.01959744 0.02258316
 0.02258356 0.01960136 0.07192943 0.02105654 0.05386538 0.01972602
 0.06426143 0.01959743 0.02258316 0.01972604 0.01959742 0.01959744
 0.01972602 0.01972603 0.05413301 0.02088131 0.01911848 0.02137906
 0.05720248 0.01695522 0.06717969 0.01936402 0.02105651 0.02258315
 0.01959743 0.02258316 0.01959742 0.01972603 0.01959744 0.01959746
 0.02630804 0.05413302 0.02292921 0.054133   0.02105655 0.04996265
 0.01972607 0.02107279]
tr_loss:[0.01923561 0.02053278 0.01860366 0.02013418 0.04588005 0.04073885
 0.0528942  0.0528942  0.02067324 0.05289422 0.06256694 0.01924007
 0.0198786  0.0186039  0.02560012 0.02053278 0.01860389 0.02053281
 0.01860391 0.01923561 0.01923562 0.04530526 0.01923725 0.01923562
 0.08585449 0.02297938 0.0858543  0.03813671 0.05576804 0.02367326
 0.0451452  0.01860389 0.01860384 0.01860391 0.02053315 0.02120458
 0.01987839 0.0205346  0.01950197 0.08136922 0.01923563 0.01923561
 0.01923561 0.02389381 0.01860284 0.01923561 0.05289426 0.01987859
 0.01987876 0.01860395]
tr_loss:[0.04213935 0.01761435 0.01933303 0.05107423 0.01859294 0.01998799
 0.05568888 0.04856757 0.05107422 0.01761432 0.01933305 0.01761436
 0.019988   0.01546974 0.01998801 0.019988   0.02066867 0.01859295
 0.019984   0.01998799 0.0206792  0.01761436 0.05484691 0.02148874
 0.08635563 0.01998797 0.019988   0.01998798 0.01998796 0.04860588
 0.01760858 0.02235403 0.01991862 0.06787546 0.01998799 0.05107424
 0.01933304 0.019988   0.01761434 0.01861611 0.01933305 0.01761434
 0.01933305 0.01998798 0.06618026 0.0510742  0.02324208 0.05198997
 0.01859291 0.01933306]
tr_loss:[0.04734577 0.01922067 0.02006434 0.04734578 0.01639313 0.01639723
 0.04734576 0.01677897 0.02034634 0.016779   0.02006434 0.01639722
 0.02006433 0.01922066 0.02006433 0.02006434 0.02006434 0.02400372
 0.01922065 0.04810238 0.01922064 0.01677867 0.02006435 0.04263928
 0.02006433 0.048101   0.04263931 0.05555344 0.02006434 0.01922064
 0.02006437 0.01639724 0.02006435 0.02114476 0.04345464 0.01986891
 0.01922066 0.02006435 0.02006427 0.01922065 0.02006434 0.02006434
 0.02006436 0.01922065 0.02006439 0.01677899 0.02006435 0.02006433
 0.01922078 0.01922064]
tr_loss:[0.06542873 0.045238   0.01957028 0.01675161 0.06068772 0.04409751
 0.02111111 0.02402522 0.01785615 0.01727762 0.04454195 0.01640891
 0.01675161 0.02111111 0.01957026 0.01640879 0.04454201 0.01428133
 0.01957024 0.01957027 0.01957026 0.01957027 0.01957027 0.02111112
 0.01640891 0.07142006 0.01957026 0.02123198 0.01675161 0.01641421
 0.01675162 0.01945583 0.01956966 0.06625111 0.01957024 0.01957032
 0.04523749 0.01957027 0.06427866 0.01957025 0.044542   0.01957027
 0.01956831 0.04454196 0.01945582 0.01675161 0.02111111 0.01675162
 0.01957028 0.01957027]
text_input.shape
(2700, 14400)
learning_input_tmp.shape
(2700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2700, 80)
learning_output.shape
(750, 80)
Model: "sequential_56"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_56 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2980812 1.3141971 1.2980812 1.2478535 1.3499844 1.2980812 1.3255389
 1.2814353 1.245677  1.350012  1.2980812 1.2814353 1.3030477 1.3499972
 1.3011376 1.3499732 1.282219  1.2980812 1.298081  1.2964356 1.3055353
 1.3207179 1.2814353 1.3125212 1.3125212 1.2980864 1.3067633 1.2814353
 1.2822182 1.3499973 1.3005579 1.2980812 1.3499973 1.3066881 1.2980812
 1.3499973 1.2979801 1.2822183 1.282218  1.2535917 1.298081  1.281066
 1.2411026 1.325237  1.298081  1.312521  1.2822182 1.2980813 1.3180821
 1.3499973]
tr_loss:[0.65066063 0.59472907 0.606613   0.63088334 0.62874734 0.6363682
 0.606613   0.6070189  0.6363683  0.6306484  0.70323074 0.606613
 0.6335401  0.62545335 0.7116836  0.606613   0.65066046 0.71174884
 0.63354015 0.6458677  0.5900043  0.65066063 0.64821815 0.5947522
 0.65066046 0.6506606  0.6335401  0.6287482  0.6363683  0.6335264
 0.62580407 0.60661304 0.6335402  0.63636816 0.6506605  0.606613
 0.606613   0.6335402  0.606613   0.6363683  0.7223711  0.62545335
 0.60661256 0.6137149  0.63498956 0.6287481  0.6220403  0.7115548
 0.63942915 0.6231085 ]
tr_loss:[0.31738624 0.33303967 0.31738704 0.3173863  0.31738624 0.3248722
 0.34443635 0.31976497 0.29500696 0.32487363 0.32491142 0.326907
 0.3373167  0.31738627 0.31738627 0.33364552 0.31924272 0.31998754
 0.3373167  0.35275862 0.3248722  0.29045576 0.35275862 0.332688
 0.32840958 0.31738633 0.33163813 0.32840955 0.3173863  0.3173864
 0.2904536  0.3375575  0.34481207 0.31894207 0.31738627 0.33307403
 0.31738624 0.3105012  0.33370322 0.32840952 0.29499975 0.3527586
 0.28280026 0.3527587  0.33778185 0.32840952 0.32486776 0.31738624
 0.31738627 0.33307377]
tr_loss:[0.18680504 0.17838368 0.16865233 0.16865234 0.17838371 0.1686523
 0.17838365 0.18137412 0.18682562 0.18137452 0.19866559 0.16865239
 0.17838368 0.16865233 0.17838372 0.18680516 0.16588493 0.17283866
 0.16865233 0.19866315 0.1686523  0.19866312 0.17796798 0.1986632
 0.17838366 0.19660012 0.17838365 0.17838372 0.16865234 0.18680555
 0.16865274 0.18484934 0.16865231 0.17838371 0.17283878 0.16865234
 0.17733519 0.16865237 0.17921455 0.17796698 0.17283872 0.1728388
 0.17860532 0.17838371 0.16865322 0.16865234 0.16268751 0.17827336
 0.16865237 0.1783837 ]
tr_loss:[0.09720042 0.12272438 0.11643493 0.09720048 0.09720042 0.09949347
 0.11177679 0.12256984 0.0807493  0.11173211 0.12272432 0.0737904
 0.09949344 0.10579015 0.10578148 0.0972005  0.09949344 0.09949346
 0.10928826 0.09944242 0.09720043 0.09720041 0.1621481  0.11643486
 0.12272437 0.09720047 0.09949347 0.16214806 0.09911548 0.09949348
 0.12272438 0.14768568 0.10298089 0.11172508 0.09092432 0.11173213
 0.11236463 0.11612705 0.0909275  0.09949346 0.10983658 0.09720043
 0.09949349 0.12272433 0.09060528 0.09720905 0.12549654 0.16214857
 0.1110148  0.09949346]
tr_loss:[0.09996748 0.04767402 0.0999675  0.06881575 0.15327895 0.0846369
 0.06548768 0.07509818 0.06658711 0.06658708 0.06912629 0.06658705
 0.06039985 0.06658713 0.06658705 0.14219794 0.07266966 0.06658708
 0.08865963 0.07509822 0.06658709 0.08179673 0.06039986 0.0716741
 0.06658714 0.10568674 0.07995366 0.09996752 0.07509823 0.06659178
 0.07509821 0.06039984 0.08230748 0.07218937 0.06881268 0.06658712
 0.15338218 0.06658713 0.0999675  0.07509828 0.13805605 0.07509819
 0.06909602 0.0750982  0.06658708 0.07509784 0.07509819 0.06658719
 0.06039983 0.06658709]
tr_loss:[0.05263881 0.05263882 0.06526358 0.05263827 0.04856522 0.05782886
 0.05263876 0.05582296 0.05263878 0.056487   0.07121    0.0950227
 0.05780869 0.05648698 0.05648697 0.05583624 0.05583624 0.05353997
 0.05264486 0.05648698 0.07632361 0.04856519 0.09664661 0.06396415
 0.05616146 0.06493733 0.05263882 0.07027967 0.06396475 0.04875367
 0.05648701 0.05261041 0.09841505 0.04856526 0.05648698 0.05263879
 0.05263883 0.05263879 0.05263879 0.04927577 0.04856523 0.05263878
 0.04978304 0.0539187  0.09563667 0.05263879 0.04933465 0.05583631
 0.09505974 0.05583627]
tr_loss:[0.09420451 0.09701584 0.09420446 0.04526807 0.04872747 0.04526805
 0.04143193 0.04526805 0.04143191 0.05309812 0.04760664 0.0414319
 0.04592135 0.09859649 0.04760667 0.0452681  0.04759507 0.04526806
 0.05309574 0.04143193 0.04526807 0.04760664 0.04526809 0.05207837
 0.05110209 0.09698816 0.04760667 0.0452681  0.04960642 0.07273678
 0.09701476 0.04958446 0.04143193 0.09420446 0.04744408 0.04526808
 0.0452681  0.09178392 0.09420449 0.05207859 0.04760667 0.05207745
 0.0452681  0.04526808 0.05209316 0.1196852  0.07422262 0.0452627
 0.04715259 0.04526809]
tr_loss:[0.03948015 0.04511875 0.04853302 0.04511874 0.05059823 0.03948016
 0.04511877 0.07563861 0.04183055 0.03948016 0.04979198 0.03948015
 0.04979099 0.07563857 0.04979162 0.04511875 0.07563859 0.11832182
 0.05327173 0.04511873 0.04511874 0.04511875 0.07563855 0.04511874
 0.03948017 0.07563858 0.04183055 0.04979159 0.0668726  0.04979164
 0.06503119 0.04511877 0.03948016 0.04183058 0.04183053 0.03948016
 0.04511875 0.0743067  0.04183053 0.07177551 0.04805442 0.04183054
 0.04805163 0.04511878 0.04511865 0.04111391 0.0394793  0.08681832
 0.09168496 0.04511873]
tr_loss:[0.0476298  0.0476293  0.04762924 0.05338597 0.03837658 0.06082923
 0.04713308 0.04713309 0.04762927 0.03639201 0.04896678 0.04762927
 0.03643372 0.05310375 0.06082923 0.03837655 0.04762927 0.06082924
 0.04896675 0.03639201 0.07095884 0.03639201 0.0476293  0.07015549
 0.04753903 0.04763004 0.05107323 0.07015488 0.07015566 0.0484891
 0.11826773 0.04896672 0.04762934 0.04762924 0.036392   0.04936317
 0.04763716 0.05783897 0.06082923 0.03837657 0.04762928 0.04759777
 0.03639202 0.04762927 0.036392   0.04772974 0.04713286 0.05759561
 0.06921029 0.04762926]
tr_loss:[0.04504104 0.06397965 0.04504105 0.04108657 0.06397967 0.04504102
 0.02609186 0.04108667 0.04108656 0.03584398 0.02609187 0.11619212
 0.061095   0.02609186 0.04233388 0.04504105 0.0721524  0.06642976
 0.04504102 0.04504105 0.04108658 0.04885264 0.02609188 0.07228014
 0.02609293 0.04504103 0.07212868 0.07610206 0.03584398 0.06314708
 0.04504104 0.08920268 0.02609187 0.06397969 0.02609187 0.04108658
 0.04504105 0.10519882 0.03584398 0.04109598 0.04885995 0.04275253
 0.06314813 0.10519873 0.04237731 0.03584399 0.03584397 0.04504104
 0.04668673 0.04504102]
tr_loss:[0.03545564 0.06977991 0.08769317 0.04018689 0.06677671 0.04315064
 0.04018692 0.04312559 0.04315064 0.08813665 0.04406385 0.09860653
 0.06977984 0.03545567 0.04018694 0.0255103  0.02895324 0.07239641
 0.04018695 0.0255103  0.03545782 0.04315065 0.04091928 0.04315059
 0.04315063 0.04471061 0.04315358 0.04774399 0.04315063 0.04091916
 0.03545566 0.04774426 0.0255103  0.03545565 0.0255103  0.0255102
 0.03740455 0.03976604 0.03805351 0.04315062 0.04084967 0.04315063
 0.07259411 0.0255103  0.08080791 0.06977984 0.03545564 0.04315064
 0.04018693 0.04315061]
tr_loss:[0.03958631 0.03020151 0.03958755 0.03634749 0.03958756 0.08032379
 0.05859367 0.03020145 0.06739132 0.03958759 0.09246397 0.03958756
 0.03020152 0.0302015  0.08025053 0.0363475  0.03950737 0.08017943
 0.03020151 0.03958759 0.04503759 0.03634749 0.03634814 0.04277134
 0.04277138 0.03958756 0.0363475  0.04474324 0.03020152 0.03958755
 0.03020151 0.03634749 0.03958758 0.04240608 0.03958759 0.03958758
 0.08017954 0.03020151 0.06365599 0.03958761 0.04277132 0.03634747
 0.0302015  0.03634752 0.03634752 0.04271584 0.03020144 0.0363475
 0.06740884 0.03634747]
tr_loss:[0.0892906  0.03434782 0.03434782 0.0878348  0.03360068 0.06863721
 0.03360621 0.03360612 0.0320339  0.05002443 0.08797999 0.03453705
 0.03360618 0.03203382 0.03360619 0.04300322 0.03360618 0.08929057
 0.0320339  0.03273059 0.03360618 0.03203388 0.03360614 0.03360621
 0.0343478  0.03360618 0.08361926 0.03434779 0.03434839 0.03203391
 0.03360619 0.03360616 0.04300725 0.03360617 0.08407364 0.05706756
 0.04300725 0.03223674 0.03360617 0.03457618 0.03360618 0.03203394
 0.08783457 0.03359641 0.03360617 0.03191192 0.03360612 0.0892906
 0.0336062  0.03360617]
tr_loss:[0.06034572 0.03030673 0.02820413 0.03030675 0.08636443 0.02820415
 0.03262234 0.03142377 0.06024271 0.03142376 0.02820415 0.06277172
 0.04052262 0.03032309 0.04052262 0.02820414 0.04071925 0.02820414
 0.02820408 0.02820409 0.04052258 0.03030675 0.02820773 0.0313885
 0.03142373 0.05143576 0.032448   0.02820412 0.03030677 0.03030675
 0.05816852 0.08636446 0.04060206 0.04052261 0.05119897 0.03783045
 0.02820412 0.02820412 0.02820413 0.03142373 0.02833394 0.06866904
 0.07647174 0.02820412 0.02820414 0.07937459 0.04667461 0.02820413
 0.03030675 0.02820409]
tr_loss:[0.02749284 0.0378012  0.02759261 0.03558476 0.0756864  0.02749283
 0.02749287 0.02749286 0.02759262 0.0275926  0.02603086 0.0756864
 0.03558347 0.02934731 0.07359074 0.04466813 0.02603089 0.07005776
 0.0547704  0.02749285 0.02946978 0.05537512 0.03558347 0.09842251
 0.02603087 0.10400671 0.02934959 0.04802727 0.02603089 0.02749283
 0.03568776 0.02749281 0.0260309  0.02749284 0.02760162 0.03586565
 0.02759261 0.03558351 0.03070135 0.07568637 0.02934957 0.02749286
 0.02749283 0.02759299 0.02749282 0.07568635 0.02759262 0.02759263
 0.03690379 0.07568636]
tr_loss:[0.03388821 0.03534451 0.03715287 0.03373136 0.03105137 0.03105161
 0.03105138 0.02487553 0.03373136 0.05379213 0.03534453 0.04401404
 0.03373137 0.03373133 0.04316702 0.03534453 0.03373128 0.03105136
 0.04402393 0.03534449 0.03534459 0.02488787 0.07127575 0.03071683
 0.03373135 0.06832111 0.12168473 0.03486726 0.03674826 0.03916035
 0.03534264 0.03105138 0.02488787 0.02488787 0.03373133 0.03625698
 0.03373134 0.04470804 0.0510902  0.03373263 0.05695342 0.05381503
 0.03373066 0.03105137 0.03373135 0.0550217  0.07360433 0.06832105
 0.02488787 0.06729966]
tr_loss:[0.03454912 0.03367103 0.03454912 0.02452751 0.02452752 0.03454913
 0.03454917 0.03367488 0.10752912 0.03454914 0.06671782 0.03051448
 0.04042166 0.03367493 0.03998771 0.04041635 0.03051447 0.03660471
 0.03454913 0.03051449 0.0336749  0.03598632 0.03051448 0.03454914
 0.05385568 0.03051448 0.05382272 0.03454916 0.03571297 0.03063503
 0.03051292 0.03654544 0.02452751 0.02452755 0.06965797 0.03367487
 0.05079042 0.03454916 0.02452751 0.03367488 0.03454925 0.04042191
 0.03454913 0.10754454 0.03051448 0.03337796 0.03051446 0.03454915
 0.06455436 0.02452752]
tr_loss:[0.02977141 0.0240307  0.02857462 0.02563763 0.05242064 0.02563764
 0.06542288 0.02977142 0.03418807 0.04017552 0.06122967 0.02977143
 0.03110863 0.02563764 0.02977142 0.10473325 0.03359815 0.02977142
 0.05081047 0.02940966 0.03029749 0.02977143 0.02977143 0.06542294
 0.09441913 0.02977141 0.06542294 0.02977145 0.03167801 0.06542289
 0.02977142 0.02977143 0.05027515 0.0240307  0.06542291 0.02977144
 0.02977144 0.03029749 0.06542292 0.03133298 0.02980777 0.02563764
 0.02400491 0.0285743  0.02894276 0.02977881 0.0294097  0.0515273
 0.02977143 0.04426483]
tr_loss:[0.02813332 0.05018704 0.02813334 0.02813335 0.02478735 0.02502887
 0.02914912 0.02813331 0.02813336 0.02813336 0.06582356 0.02813334
 0.02325555 0.02813337 0.02502888 0.06676103 0.09345913 0.02813333
 0.02813409 0.02949466 0.07030459 0.0252885  0.02914912 0.05930733
 0.0693378  0.06933783 0.05252293 0.02914912 0.06933787 0.02813334
 0.02865838 0.02949467 0.02456222 0.02813334 0.02813333 0.02865837
 0.02502885 0.02813336 0.0693378  0.05955806 0.02502887 0.02502888
 0.02813334 0.09081704 0.0291491  0.02813336 0.02502886 0.05019743
 0.05288189 0.02914912]
tr_loss:[0.02482536 0.02259675 0.02482536 0.02482536 0.02790589 0.02774915
 0.02482536 0.02138132 0.02482535 0.02482538 0.02137871 0.02790586
 0.02482535 0.02774914 0.06412318 0.02774914 0.02482536 0.02259675
 0.02774915 0.04679343 0.02482535 0.05944607 0.04488198 0.02482537
 0.04014899 0.02599333 0.02482537 0.02482536 0.06412321 0.02774913
 0.02790573 0.0469188  0.02259674 0.02482535 0.02790585 0.06490425
 0.02482535 0.02259674 0.02482535 0.02482536 0.02482536 0.0635071
 0.02482538 0.02601356 0.02482537 0.059448   0.02774914 0.02496281
 0.06412324 0.044882  ]
tr_loss:[0.02166644 0.02332119 0.0216665  0.01925905 0.02567307 0.03564816
 0.07272577 0.02166646 0.0461625  0.05441653 0.02166644 0.02166646
 0.02332366 0.0254191  0.02487124 0.02332367 0.02201529 0.01924963
 0.05159044 0.02332364 0.02166645 0.03470553 0.01924963 0.02332364
 0.02166643 0.0176303  0.0192496  0.02486676 0.03440021 0.02255967
 0.02166646 0.02160842 0.0192496  0.02486313 0.01928103 0.02166645
 0.02257427 0.02332366 0.02166645 0.04616835 0.02166648 0.01924962
 0.0544166  0.01924964 0.05187909 0.02166646 0.02166646 0.02166646
 0.05365785 0.02486309]
tr_loss:[0.01739408 0.0155186  0.02239405 0.07227724 0.03867774 0.0487978
 0.01912247 0.02239405 0.02239402 0.0341184  0.01739408 0.02254777
 0.02238468 0.07222112 0.02239406 0.01551859 0.01551858 0.01912248
 0.01968465 0.03140549 0.02239404 0.02253722 0.02239404 0.02239405
 0.02237622 0.01551861 0.01900097 0.0223973  0.02239406 0.01912246
 0.01503243 0.0435329  0.02239405 0.0471631  0.02239404 0.01551858
 0.07068415 0.01739408 0.03211259 0.02239404 0.01551857 0.01912246
 0.01739411 0.02164348 0.02237615 0.01739408 0.04509819 0.01739408
 0.0435329  0.01551857]
tr_loss:[0.01918911 0.01652563 0.05044588 0.02537961 0.0208524  0.04203667
 0.039052   0.01492485 0.01492486 0.0308718  0.02534476 0.01946533
 0.01595096 0.01492486 0.02534466 0.01492485 0.08406208 0.04546406
 0.04546405 0.02080195 0.02534476 0.03905214 0.02835374 0.02534476
 0.04546408 0.0165256  0.04546409 0.0197982  0.02233745 0.02534475
 0.02534476 0.02534472 0.02534475 0.01918915 0.01492486 0.03567088
 0.04546403 0.03598187 0.01492235 0.01652562 0.01556279 0.03624562
 0.04432984 0.02534737 0.0159419  0.01652561 0.04352658 0.01652562
 0.03229097 0.01652562]
tr_loss:[0.01349951 0.01748617 0.02233317 0.02233317 0.0116591  0.01748618
 0.02233319 0.03045852 0.02233318 0.03283064 0.02500392 0.01165857
 0.01165909 0.03626972 0.02233317 0.0334025  0.03540553 0.02233317
 0.02233319 0.02233318 0.01165909 0.02233317 0.034319   0.01165908
 0.02233317 0.02233316 0.01349183 0.04116589 0.01488713 0.01165859
 0.01349175 0.02055701 0.0411659  0.01165897 0.02847025 0.01165907
 0.0107691  0.0910465  0.02041064 0.03400669 0.01165909 0.02233317
 0.02233315 0.0148931  0.0116591  0.01570796 0.01165908 0.01165908
 0.01572194 0.0866635 ]
tr_loss:[0.02051026 0.01999306 0.01175402 0.0168581  0.02046973 0.01175401
 0.02046991 0.01175401 0.01171664 0.02046977 0.02046973 0.01480407
 0.02637268 0.08816124 0.01999312 0.02514868 0.02422255 0.01480408
 0.02049485 0.02046975 0.01999306 0.01600053 0.01999306 0.02046975
 0.02046975 0.01480406 0.01571523 0.01175392 0.02046975 0.03337534
 0.05192733 0.01175402 0.01175402 0.01683311 0.02046971 0.02046978
 0.04226149 0.02046973 0.01175402 0.09385876 0.02225765 0.03424775
 0.02046975 0.02046974 0.01175401 0.04226149 0.01999305 0.02631606
 0.0378086  0.02046975]
tr_loss:[0.04660546 0.01437123 0.04660554 0.04660554 0.09517113 0.02233961
 0.01437122 0.01437124 0.01931792 0.0223396  0.01424774 0.01931792
 0.01931792 0.01874162 0.01931791 0.0193179  0.01931792 0.05841285
 0.01437123 0.0223396  0.01874156 0.01931791 0.01931794 0.02993707
 0.01437123 0.01437124 0.01874156 0.06401964 0.02297701 0.02233958
 0.01931793 0.01437124 0.01931791 0.0223396  0.04660553 0.05674128
 0.0193179  0.01932397 0.01437123 0.01437124 0.06402566 0.03840584
 0.02233961 0.06387436 0.01437123 0.01437124 0.04660552 0.01874164
 0.04660552 0.0193179 ]
tr_loss:[0.02130846 0.04569439 0.01739128 0.0122804  0.01925105 0.01996025
 0.01739127 0.01874044 0.01882109 0.04683999 0.01739129 0.01996021
 0.01739129 0.09454965 0.02027042 0.01996024 0.01739129 0.02096658
 0.03812132 0.01996022 0.08919497 0.01996023 0.01739129 0.0188207
 0.01228042 0.09454966 0.01228041 0.01739128 0.01228043 0.04569437
 0.04569437 0.04569438 0.01996022 0.01874042 0.01739116 0.01739129
 0.01826301 0.01739141 0.02131631 0.01996022 0.01874043 0.01739129
 0.01228042 0.01739128 0.01739126 0.01739127 0.01739126 0.01739129
 0.01739128 0.01228042]
tr_loss:[0.01759878 0.00942907 0.01846709 0.01784939 0.01844891 0.01785161
 0.01729378 0.00991726 0.04695439 0.01622522 0.01759879 0.03880306
 0.01622821 0.01975463 0.01759879 0.00991726 0.0213881  0.01633833
 0.01621998 0.09266488 0.00900136 0.04518042 0.05814832 0.0175998
 0.02140134 0.0162267  0.04512408 0.01759877 0.08941194 0.02770781
 0.01622668 0.01857684 0.00990675 0.01844921 0.01759877 0.03210469
 0.01640174 0.01622666 0.02027657 0.01729088 0.03882058 0.05479714
 0.0188616  0.0197425  0.01622668 0.09362901 0.0175988  0.03881911
 0.00991728 0.01622667]
tr_loss:[0.01596271 0.01596269 0.01596271 0.01606747 0.01669994 0.034513
 0.01596265 0.00857663 0.00857663 0.01431974 0.01596272 0.01452072
 0.04641009 0.01557475 0.01596272 0.01669994 0.01932178 0.01669994
 0.00857665 0.08602335 0.01596269 0.01596272 0.04641014 0.01596274
 0.03425325 0.04641012 0.02477654 0.01557475 0.04641011 0.01046125
 0.0085766  0.01557474 0.01669974 0.01596271 0.01596271 0.01557476
 0.04641013 0.01557849 0.01557476 0.04641011 0.01720971 0.00857664
 0.01596271 0.0193215  0.0858256  0.01557474 0.01557473 0.01557476
 0.08582318 0.0388841 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2700 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2701, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2701 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2702, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2702 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2703, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2703 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2704, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2704 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2705, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2705 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2706, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2706 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2707, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2707 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2708, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2708 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2709, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2709 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2710, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2710 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2711, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2711 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2712, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2712 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2713, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2713 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2714, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2714 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2715, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2715 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2716, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2716 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2717, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2717 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2718, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2718 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2719, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2719 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2720, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2720 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2721, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2721 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2722, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2722 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2723, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2723 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2724, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2724 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2725, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2725 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2726, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2726 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2727, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2727 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2728, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2728 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2729, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2729 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2730, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2730 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2731, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2731 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2732, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2732 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2733, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2733 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2734, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2734 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2735, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2735 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2736, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2736 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2737, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2737 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2738, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2738 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2739, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2739 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2740, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2740 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2741, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2741 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2742, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2742 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2743, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2743 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2744, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2744 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2745, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2745 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2746, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2746 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2747, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2747 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2748, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2748 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2749, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2749 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2750, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2750 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2751, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2751 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2752, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2752 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2753, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2753 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2754, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2754 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2755, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2755 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2756, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2756 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2757, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2757 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2758, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2758 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2759, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2759 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2760, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2760 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2761, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2761 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2762, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2762 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2763, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2763 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2764, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2764 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2765, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2765 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2766, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2766 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2767, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2767 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2768, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2768 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2769, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2769 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2770, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2770 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2771, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2771 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2772, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2772 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2773, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2773 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2774, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2774 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2775, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2775 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2776, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2776 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2777, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2777 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2778, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2778 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2779, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2779 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2780, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2780 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2781, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2781 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2782, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2782 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2783, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2783 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2784, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2784 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2785, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2785 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2786, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2786 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2787, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2787 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2788, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2788 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2789, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2789 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2790, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2790 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2791, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2791 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2792, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2792 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2793, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2793 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2794, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2794 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2795, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2795 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2796, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2796 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2797, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2797 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2798, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2798 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2799, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2799 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2800, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2700
text_input.shape
(2800, 14400)
learning_input_tmp.shape
(2800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2800, 80)
learning_output.shape
(750, 80)
Model: "sequential_57"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_57 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3262119 1.3262846 1.3262119 1.3807161 1.3807161 1.3788738 1.3262119
 1.3262119 1.3211434 1.3807161 1.3262119 1.3788741 1.3807162 1.2565577
 1.3807162 1.3262119 1.3947303 1.3262208 1.3001294 1.4366944 1.3807164
 1.3807162 1.3004525 1.3807161 1.3263702 1.4365151 1.3788738 1.3262122
 1.3259007 1.3262246 1.2741269 1.3809965 1.326212  1.2528228 1.4364159
 1.3262119 1.3807161 1.3803586 1.3947065 1.3807161 1.3262119 1.2499387
 1.3002256 1.326212  1.4347591 1.3262119 1.3980582 1.3807161 1.3788737
 1.326212 ]
tr_loss:[0.7917965  0.7917965  0.79179657 0.7917965  0.80233335 0.80444604
 0.7922266  0.80444604 0.8147523  0.8451616  0.7953792  0.8147523
 0.79543877 0.80444604 0.8442246  0.8147522  0.80444604 0.80444604
 0.7624564  0.7917964  0.7917965  0.78155345 0.7892693  0.8147521
 0.80439425 0.79535776 0.8442246  0.8147523  0.80444586 0.7953578
 0.80320233 0.81476134 0.79479206 0.80444604 0.7893237  0.8147522
 0.8147548  0.8147519  0.8457128  0.80443794 0.7917965  0.76464033
 0.79179657 0.8147522  0.8442246  0.84422463 0.8496232  0.7646405
 0.80444604 0.7953557 ]
tr_loss:[0.4416079  0.4760182  0.48325485 0.4760182  0.47123647 0.46181363
 0.4330522  0.47601813 0.4416079  0.47601813 0.44160795 0.44160795
 0.47601813 0.45326167 0.5420546  0.44528085 0.47601825 0.4760182
 0.46181363 0.48438445 0.46181363 0.46181363 0.43305224 0.4618137
 0.45056573 0.47601813 0.43039626 0.54079884 0.45050207 0.44528085
 0.4618137  0.46181363 0.45056468 0.4720052  0.44528022 0.4618136
 0.46181363 0.4416079  0.44526762 0.47122592 0.46181375 0.45542628
 0.44528094 0.43305215 0.4330522  0.46181375 0.46198002 0.4365098
 0.44160786 0.46181363]
tr_loss:[0.32693025 0.32156235 0.32018128 0.34337896 0.32008678 0.31769767
 0.31769767 0.31651655 0.32018122 0.32693025 0.31795058 0.31769767
 0.32693022 0.31769767 0.31862304 0.32018122 0.31769767 0.32018122
 0.31862283 0.3178974  0.35359123 0.33062142 0.34255922 0.3357666
 0.3201812  0.3003891  0.3179502  0.321308   0.30038905 0.3176977
 0.32018122 0.29843575 0.32018125 0.31769767 0.31765866 0.3003891
 0.3316978  0.3201812  0.31769767 0.31769764 0.31084657 0.32156187
 0.31795055 0.3108461  0.31769767 0.32693028 0.30038908 0.32018125
 0.330763   0.300389  ]
tr_loss:[0.18880722 0.21681342 0.18543279 0.18880716 0.20082478 0.2053022
 0.19160603 0.19147226 0.18543279 0.18543278 0.2053022  0.19766921
 0.19766918 0.20530224 0.20530221 0.18543279 0.20530224 0.19147226
 0.21825662 0.1976692  0.18543279 0.20530224 0.21951005 0.19592983
 0.18543282 0.20530224 0.19147229 0.19766922 0.18543278 0.20530224
 0.20530221 0.21785697 0.20530224 0.20530224 0.1888216  0.21825385
 0.18880168 0.20530221 0.19594452 0.20531125 0.21367335 0.20530221
 0.19635971 0.18880713 0.20530221 0.20530224 0.20530221 0.19766922
 0.18874924 0.19766918]
tr_loss:[0.11461516 0.10653081 0.13287912 0.13271607 0.15584779 0.11132194
 0.11210629 0.115135   0.15584758 0.13271606 0.13271609 0.11211053
 0.11460534 0.10422148 0.11461522 0.11211605 0.17968209 0.1121105
 0.1113219  0.10422149 0.132737   0.11132194 0.10594632 0.11211048
 0.1121105  0.13271606 0.10949934 0.11200714 0.1113219  0.11211048
 0.12015522 0.12367456 0.175967   0.11132193 0.13271789 0.16065793
 0.1095111  0.1042215  0.1434753  0.1327161  0.1121105  0.18227774
 0.10949929 0.10949731 0.14465322 0.13281688 0.1113219  0.1113219
 0.1327161  0.10422151]
tr_loss:[0.08219217 0.08219217 0.11431887 0.08355083 0.08784086 0.07831961
 0.08240595 0.11431889 0.08194948 0.08784088 0.10919017 0.11431886
 0.08355086 0.12637517 0.08784087 0.08784086 0.11526544 0.11322905
 0.08355078 0.08355077 0.08220178 0.07831232 0.07831229 0.08355077
 0.11431888 0.15230724 0.11431883 0.11431873 0.11431887 0.11431889
 0.07831229 0.1575011  0.11431889 0.11431887 0.0783123  0.07831232
 0.08480343 0.08355076 0.08219214 0.08784087 0.15230751 0.08219219
 0.08355077 0.11921012 0.11431888 0.0835508  0.11431883 0.15751505
 0.11512967 0.0783125 ]
tr_loss:[0.07792668 0.11477195 0.15060231 0.13465957 0.11477189 0.11477194
 0.08365088 0.08702672 0.11477195 0.12196179 0.08100267 0.08100251
 0.0881465  0.07566948 0.15911785 0.0820505  0.1147719  0.11116815
 0.07793703 0.08100268 0.08806518 0.08806519 0.08806518 0.07792669
 0.11477192 0.08820418 0.08806522 0.07566948 0.11477196 0.11477194
 0.08806522 0.11477196 0.11477192 0.12537801 0.11477196 0.07566947
 0.08806519 0.11477192 0.0880653  0.0756695  0.11477192 0.07792673
 0.11477194 0.0880652  0.07566948 0.11477194 0.07566948 0.08806515
 0.07566946 0.07792668]
tr_loss:[0.07507139 0.10113422 0.08286528 0.08462945 0.07507137 0.10611405
 0.11564521 0.10611403 0.10611404 0.10611401 0.07516513 0.07507133
 0.10611404 0.10611404 0.12524214 0.07707219 0.11213256 0.10611405
 0.10611405 0.08457379 0.13286476 0.08130208 0.08457651 0.10611653
 0.06948617 0.07508976 0.06948616 0.14040479 0.10611407 0.10611399
 0.12524207 0.06949325 0.06948617 0.07066186 0.10611405 0.06948697
 0.06948616 0.10543811 0.10611401 0.10611404 0.14516306 0.10611405
 0.12524252 0.07507141 0.10611405 0.10623401 0.07507132 0.13286038
 0.10611165 0.07507136]
tr_loss:[0.10044749 0.1004475  0.10044751 0.10044749 0.08445688 0.06790293
 0.1004475  0.10044749 0.08019882 0.08445688 0.08445691 0.07626025
 0.1004475  0.1004475  0.07900486 0.08570157 0.1056964  0.10044749
 0.10044749 0.08446295 0.10044786 0.08445761 0.0801989  0.06790294
 0.08019881 0.10044742 0.14000055 0.09885002 0.1004474  0.07913855
 0.10044748 0.0844569  0.06790294 0.08553605 0.10044748 0.06790294
 0.08445686 0.08445685 0.08797905 0.07730205 0.10044754 0.06790294
 0.08445687 0.08570223 0.06790294 0.14018324 0.08019879 0.08445691
 0.10044686 0.10351622]
tr_loss:[0.05558468 0.11331165 0.08815285 0.07235954 0.08815288 0.0881528
 0.08815286 0.07235958 0.06003805 0.08811024 0.09641308 0.05558468
 0.07654412 0.07691703 0.05558396 0.07491247 0.07491244 0.08815283
 0.08815289 0.13527203 0.05558467 0.07235958 0.08815284 0.07653686
 0.05558467 0.08815286 0.07235953 0.05558468 0.05704888 0.05558465
 0.11309693 0.06839581 0.07235953 0.08815288 0.07654414 0.11309695
 0.07654417 0.07654413 0.07491244 0.09620014 0.07654387 0.07235958
 0.07653214 0.08815281 0.05558466 0.08815284 0.08815287 0.09638572
 0.13228516 0.07236023]
tr_loss:[0.06232959 0.06232961 0.05003942 0.03107961 0.12048273 0.06232517
 0.05003942 0.0310796  0.0623296  0.0623296  0.03107958 0.06232963
 0.07429426 0.07027431 0.04705962 0.0481969  0.06315202 0.07429437
 0.06318198 0.06232962 0.12167096 0.04705964 0.05003943 0.03107959
 0.0623296  0.06314301 0.05003948 0.06232961 0.06315186 0.03107958
 0.03107958 0.0470596  0.06232956 0.0470596  0.09093398 0.12080531
 0.03107958 0.06232962 0.04705959 0.06232953 0.06232955 0.0470596
 0.0492648  0.05003944 0.03107958 0.04926477 0.0623296  0.0688059
 0.04072057 0.06232958]
tr_loss:[0.04953443 0.04953441 0.03669612 0.04953444 0.03669609 0.04662059
 0.03669607 0.04953443 0.03743941 0.04826486 0.04953442 0.02247941
 0.03669608 0.03743942 0.03743943 0.0495372  0.02247945 0.03417867
 0.0341763  0.03417629 0.02247944 0.08377372 0.06611006 0.02247943
 0.04952642 0.11253037 0.03669607 0.04953443 0.03417629 0.02247944
 0.03669612 0.03743943 0.03759791 0.06053343 0.04704932 0.06906525
 0.0401613  0.04953443 0.05822261 0.06906496 0.0378399  0.04953443
 0.04953443 0.04953443 0.04016116 0.03417628 0.04953443 0.03417629
 0.04953443 0.05456679]
tr_loss:[0.04378184 0.0315126  0.01853938 0.07161471 0.03717302 0.04497571
 0.01853939 0.03144316 0.03144313 0.02807134 0.04497571 0.04388366
 0.03144317 0.02764351 0.04497566 0.03144373 0.05712323 0.03822779
 0.06587937 0.04497571 0.03144315 0.04497571 0.04797731 0.0449757
 0.06655009 0.04497568 0.04742803 0.04497581 0.02764351 0.0449757
 0.03151261 0.0276435  0.04497569 0.02764349 0.03145029 0.02764351
 0.05939366 0.04497569 0.02764352 0.03151261 0.0276435  0.04497566
 0.01853939 0.01853941 0.0185394  0.06928801 0.03144315 0.11907077
 0.03402702 0.02764351]
tr_loss:[0.02986696 0.01785966 0.0415509  0.01785966 0.04508375 0.01785966
 0.03243583 0.04315836 0.11291127 0.026387   0.04594499 0.01785968
 0.0434925  0.04315837 0.02638697 0.04315835 0.0298687  0.01785967
 0.01785966 0.03286695 0.03270995 0.02638697 0.03286692 0.01785967
 0.04315836 0.03259195 0.0298687  0.04315835 0.03440375 0.04315837
 0.01785968 0.08685477 0.04319925 0.01785963 0.04315839 0.04507887
 0.04754139 0.0328669  0.04325808 0.03286692 0.0263872  0.01785966
 0.02638698 0.03286691 0.04155079 0.03395005 0.04315832 0.01787115
 0.02638698 0.02986873]
tr_loss:[0.02859864 0.04425503 0.02859864 0.02859863 0.03710993 0.04425504
 0.04425506 0.04692281 0.04415628 0.04425509 0.04425507 0.04516348
 0.04425213 0.03710991 0.04425504 0.04632149 0.03498613 0.02012661
 0.0371099  0.11569247 0.04705915 0.02012662 0.11647271 0.04425503
 0.03143353 0.04425505 0.02859866 0.04715319 0.02859863 0.0326248
 0.02012663 0.04251588 0.02859865 0.10885849 0.06247411 0.03710993
 0.0338411  0.0442551  0.04425504 0.03143355 0.02012662 0.02859866
 0.04425503 0.04425506 0.03710992 0.02012664 0.02859866 0.04483285
 0.04742193 0.04425504]
tr_loss:[0.03365883 0.0452003  0.02848483 0.01917764 0.01917765 0.03132003
 0.02848484 0.01961814 0.04526164 0.02732176 0.02732177 0.02848225
 0.01917762 0.09967576 0.04520031 0.02946891 0.04520029 0.01917763
 0.03057832 0.04520028 0.02845477 0.01917862 0.0448405  0.0452003
 0.01917765 0.03102029 0.03365989 0.06630703 0.02732174 0.02732175
 0.0490347  0.01917762 0.08161227 0.03087667 0.03365888 0.04520029
 0.04483363 0.02732175 0.03367224 0.01917763 0.03365887 0.10620005
 0.0452004  0.02732174 0.03803445 0.04520028 0.03365887 0.04401598
 0.02732173 0.03365884]
tr_loss:[0.02604772 0.04527904 0.04269655 0.02666242 0.02995029 0.02604774
 0.02809856 0.02604772 0.0260477  0.02656155 0.04527907 0.04527904
 0.07097492 0.0178998  0.06307107 0.04527904 0.07694592 0.05164329
 0.04527906 0.04527905 0.02604771 0.04527904 0.01789981 0.02995032
 0.02604772 0.05843478 0.04527904 0.01789981 0.02606765 0.0265616
 0.02995034 0.0260477  0.02604774 0.0178998  0.02995034 0.04527904
 0.02995034 0.0260477  0.04527919 0.04527906 0.02604771 0.0260477
 0.04448918 0.03008267 0.04527904 0.04527905 0.05126697 0.0265616
 0.04527998 0.08139437]
tr_loss:[0.08974396 0.02880173 0.02880173 0.04279245 0.02699165 0.05583244
 0.02880174 0.0891469  0.02880175 0.02880174 0.04517535 0.04517541
 0.0272988  0.04517538 0.02880174 0.01941    0.05582058 0.04517541
 0.04517539 0.04915153 0.04517537 0.02699168 0.01941    0.0451754
 0.01940998 0.02880172 0.0648668  0.02729879 0.02880173 0.02699168
 0.0451754  0.02880173 0.02880173 0.0269933  0.0451754  0.04517541
 0.04517541 0.0451754  0.02762173 0.0234392  0.07490736 0.02699169
 0.02880173 0.02699168 0.01940998 0.01941029 0.04513767 0.0451754
 0.02729878 0.04517539]
tr_loss:[0.06193421 0.0300535  0.03027341 0.02272787 0.0305043  0.0300502
 0.02272786 0.04671531 0.02053858 0.02987907 0.0300502  0.03006389
 0.03049639 0.03026951 0.02272787 0.04671531 0.02260141 0.0467153
 0.0467153  0.03913785 0.04671533 0.04671532 0.04671533 0.04671531
 0.04671532 0.02987964 0.0568859  0.03049611 0.04671527 0.03005021
 0.02272785 0.03049608 0.04671533 0.04671533 0.04670068 0.04671529
 0.05103355 0.04679497 0.03005022 0.04671527 0.03049609 0.03479273
 0.04671531 0.06541153 0.03049606 0.02272783 0.0467153  0.03026949
 0.04671531 0.07514433]
tr_loss:[0.03026925 0.04582453 0.04371559 0.04582452 0.03026925 0.0301012
 0.04582453 0.03010197 0.03026924 0.04653611 0.03026927 0.03026924
 0.05524587 0.030102   0.03009522 0.04582452 0.02199569 0.08459549
 0.02199558 0.02933662 0.07180194 0.03026928 0.0889808  0.02933661
 0.02199559 0.04582453 0.05899478 0.06217393 0.03026926 0.02199556
 0.03645208 0.07575767 0.02199555 0.04582452 0.04582451 0.02199559
 0.04582454 0.02199559 0.0293368  0.04582452 0.02199557 0.04371563
 0.04582449 0.0216519  0.06796248 0.02933663 0.04582454 0.04371553
 0.03026924 0.04582453]
tr_loss:[0.04280386 0.0278698  0.05267487 0.02786985 0.02735557 0.08960195
 0.02585238 0.08961808 0.04280385 0.02735561 0.02786971 0.0258524
 0.04589321 0.02786981 0.04589323 0.02735544 0.0273556  0.01798081
 0.04280383 0.02786983 0.02762466 0.01798079 0.04280385 0.01798079
 0.0273556  0.0278698  0.04280384 0.02108172 0.0428144  0.0903267
 0.04280386 0.03134093 0.03912219 0.04280286 0.04280386 0.07839094
 0.02735558 0.02585238 0.01554282 0.02786978 0.04280385 0.02585238
 0.07839174 0.04280384 0.04769734 0.02786979 0.01798078 0.02585239
 0.06945933 0.02585278]
tr_loss:[0.04008725 0.02339993 0.04008725 0.02187107 0.02187109 0.06298406
 0.02187107 0.04008726 0.04008725 0.02187108 0.01522771 0.02514196
 0.02514201 0.01523554 0.04008725 0.02514198 0.04008725 0.04008725
 0.01522769 0.04522004 0.02187109 0.04008726 0.05256574 0.02514199
 0.04008723 0.025142   0.0820614  0.02187109 0.0267786  0.02339994
 0.04008728 0.02144452 0.02680051 0.02685313 0.02187107 0.02339952
 0.05943022 0.06298387 0.0470696  0.01522768 0.02348471 0.0152278
 0.02514199 0.02339994 0.02339914 0.02187109 0.02442386 0.04008725
 0.04008722 0.05943531]
tr_loss:[0.01825397 0.01836592 0.0225292  0.01444246 0.02252919 0.01444246
 0.03665546 0.0200565  0.03805419 0.01858007 0.03805418 0.01858007
 0.03805417 0.01858006 0.01444246 0.03805419 0.03805418 0.01831828
 0.01444246 0.01444246 0.02254613 0.04408768 0.03696482 0.01831829
 0.03805419 0.03805419 0.0225292  0.03805419 0.03679468 0.03805418
 0.01873652 0.01858006 0.01444247 0.04271038 0.01831842 0.01444248
 0.08598994 0.03805419 0.02348435 0.02387533 0.03853262 0.03805416
 0.0225292  0.0225292  0.01444246 0.01444246 0.01444248 0.01831829
 0.02252918 0.03805418]
tr_loss:[0.04887883 0.01769609 0.03932042 0.01769609 0.04815469 0.02055258
 0.07236116 0.02524491 0.01750828 0.0723611  0.04035883 0.04035882
 0.02524426 0.03117716 0.04035882 0.0252449  0.04035882 0.017508
 0.03225475 0.02073225 0.02345685 0.04035883 0.04035858 0.04188808
 0.05296304 0.02524493 0.01750829 0.121192   0.057266   0.01750829
 0.04594155 0.04035882 0.04035882 0.0175083  0.02086148 0.02055764
 0.02087815 0.01750831 0.05726425 0.11482485 0.04633194 0.04035883
 0.04634079 0.09934466 0.01750831 0.02055259 0.04036239 0.04035883
 0.02055259 0.04121695]
tr_loss:[0.0181564  0.03962529 0.02775831 0.01815638 0.01882969 0.02062907
 0.06989583 0.01878385 0.03962167 0.03909651 0.02062906 0.02775835
 0.02062904 0.01815637 0.03909791 0.02775834 0.01815636 0.02775833
 0.04586858 0.01878385 0.05482795 0.02062907 0.01815635 0.02775832
 0.01878388 0.04687461 0.02775833 0.02062903 0.02285091 0.01815639
 0.03962167 0.02775733 0.01815642 0.039621   0.0577285  0.04655813
 0.03962167 0.04408102 0.02775831 0.01878386 0.10873091 0.02145756
 0.03962168 0.03962151 0.01878384 0.02775831 0.02775832 0.03962167
 0.05482768 0.03962183]
tr_loss:[0.01811272 0.02177528 0.03550832 0.01636261 0.01636262 0.03707189
 0.03707207 0.02429501 0.05332469 0.02429514 0.03707189 0.0370719
 0.03707189 0.0187843  0.03305854 0.02429515 0.01811237 0.09221119
 0.04656705 0.03603277 0.03707189 0.01816271 0.03707191 0.0370719
 0.03707189 0.03707189 0.03707191 0.01878434 0.03707189 0.0370719
 0.03707189 0.02066134 0.05871546 0.01878427 0.04329171 0.0206615
 0.04585116 0.04585079 0.05871523 0.01811239 0.01878427 0.02429511
 0.03309698 0.02429511 0.01636262 0.03562795 0.0370719  0.01878426
 0.03707196 0.03707191]
tr_loss:[0.03495964 0.02223184 0.01827205 0.0349596  0.02840953 0.03495963
 0.04841015 0.02110977 0.01475503 0.08255191 0.02307124 0.01827202
 0.03495961 0.04212507 0.01475503 0.0335853  0.0147743  0.03495963
 0.01475505 0.01827206 0.01475504 0.03495964 0.03495964 0.01475502
 0.02089837 0.01475502 0.04425838 0.01475502 0.01827206 0.01827206
 0.01827204 0.03495963 0.02108612 0.08255203 0.02147565 0.02147559
 0.03495964 0.01827207 0.03496911 0.03496023 0.03495963 0.03495755
 0.02085302 0.02317128 0.01480326 0.03495964 0.03495964 0.03495963
 0.03495963 0.02102442]
tr_loss:[0.03619483 0.03619483 0.01516054 0.02320485 0.02163132 0.03625378
 0.03619484 0.02163131 0.02614382 0.04574747 0.03619482 0.02320485
 0.02163133 0.03619485 0.09057752 0.03619481 0.03619484 0.03619483
 0.02320486 0.03628285 0.01516054 0.03619483 0.01516057 0.05528725
 0.03619485 0.02163132 0.03722323 0.02677934 0.01516056 0.02163133
 0.03619483 0.04577012 0.01516056 0.02434539 0.01516056 0.03619481
 0.01516056 0.03619483 0.05317282 0.02602884 0.01516055 0.02320486
 0.02331251 0.02242002 0.01516056 0.03619483 0.03619481 0.07925043
 0.01516057 0.03619484]
tr_loss:[0.02286311 0.03801007 0.03559876 0.01580881 0.02537927 0.02291443
 0.05872909 0.03559876 0.01580882 0.02286378 0.02538955 0.01580881
 0.02537928 0.03559875 0.03559875 0.0228631  0.02515075 0.03559875
 0.09070543 0.02722378 0.03271457 0.02537927 0.04185075 0.0158088
 0.03559878 0.01580882 0.01580882 0.06286428 0.02286313 0.0228631
 0.03559873 0.03559874 0.02515076 0.02515074 0.02515076 0.03559875
 0.05218192 0.01789968 0.03559876 0.02515074 0.03559876 0.0158088
 0.02459779 0.0521818  0.0228631  0.02515074 0.03802719 0.03559875
 0.06613201 0.03559875]
text_input.shape
(2800, 14400)
learning_input_tmp.shape
(2800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2800, 80)
learning_output.shape
(750, 80)
Model: "sequential_58"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_58 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2781044 1.2871721 1.343268  1.3026005 1.2872266 1.2872171 1.2785295
 1.2781079 1.2779462 1.2781042 1.2913762 1.3432682 1.343268  1.2779608
 1.2781045 1.2781044 1.2842534 1.2930506 1.2698685 1.343268  1.3089457
 1.2781043 1.2930872 1.2973886 1.2781044 1.2872158 1.2781044 1.2781044
 1.2930505 1.3468503 1.284044  1.3468504 1.2911639 1.2781044 1.344012
 1.2840443 1.2998421 1.2556988 1.2910671 1.3468502 1.3432682 1.328055
 1.3022537 1.2781044 1.3026009 1.3432682 1.2781044 1.2840443 1.292932
 1.352252 ]
tr_loss:[0.70773774 0.65741855 0.6574193  0.6574193  0.6731941  0.6976159
 0.71795475 0.814818   0.6856902  0.6819224  0.68569046 0.6574193
 0.6745909  0.6789684  0.7179548  0.6808898  0.69052553 0.6574192
 0.7189374  0.749979   0.71795475 0.7179548  0.8259756  0.71795475
 0.6733201  0.67549354 0.72133744 0.6856903  0.7214523  0.6856903
 0.65741926 0.67459095 0.682391   0.6574193  0.72145236 0.68240356
 0.7214523  0.71795475 0.71795714 0.72145236 0.65741926 0.67989415
 0.7162358  0.6789888  0.71795475 0.72145236 0.6574193  0.71795475
 0.6856901  0.71790445]
tr_loss:[0.40333033 0.40873986 0.4078343  0.447316   0.40783435 0.4347457
 0.40783435 0.40783435 0.4078343  0.41982144 0.40333024 0.4347457
 0.42001376 0.40874052 0.40783435 0.4078343  0.40333033 0.4396743
 0.4347458  0.42125767 0.42688593 0.4473177  0.4078273  0.43474588
 0.40333027 0.40783423 0.40783423 0.42757636 0.4217592  0.40333024
 0.4078343  0.4347457  0.4212613  0.4347457  0.4212613  0.40783435
 0.41190118 0.40783423 0.40783435 0.40783435 0.40333024 0.4033305
 0.40437156 0.43967438 0.4347457  0.4078618  0.42002243 0.4200229
 0.40783435 0.40783435]
tr_loss:[0.23063362 0.23058558 0.23063359 0.25565147 0.23134169 0.23063365
 0.2532865  0.23134169 0.32638898 0.2556515  0.276657   0.23063359
 0.23058558 0.23063365 0.24334855 0.22884107 0.2305856  0.25565067
 0.23063357 0.24334416 0.23058558 0.22884107 0.23063354 0.23063357
 0.23134169 0.2561376  0.23063362 0.23063354 0.22884102 0.24334863
 0.23058562 0.23063362 0.32643035 0.23063359 0.24257378 0.23517421
 0.23134165 0.23063406 0.23063359 0.3351158  0.23058562 0.24561708
 0.23058558 0.23063359 0.31929386 0.23063359 0.25552052 0.25613007
 0.23397665 0.23063365]
tr_loss:[0.11420891 0.09735001 0.09877472 0.16413513 0.09734999 0.11420895
 0.09474666 0.10633548 0.11420891 0.11420896 0.11420894 0.1142089
 0.10633548 0.09734999 0.11420896 0.09735    0.09285804 0.09474666
 0.09285798 0.09474666 0.11438122 0.09285804 0.11062567 0.10951553
 0.11516085 0.09285802 0.11699291 0.11420892 0.11420891 0.11420882
 0.09474662 0.09735002 0.09735001 0.09734999 0.11191282 0.16687945
 0.09734999 0.09734996 0.11420918 0.09474663 0.09474661 0.11420886
 0.09285803 0.11422936 0.09474666 0.09474663 0.18080899 0.09285799
 0.11420891 0.10664359]
tr_loss:[0.09572226 0.04455461 0.03937554 0.03670235 0.06760157 0.04980856
 0.05474037 0.06760164 0.06760201 0.04455459 0.11925155 0.06760163
 0.04980853 0.06855632 0.0504517  0.05474045 0.06760161 0.04455461
 0.06760155 0.06760162 0.09532271 0.0445546  0.09595291 0.05417448
 0.05474057 0.04980857 0.06760161 0.04455459 0.11894436 0.04455464
 0.03670238 0.04505204 0.04980851 0.06760164 0.06760164 0.09532267
 0.0498086  0.0445546  0.06584698 0.06760161 0.03670238 0.05474039
 0.04455461 0.04455463 0.0684647  0.06760163 0.05474039 0.04455461
 0.03670235 0.03670236]
tr_loss:[0.05388971 0.05800112 0.05388968 0.07707033 0.05388972 0.09618838
 0.06157489 0.0538897  0.05532873 0.05800112 0.06159708 0.06101644
 0.05388967 0.0538894  0.03675583 0.04048985 0.04048988 0.05388973
 0.08855141 0.09431005 0.05388972 0.10773326 0.05957839 0.05290795
 0.04048987 0.06101657 0.0538897  0.05135005 0.04048988 0.05290795
 0.09624181 0.0538897  0.05388971 0.04060213 0.05388971 0.05290795
 0.05800107 0.05800111 0.04048988 0.04048987 0.05800127 0.05290794
 0.0580011  0.05290792 0.0580011  0.05290794 0.06159803 0.04048988
 0.04048987 0.04048986]
tr_loss:[0.05133481 0.0439522  0.05446436 0.05133485 0.09564012 0.04796878
 0.03451275 0.04796879 0.04796879 0.03451274 0.09758981 0.04395217
 0.04395221 0.10165823 0.04796879 0.05021578 0.04395219 0.0439522
 0.03451272 0.03451275 0.0439522  0.04796881 0.0479688  0.04395221
 0.0439522  0.08137959 0.0513348  0.05133486 0.05316454 0.05447611
 0.04395218 0.03480187 0.09170984 0.03451274 0.05133666 0.04174856
 0.05422209 0.04796879 0.04395219 0.07097021 0.04395222 0.04395218
 0.04796883 0.04395146 0.04796879 0.07044728 0.05027445 0.04796896
 0.04796879 0.04208322]
tr_loss:[0.03271779 0.0327867  0.0387423  0.08006249 0.08733715 0.03874229
 0.03271783 0.09216475 0.03743802 0.03874226 0.03898375 0.03647513
 0.0387423  0.03874229 0.03743862 0.03743803 0.03271315 0.037438
 0.03271782 0.04222341 0.03271783 0.02686193 0.02648548 0.03874229
 0.08733795 0.03874229 0.03745048 0.05426931 0.03271782 0.04222352
 0.03271782 0.0387423  0.03743802 0.03271782 0.06813294 0.03743801
 0.04222351 0.02686192 0.04222347 0.05302169 0.03271781 0.03271781
 0.03539842 0.02686195 0.0387423  0.03271779 0.03539513 0.03874229
 0.03277956 0.03743804]
tr_loss:[0.03155426 0.02961    0.03833581 0.05326049 0.03585986 0.03155425
 0.03585982 0.10438095 0.03585986 0.10438011 0.0421895  0.03585985
 0.10298312 0.03155426 0.03833646 0.0352633  0.03585984 0.03586017
 0.03585983 0.03420598 0.03585982 0.03424206 0.03585984 0.0345869
 0.03585986 0.1033444  0.03830264 0.03585983 0.03820486 0.03585981
 0.03420595 0.03833646 0.03585985 0.04071975 0.04055126 0.03155427
 0.03585982 0.03585982 0.04177338 0.04218952 0.0421895  0.034206
 0.03420598 0.03420597 0.03155426 0.03585982 0.03817042 0.04218932
 0.03420599 0.09573866]
tr_loss:[0.03469737 0.03797833 0.04443967 0.03894986 0.03894988 0.04253794
 0.03797833 0.04443964 0.0346966  0.03797833 0.03894985 0.04443965
 0.03894986 0.03788161 0.03566719 0.04445732 0.03797833 0.03786471
 0.04443967 0.04002998 0.03797834 0.03469659 0.03894986 0.03300729
 0.03894985 0.03797834 0.03797832 0.03797834 0.03894992 0.03566719
 0.03469659 0.0346966  0.03566719 0.07360367 0.03894986 0.08455141
 0.0346966  0.11092289 0.0389499  0.03797834 0.03593395 0.03797833
 0.03276252 0.03894988 0.03566719 0.03469658 0.03566717 0.0346966
 0.04443963 0.03566717]
tr_loss:[0.03500278 0.03913422 0.03186309 0.03730638 0.0350025  0.04372521
 0.03492207 0.03573396 0.03186309 0.03947829 0.02880052 0.07525887
 0.0685565  0.03730639 0.09088252 0.0318631  0.03730639 0.03730641
 0.09472268 0.03730641 0.02880051 0.02880051 0.0318631  0.03573395
 0.1029356  0.03730639 0.03573398 0.03361965 0.03730638 0.02880051
 0.04211541 0.03730639 0.03730639 0.03573395 0.03573397 0.03573408
 0.03730639 0.03730639 0.03573395 0.03573393 0.0318631  0.03573395
 0.03185788 0.03573396 0.03573397 0.03186309 0.02880052 0.03730641
 0.03948081 0.03909548]
tr_loss:[0.06307533 0.03707561 0.0375609  0.04154446 0.03707544 0.03960162
 0.10211481 0.03960164 0.02841343 0.02684652 0.0370754  0.03960165
 0.0268461  0.04067017 0.04067722 0.0415445  0.02684618 0.03718632
 0.02841341 0.06718165 0.03707542 0.02841341 0.0415445  0.03960165
 0.03965301 0.02841341 0.02841345 0.0415445  0.03960162 0.09206476
 0.03707545 0.06310564 0.02684608 0.03707541 0.04154447 0.04154455
 0.03960164 0.03960163 0.04154511 0.07029118 0.09206511 0.04127035
 0.02840171 0.03707542 0.03960162 0.02684789 0.03960164 0.03848694
 0.04018802 0.10211812]
tr_loss:[0.02778098 0.04214094 0.02671193 0.02913789 0.02778098 0.03750945
 0.02778115 0.04145662 0.02778785 0.04145586 0.0987701  0.03750943
 0.04063087 0.03953995 0.04335942 0.04145661 0.03812295 0.03954016
 0.04146097 0.02671191 0.03750942 0.027781   0.04228754 0.04179064
 0.0375094  0.0414566  0.04087266 0.04159493 0.04145539 0.0414566
 0.04087267 0.03787982 0.04233437 0.09467771 0.04190898 0.04141807
 0.04196052 0.04145663 0.04145661 0.0414566  0.06632607 0.04087267
 0.02778099 0.04145661 0.0414566  0.04187018 0.03662413 0.02778099
 0.0664491  0.0664486 ]
tr_loss:[0.02591762 0.04071199 0.0944054  0.02841445 0.06919376 0.04071199
 0.03667188 0.02841442 0.02841443 0.04071193 0.04071201 0.04071197
 0.02595833 0.02841443 0.10299344 0.04071199 0.02595833 0.09440555
 0.04071198 0.03954408 0.09444127 0.04071198 0.03954291 0.04071198
 0.02595834 0.04071201 0.0422866  0.04071199 0.04071202 0.02844731
 0.04071198 0.09085164 0.03585698 0.03865651 0.03924618 0.04071195
 0.02841442 0.04071199 0.04070816 0.02841723 0.04071198 0.03585703
 0.09000246 0.03954408 0.04071198 0.03954407 0.04298806 0.03954408
 0.03585701 0.0431556 ]
tr_loss:[0.03946653 0.03232339 0.03800096 0.06174985 0.02731339 0.03946651
 0.03946655 0.02886228 0.03232339 0.03946651 0.03946652 0.0273134
 0.03850902 0.0273134  0.0273134  0.02886231 0.03946649 0.03946652
 0.03946655 0.02886348 0.03232338 0.02886228 0.03946651 0.03460727
 0.03946652 0.06172974 0.03946652 0.02886229 0.03232341 0.04047643
 0.02886229 0.03946652 0.02731339 0.02886229 0.0323234  0.02731341
 0.06174771 0.0288623  0.02886259 0.03232335 0.0273134  0.09056099
 0.03974096 0.03946654 0.0372255  0.03946652 0.03719249 0.03946653
 0.03946663 0.02886228]
tr_loss:[0.03732945 0.03759516 0.03479001 0.03045288 0.02925836 0.03759549
 0.03759519 0.02976033 0.03759519 0.03045288 0.03758436 0.03759521
 0.04031987 0.03764189 0.02925838 0.03690336 0.06227831 0.0372171
 0.03759516 0.02976033 0.02929022 0.03759516 0.02976032 0.03759529
 0.03758436 0.03759436 0.03759516 0.03045286 0.02976033 0.03759517
 0.03759516 0.03759494 0.02925838 0.0375946  0.03746052 0.02925839
 0.03759517 0.03759518 0.03045289 0.0304529  0.03758436 0.03045287
 0.03045288 0.03759514 0.03045288 0.08598652 0.0304529  0.03759519
 0.03758435 0.03551826]
tr_loss:[0.08912136 0.03512707 0.0368563  0.03512709 0.03437905 0.03380966
 0.03512708 0.03649259 0.02987053 0.03686829 0.03512712 0.03685632
 0.03741112 0.03511927 0.03512707 0.02951664 0.03685635 0.03512707
 0.04515354 0.0351271  0.03512711 0.03090381 0.03685442 0.03090379
 0.02951665 0.02951665 0.03512711 0.03515398 0.03512708 0.08052041
 0.08993009 0.06203619 0.03512708 0.02987053 0.03685632 0.03086961
 0.03512703 0.03685645 0.02987055 0.03512707 0.03512712 0.03437809
 0.0309038  0.03512709 0.02987054 0.03580427 0.02951903 0.03685632
 0.10154472 0.08543925]
tr_loss:[0.08903956 0.03064917 0.03195468 0.03359047 0.03064916 0.02935572
 0.03548975 0.02935573 0.0293557  0.03195466 0.03548981 0.0562389
 0.03063928 0.0293557  0.02903924 0.02903927 0.03182266 0.03195469
 0.0354898  0.03419831 0.03188075 0.03362966 0.02935572 0.03195468
 0.03195466 0.03064907 0.03064916 0.03322733 0.03195466 0.09573422
 0.03550173 0.09081972 0.02903641 0.03358865 0.03198081 0.0293557
 0.08796936 0.03195466 0.03548979 0.03195466 0.03547382 0.02903927
 0.02903923 0.03195466 0.03182548 0.03195468 0.03064917 0.03032792
 0.02903924 0.02903926]
tr_loss:[0.0339813  0.02911336 0.02826955 0.02911338 0.02740522 0.02911338
 0.03121996 0.02630215 0.06123333 0.02740524 0.02740522 0.02630216
 0.02740523 0.03109116 0.02630215 0.08407805 0.02740521 0.02911338
 0.02740197 0.02911336 0.08547208 0.02740523 0.02911337 0.02630216
 0.02911338 0.02754078 0.08436952 0.02911337 0.03397948 0.0274052
 0.02740521 0.02740524 0.029108   0.07636803 0.0339813  0.02630217
 0.02630215 0.02740527 0.02923444 0.02740524 0.0338363  0.02740522
 0.03059497 0.02826953 0.08618402 0.04700788 0.02740523 0.03398129
 0.02751134 0.02833944]
tr_loss:[0.08268615 0.03129129 0.02549417 0.04533451 0.03125639 0.02549416
 0.03125639 0.02647416 0.02549417 0.02549418 0.02563599 0.02549418
 0.02549416 0.03659571 0.02647416 0.02156209 0.02549414 0.02647471
 0.03659622 0.02647416 0.02549416 0.02549418 0.02647416 0.03128776
 0.02764219 0.03125638 0.08370095 0.02549416 0.02647416 0.03128777
 0.02647415 0.02764218 0.02647416 0.03125636 0.03128778 0.0818694
 0.02549416 0.02549418 0.02549416 0.03125638 0.03462695 0.03079094
 0.02549416 0.06812291 0.02402739 0.02549414 0.0254952  0.02549414
 0.02647414 0.03782595]
tr_loss:[0.02856338 0.02935134 0.02757377 0.02659639 0.03817956 0.03211238
 0.02656909 0.02656519 0.02656517 0.02630681 0.0265652  0.02630674
 0.03405241 0.02656538 0.02656521 0.03211238 0.03211242 0.04150868
 0.02757378 0.02656522 0.03405242 0.03817957 0.03211241 0.0351475
 0.0294539  0.03405244 0.03211238 0.03405242 0.07495663 0.03405243
 0.03835363 0.04687752 0.0468775  0.03405242 0.02656377 0.04078836
 0.02878327 0.0321124  0.0265652  0.06612307 0.02757377 0.0265652
 0.03405244 0.02490988 0.02656519 0.08314337 0.03451632 0.02658145
 0.03405243 0.0467202 ]
tr_loss:[0.02696864 0.02696864 0.08109185 0.02814526 0.0845228  0.03470931
 0.0308236  0.0308236  0.03082359 0.02814525 0.04865992 0.03560908
 0.03465449 0.02975181 0.02975184 0.03082362 0.03570758 0.02814525
 0.02673709 0.02696865 0.02814524 0.08452357 0.0308236  0.0474233
 0.02696866 0.08196547 0.02702732 0.03082362 0.03082362 0.02814524
 0.02814525 0.02696866 0.0327362  0.02696899 0.08196426 0.02695271
 0.02696857 0.0327362  0.03596736 0.0297477  0.02697179 0.02696864
 0.08160537 0.02814525 0.02769846 0.0308236  0.02814523 0.03273622
 0.06571949 0.08196543]
tr_loss:[0.02679585 0.02661361 0.05811618 0.02708653 0.0349126  0.03111929
 0.02638739 0.02638635 0.04683489 0.07586093 0.03299983 0.02710245
 0.03300695 0.03111929 0.02638634 0.02673606 0.02638637 0.02708653
 0.029073   0.02634746 0.07888204 0.02638635 0.02638635 0.02638636
 0.02634746 0.03300697 0.03312033 0.02638637 0.02638637 0.03732543
 0.03111928 0.02651305 0.02638633 0.08155535 0.03300697 0.03785738
 0.02708653 0.03111928 0.03788105 0.04786119 0.02634746 0.03111929
 0.0311193  0.0311193  0.02708655 0.02708613 0.02638633 0.02638637
 0.02634747 0.03112096]
tr_loss:[0.06544433 0.02552957 0.02477639 0.0328737  0.024117   0.0247764
 0.02826475 0.02826476 0.02537934 0.02568377 0.0306394  0.06544434
 0.02826475 0.0309966  0.02552955 0.02552956 0.03100044 0.0309966
 0.0247764  0.02477638 0.02826474 0.02552957 0.04001255 0.024117
 0.02720348 0.0255296  0.02655101 0.0305509  0.02397282 0.02551923
 0.02478021 0.0306986  0.02554041 0.0255296  0.02552957 0.02477638
 0.0255711  0.02826475 0.02826471 0.02477639 0.02477639 0.02826476
 0.03287794 0.0241089  0.02826477 0.04657006 0.02411703 0.08072841
 0.02411549 0.0309966 ]
tr_loss:[0.02487091 0.03366134 0.02465918 0.06500388 0.02655258 0.02465918
 0.02465918 0.02487092 0.02487097 0.03125345 0.0248709  0.02587778
 0.02586923 0.02655258 0.0265526  0.03125348 0.02881225 0.02655257
 0.03824046 0.02465916 0.02586926 0.06768569 0.0248709  0.02465917
 0.03824121 0.03125354 0.03013728 0.02586925 0.02676998 0.02586927
 0.02465918 0.06474349 0.02586924 0.02465918 0.02655258 0.02487091
 0.0265526  0.02487091 0.03125346 0.033666   0.02690071 0.06341805
 0.02655255 0.02676889 0.02655258 0.03178196 0.02586927 0.02586929
 0.02586927 0.02655261]
tr_loss:[0.06486388 0.02817287 0.06859841 0.03300913 0.02731243 0.06859837
 0.02731237 0.07366759 0.02817289 0.02606171 0.02817288 0.03300913
 0.03077483 0.0281729  0.02817291 0.0281729  0.02817289 0.0281729
 0.0281729  0.0281729  0.02606146 0.03212588 0.02817287 0.03313147
 0.02943997 0.02606148 0.03300913 0.02616121 0.08413369 0.0281729
 0.0736676  0.06488351 0.02817289 0.02731243 0.0398182  0.03300913
 0.02616136 0.04693232 0.03301414 0.0281729  0.03260366 0.06861131
 0.02731244 0.03151364 0.02616126 0.02616125 0.02616126 0.02731243
 0.02731242 0.02731792]
tr_loss:[0.08644638 0.02615216 0.02585153 0.06570046 0.02585154 0.07290639
 0.03262236 0.02813328 0.02808122 0.02813329 0.02808122 0.02882613
 0.02808122 0.02813331 0.02808121 0.02813328 0.02808123 0.02808125
 0.0261776  0.08357911 0.07290415 0.02808124 0.02808122 0.02808123
 0.02808121 0.02629196 0.02615213 0.02808122 0.02615215 0.02808121
 0.02585154 0.02615214 0.02813328 0.08294968 0.05794463 0.02813329
 0.0280812  0.02808122 0.02808124 0.02585154 0.08294602 0.02808121
 0.02808123 0.03132679 0.06438102 0.02813216 0.02808123 0.02813328
 0.02813331 0.03262239]
tr_loss:[0.02688206 0.03041988 0.02652348 0.04588649 0.02652348 0.02688208
 0.02652349 0.02689658 0.0265235  0.02426616 0.02689677 0.02964114
 0.02689677 0.02688208 0.03092729 0.02426615 0.0291197  0.02652517
 0.02692002 0.02652348 0.0268821  0.02688209 0.02652348 0.02689679
 0.02426615 0.02688209 0.02688207 0.02688209 0.06283204 0.02652348
 0.02426616 0.02703999 0.0268821  0.02426616 0.02689678 0.02652348
 0.02652348 0.02652348 0.02652346 0.04551894 0.03021937 0.02688206
 0.0265235  0.0656013  0.03092726 0.02427543 0.07945448 0.02652348
 0.02689679 0.02688211]
tr_loss:[0.02816031 0.02586306 0.03120008 0.06947017 0.03064672 0.03064576
 0.02525491 0.02525493 0.02251939 0.05114968 0.07819525 0.02816031
 0.02525491 0.02586305 0.02622866 0.02586303 0.02816108 0.02251939
 0.02586905 0.0281603  0.03064573 0.02259749 0.02251938 0.02586307
 0.02525491 0.02251939 0.03064572 0.02525491 0.02525491 0.0281603
 0.02586305 0.08262384 0.0225194  0.02251939 0.02525495 0.03029371
 0.02525493 0.0225194  0.02525491 0.02586304 0.03038297 0.02251938
 0.02525488 0.02525494 0.02586305 0.02542035 0.062027   0.06202648
 0.02816031 0.08415451]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2800 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2801, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2801 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2802, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2802 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2803, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2803 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2804, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2804 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2805, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2805 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2806, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2806 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2807, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2807 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2808, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2808 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2809, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2809 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2810, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2810 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2811, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2811 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2812, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2812 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2813, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2813 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2814, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2814 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2815, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2815 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2816, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2816 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2817, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2817 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2818, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2818 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2819, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2819 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2820, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2820 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2821, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2821 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2822, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2822 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2823, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2823 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2824, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2824 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2825, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2825 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2826, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2826 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2827, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2827 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2828, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2828 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2829, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2829 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2830, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2830 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2831, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2831 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2832, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2832 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2833, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2833 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2834, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2834 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2835, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2835 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2836, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2836 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2837, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2837 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2838, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2838 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2839, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2839 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2840, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2840 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2841, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2841 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2842, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2842 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2843, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2843 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2844, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2844 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2845, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2845 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2846, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2846 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2847, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2847 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2848, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2848 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2849, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2849 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2850, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2850 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2851, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2851 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2852, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2852 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2853, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2853 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2854, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2854 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2855, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2855 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2856, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2856 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2857, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2857 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2858, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2858 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2859, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2859 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2860, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2860 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2861, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2861 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2862, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2862 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2863, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2863 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2864, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2864 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2865, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2865 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2866, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2866 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2867, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2867 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2868, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2868 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2869, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2869 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2870, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2870 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2871, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2871 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2872, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2872 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2873, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2873 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2874, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2874 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2875, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2875 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2876, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2876 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2877, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2877 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2878, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2878 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2879, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2879 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2880, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2880 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2881, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2881 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2882, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2882 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2883, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2883 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2884, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2884 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2885, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2885 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2886, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2886 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2887, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2887 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2888, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2888 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2889, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2889 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2890, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2890 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2891, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2891 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2892, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2892 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2893, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2893 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2894, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2894 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2895, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2895 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2896, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2896 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2897, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2897 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2898, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2898 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2899, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2899 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2900, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-2800
text_input.shape
(2900, 14400)
learning_input_tmp.shape
(2900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2900, 80)
learning_output.shape
(750, 80)
Model: "sequential_59"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_59 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2196672 1.184613  1.1842937 1.2196652 1.1842937 1.2196653 1.2110957
 1.1902132 1.1842902 1.1842937 1.1987339 1.1842939 1.218146  1.1981999
 1.1982    1.2196664 1.1843622 1.1815033 1.2258812 1.1982013 1.2033455
 1.1872094 1.219485  1.1842939 1.1842937 1.1469558 1.2196652 1.1842936
 1.1469558 1.1842935 1.1982    1.1842937 1.1981999 1.1982    1.1842939
 1.1901622 1.1981999 1.219661  1.1981999 1.23801   1.1842911 1.2380081
 1.1982    1.1841072 1.219665  1.2219051 1.2196652 1.1982    1.1846696
 1.2046887]
tr_loss:[0.68740356 0.6991475  0.7209533  0.7209533  0.72095335 0.7593578
 0.68740356 0.7209532  0.7209532  0.7209533  0.69055116 0.7667196
 0.7209532  0.75935763 0.6867978  0.75935775 0.7209489  0.69055283
 0.6874035  0.77610284 0.6874037  0.68740356 0.69053733 0.7209526
 0.7209325  0.68740386 0.7209533  0.7209533  0.69899684 0.7451381
 0.7667522  0.72095335 0.6874035  0.687403   0.7209533  0.7209548
 0.74514014 0.6905664  0.72095335 0.68740356 0.72095335 0.7667383
 0.7573339  0.75935775 0.6905512  0.75935775 0.75935763 0.6874036
 0.7709835  0.6881339 ]
tr_loss:[0.39132342 0.3676722  0.3876513  0.39974993 0.36617106 0.4059797
 0.41913825 0.39132348 0.40597963 0.3688504  0.36617097 0.40597963
 0.4002955  0.36617097 0.36100054 0.36100626 0.3676725  0.40597963
 0.39822093 0.3913258  0.39833695 0.38764608 0.40597957 0.40597963
 0.36307073 0.39132342 0.40597963 0.36100054 0.36617097 0.4059797
 0.366171   0.40275842 0.39132348 0.4059797  0.4190289  0.36617097
 0.36617097 0.40597963 0.40597963 0.39132348 0.39132345 0.39132363
 0.39132348 0.3958879  0.40239257 0.3913037  0.3982338  0.4059797
 0.36100048 0.40597963]
tr_loss:[0.21209817 0.21392488 0.21351643 0.21351644 0.21351647 0.20388286
 0.2053338  0.2115458  0.19331828 0.19626033 0.19626032 0.21351647
 0.21365145 0.21351643 0.19611515 0.1962535  0.2135165  0.2038829
 0.21351647 0.2038829  0.25791883 0.19328079 0.21797888 0.21351643
 0.21219894 0.19069363 0.22620034 0.20388289 0.19626033 0.19626032
 0.19328098 0.22642048 0.21232156 0.2038829  0.24979272 0.21351644
 0.21351647 0.20388293 0.21486299 0.20748138 0.21351647 0.20383456
 0.2148618  0.215041   0.19592375 0.19328107 0.19626033 0.21351643
 0.1906801  0.21351647]
tr_loss:[0.14342412 0.16174187 0.14664502 0.16225696 0.14710549 0.14358261
 0.14338103 0.14358261 0.14664903 0.14633659 0.15141371 0.15141372
 0.14611086 0.1435826  0.14610979 0.14358261 0.14342412 0.14418569
 0.13671732 0.14342622 0.14338106 0.15352458 0.14358264 0.14342408
 0.13656855 0.13716249 0.14358519 0.1356903  0.1435826  0.14611086
 0.1893204  0.15141377 0.15141371 0.14611085 0.19093105 0.15141374
 0.14338137 0.14611085 0.15141371 0.14358261 0.15141371 0.15141372
 0.14358261 0.14342412 0.1514137  0.14358266 0.1434241  0.14710549
 0.14236328 0.14710552]
tr_loss:[0.12818472 0.12606436 0.12682293 0.1226146  0.11604731 0.18323809
 0.1248423  0.12448599 0.127394   0.13077874 0.12966117 0.11900947
 0.13487121 0.12448599 0.12601021 0.12451921 0.18323663 0.12966122
 0.12601021 0.12606426 0.14807214 0.12448599 0.14184184 0.12601021
 0.1260652  0.12435982 0.12484231 0.12448601 0.12601021 0.13077876
 0.12448595 0.12448601 0.12601021 0.13487121 0.12448599 0.11958446
 0.13487118 0.13487117 0.12601021 0.11747892 0.1296612  0.13077873
 0.12448597 0.12818542 0.1348712  0.1264304  0.12448597 0.12484336
 0.12484226 0.16853249]
tr_loss:[0.08858174 0.10423684 0.10423674 0.10528784 0.09818102 0.09718533
 0.10423666 0.09369193 0.10269196 0.10056456 0.10268374 0.10423682
 0.09719169 0.09718554 0.0971856  0.08987488 0.10056456 0.09718561
 0.08858185 0.09952703 0.13705519 0.10268333 0.1042368  0.10269196
 0.08858176 0.0971856  0.0885819  0.10056456 0.10423678 0.10275428
 0.09718563 0.08858175 0.10269195 0.0971856  0.10275582 0.10269193
 0.10269196 0.10269195 0.14753768 0.08967333 0.0971856  0.14815898
 0.13706422 0.08858173 0.10269667 0.09718563 0.10275529 0.09718563
 0.09718563 0.10528784]
tr_loss:[0.05958471 0.07833578 0.07539211 0.07529704 0.07237776 0.07240695
 0.06558926 0.05959537 0.05958472 0.05958473 0.07073394 0.07847331
 0.07833578 0.07073397 0.07529621 0.08174384 0.07237775 0.05958472
 0.07833578 0.08018924 0.07529619 0.08492295 0.07446278 0.06681176
 0.07529621 0.07073397 0.07529618 0.07446279 0.06568222 0.07529622
 0.08018874 0.07236862 0.05958473 0.07529619 0.07965773 0.07579033
 0.07529619 0.07529619 0.07073395 0.07529622 0.05958473 0.07852429
 0.07446278 0.12723102 0.07833578 0.07313173 0.07529621 0.07194538
 0.07529617 0.0752962 ]
tr_loss:[0.07109464 0.06738152 0.07109465 0.06601232 0.06307127 0.13868204
 0.06666933 0.06663354 0.06666932 0.06601286 0.0660121  0.06601229
 0.06601229 0.07202296 0.07184716 0.06601231 0.07184733 0.07271568
 0.06307127 0.06307127 0.06666935 0.0660123  0.07109466 0.06601229
 0.07109468 0.06666933 0.06601232 0.06738144 0.06307127 0.0660123
 0.06666933 0.07425709 0.06693307 0.06883936 0.06601229 0.07202203
 0.07109468 0.06600378 0.06601231 0.06601231 0.06601231 0.06666932
 0.06601229 0.06307127 0.07184678 0.06969655 0.06601229 0.07109467
 0.07220183 0.06666934]
tr_loss:[0.06961105 0.06969479 0.05557624 0.06925026 0.07731815 0.07474102
 0.06969479 0.05925751 0.07461314 0.07461324 0.06571885 0.0555761
 0.07731818 0.05518142 0.06961109 0.06831478 0.05250935 0.07461315
 0.07731817 0.05250936 0.05557609 0.06961106 0.07731818 0.07731815
 0.05308548 0.05557609 0.05446432 0.0555761  0.06961916 0.15764813
 0.05557611 0.0555761  0.06831479 0.06831479 0.05557612 0.07731812
 0.06961106 0.05932311 0.05557612 0.07603846 0.07461301 0.07731818
 0.0696948  0.05732854 0.05557241 0.07604216 0.07461317 0.05557611
 0.05557609 0.0696948 ]
tr_loss:[0.05099019 0.05663325 0.04955052 0.05663323 0.0291306  0.05573215
 0.03064921 0.05283298 0.12507899 0.0509902  0.05997328 0.03064922
 0.05663325 0.03064921 0.05099018 0.04955051 0.03471483 0.04738369
 0.05997328 0.03064921 0.03064922 0.03452494 0.0399536  0.05955433
 0.13844594 0.05099018 0.0679123  0.05099021 0.05663328 0.04955051
 0.03064921 0.0509902  0.05099019 0.03516611 0.03064921 0.04955053
 0.13851416 0.0306492  0.03064919 0.03064922 0.05283299 0.05099019
 0.05283294 0.0306497  0.03064922 0.05098993 0.02913133 0.05997325
 0.05099019 0.05283298]
tr_loss:[0.02073274 0.01932317 0.02432674 0.01932319 0.02004815 0.02343156
 0.02203871 0.02857785 0.02756259 0.02004871 0.01932319 0.01940013
 0.02073276 0.01932318 0.01932318 0.01932318 0.09675281 0.0220387
 0.01932318 0.0193232  0.02004817 0.01932319 0.01932317 0.02073272
 0.02073273 0.0193232  0.02073273 0.02073274 0.02343156 0.02256228
 0.02073274 0.02073273 0.03470151 0.02004166 0.02004817 0.02073248
 0.02756258 0.02203871 0.01932318 0.01932201 0.01935349 0.02001071
 0.0174061  0.02073274 0.02073274 0.0220387  0.02203871 0.0193232
 0.01932317 0.02203869]
tr_loss:[0.02203243 0.08024839 0.02203243 0.01691241 0.01700637 0.01691241
 0.02127195 0.02127194 0.01739326 0.01048097 0.01048097 0.02203241
 0.02203241 0.02203242 0.01691241 0.01723157 0.01739324 0.02301594
 0.01739468 0.01048097 0.01750169 0.02203242 0.02502597 0.02127195
 0.02203242 0.01739327 0.02232797 0.02203243 0.01691242 0.02203253
 0.01316559 0.02646025 0.03621869 0.01048097 0.01691241 0.02157631
 0.02203244 0.02203241 0.02645201 0.02203242 0.0806444  0.0228238
 0.02203241 0.02350387 0.01316553 0.02203243 0.01691241 0.02203243
 0.01314835 0.01048097]
tr_loss:[0.01941088 0.02138415 0.01941088 0.0256168  0.0194109  0.01795158
 0.00905847 0.0189367  0.01893673 0.01944286 0.0194109  0.00905841
 0.01400748 0.01995231 0.00905847 0.0194109  0.01941089 0.01893673
 0.00905847 0.0233338  0.01912682 0.01893672 0.02138409 0.0177316
 0.0194109  0.01941088 0.01173361 0.0194109  0.0191308  0.01173361
 0.0194109  0.01944421 0.08097503 0.03426523 0.01775949 0.01400748
 0.00904472 0.02424131 0.01941089 0.01400747 0.01306807 0.01173361
 0.01877137 0.01885669 0.03426529 0.07907988 0.01877214 0.0117336
 0.0247058  0.01400746]
tr_loss:[0.08200017 0.02688688 0.01737808 0.01073214 0.02258537 0.01560798
 0.08199199 0.01560796 0.01560794 0.01495004 0.02529469 0.02258599
 0.01309045 0.00734818 0.02222807 0.01560802 0.01562935 0.01560795
 0.01664541 0.01560797 0.07872361 0.02314794 0.0268869  0.01073213
 0.01495003 0.01560796 0.01073213 0.01495003 0.01495004 0.01495003
 0.01073213 0.01684302 0.01495003 0.02688691 0.01309045 0.02268489
 0.01309044 0.02688686 0.01560779 0.01309045 0.01560795 0.01560796
 0.01073215 0.01560796 0.01073213 0.01560796 0.01560796 0.01495201
 0.02902294 0.0268869 ]
tr_loss:[0.02165357 0.02135549 0.01184308 0.01109223 0.0110922  0.01300781
 0.02034549 0.01300785 0.02165171 0.02115138 0.01300782 0.01158579
 0.0115858  0.01109222 0.01105922 0.01894783 0.01310307 0.00899889
 0.02164437 0.02165174 0.02115161 0.0115858  0.01184308 0.01158579
 0.01109221 0.01109223 0.01438536 0.01438535 0.02115161 0.0118435
 0.01438527 0.01158578 0.0130078  0.0130078  0.01158591 0.01158579
 0.01310935 0.00807001 0.01300782 0.02165175 0.0115858  0.01184308
 0.01156673 0.01157874 0.01184312 0.0115858  0.01158579 0.02169316
 0.02165172 0.02165169]
tr_loss:[0.00999934 0.0134942  0.01311874 0.02146389 0.02146963 0.01345052
 0.01137248 0.00943334 0.01345051 0.01311875 0.01137248 0.01345553
 0.00999934 0.01311875 0.02167014 0.02410232 0.01137247 0.00999931
 0.0214639  0.01345053 0.01345053 0.00926376 0.01311875 0.01345052
 0.01311823 0.00999931 0.01345053 0.00999933 0.01345051 0.00999837
 0.00999933 0.02736362 0.01137239 0.00925927 0.00999932 0.01311874
 0.00841492 0.02252075 0.01137248 0.01137248 0.00999932 0.02168253
 0.02146385 0.01311745 0.00999932 0.0118854  0.00999931 0.00999933
 0.00999936 0.0214641 ]
tr_loss:[0.01167141 0.02938588 0.01275937 0.0116714  0.02063569 0.01161222
 0.08490119 0.01504913 0.0116714  0.01167141 0.01275936 0.0116714
 0.0116714  0.01080872 0.01275938 0.0116714  0.02063568 0.01167141
 0.01167001 0.02582441 0.01504913 0.01275938 0.01275936 0.02192397
 0.01275936 0.0116714  0.01174345 0.02149707 0.01538652 0.01275936
 0.01167141 0.01080872 0.01218591 0.01504916 0.0116714  0.01257626
 0.0116714  0.01504914 0.0116714  0.01504913 0.09529521 0.01275936
 0.02063568 0.0184581  0.02063566 0.0116714  0.01275935 0.01124453
 0.01504912 0.01275938]
tr_loss:[0.01276392 0.01915208 0.01002651 0.01276392 0.010012   0.01915207
 0.01549794 0.0191521  0.01277173 0.01276392 0.08957997 0.00964727
 0.01276392 0.01915209 0.01276391 0.02102862 0.01276396 0.02416527
 0.01915209 0.01755142 0.08958007 0.01549794 0.01276393 0.01276394
 0.01276383 0.01276394 0.01549795 0.01549794 0.0191521  0.01275075
 0.01549794 0.01276394 0.00964728 0.02416302 0.01276393 0.02119601
 0.00964727 0.00964727 0.02119602 0.02118182 0.01276391 0.01915208
 0.01002664 0.01276393 0.00964727 0.01915209 0.01549792 0.01781661
 0.01531889 0.01002687]
tr_loss:[0.01530979 0.01301737 0.00698457 0.00931757 0.01896056 0.01896058
 0.01896058 0.08360018 0.01301737 0.01301739 0.01301736 0.01224358
 0.01301737 0.01498916 0.07891937 0.01301737 0.01498915 0.02021817
 0.01301737 0.08381154 0.00926197 0.00956061 0.01498915 0.02021825
 0.00698456 0.01290452 0.01301738 0.01224361 0.01498916 0.01498916
 0.01498913 0.02048358 0.00698456 0.01309479 0.01301739 0.01301737
 0.01656881 0.01896058 0.01301737 0.01301723 0.01301738 0.01301738
 0.01647875 0.01896058 0.02021819 0.01498913 0.01498915 0.00956061
 0.00956061 0.01498905]
tr_loss:[0.00675951 0.01112686 0.01355693 0.00677445 0.01247361 0.009354
 0.0067595  0.01112299 0.009354   0.01892002 0.00675952 0.00675951
 0.01950562 0.01112299 0.01112299 0.011123   0.01353449 0.0189789
 0.01897903 0.011123   0.01112299 0.01355695 0.01961502 0.02042345
 0.08137258 0.0189783  0.01112299 0.00865416 0.00675951 0.00935449
 0.009354   0.0189455  0.01961504 0.01112331 0.01355694 0.0189789
 0.01355697 0.011123   0.01112299 0.0814117  0.01355695 0.01908823
 0.01355694 0.01355696 0.01055754 0.01355217 0.01355696 0.01748038
 0.0067595  0.01897891]
tr_loss:[0.01798335 0.00976225 0.00915884 0.00976225 0.01191819 0.00915928
 0.00976224 0.038519   0.02049654 0.00976226 0.02049652 0.00915883
 0.00976225 0.00976226 0.01156852 0.00976225 0.00976226 0.01191817
 0.00976226 0.00962393 0.01827231 0.01869542 0.00962391 0.00976225
 0.01813856 0.00976225 0.00976224 0.01191816 0.00998328 0.01827231
 0.01191818 0.00915884 0.00976225 0.01272314 0.00976226 0.01191818
 0.00971157 0.01191816 0.00915884 0.00915883 0.00962394 0.02049656
 0.02049653 0.00976225 0.00915885 0.01827232 0.01420648 0.00976408
 0.08246623 0.00915883]
tr_loss:[0.00969833 0.00782572 0.00782576 0.01249654 0.01120199 0.0124298
 0.02098485 0.00782572 0.01120199 0.00963639 0.01858506 0.08301959
 0.00912174 0.01829832 0.00782572 0.00782572 0.01799758 0.02001221
 0.00968154 0.0070079  0.01120199 0.01890691 0.01242979 0.01119419
 0.0124381  0.00782572 0.01242979 0.00782573 0.01824776 0.01275541
 0.01970772 0.00805613 0.01120199 0.01120198 0.00782573 0.00805613
 0.02002019 0.00782572 0.01796946 0.00700851 0.01801255 0.00782572
 0.00963639 0.00782573 0.02098485 0.00986981 0.0180125  0.01242979
 0.00782572 0.0124298 ]
tr_loss:[0.01135202 0.01502773 0.02006926 0.01766441 0.0102611  0.00588041
 0.01766445 0.02006925 0.00725204 0.08234452 0.01135203 0.0211515
 0.0730898  0.01907749 0.01026146 0.00588045 0.00588045 0.00588045
 0.00588046 0.00899357 0.00697051 0.00776049 0.00588045 0.00588045
 0.00761748 0.01502771 0.01502773 0.01979734 0.00588045 0.01740965
 0.01135204 0.01502769 0.00899274 0.011352   0.00874994 0.01135202
 0.01146337 0.00588045 0.02026124 0.01502771 0.01135204 0.00588045
 0.00899358 0.02006925 0.01502771 0.00588046 0.01135202 0.01135202
 0.02006925 0.02006925]
tr_loss:[0.01764223 0.00690597 0.0121772  0.01668261 0.01466532 0.00527059
 0.07754169 0.00527059 0.01926574 0.01736772 0.01801923 0.00717078
 0.00527059 0.00527062 0.0121772  0.01217705 0.01722487 0.00527059
 0.00527058 0.0121772  0.0069078  0.00500733 0.07275842 0.01217722
 0.00527059 0.01466532 0.00527059 0.01736773 0.00527059 0.00527059
 0.01736773 0.01960133 0.07275843 0.00527058 0.00527059 0.07275838
 0.01466532 0.0173677  0.0121772  0.07275812 0.00633121 0.00527059
 0.00527059 0.01217722 0.00527059 0.01466533 0.01466532 0.01736773
 0.01029296 0.01466531]
tr_loss:[0.00546585 0.00555052 0.01955378 0.00555052 0.00561234 0.012876
 0.00705968 0.01315442 0.00555052 0.0131544  0.02161745 0.0170803
 0.012876   0.00555031 0.01315441 0.01287601 0.01465685 0.00555049
 0.01315441 0.01293865 0.00555051 0.01291256 0.01287664 0.0131544
 0.012876   0.00725781 0.00541745 0.01545028 0.01545026 0.00555052
 0.07365874 0.00555052 0.01545028 0.03419909 0.01569006 0.00555053
 0.00555052 0.00705969 0.07986108 0.00555052 0.00691376 0.012876
 0.00555052 0.01315441 0.01547069 0.00555052 0.01315439 0.01315439
 0.01545028 0.00555052]
tr_loss:[0.01278006 0.00804879 0.01270322 0.07884479 0.01314084 0.00496799
 0.00541151 0.00541151 0.00541151 0.01098007 0.01270324 0.08040787
 0.01270323 0.00481979 0.01098005 0.01314211 0.00604677 0.01416129
 0.00804879 0.00486329 0.01314211 0.00541151 0.01098007 0.00541151
 0.01270325 0.00804879 0.0054115  0.07465096 0.00541151 0.07467495
 0.01449403 0.02101059 0.01314213 0.01987384 0.00541151 0.01987243
 0.00542708 0.01098007 0.01270324 0.00885264 0.02096488 0.01365259
 0.00541151 0.00804879 0.01365259 0.01365257 0.01098006 0.07466124
 0.01098004 0.00541151]
tr_loss:[0.00574014 0.01367127 0.01367129 0.00573755 0.00574014 0.00573964
 0.0073858  0.00574014 0.00574014 0.01367128 0.00574014 0.00574014
 0.01379202 0.01239821 0.01366897 0.01015937 0.01015787 0.01239821
 0.01367128 0.00825978 0.00585027 0.00574014 0.00738581 0.00574013
 0.00825981 0.0082598  0.00574013 0.01239819 0.00687778 0.0123982
 0.00574013 0.00702489 0.01367116 0.01230551 0.01379202 0.00574014
 0.01015937 0.00574013 0.00552899 0.0073858  0.01460793 0.00574014
 0.0055255  0.01475067 0.00702938 0.01232046 0.01379201 0.00825985
 0.01239821 0.01367128]
tr_loss:[0.01225468 0.01697963 0.01497594 0.01419043 0.00486632 0.01628298
 0.01628297 0.00486633 0.00486632 0.0071289  0.01419041 0.00486633
 0.00761465 0.00712904 0.0071289  0.00486633 0.00486633 0.01445049
 0.01497511 0.00515034 0.00486238 0.00716572 0.0076101  0.01686022
 0.01628297 0.00486632 0.00486633 0.01419043 0.00486632 0.016283
 0.00486633 0.01097411 0.00515014 0.01679796 0.00486632 0.00486632
 0.00486632 0.00761011 0.01417066 0.01524898 0.0071289  0.01419057
 0.00437813 0.01119016 0.01225464 0.01628298 0.00962929 0.00761011
 0.00748756 0.00761011]
tr_loss:[0.01496451 0.07537846 0.01291471 0.00410212 0.01496471 0.01567765
 0.01574207 0.00710025 0.01878399 0.00410212 0.08159368 0.01963798
 0.00710024 0.07583807 0.01238403 0.00395635 0.0129147  0.00710025
 0.0041021  0.00469556 0.00401553 0.00410212 0.0129147  0.01878397
 0.01549186 0.00410212 0.0182536  0.00410212 0.01496472 0.00410212
 0.00410211 0.00812813 0.00710025 0.00410212 0.01567762 0.00666084
 0.00710026 0.00410212 0.00410212 0.00408306 0.00410054 0.00710025
 0.00710025 0.00710148 0.00410212 0.00419606 0.01878396 0.01397327
 0.00401696 0.01549453]
text_input.shape
(2900, 14400)
learning_input_tmp.shape
(2900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(2900, 80)
learning_output.shape
(750, 80)
Model: "sequential_60"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_60 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2411515 1.2237583 1.2237587 1.2433504 1.2237585 1.2038145 1.2413807
 1.2237586 1.2237585 1.2237586 1.2237586 1.3440428 1.2237585 1.2432106
 1.2047215 1.2047216 1.2772143 1.2237585 1.2235043 1.183317  1.2302076
 1.2639682 1.3395008 1.183317  1.2736156 1.2237586 1.183317  1.2047215
 1.2772143 1.2074969 1.2237585 1.339515  1.183317  1.2411652 1.2411649
 1.2755892 1.2411649 1.2237585 1.2144371 1.2237586 1.2047222 1.2763479
 1.2237694 1.183317  1.2196449 1.2411649 1.3395151 1.2726675 1.2795215
 1.2116985]
tr_loss:[0.697514   0.7259614  0.6625725  0.6625727  0.7259615  0.7127743
 0.6990045  0.7276114  0.6625724  0.6863898  0.74527574 0.7389376
 0.6625725  0.6625723  0.67678434 0.69908386 0.7259615  0.662598
 0.66257244 0.6677831  0.66257244 0.761539   0.7279072  0.7121438
 0.66268605 0.69262546 0.64497435 0.66257244 0.761539   0.7619303
 0.761539   0.62063664 0.7410614  0.6990458  0.6625725  0.7615389
 0.7378543  0.761539   0.7389376  0.6625725  0.77225286 0.76153904
 0.6926255  0.7615385  0.6625724  0.76155794 0.6990456  0.72615993
 0.7722529  0.6625725 ]
tr_loss:[0.51407826 0.37343317 0.37343308 0.37343258 0.37343305 0.41806707
 0.49683508 0.4072114  0.37343314 0.43405017 0.3964869  0.42697555
 0.39648682 0.3734331  0.37343305 0.48254365 0.37343308 0.41806713
 0.4494651  0.37343317 0.43405017 0.37343308 0.43405008 0.45935717
 0.4494651  0.4494651  0.43405017 0.4336927  0.4494651  0.37343308
 0.43405026 0.43145722 0.4175132  0.37343305 0.4494651  0.4494651
 0.43405017 0.43405017 0.3964869  0.39000446 0.41806707 0.43409362
 0.4611822  0.41806713 0.3749612  0.37343317 0.37343317 0.4067731
 0.46307296 0.43405023]
tr_loss:[0.18490693 0.18490691 0.18490693 0.22827363 0.24355929 0.23667157
 0.1849069  0.1849069  0.20696804 0.23667149 0.23667154 0.18490383
 0.2171551  0.23667148 0.18490694 0.18517882 0.24355932 0.2175915
 0.18490694 0.24355932 0.23667149 0.21759152 0.22479229 0.22647583
 0.18490696 0.22818199 0.22936699 0.18490693 0.2175915  0.224791
 0.24355932 0.18490696 0.23667154 0.22650139 0.23667154 0.24355927
 0.22827363 0.18490691 0.22384961 0.23667149 0.1849069  0.23667148
 0.24355932 0.215621   0.22827396 0.1849068  0.18490693 0.18490693
 0.24355932 0.22683792]
tr_loss:[0.09666751 0.12145881 0.13024987 0.12432966 0.12706932 0.12706935
 0.09666749 0.09666748 0.09666751 0.0966675  0.12706932 0.13023825
 0.13023825 0.1111267  0.23342946 0.13123465 0.13023825 0.09666751
 0.09666745 0.12227198 0.09666749 0.11216287 0.2161592  0.12706931
 0.09666749 0.15316615 0.12706932 0.11682741 0.15316617 0.21616745
 0.13023825 0.15316817 0.10382645 0.09666751 0.0966675  0.12706931
 0.15316615 0.12706935 0.09666748 0.14106642 0.13023822 0.09544335
 0.10990155 0.12706932 0.09666749 0.09666751 0.15316617 0.09666748
 0.09666748 0.11152637]
tr_loss:[0.05185055 0.0500606  0.05970117 0.05006059 0.05006058 0.05970117
 0.05185059 0.05970116 0.05970119 0.05006061 0.05030055 0.0564423
 0.05331081 0.05006061 0.05644229 0.05185058 0.05726523 0.05970117
 0.05006059 0.05006059 0.0564423  0.05029788 0.05006061 0.05970117
 0.05006059 0.13739409 0.05006059 0.07122849 0.0790727  0.05811923
 0.05185055 0.0597012  0.05006059 0.04737799 0.05231566 0.05985732
 0.05644231 0.05644231 0.0598573  0.05006061 0.0598573  0.05644231
 0.05644231 0.04767856 0.05970119 0.05006059 0.04735546 0.05970116
 0.05985732 0.05181353]
tr_loss:[0.02622531 0.0313944  0.03402894 0.03402903 0.03402893 0.03302591
 0.09585558 0.0305513  0.02581632 0.01959169 0.0340436  0.03402895
 0.03402894 0.02570612 0.03137336 0.030555   0.0214645  0.02146449
 0.01958046 0.0195917  0.019629   0.02769823 0.03402895 0.01959168
 0.02147196 0.03461802 0.03402891 0.02769824 0.03402894 0.04285317
 0.03402893 0.02493592 0.03402895 0.02452945 0.02707508 0.02769822
 0.02825963 0.02146451 0.03402894 0.03402897 0.03402892 0.0236059
 0.02826194 0.03402896 0.03055169 0.03402893 0.02146479 0.01959167
 0.03632305 0.01959168]
tr_loss:[0.03346399 0.02851486 0.01963599 0.03143977 0.0280152  0.033464
 0.01917427 0.01963613 0.03346398 0.01963598 0.03346397 0.03339522
 0.01917431 0.09417552 0.03133012 0.01539848 0.01539852 0.01539852
 0.03001529 0.03346397 0.01539758 0.01970469 0.04690148 0.03143974
 0.03346395 0.01963599 0.03346395 0.02805414 0.02914124 0.01539855
 0.02805362 0.04690195 0.01539842 0.01963599 0.01963597 0.033464
 0.01917429 0.01539852 0.01917428 0.03346399 0.01917428 0.02851483
 0.01917429 0.01963599 0.03346398 0.01963597 0.02851487 0.08274935
 0.03346397 0.03346399]
tr_loss:[0.03233129 0.0289812  0.02631798 0.03077132 0.03232152 0.01709883
 0.0173157  0.03079495 0.02892744 0.08873443 0.0323313  0.03233128
 0.03238627 0.01556839 0.03230205 0.02672752 0.03233127 0.01507277
 0.01507309 0.03445124 0.03233131 0.02893957 0.03233131 0.01731572
 0.02608678 0.04775872 0.0323313  0.0323313  0.03077315 0.01512801
 0.02629466 0.04773914 0.0323313  0.03233131 0.01731573 0.0323313
 0.02672753 0.0307713  0.01507276 0.02672753 0.0323313  0.0173157
 0.03232885 0.03233127 0.0173157  0.01731573 0.02672752 0.01731572
 0.03256748 0.0289812 ]
tr_loss:[0.02830901 0.01054725 0.0236855  0.0257018  0.01990795 0.01989514
 0.01590505 0.01054725 0.01585929 0.02368547 0.02368549 0.01346939
 0.01054725 0.02830904 0.02460497 0.04131128 0.02830902 0.01944856
 0.02453825 0.01054726 0.02368549 0.01054727 0.01054728 0.02723271
 0.01590507 0.0194271  0.01590041 0.02830902 0.01648197 0.03009836
 0.01987425 0.0261105  0.01054727 0.02617947 0.0134694  0.0286376
 0.02830903 0.01718743 0.03009836 0.03009835 0.04131586 0.01590507
 0.01346939 0.08125614 0.01348571 0.01054844 0.01957874 0.02725833
 0.02830902 0.03326529]
tr_loss:[0.01041681 0.014329   0.01557096 0.02481826 0.02481829 0.02865622
 0.03240722 0.0104168  0.02339042 0.02481829 0.02970123 0.02481872
 0.01041679 0.02530369 0.02604171 0.02604171 0.02070623 0.02604171
 0.02604164 0.01041681 0.02614187 0.02481837 0.02339045 0.01559467
 0.09743609 0.01041682 0.01557099 0.02481828 0.02481825 0.02605572
 0.02577229 0.01041679 0.02339044 0.02339042 0.02478941 0.01041679
 0.0207273  0.01133304 0.02604171 0.01223182 0.02339042 0.02970129
 0.01041685 0.02481826 0.02481829 0.02481827 0.02481826 0.01172474
 0.02970129 0.02481827]
tr_loss:[0.02546732 0.02136113 0.02546733 0.02734921 0.02546733 0.02546731
 0.01635005 0.0300811  0.02171222 0.02546732 0.02734919 0.02546733
 0.09822837 0.02546733 0.01523047 0.02546733 0.01523047 0.0300811
 0.03025142 0.02734922 0.01523045 0.0217122  0.03008111 0.02550855
 0.02546733 0.02171222 0.02544763 0.01565542 0.02171202 0.01425168
 0.02477784 0.10518013 0.02995262 0.02171224 0.0307307  0.02477708
 0.02546733 0.0300811  0.02544706 0.0300428  0.02546747 0.01523047
 0.01416157 0.02546732 0.02331347 0.0254673  0.02699913 0.02546734
 0.02477739 0.01523047]
tr_loss:[0.0210442  0.02465205 0.0210442  0.02455357 0.02365324 0.01201968
 0.02477746 0.02104419 0.02365325 0.01201967 0.02104421 0.02455357
 0.02465203 0.02065002 0.02365324 0.02915165 0.01201967 0.0298932
 0.02013478 0.02465204 0.02455356 0.0210442  0.02455358 0.02902062
 0.02104419 0.01463679 0.02455354 0.01201967 0.02365324 0.02323074
 0.02915136 0.02365325 0.02365323 0.02365323 0.02455357 0.02365322
 0.02296046 0.01520872 0.01201968 0.02908409 0.02365323 0.0210442
 0.02455357 0.02448075 0.02455356 0.02365331 0.02365323 0.01201968
 0.02465206 0.0210442 ]
tr_loss:[0.01029257 0.01872086 0.01872086 0.01094834 0.01029257 0.01775202
 0.01469128 0.01029257 0.01469144 0.01872086 0.01863182 0.01955463
 0.02813287 0.01872084 0.02367284 0.09269474 0.02452571 0.02671945
 0.02815476 0.01872084 0.01469142 0.02367286 0.02944351 0.0245257
 0.01029257 0.01029258 0.02454469 0.01469143 0.02598237 0.01578473
 0.02712261 0.03707344 0.02452569 0.01872086 0.02320581 0.02367285
 0.0245287  0.02813285 0.02452569 0.0245257  0.01624836 0.09443332
 0.01468702 0.09443332 0.02813252 0.01872086 0.02452569 0.01029257
 0.01029256 0.02813286]
tr_loss:[0.02687807 0.02633698 0.01466788 0.0236697  0.02633698 0.02687809
 0.01007467 0.0236697  0.01007467 0.02633699 0.02633698 0.02687806
 0.02687803 0.02633698 0.01529291 0.00986665 0.01529291 0.02633699
 0.02687808 0.08304394 0.02633701 0.02027059 0.01734726 0.01023429
 0.02633699 0.02633699 0.0152929  0.02687807 0.08305283 0.02635316
 0.01529289 0.02633702 0.02782706 0.01014478 0.02633701 0.02366972
 0.02633699 0.02633699 0.01007468 0.00986665 0.02633709 0.00986666
 0.02687808 0.02687809 0.02343143 0.02687806 0.01437168 0.02633699
 0.00986652 0.08361199]
tr_loss:[0.02795265 0.01397783 0.02793073 0.01286726 0.02555043 0.02795267
 0.01536829 0.0403635  0.01495803 0.02555044 0.0821045  0.01397782
 0.01286726 0.02693846 0.02795264 0.01495754 0.0279307  0.01286725
 0.01131376 0.0154524  0.02793075 0.02795264 0.02795216 0.0403619
 0.02795264 0.02795266 0.02795266 0.01287371 0.01286725 0.0139778
 0.01286724 0.02793072 0.02795266 0.01131179 0.08210175 0.02795265
 0.01286725 0.01286742 0.01397781 0.02795266 0.02555046 0.01131376
 0.02555042 0.0238495  0.01131721 0.01397781 0.02795265 0.02795265
 0.01131376 0.03200863]
tr_loss:[0.08416544 0.02609561 0.01974034 0.02681236 0.01226252 0.02681238
 0.02682165 0.08329316 0.02681235 0.02589564 0.0138484  0.01384837
 0.02743129 0.01381751 0.01381751 0.02681237 0.01381752 0.01226254
 0.02165431 0.01594443 0.03188495 0.027549   0.02681236 0.0138484
 0.02608993 0.02681236 0.02681234 0.0264163  0.01226254 0.0268124
 0.01226252 0.02699623 0.02681238 0.02681237 0.02681235 0.02681236
 0.02176394 0.01384874 0.02681236 0.02681241 0.01226241 0.02516793
 0.01384838 0.01381987 0.01384909 0.01384838 0.01390472 0.02681238
 0.01226252 0.01226252]
tr_loss:[0.01676319 0.02232533 0.01104662 0.01479836 0.0330661  0.02357794
 0.01190653 0.02357793 0.02357793 0.02409174 0.01190654 0.02232536
 0.02357793 0.02357793 0.02354667 0.01529317 0.02357793 0.0252248
 0.02232536 0.02232537 0.01907882 0.02463898 0.02359214 0.01479835
 0.02832952 0.01105036 0.025229   0.025229   0.0110503  0.02357795
 0.01190654 0.02232534 0.01873758 0.0235816  0.02232533 0.01190654
 0.02984065 0.02357614 0.02522899 0.02357793 0.01190654 0.02413907
 0.01105034 0.02357791 0.02232536 0.02357792 0.01105034 0.01505564
 0.02357793 0.0235779 ]
tr_loss:[0.01055488 0.02200659 0.02067192 0.02184281 0.0220066  0.01055488
 0.01704357 0.01055488 0.09231472 0.0133464  0.01055492 0.02067189
 0.02200734 0.01463575 0.02200659 0.02200659 0.01688223 0.02448123
 0.01055489 0.01055488 0.01334637 0.0220066  0.01055488 0.0220066
 0.01055489 0.01334638 0.0157736  0.02200659 0.02067191 0.0220066
 0.02452    0.01334638 0.01688223 0.01055488 0.0134539  0.02450788
 0.02261518 0.02451996 0.01334638 0.01334639 0.02451999 0.01055487
 0.02451999 0.03021125 0.02200658 0.01334639 0.01600636 0.01055488
 0.01811348 0.02200658]
tr_loss:[0.02591161 0.02311151 0.01147766 0.01730303 0.01450078 0.02591161
 0.02311151 0.02987181 0.01730303 0.02591161 0.0123978  0.09564196
 0.01997504 0.02311151 0.02591141 0.0231115  0.01730304 0.02311151
 0.01997569 0.01673384 0.02143258 0.02591158 0.01524714 0.02412629
 0.02486719 0.02314352 0.02143255 0.02007947 0.02311151 0.02311148
 0.02311169 0.01730304 0.02591161 0.02311151 0.02994499 0.02460791
 0.02017161 0.02311151 0.01997507 0.02311152 0.01147767 0.02311152
 0.01868664 0.02143259 0.01730305 0.02311154 0.02017374 0.02591159
 0.02143259 0.02591215]
tr_loss:[0.02248832 0.01662235 0.02111189 0.01098423 0.01120436 0.0211119
 0.02248826 0.01098423 0.09489209 0.02111187 0.02111189 0.01098423
 0.02111187 0.01662233 0.01098423 0.01863969 0.01098423 0.02111187
 0.02111189 0.01098424 0.02395939 0.09072645 0.02111187 0.02111189
 0.01165891 0.09342698 0.02472773 0.02651396 0.01392313 0.02021788
 0.01098423 0.02021789 0.01098422 0.02110426 0.01106207 0.01864109
 0.01098422 0.01662233 0.02111186 0.02111238 0.01662235 0.02651234
 0.01117511 0.01662232 0.02111189 0.0232975  0.01099955 0.0211119
 0.02651255 0.02111185]
tr_loss:[0.01072288 0.08711948 0.01523024 0.01523024 0.01989527 0.01067331
 0.01951112 0.0937147  0.08711943 0.02384759 0.01989527 0.01989535
 0.01067331 0.01951113 0.0198953  0.01523024 0.01019635 0.01067331
 0.01788465 0.01523023 0.01523021 0.0233924  0.01706676 0.01067331
 0.02383931 0.01564348 0.01989521 0.01564348 0.01989527 0.01564375
 0.0136259  0.02331491 0.01989527 0.01523025 0.01067331 0.01523024
 0.01989525 0.01523022 0.09066619 0.01523023 0.02499548 0.01513975
 0.01989526 0.01067331 0.01564348 0.01988198 0.01564346 0.01523022
 0.02383939 0.02321902]
tr_loss:[0.0109383  0.02135244 0.02135246 0.08313914 0.02007481 0.01401462
 0.01093833 0.020044   0.02135248 0.02135246 0.02135246 0.01480125
 0.02135248 0.01946098 0.0109383  0.01703802 0.01480128 0.02333013
 0.02135245 0.02004403 0.02379606 0.01172581 0.01270223 0.02004403
 0.01946309 0.02379685 0.01270224 0.02152979 0.02135245 0.01093831
 0.01480129 0.08745317 0.02135247 0.02135247 0.02379683 0.01270224
 0.0109383  0.01992747 0.01093828 0.02135247 0.01992744 0.01108229
 0.01811645 0.02004404 0.01992889 0.09015146 0.02135244 0.01476137
 0.02135243 0.09013964]
tr_loss:[0.02482087 0.01059606 0.01579119 0.02337201 0.02322997 0.02322999
 0.02323    0.01443348 0.02322999 0.01059272 0.01059605 0.01058027
 0.02264825 0.02322998 0.02322996 0.02322998 0.02322997 0.02037236
 0.01819884 0.02058501 0.01427994 0.02037237 0.02322998 0.01443244
 0.02322999 0.01059603 0.03165267 0.01059605 0.02364149 0.02037235
 0.02348464 0.01978688 0.02323    0.02322999 0.02322996 0.01059604
 0.02323792 0.01575061 0.02037238 0.02322998 0.01059605 0.01058027
 0.01399503 0.01443348 0.01888975 0.02482087 0.01541518 0.03223344
 0.02362574 0.02322999]
tr_loss:[0.02326225 0.01039938 0.08314024 0.01585    0.02326225 0.0137156
 0.02343797 0.01371405 0.02326226 0.02032063 0.01039705 0.01039708
 0.02343475 0.01371543 0.02032062 0.01006909 0.01371562 0.01039707
 0.01543608 0.02032064 0.02326224 0.02032063 0.02326226 0.01006904
 0.01039707 0.01870153 0.02326227 0.02032063 0.02286511 0.02326225
 0.02326225 0.02326226 0.01006871 0.01629869 0.02894272 0.01039706
 0.02326225 0.02326225 0.01371561 0.01006904 0.01039706 0.01908429
 0.01039707 0.02326223 0.01371562 0.02894275 0.01018483 0.01646919
 0.02326228 0.01371561]
tr_loss:[0.01280265 0.01311584 0.01280265 0.02188252 0.02319243 0.01596718
 0.01046123 0.02196858 0.01017247 0.02196857 0.01370725 0.02319224
 0.01280265 0.0219686  0.02196859 0.02839809 0.02323078 0.02840238
 0.0231926  0.01017248 0.01280265 0.0219686  0.02319245 0.0127974
 0.02196859 0.02319245 0.01280267 0.02241322 0.02196857 0.0219686
 0.02302346 0.02317195 0.01979629 0.01046128 0.02196858 0.03255334
 0.02196861 0.01280265 0.02196861 0.02196862 0.023834   0.01596283
 0.02196861 0.02196858 0.02241416 0.01046128 0.01280266 0.0146631
 0.01280265 0.02319246]
tr_loss:[0.02012613 0.02012612 0.0147592  0.02012612 0.02231074 0.02012613
 0.02012611 0.01192303 0.01938977 0.01053185 0.01053186 0.01053185
 0.02863533 0.01217031 0.01275727 0.02124144 0.02327885 0.02327889
 0.02329614 0.01938977 0.02197236 0.01938977 0.02013851 0.02327879
 0.02012613 0.02012612 0.02012612 0.01053185 0.01053185 0.0811766
 0.02229725 0.02012612 0.02012613 0.02012612 0.00859116 0.02012612
 0.0246318  0.01192305 0.02012608 0.02012611 0.02013733 0.01277238
 0.08227099 0.01192305 0.08672174 0.01463326 0.01053186 0.01658128
 0.0201261  0.02012611]
tr_loss:[0.00929691 0.01237352 0.01266017 0.01484331 0.01266017 0.01094131
 0.01266016 0.01266018 0.01957876 0.00930571 0.01324488 0.01429246
 0.01490542 0.01264526 0.01715864 0.01957889 0.01094132 0.01490542
 0.08449739 0.01943743 0.01266018 0.01266017 0.0123613  0.0149052
 0.02365867 0.01261051 0.02365867 0.01490542 0.02054564 0.01957889
 0.02365865 0.02365867 0.02365866 0.02054474 0.01957431 0.01943748
 0.01957889 0.01484027 0.01266017 0.01957888 0.01943745 0.01094131
 0.02364229 0.01957889 0.02066777 0.02054569 0.00886385 0.01957889
 0.01957894 0.02549657]
tr_loss:[0.01405722 0.01337926 0.00979096 0.00992452 0.01059829 0.01937513
 0.01379714 0.01337927 0.08551767 0.01937517 0.01937518 0.09190556
 0.01337927 0.01337926 0.0193769  0.0142111  0.02238914 0.08546214
 0.02315811 0.0105983  0.02315758 0.01530028 0.08546209 0.01697179
 0.01337926 0.09190569 0.01346311 0.01337925 0.01059829 0.01421159
 0.01940649 0.0105983  0.02370051 0.09190352 0.0235877  0.0214611
 0.02315761 0.02315761 0.01337926 0.01458964 0.01530028 0.01937517
 0.01937518 0.02142647 0.01903988 0.01937519 0.01937518 0.01059828
 0.01903987 0.0193752 ]
tr_loss:[0.00884692 0.01364694 0.01359006 0.01934044 0.01934044 0.02100573
 0.01353912 0.01761452 0.00883884 0.01934044 0.01934043 0.0135391
 0.00883882 0.02371386 0.01436157 0.01761448 0.00883883 0.01934043
 0.01364693 0.0136466  0.01934043 0.01364693 0.02135757 0.01316996
 0.01008231 0.00883883 0.01934044 0.01934044 0.01934128 0.01934044
 0.01761452 0.01364691 0.00883884 0.01210488 0.01263363 0.01934043
 0.01353912 0.01934042 0.01934043 0.01436167 0.00883967 0.01934043
 0.01364692 0.01364692 0.00883885 0.01934045 0.01364692 0.01761451
 0.0176145  0.0213576 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2900 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2901, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2901 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2902, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2902 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2903, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2903 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2904, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2904 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2905, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2905 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2906, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2906 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2907, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2907 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2908, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2908 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2909, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2909 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2910, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2910 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2911, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2911 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2912, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2912 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2913, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2913 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2914, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2914 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2915, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2915 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2916, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2916 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2917, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2917 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2918, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2918 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2919, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2919 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2920, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2920 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2921, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2921 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2922, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2922 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2923, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2923 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2924, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2924 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2925, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2925 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2926, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2926 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2927, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2927 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2928, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2928 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2929, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2929 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2930, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2930 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2931, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2931 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2932, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2932 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2933, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2933 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2934, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2934 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2935, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2935 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2936, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2936 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2937, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2937 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2938, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2938 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2939, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2939 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2940, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2940 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2941, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2941 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2942, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2942 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2943, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2943 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2944, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2944 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2945, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2945 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2946, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2946 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2947, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2947 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2948, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2948 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2949, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2949 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2950, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2950 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2951, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2951 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2952, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2952 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2953, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2953 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2954, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2954 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2955, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2955 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2956, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2956 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2957, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2957 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2958, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2958 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2959, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2959 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2960, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2960 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2961, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2961 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2962, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2962 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2963, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2963 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2964, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2964 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2965, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2965 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2966, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2966 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2967, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2967 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2968, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2968 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2969, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2969 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2970, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2970 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2971, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2971 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2972, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2972 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2973, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2973 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2974, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2974 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2975, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2975 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2976, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2976 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2977, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2977 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2978, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2978 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2979, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2979 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2980, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2980 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2981, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2981 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2982, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2982 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2983, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2983 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2984, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2984 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2985, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2985 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2986, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2986 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2987, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2987 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2988, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2988 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2989, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2989 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2990, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2990 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2991, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2991 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2992, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2992 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2993, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2993 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2994, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2994 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2995, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2995 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2996, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2996 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2997, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2997 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2998, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2998 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(2999, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 2999 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3000, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-2900
text_input.shape
(3000, 14400)
learning_input_tmp.shape
(3000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3000, 80)
learning_output.shape
(750, 80)
Model: "sequential_61"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_61 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.343775  1.2923977 1.37096   1.2923976 1.4523604 1.343775  1.2923985
 1.4083313 1.2923976 1.343775  1.40872   1.309166  1.2746913 1.2923977
 1.2877295 1.2923977 1.4523604 1.2923976 1.3163236 1.2923977 1.2923977
 1.4087198 1.2923976 1.2923977 1.4523714 1.2923977 1.2923977 1.286739
 1.2923975 1.4086612 1.3217236 1.40872   1.4087199 1.3217233 1.343775
 1.4523604 1.343775  1.45236   1.2923977 1.343775  1.4523599 1.4165792
 1.2923976 1.4087201 1.3437749 1.2923977 1.4087131 1.2978107 1.4546267
 1.4433424]
tr_loss:[0.8259535  0.7587285  0.7587284  0.7587284  0.75872844 0.84124595
 0.7587284  0.8059589  0.7587283  0.7536354  0.75664574 0.75872844
 0.7587284  0.7701473  0.7592336  0.7536355  0.75872844 0.8163662
 0.8350301  0.7536354  0.8059589  0.75872844 0.7587284  0.8101384
 0.8163662  0.8059589  0.7546479  0.84126395 0.78717023 0.78717023
 0.7613672  0.75872844 0.8059589  0.7871703  0.75464785 0.7536354
 0.75872844 0.8163663  0.75872844 0.7536499  0.7536354  0.7714191
 0.7587285  0.7587284  0.75872844 0.8059589  0.7536354  0.80596286
 0.7587284  0.84127903]
tr_loss:[0.33534577 0.3294651  0.32946506 0.3294651  0.3505203  0.34826264
 0.35118347 0.36745894 0.3674589  0.34809816 0.36745903 0.32946503
 0.367459   0.36745897 0.32946512 0.32817546 0.3294651  0.3294651
 0.32184634 0.34826258 0.32946506 0.34550306 0.367459   0.32946512
 0.32946506 0.32946506 0.40285516 0.367459   0.32946506 0.40599555
 0.3482626  0.34826264 0.32946515 0.40285522 0.34826258 0.367459
 0.32946512 0.32946506 0.40316495 0.35063857 0.32946503 0.32946503
 0.3294651  0.32946497 0.34825438 0.33011827 0.34404248 0.41220108
 0.3294651  0.4028551 ]
tr_loss:[0.15088174 0.17967096 0.21836033 0.1347397  0.15088171 0.1508817
 0.21611437 0.15088174 0.15088174 0.13473757 0.17967102 0.1508817
 0.13548854 0.19102225 0.1910223  0.18086338 0.17967096 0.21854219
 0.1508817  0.15087846 0.19102226 0.15479507 0.21654192 0.19102219
 0.13473758 0.19102222 0.17967096 0.17811665 0.15486522 0.22693405
 0.17811659 0.21853304 0.152204   0.21490428 0.19102228 0.13473725
 0.15088168 0.15501562 0.15088177 0.17811663 0.17967102 0.15088175
 0.15088172 0.15088174 0.16114943 0.15479508 0.16467388 0.17967097
 0.15092145 0.19102232]
tr_loss:[0.07909356 0.06637281 0.06081129 0.13320425 0.06657344 0.06081127
 0.06081126 0.07489423 0.05790778 0.06890339 0.0682892  0.09814259
 0.09814258 0.0625341  0.05925937 0.0749132  0.07909356 0.07491314
 0.09806924 0.07491316 0.07370261 0.06081123 0.06081124 0.06113023
 0.06081129 0.06151097 0.06081101 0.07491315 0.07491322 0.05929166
 0.06081899 0.06081129 0.07909358 0.06081123 0.05928529 0.07855986
 0.07370263 0.06081126 0.13303494 0.07491318 0.07909356 0.07909356
 0.06081128 0.06081128 0.07370259 0.0608113  0.12678799 0.06081126
 0.07491314 0.05468125]
tr_loss:[0.03249934 0.01801549 0.03229665 0.01801552 0.09618704 0.03229664
 0.0191204  0.03229665 0.03013333 0.10111549 0.03399139 0.03229666
 0.01801549 0.09618413 0.03229133 0.03229663 0.02510157 0.0251125
 0.03229666 0.0180155  0.02821312 0.03146909 0.03229667 0.03229667
 0.02511249 0.03229664 0.03229667 0.03229667 0.03212803 0.03229528
 0.01733625 0.03229664 0.03229662 0.03229667 0.03229664 0.03153071
 0.03229682 0.02821312 0.02641161 0.0251125  0.03229661 0.03229667
 0.0325451  0.09618702 0.0419408  0.03249    0.03229667 0.02802264
 0.03229667 0.02821311]
tr_loss:[0.00945512 0.02328293 0.01502837 0.03549943 0.0156961  0.09275917
 0.02328268 0.03391693 0.03391694 0.03391696 0.03391696 0.0271666
 0.0319669  0.02328295 0.03391691 0.00945512 0.03391696 0.03391695
 0.02984198 0.03391695 0.00945511 0.01502839 0.03391672 0.01503146
 0.03391694 0.03427645 0.03391694 0.02992398 0.03385714 0.03391692
 0.03391691 0.09068359 0.02716418 0.03369122 0.03391694 0.02328295
 0.03123028 0.02328294 0.02992414 0.03420628 0.01502838 0.03391694
 0.03363194 0.03522025 0.01502838 0.01991345 0.02328294 0.03391691
 0.02328293 0.02328294]
tr_loss:[0.03219863 0.03429286 0.03429281 0.03429282 0.0156372  0.02420895
 0.0342928  0.0185564  0.03428016 0.03429287 0.03429129 0.02732735
 0.01855639 0.01855638 0.09751787 0.03823861 0.03429281 0.03429282
 0.03416474 0.03429282 0.02460972 0.03823858 0.01563757 0.03429287
 0.01563742 0.03823863 0.01855639 0.02732733 0.02732723 0.0382386
 0.02732735 0.02562024 0.05560478 0.03429283 0.03429283 0.09839898
 0.03006904 0.03240008 0.03429281 0.03429283 0.03347121 0.03429283
 0.0300707  0.01563746 0.02420871 0.01563742 0.02732641 0.01855639
 0.02732734 0.02732732]
tr_loss:[0.04462242 0.03675001 0.02902244 0.03675003 0.03674999 0.03099498
 0.10029502 0.03473921 0.04882405 0.03674998 0.03729821 0.04462246
 0.03920628 0.03681302 0.02540197 0.03473922 0.025402   0.08874015
 0.03675002 0.09745779 0.03675005 0.02540205 0.03675003 0.03810174
 0.03473921 0.03674998 0.03773388 0.03690785 0.03473923 0.03755174
 0.03974691 0.03675    0.10029501 0.03674996 0.03674998 0.03675002
 0.02600694 0.03675    0.04462244 0.02558449 0.02558452 0.03675001
 0.03473923 0.02959235 0.03719896 0.04462247 0.03675001 0.03669415
 0.03473922 0.02540221]
tr_loss:[0.03364108 0.05877247 0.0234527  0.03695188 0.05877303 0.02824726
 0.03854092 0.03685271 0.03364107 0.03685269 0.04533655 0.04328925
 0.03140596 0.03685268 0.0234527  0.03685271 0.03124647 0.03685271
 0.02301349 0.02345269 0.03778882 0.03751225 0.0234527  0.02345268
 0.04462922 0.03685268 0.03685271 0.0234527  0.02345268 0.02345269
 0.03685272 0.0368527  0.03685271 0.03700723 0.08747997 0.0370068
 0.03364096 0.03364108 0.02345268 0.03685273 0.03683295 0.03685267
 0.04455548 0.03960841 0.03685271 0.04328921 0.03685269 0.02345269
 0.02345268 0.03685271]
tr_loss:[0.03630266 0.03630266 0.03630266 0.03630261 0.03034402 0.02995113
 0.03630264 0.03850382 0.03248826 0.03630263 0.01916618 0.03034401
 0.03997913 0.01531577 0.03630263 0.030344   0.03630266 0.01910706
 0.0402716  0.03630264 0.03630263 0.03597165 0.030344   0.030344
 0.03736236 0.03519176 0.03034401 0.03630264 0.01910705 0.01531089
 0.01910707 0.0590398  0.01910709 0.01910711 0.03034401 0.03760829
 0.09744398 0.01910706 0.03630263 0.03635059 0.03630267 0.03754931
 0.03630263 0.03630264 0.01531577 0.03417904 0.03034401 0.01910708
 0.08788066 0.01531576]
tr_loss:[0.0707428  0.03373881 0.03726395 0.03726096 0.03726101 0.09637206
 0.04402927 0.03373882 0.03726093 0.0372785  0.02690717 0.03725509
 0.03726099 0.04087181 0.10417233 0.03726098 0.03726101 0.03726093
 0.03726099 0.03726099 0.03726098 0.03373881 0.04260362 0.03726098
 0.01587121 0.02169101 0.03726096 0.037261   0.02169103 0.01587113
 0.03726095 0.04402927 0.037261   0.03726097 0.03909209 0.04394022
 0.02169103 0.02169951 0.03373883 0.01587129 0.03726095 0.0356875
 0.02169101 0.03726102 0.03373883 0.03373881 0.09637188 0.03284716
 0.03726097 0.03773651]
tr_loss:[0.03433526 0.03433524 0.03619593 0.03545847 0.02321348 0.02321349
 0.03433525 0.03433441 0.03433524 0.03433539 0.02531352 0.01774666
 0.03604233 0.0312677  0.03433527 0.03433641 0.02321359 0.03986105
 0.03545847 0.03545848 0.0232135  0.01774666 0.02989274 0.03545846
 0.05664984 0.02620491 0.02321526 0.01774665 0.04568011 0.03433524
 0.03433522 0.02321349 0.03433525 0.0261435  0.0339563  0.03545851
 0.03545846 0.03619593 0.03340464 0.03433522 0.01774666 0.03433522
 0.03545845 0.02321349 0.03433525 0.03433522 0.03545848 0.03433524
 0.03433524 0.03545849]
tr_loss:[0.03447045 0.03187425 0.01748574 0.03212245 0.02138006 0.03171971
 0.02138085 0.03171968 0.01831388 0.02733472 0.01199066 0.03171971
 0.02138005 0.04206406 0.03172    0.0317197  0.02138005 0.01746614
 0.03212245 0.02138005 0.0317197  0.02588447 0.0317197  0.03171967
 0.02138006 0.03171968 0.03223563 0.03009369 0.02138026 0.03172093
 0.03171971 0.03171971 0.04314453 0.02138005 0.0317197  0.03171969
 0.02534926 0.04206435 0.03171971 0.0901856  0.03212244 0.01748578
 0.0292073  0.03171974 0.03171977 0.03171968 0.03174403 0.03171907
 0.02720179 0.02770018]
tr_loss:[0.03073764 0.03220857 0.03073955 0.02931227 0.03073959 0.02944637
 0.03073957 0.03073956 0.04332216 0.03234438 0.035666   0.03073954
 0.03073958 0.02450256 0.03234439 0.03073957 0.03073949 0.05170251
 0.04198844 0.02237828 0.03344458 0.02554386 0.03143124 0.03231271
 0.03234438 0.03073956 0.03073955 0.03073955 0.0433222  0.02204092
 0.03073957 0.03073958 0.03234437 0.03234439 0.03073955 0.03567709
 0.03073956 0.03073957 0.03073889 0.04332215 0.03234303 0.02237827
 0.03073958 0.03495985 0.02237828 0.03344471 0.01925837 0.01925835
 0.03163368 0.0223783 ]
tr_loss:[0.02993721 0.01454826 0.02020213 0.02596416 0.02596415 0.01454839
 0.02993718 0.02596417 0.02020214 0.02653006 0.02020213 0.02596416
 0.02993718 0.02099149 0.03201655 0.02596418 0.0299372  0.02099142
 0.0413648  0.022174   0.02596415 0.03333179 0.02596416 0.02702333
 0.04134079 0.02020213 0.02020214 0.04040976 0.02596414 0.02985696
 0.02962343 0.02596417 0.02837143 0.04134079 0.0286494  0.02596417
 0.02596417 0.04136397 0.02178015 0.02020213 0.02596416 0.0299372
 0.04134079 0.08874969 0.02596419 0.02596416 0.02596416 0.02596418
 0.02020214 0.04035919]
tr_loss:[0.02361896 0.0403138  0.04013557 0.00729803 0.02255808 0.01783594
 0.0225581  0.02256024 0.0225581  0.02227909 0.01783567 0.00729803
 0.03181087 0.02255808 0.04013558 0.02255812 0.0225581  0.02255812
 0.02255809 0.03180338 0.00729439 0.04013556 0.02817114 0.02255812
 0.01783568 0.01783567 0.02817115 0.02254933 0.02255809 0.09362374
 0.01847241 0.00631201 0.00729803 0.02084054 0.01783566 0.04013557
 0.0225581  0.02020427 0.0225581  0.02255812 0.02255808 0.0401356
 0.02361896 0.02255809 0.02448026 0.02255809 0.02255818 0.0401356
 0.01847772 0.02817114]
tr_loss:[0.02426534 0.02435661 0.04216103 0.02052578 0.01896937 0.03151236
 0.03149622 0.02426537 0.02426535 0.03151238 0.02426536 0.02426537
 0.01862458 0.03151237 0.01896937 0.03151237 0.02426476 0.02426535
 0.03151236 0.01896937 0.04335652 0.00523493 0.03526585 0.02221959
 0.02426535 0.03263187 0.02045751 0.02426537 0.02015253 0.02222233
 0.04335651 0.00523493 0.0204575  0.02426536 0.02426535 0.00523493
 0.02426535 0.02426537 0.10566279 0.01862806 0.04335655 0.03151188
 0.02426535 0.00523493 0.0222223  0.00501132 0.02103942 0.02079618
 0.02426537 0.02426331]
tr_loss:[0.02229009 0.02091116 0.01979872 0.02497625 0.02158583 0.02113854
 0.04520354 0.02497627 0.00503229 0.03762501 0.03366914 0.02497625
 0.03366913 0.02091074 0.03346866 0.02497628 0.02444785 0.0249763
 0.02497628 0.02298264 0.03366914 0.03312489 0.0199686  0.03366904
 0.03366914 0.0380306  0.02497626 0.02233164 0.04316805 0.02497626
 0.02497626 0.0197906  0.02497625 0.04316859 0.04439511 0.01979048
 0.03366916 0.02233902 0.02497632 0.04439512 0.02497627 0.02497627
 0.02497628 0.01979046 0.11516746 0.01979048 0.02497629 0.01979048
 0.04439513 0.02620889]
tr_loss:[0.02299407 0.01782251 0.1052345  0.04225815 0.02299405 0.03277411
 0.03277411 0.02141646 0.0327741  0.0188167  0.0327741  0.02299408
 0.02299407 0.02299407 0.01902548 0.02299407 0.03277341 0.04225821
 0.04233088 0.02299709 0.00575249 0.02326964 0.03277409 0.02299408
 0.03018104 0.02077286 0.0263416  0.01813385 0.02075145 0.10523453
 0.02299422 0.02299408 0.01902548 0.02299409 0.00575249 0.02299409
 0.01902547 0.01795436 0.02299577 0.02299408 0.02310877 0.00575247
 0.02299407 0.02299407 0.02299409 0.01902547 0.02132432 0.02299408
 0.00575249 0.01902548]
tr_loss:[0.02668268 0.02016662 0.03175278 0.02185803 0.02185801 0.02185802
 0.02185803 0.02137529 0.02346304 0.0317561  0.03131799 0.04202836
 0.03331495 0.03331494 0.02346386 0.03331494 0.02185806 0.10525607
 0.00915856 0.02173764 0.00921263 0.03331495 0.02185803 0.03331495
 0.02185804 0.02185798 0.02186368 0.02016662 0.02194248 0.02185802
 0.01727935 0.03175279 0.02185802 0.03331494 0.02185802 0.03331495
 0.02083565 0.02185803 0.02411843 0.02016662 0.03331483 0.02185802
 0.03331495 0.02185804 0.03158922 0.04119814 0.03331214 0.03331494
 0.03331496 0.1052572 ]
tr_loss:[0.02056319 0.0102265  0.02056319 0.0209835  0.03235885 0.02056322
 0.0205632  0.01938844 0.0205632  0.02054449 0.09492645 0.0205632
 0.02056322 0.01968035 0.04020449 0.01621748 0.02068737 0.02056267
 0.01938845 0.02056319 0.02417517 0.03235883 0.01022653 0.02056318
 0.02056305 0.0205632  0.03235883 0.02056322 0.01621018 0.04081204
 0.01023124 0.03235885 0.0102265  0.03235886 0.02121184 0.09492427
 0.0205632  0.02047684 0.03235882 0.0162799  0.03235883 0.02054177
 0.10164571 0.03234249 0.02995033 0.01639122 0.02056319 0.02056319
 0.03983054 0.02056319]
tr_loss:[0.01914676 0.01914675 0.01751532 0.03070044 0.01914673 0.01914698
 0.03066527 0.09273576 0.01914675 0.01739897 0.01914676 0.02895869
 0.01914674 0.01914674 0.03070044 0.03955806 0.03312772 0.01914675
 0.00920634 0.01739896 0.03070045 0.00920633 0.03070045 0.0191476
 0.1010768  0.01914675 0.03884834 0.03070046 0.01806877 0.03306412
 0.03070046 0.01739896 0.02295823 0.01739896 0.0165835  0.03070046
 0.01806879 0.01914699 0.01739896 0.01739898 0.03070048 0.01914676
 0.01549842 0.01739897 0.01739896 0.03070046 0.01914674 0.01889705
 0.04991163 0.02801738]
tr_loss:[0.02010446 0.02107758 0.0394842  0.02086171 0.02086172 0.00857799
 0.01697324 0.01697324 0.02086173 0.02086171 0.0208617  0.0208617
 0.02086609 0.0208695  0.01697324 0.02161968 0.01697325 0.0216166
 0.02086172 0.0208617  0.03827691 0.02943078 0.09348676 0.01788643
 0.02086172 0.10208698 0.03948422 0.00857799 0.10066738 0.01697402
 0.01697324 0.00857799 0.01697323 0.01697324 0.02086172 0.00857799
 0.02086172 0.02955427 0.02086493 0.02814872 0.02003871 0.02086171
 0.02955429 0.10210989 0.02086172 0.09243684 0.01697324 0.02086172
 0.01697327 0.008578  ]
tr_loss:[0.01713838 0.01904441 0.02334158 0.03120001 0.02333588 0.01713838
 0.02333588 0.01925535 0.02333587 0.01713837 0.01713844 0.02333591
 0.03263108 0.02333586 0.02333588 0.00790248 0.02333201 0.02333585
 0.01958952 0.00790231 0.0171384  0.02333587 0.03104522 0.02864115
 0.03948816 0.00790213 0.01713837 0.02333586 0.02333588 0.02864113
 0.02416063 0.02864116 0.03230431 0.02864113 0.02333579 0.02129314
 0.02333588 0.02333587 0.02333588 0.00790241 0.0233359  0.02333588
 0.02864114 0.02333586 0.02333586 0.02333586 0.03209987 0.02383483
 0.02333586 0.04118382]
tr_loss:[0.03217163 0.02922632 0.02102187 0.02397582 0.02168183 0.02311592
 0.02311594 0.01694735 0.01694733 0.02311592 0.02311593 0.03871048
 0.02311596 0.02311592 0.02311596 0.02311592 0.02791985 0.02629372
 0.02103456 0.03358865 0.02311594 0.01694735 0.03871046 0.02311594
 0.02791985 0.00690062 0.02791983 0.00690308 0.02311596 0.02311593
 0.01694735 0.02791984 0.02311595 0.00690121 0.02791983 0.02311596
 0.02311594 0.00690166 0.02311593 0.0069056  0.02311593 0.02311594
 0.02311593 0.03871047 0.01700602 0.02311639 0.02031007 0.02311591
 0.02311593 0.01694734]
tr_loss:[0.02067884 0.02496325 0.02063435 0.02954496 0.00589135 0.02063436
 0.00589135 0.02738429 0.00589135 0.02043629 0.02738431 0.02063437
 0.01652673 0.03791955 0.00589136 0.02063436 0.02063437 0.02230295
 0.02208293 0.02230671 0.01650507 0.02146986 0.02496256 0.03791955
 0.0206389  0.02349831 0.03051172 0.02063437 0.02063495 0.02620857
 0.02063439 0.02063436 0.01650852 0.03824438 0.03791112 0.02738431
 0.02063452 0.00589135 0.02051281 0.02230668 0.02063436 0.02063467
 0.03793388 0.01650464 0.00589135 0.01754487 0.00589135 0.03180793
 0.01650464 0.01741767]
tr_loss:[0.01698218 0.01895999 0.01712703 0.01895997 0.01712695 0.01902149
 0.0171269  0.02820736 0.09411485 0.02810267 0.02047332 0.02820734
 0.01969866 0.01895998 0.01895997 0.01712694 0.01712695 0.01895998
 0.01895997 0.01895996 0.02820742 0.02015161 0.02820739 0.02820737
 0.01712693 0.01895997 0.02820738 0.02820736 0.01712695 0.02820735
 0.01868842 0.09411749 0.01712694 0.02820734 0.02820737 0.10217335
 0.01712695 0.02820599 0.01895997 0.01895998 0.01895997 0.01712694
 0.01798575 0.01895997 0.01895997 0.01712694 0.0179823  0.01712694
 0.02820134 0.01895997]
tr_loss:[0.09851445 0.01801083 0.01801084 0.0192188  0.01491632 0.01801082
 0.01801083 0.01921884 0.01921879 0.03712148 0.00659231 0.00659231
 0.01921571 0.01491632 0.01801231 0.01921878 0.01717151 0.0192189
 0.01563045 0.01801083 0.01653833 0.03959524 0.02945348 0.01801083
 0.01925198 0.01921879 0.01921878 0.02891443 0.02945348 0.01921877
 0.01921878 0.02945352 0.09669955 0.03959521 0.02945349 0.03934268
 0.02945348 0.01644769 0.04040356 0.01801084 0.01921878 0.01801083
 0.01921877 0.01921879 0.01921878 0.10171368 0.01921877 0.01563043
 0.03081944 0.01921879]
tr_loss:[0.01954662 0.01954661 0.02560312 0.00593931 0.02051224 0.10192273
 0.01954662 0.05341003 0.03980398 0.01954662 0.01748915 0.01954663
 0.01748914 0.02964046 0.10118724 0.01748914 0.01954662 0.01954663
 0.01954662 0.01954663 0.01748914 0.02964048 0.10118735 0.01748916
 0.01954661 0.01954663 0.01748915 0.03777191 0.01954664 0.01954661
 0.00593931 0.01748915 0.01954662 0.10115788 0.01954662 0.01580794
 0.01954661 0.01954661 0.01580803 0.01773037 0.01954662 0.02964048
 0.01954661 0.02947592 0.02964045 0.02964047 0.0195466  0.01493793
 0.01748915 0.03980402]
text_input.shape
(3000, 14400)
learning_input_tmp.shape
(3000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3000, 80)
learning_output.shape
(750, 80)
Model: "sequential_62"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_62 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1443487 1.1432527 1.1484629 1.1422455 1.2344452 1.2408189 1.2292106
 1.1422457 1.2292106 1.1422346 1.1424725 1.2292106 1.2344452 1.1422457
 1.1982286 1.2313179 1.1422457 1.1492313 1.1419638 1.2353197 1.2235501
 1.2344451 1.1422457 1.1430843 1.142225  1.1426154 1.1422455 1.2448804
 1.1422884 1.1422457 1.1422455 1.195474  1.234445  1.142301  1.1867605
 1.1422457 1.1422457 1.1982481 1.2448803 1.1422455 1.2448806 1.2343146
 1.1644052 1.1422457 1.1422455 1.1644051 1.1286255 1.1441096 1.2344041
 1.1741751]
tr_loss:[0.9255311  0.8606148  0.8184779  0.92553073 0.85985565 0.8473581
 0.83446217 0.8237804  0.86061394 0.8232967  0.91741836 0.8288418
 0.86061466 0.9049946  0.8237797  0.8237797  0.81985223 0.8237797
 0.86061466 0.82377976 0.90499467 0.8237797  0.84807956 0.925535
 0.9049946  0.823734   0.90506124 0.9049946  0.8502242  0.82780105
 0.94512117 0.8607224  0.9049946  0.83446234 0.8238037  0.81835157
 0.82282084 0.85341436 0.9049948  0.9049946  0.92553073 0.86061466
 0.9229727  0.8554157  0.9049946  0.90499467 0.8237607  0.82377976
 0.83446217 0.8237799 ]
tr_loss:[0.5362196  0.5130002  0.5130002  0.51300025 0.5130003  0.56315255
 0.5631525  0.51312286 0.5127883  0.56944925 0.5379487  0.5180479
 0.51300013 0.5631525  0.5130003  0.6046722  0.51299953 0.51300013
 0.52331465 0.5090279  0.5130003  0.5791103  0.51300025 0.562709
 0.5631526  0.5130003  0.53254986 0.5362197  0.55096114 0.53621966
 0.5379487  0.53622025 0.5631526  0.51300025 0.53621966 0.5130002
 0.5285066  0.53621966 0.5130002  0.5130042  0.5379487  0.51300025
 0.5130002  0.5969142  0.513126   0.51300013 0.5694492  0.5130003
 0.56944925 0.5830236 ]
tr_loss:[0.27608496 0.29952326 0.29952335 0.26060468 0.27295715 0.2685512
 0.2606081  0.26060456 0.26054758 0.26060462 0.2995233  0.275958
 0.26060462 0.2613842  0.26060468 0.28340873 0.28340882 0.26060468
 0.282808   0.2606041  0.26060468 0.26060468 0.26060468 0.26060468
 0.26060462 0.276085   0.2995074  0.2807596  0.29952908 0.2995232
 0.26060465 0.2995283  0.31089124 0.31089133 0.26060468 0.26060468
 0.26060462 0.28075957 0.2685574  0.28340873 0.26060468 0.27608502
 0.2995233  0.26060465 0.3211747  0.26060462 0.276085   0.31505853
 0.28747383 0.31508875]
tr_loss:[0.16478351 0.12977298 0.12315579 0.11678324 0.123155   0.16483848
 0.19321051 0.16483848 0.12315305 0.12315579 0.19321047 0.12315583
 0.19321051 0.12315579 0.18166463 0.19251661 0.12315579 0.17766461
 0.19744384 0.16483851 0.12315579 0.12362988 0.14787567 0.12315577
 0.17640325 0.16483852 0.1245798  0.1526583  0.12315581 0.19224396
 0.15588401 0.19321044 0.19321054 0.19224401 0.13145028 0.13901699
 0.12315579 0.12315581 0.12315581 0.12315579 0.13188632 0.12315583
 0.17766589 0.12315581 0.1297744  0.12447033 0.16483852 0.12315579
 0.12310183 0.12315583]
tr_loss:[0.10588162 0.05893678 0.05893682 0.10591044 0.06246426 0.08706931
 0.10588284 0.05893682 0.05893679 0.05893682 0.05893681 0.05893679
 0.0589368  0.10588159 0.05775649 0.06010365 0.10554582 0.05894025
 0.05893682 0.10588159 0.0601037  0.0589368  0.05893682 0.05893592
 0.05858885 0.10472069 0.05893683 0.10554583 0.10392968 0.0630544
 0.06246429 0.10472067 0.10588163 0.10588165 0.05893681 0.0589368
 0.10554582 0.10588157 0.05893681 0.05893683 0.10472071 0.05893679
 0.10472067 0.05893683 0.06246423 0.0938125  0.05893683 0.10588162
 0.06505807 0.10588161]
tr_loss:[0.06687757 0.03773946 0.04701883 0.04390104 0.0397335  0.03973349
 0.04086319 0.08493157 0.03973348 0.0721123  0.0397335  0.06687763
 0.05918837 0.04225605 0.0776782  0.0397335  0.07767817 0.065455
 0.06687756 0.03973348 0.0397335  0.03972319 0.07767819 0.0397339
 0.06712289 0.04248867 0.06687818 0.03584339 0.05031056 0.03973351
 0.07302551 0.03973348 0.07767814 0.0668776  0.0668776  0.03973349
 0.07211231 0.03973515 0.0397335  0.06687759 0.07767814 0.06687763
 0.06687759 0.03973349 0.03973346 0.072103   0.07211226 0.03973344
 0.0591884  0.03973349]
tr_loss:[0.02831024 0.08643829 0.03568741 0.0283102  0.02831018 0.0283102
 0.03089726 0.0283102  0.03707274 0.0283102  0.03568737 0.04907079
 0.04656712 0.04656627 0.02831019 0.04907077 0.02831018 0.04656733
 0.02831018 0.02691196 0.02831017 0.0283102  0.02831018 0.02824392
 0.02965885 0.04907078 0.03289171 0.0283102  0.08185694 0.04907078
 0.04905285 0.02831019 0.0283102  0.02572479 0.02831019 0.0490708
 0.03584342 0.04656716 0.0490708  0.0283102  0.02831016 0.08643828
 0.0359507  0.03568741 0.02831019 0.02958078 0.03568741 0.04907077
 0.02952061 0.02827358]
tr_loss:[0.03342544 0.03342543 0.03139198 0.03342542 0.03342543 0.03139198
 0.03342543 0.03521249 0.03342543 0.03342542 0.0335507  0.03300675
 0.03266218 0.03337616 0.03139198 0.02222717 0.03267444 0.03342544
 0.03342542 0.09315683 0.02690012 0.03635673 0.03586461 0.03342544
 0.03342564 0.03342543 0.0334255  0.03139198 0.03342541 0.02222707
 0.03521304 0.03342542 0.03139199 0.03342543 0.03267569 0.0334254
 0.02399274 0.03376237 0.03342541 0.02222705 0.03139199 0.02744441
 0.09419139 0.03342543 0.03342694 0.03342541 0.03139199 0.03342541
 0.09391341 0.03139198]
tr_loss:[0.024442   0.09127081 0.02445593 0.02445593 0.0291745  0.02917447
 0.02917449 0.03032706 0.0299396  0.09122355 0.04170554 0.02917446
 0.02917448 0.02814623 0.02034608 0.02917449 0.02085489 0.02993958
 0.03262488 0.03137444 0.02917446 0.02571697 0.01380519 0.02085493
 0.01380518 0.02101345 0.02917447 0.01380522 0.0910582  0.01380518
 0.02917445 0.01380518 0.02445593 0.02855157 0.09127837 0.02993959
 0.02917447 0.02918347 0.02571697 0.02571698 0.01860286 0.01380519
 0.02917447 0.02917448 0.02445593 0.02917446 0.02917448 0.09105822
 0.02917449 0.03124527]
tr_loss:[0.08170585 0.02129735 0.01972536 0.01968809 0.02129736 0.02039039
 0.00912899 0.02129738 0.00724852 0.01993291 0.08170593 0.02618875
 0.02129736 0.01341178 0.02129736 0.02129738 0.02618875 0.01986802
 0.00724854 0.02129735 0.02129738 0.02129737 0.02039039 0.01301302
 0.02039039 0.02618876 0.02129737 0.0180711  0.02038615 0.02039041
 0.02129737 0.02129737 0.02039039 0.02448228 0.0219186  0.03299015
 0.03298982 0.02129736 0.02191842 0.02129737 0.02039041 0.02039001
 0.00724853 0.02129734 0.02129734 0.02129737 0.01745524 0.01986802
 0.02129739 0.02129735]
tr_loss:[0.07936314 0.01563543 0.03095312 0.02018288 0.02018288 0.03179439
 0.01116525 0.02634182 0.01688672 0.02608065 0.02018286 0.02634181
 0.0232861  0.02017542 0.01116526 0.02595158 0.02018287 0.03117083
 0.01116525 0.01344524 0.02351555 0.02018287 0.02608065 0.02608066
 0.02100026 0.02018289 0.0311708  0.02018286 0.02012801 0.01116525
 0.02018527 0.01116525 0.02729417 0.0839358  0.02018287 0.02018288
 0.03117081 0.02634183 0.02018289 0.02018287 0.02018286 0.01116526
 0.01116526 0.03117081 0.02018285 0.02018285 0.01116524 0.02634181
 0.02018289 0.02018288]
tr_loss:[0.03051331 0.08448304 0.03046086 0.01364456 0.03051331 0.02372349
 0.02086862 0.02086863 0.01364456 0.01471458 0.01524998 0.02086862
 0.0305133  0.03051328 0.01364455 0.03051332 0.03309242 0.03051332
 0.08320322 0.03046011 0.02086864 0.02086865 0.0305133  0.01364459
 0.01503739 0.01695601 0.02086862 0.03051334 0.01364456 0.0147144
 0.03309458 0.01524758 0.01551692 0.03046097 0.03323101 0.02372351
 0.02091077 0.01417152 0.01323877 0.01524856 0.02086864 0.02086863
 0.02086865 0.01364455 0.02086915 0.01364455 0.01529275 0.02086864
 0.02086864 0.01364456]
tr_loss:[0.0222614  0.01340513 0.02745872 0.02071764 0.00768943 0.02071764
 0.00997668 0.01731966 0.02869181 0.00997668 0.00997667 0.02879072
 0.02867139 0.02071763 0.02071768 0.02745869 0.02071764 0.02196438
 0.01350133 0.02066303 0.02071764 0.0262481  0.02058342 0.02745869
 0.00997667 0.00997669 0.02879074 0.00997669 0.02071764 0.02071765
 0.02071765 0.01214116 0.02439497 0.02071765 0.02071765 0.0286945
 0.08519739 0.02745872 0.02071764 0.00997668 0.01761444 0.02214659
 0.02071859 0.02745868 0.00997669 0.02826682 0.02071765 0.02071811
 0.02745871 0.02869179]
tr_loss:[0.02285326 0.02498177 0.01509267 0.00674064 0.01509294 0.02321306
 0.02285325 0.00674064 0.02395288 0.02485679 0.02321309 0.02285327
 0.02321306 0.0251747  0.02321303 0.02285326 0.02285327 0.02321305
 0.02321307 0.00676069 0.0206055  0.02447513 0.02285326 0.02498172
 0.02285325 0.02285323 0.00674063 0.02285324 0.02858974 0.0201368
 0.01955486 0.00674064 0.02485681 0.02285329 0.02494161 0.01633607
 0.02285327 0.02203796 0.02321307 0.02285326 0.01436883 0.02285327
 0.02321307 0.02321308 0.0228534  0.02285326 0.02493791 0.02493776
 0.02283211 0.00729947]
tr_loss:[0.02002872 0.02151965 0.01950511 0.02531423 0.00534853 0.08877819
 0.02037531 0.02151955 0.0149406  0.01314188 0.02531425 0.00534853
 0.0200287  0.01929905 0.02197406 0.02531425 0.02151956 0.02531424
 0.02002873 0.02151706 0.02531422 0.02197397 0.02531423 0.0200287
 0.02531424 0.00534853 0.08796956 0.02002861 0.02531425 0.02531424
 0.02151903 0.02841001 0.00534854 0.00534853 0.02531424 0.02531424
 0.0053486  0.0200287  0.02376328 0.02196494 0.02002686 0.02531422
 0.01929891 0.02493086 0.02003289 0.02531425 0.02630119 0.02002872
 0.0229472  0.02531427]
tr_loss:[0.02629672 0.02269219 0.01128882 0.02629679 0.00580355 0.01852719
 0.01835119 0.01733153 0.00580355 0.00580355 0.00757635 0.02241989
 0.02241987 0.01388458 0.00580354 0.02629675 0.02574856 0.02629672
 0.02629673 0.02596179 0.0158185  0.00580355 0.0212126  0.0229256
 0.0262967  0.02629672 0.02629671 0.02629672 0.01835123 0.01848911
 0.01835122 0.01835122 0.00580949 0.00580355 0.01697309 0.01835126
 0.02629852 0.02241987 0.01835122 0.02629671 0.00580356 0.01822219
 0.02629671 0.00580355 0.00580355 0.02621598 0.02873413 0.02629669
 0.02629674 0.01737504]
tr_loss:[0.01584524 0.08646951 0.01585392 0.01852649 0.0234495  0.02574175
 0.02574176 0.00706861 0.01585395 0.02574175 0.01903933 0.0260316
 0.01886687 0.02574174 0.00711884 0.00706862 0.00706861 0.01828144
 0.02603159 0.02574174 0.02222436 0.01585395 0.02357858 0.02574173
 0.0185265  0.02603155 0.03742423 0.00707138 0.01585392 0.02344953
 0.01585392 0.01852652 0.01885944 0.02574175 0.00706861 0.00706861
 0.02574172 0.02574172 0.02574176 0.00708622 0.02574171 0.02574174
 0.0257482  0.02574172 0.00706862 0.02598416 0.02574175 0.01886084
 0.0185265  0.02574175]
tr_loss:[0.02367835 0.02367837 0.01770091 0.00757767 0.02367835 0.02367826
 0.0236202  0.02367836 0.02367836 0.01280135 0.02367833 0.02370284
 0.00757767 0.02367836 0.03530785 0.00757767 0.02367836 0.02367836
 0.02367835 0.02475034 0.02368732 0.01071192 0.01785198 0.00757767
 0.0240564  0.02367836 0.012896   0.01962822 0.00757767 0.02367835
 0.02472212 0.01873135 0.00757768 0.01873136 0.0236786  0.00757767
 0.01872754 0.01289896 0.01873133 0.01409366 0.01962878 0.03521866
 0.01409366 0.08484928 0.00757768 0.01289632 0.02367835 0.02367833
 0.01873136 0.00757767]
tr_loss:[0.02258982 0.00868766 0.02307459 0.02031326 0.02032072 0.0230746
 0.02307462 0.08124468 0.02307461 0.00868782 0.02101453 0.02032071
 0.02307462 0.00868766 0.02744961 0.02307462 0.01657458 0.02744959
 0.01484867 0.02032072 0.02307445 0.01652826 0.033843   0.01484866
 0.00868767 0.00868767 0.0230744  0.02744957 0.0230746  0.02307461
 0.0274496  0.08123753 0.02307461 0.02307463 0.02307455 0.02744957
 0.02032074 0.02307463 0.02603067 0.0230746  0.02386281 0.02307461
 0.02307463 0.00868767 0.02307462 0.00868767 0.00868766 0.0230746
 0.08124381 0.02307702]
tr_loss:[0.01670182 0.02611459 0.02283477 0.02661457 0.00800673 0.02221389
 0.02093844 0.02283477 0.02283475 0.00800673 0.02093843 0.02283477
 0.02093844 0.08287382 0.01278567 0.02283481 0.02283475 0.02093841
 0.02093841 0.0261145  0.02283477 0.01912047 0.00800673 0.02283475
 0.03176749 0.01663223 0.01280096 0.02225593 0.02283477 0.02221386
 0.00800673 0.0209384  0.02283477 0.01684914 0.00800674 0.02283477
 0.02611264 0.0228377  0.01684916 0.01274872 0.02093843 0.00800672
 0.01318063 0.02740136 0.02283103 0.0279013  0.02740137 0.02283474
 0.02283478 0.02093843]
tr_loss:[0.019017   0.019017   0.0051432  0.01394933 0.02198726 0.00514319
 0.02452951 0.02547902 0.02198721 0.01862917 0.02198724 0.02198722
 0.02001567 0.02277544 0.02198722 0.0051432  0.02198723 0.02198723
 0.026419   0.02198724 0.0200157  0.02198724 0.02198723 0.02869584
 0.01830116 0.01901985 0.01901638 0.02277575 0.01135723 0.02869587
 0.02001569 0.02198721 0.01818442 0.02198722 0.02001567 0.02869608
 0.02452951 0.02198724 0.02001568 0.02001567 0.02001567 0.02198726
 0.00514319 0.02198725 0.02198722 0.02198723 0.02198722 0.02277545
 0.02198725 0.02198725]
tr_loss:[0.0200123  0.01176258 0.02010879 0.02186901 0.02010879 0.02010883
 0.01520545 0.02186846 0.01839751 0.01412611 0.02177582 0.021869
 0.02186901 0.0223322  0.02186901 0.00355225 0.021869   0.02233219
 0.08305147 0.02186902 0.02186861 0.02010883 0.02186901 0.02186899
 0.02186899 0.021869   0.02010879 0.02186901 0.02186898 0.0201088
 0.02186948 0.02231681 0.01113169 0.0201088  0.02186901 0.02186379
 0.00355227 0.0221926  0.02010878 0.02186901 0.01114544 0.02186901
 0.01113749 0.01108884 0.02010881 0.0223322  0.02186899 0.01847716
 0.02177508 0.02186901]
tr_loss:[0.0222813  0.01303559 0.02228129 0.02139702 0.00345462 0.02219361
 0.02093804 0.02388048 0.02214834 0.02228128 0.02388449 0.0149477
 0.0224641  0.02093804 0.02093805 0.02139704 0.02388049 0.00732626
 0.02228128 0.02228129 0.02228128 0.00345463 0.02228128 0.02228123
 0.01926326 0.01761504 0.02228126 0.02228128 0.02091788 0.02228128
 0.01783856 0.01308575 0.02093804 0.00345463 0.02388046 0.01148598
 0.08299536 0.02563227 0.02228126 0.02093768 0.00345462 0.00345462
 0.02228127 0.02228083 0.02388049 0.02093804 0.01361092 0.02373851
 0.08299515 0.0222813 ]
tr_loss:[0.00352888 0.02142296 0.00352888 0.01811743 0.02163565 0.02439014
 0.02830273 0.01791898 0.02163564 0.02163563 0.02439013 0.02147443
 0.00352888 0.08672466 0.02142258 0.02020221 0.02142295 0.02142297
 0.01389508 0.08505574 0.02142296 0.02142296 0.02142295 0.02143328
 0.02142297 0.02142295 0.01337664 0.00358861 0.00352935 0.01117502
 0.02142296 0.02142296 0.02099186 0.02142296 0.02020223 0.02020223
 0.02142296 0.00352888 0.02142298 0.00352889 0.02142299 0.0036752
 0.02142296 0.02020222 0.02020203 0.08333428 0.02142294 0.02020221
 0.02084855 0.02020224]
tr_loss:[0.02269479 0.01787359 0.01120147 0.02033367 0.08258617 0.02033365
 0.08381971 0.01787476 0.01904343 0.02833753 0.02033367 0.02812529
 0.00432286 0.02033366 0.02264332 0.08176313 0.01904341 0.02033368
 0.02033368 0.02033368 0.0043225  0.01684628 0.02033366 0.02033367
 0.01787476 0.00432249 0.02033365 0.02033366 0.02033473 0.02033368
 0.02033369 0.02033367 0.01378222 0.02033367 0.01904342 0.08381975
 0.0190434  0.00432249 0.02344531 0.01904342 0.02033365 0.02033365
 0.01904342 0.00432249 0.02146352 0.02033358 0.02135412 0.02132573
 0.00432249 0.0213538 ]
tr_loss:[0.02330344 0.01923006 0.00613071 0.00613071 0.00613071 0.02060196
 0.08085053 0.02059303 0.01287869 0.08321283 0.02059467 0.02059467
 0.02059481 0.02330345 0.02059465 0.00682487 0.02059466 0.08322076
 0.0178168  0.01923005 0.02059467 0.01923004 0.02059466 0.00613071
 0.02059466 0.01578019 0.02251039 0.01923002 0.02059467 0.08085059
 0.00613071 0.01216422 0.01578019 0.02059464 0.02059465 0.01578019
 0.02177947 0.02059464 0.02059464 0.02059464 0.01923005 0.02059467
 0.00613071 0.02059466 0.02059467 0.08313424 0.08322078 0.02226361
 0.02059465 0.02059464]
tr_loss:[0.01392637 0.02129008 0.02129006 0.00675959 0.01941013 0.01485
 0.01644348 0.0164431  0.01485    0.00675958 0.02129019 0.02364413
 0.02001944 0.02129009 0.02315045 0.01941011 0.01937488 0.02367424
 0.01484325 0.02365886 0.01941011 0.02380183 0.01941013 0.012838
 0.02353696 0.08209953 0.02383198 0.01746131 0.02129009 0.02441187
 0.00675958 0.02129009 0.01485    0.02129008 0.02129007 0.02129007
 0.01484214 0.0067596  0.00675959 0.02198723 0.01941011 0.0078303
 0.02129006 0.02127231 0.02129008 0.02129007 0.0212901  0.02353581
 0.0212901  0.07993238]
tr_loss:[0.02492214 0.02153798 0.00564653 0.01712546 0.08095081 0.02153799
 0.01831518 0.02153799 0.02153799 0.02017308 0.01862807 0.00564653
 0.01862806 0.01377735 0.02153799 0.02153798 0.02153795 0.00564654
 0.02153799 0.01355779 0.02153798 0.02153799 0.02153799 0.02153796
 0.02153797 0.02153797 0.01862807 0.02153798 0.00564653 0.01377735
 0.01712546 0.02249942 0.02491876 0.00564653 0.01337198 0.01377735
 0.00760123 0.02153799 0.00564653 0.02153798 0.01337107 0.01193219
 0.0171254  0.02438447 0.00564674 0.01377735 0.00564654 0.01862807
 0.02153795 0.02127608]
tr_loss:[0.01253626 0.02161285 0.01015974 0.01084744 0.01211383 0.00424539
 0.02161284 0.01798815 0.00424539 0.00424539 0.01002131 0.02264038
 0.02264036 0.018704   0.01361025 0.02161283 0.02950194 0.02161285
 0.02161283 0.01798816 0.02006523 0.01798745 0.01798814 0.01701296
 0.01361025 0.02161284 0.00424539 0.02161281 0.02140788 0.02161284
 0.02161281 0.02161285 0.02161284 0.02264038 0.02264036 0.02161285
 0.02161284 0.01798818 0.02171643 0.0121138  0.02106374 0.01284867
 0.07953264 0.01798815 0.02161287 0.02161284 0.02264037 0.0216128
 0.01055193 0.02161284]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3000 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3001, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3001 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3002, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3002 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3003, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3003 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3004, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3004 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3005, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3005 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3006, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3006 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3007, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3007 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3008, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3008 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3009, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3009 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3010, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3010 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3011, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3011 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3012, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3012 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3013, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3013 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3014, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3014 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3015, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3015 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3016, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3016 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3017, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3017 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3018, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3018 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3019, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3019 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3020, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3020 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3021, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3021 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3022, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3022 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3023, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3023 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3024, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3024 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3025, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3025 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3026, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3026 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3027, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3027 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3028, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3028 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3029, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3029 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3030, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3030 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3031, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3031 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3032, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3032 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3033, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3033 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3034, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3034 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3035, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3035 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3036, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3036 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3037, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3037 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3038, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3038 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3039, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3039 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3040, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3040 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3041, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3041 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3042, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3042 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3043, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3043 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3044, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3044 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3045, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3045 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3046, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3046 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3047, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3047 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3048, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3048 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3049, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3049 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3050, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3050 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3051, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3051 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3052, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3052 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3053, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3053 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3054, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3054 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3055, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3055 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3056, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3056 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3057, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3057 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3058, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3058 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3059, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3059 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3060, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3060 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3061, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3061 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3062, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3062 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3063, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3063 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3064, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3064 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3065, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3065 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3066, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3066 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3067, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3067 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3068, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3068 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3069, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3069 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3070, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3070 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3071, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3071 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3072, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3072 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3073, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3073 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3074, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3074 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3075, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3075 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3076, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3076 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3077, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3077 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3078, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3078 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3079, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3079 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3080, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3080 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3081, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3081 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3082, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3082 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3083, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3083 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3084, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3084 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3085, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3085 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3086, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3086 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3087, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3087 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3088, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3088 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3089, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3089 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3090, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3090 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3091, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3091 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3092, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3092 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3093, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3093 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3094, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3094 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3095, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3095 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3096, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3096 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3097, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3097 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3098, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3098 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3099, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3099 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3100, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-3000
text_input.shape
(3100, 14400)
learning_input_tmp.shape
(3100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3100, 80)
learning_output.shape
(750, 80)
Model: "sequential_63"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_63 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.501811  1.3636076 1.4751552 1.4407268 1.495043  1.3636076 1.4501454
 1.383238  1.4440212 1.5015934 1.3636074 1.4391873 1.4334252 1.5016642
 1.4557565 1.4335644 1.3831762 1.3832381 1.4636456 1.363616  1.4501455
 1.379794  1.4420443 1.3832381 1.4740419 1.3636053 1.5016937 1.3636076
 1.4501454 1.3832381 1.4616244 1.3832381 1.3639642 1.4647187 1.3636076
 1.4647185 1.3636076 1.3981293 1.3636078 1.4501469 1.4440094 1.3668921
 1.3636076 1.3834832 1.3636076 1.3636076 1.4501455 1.3636074 1.3636076
 1.3636141]
tr_loss:[0.8535601  0.90302515 0.866137   0.85355985 0.85356    0.8535601
 0.8535601  0.8535601  0.85356    0.8769846  0.8535601  0.90302527
 0.8555883  0.8690554  0.9049179  0.93630743 0.86297524 0.85568416
 0.90302503 0.90512246 0.9346943  0.90302515 0.91192704 0.9261303
 0.90302527 0.867568   0.8535601  0.8535601  0.8403659  0.9025699
 0.90302503 0.8535597  0.8776374  0.85370195 0.8556274  0.8535601
 0.92693937 0.87226945 0.90269697 0.9025699  0.9025698  0.912591
 0.8535601  0.85356    0.8535601  0.9060421  0.93630743 0.9118618
 0.85950553 0.8669111 ]
tr_loss:[0.4692956  0.4692945  0.4692956  0.5740652  0.51301086 0.47731775
 0.4692956  0.5104406  0.46831903 0.50941217 0.4692935  0.4692956
 0.49435216 0.51531327 0.51340073 0.46831903 0.4692956  0.4692955
 0.46829623 0.46929485 0.4692955  0.4677062  0.46831903 0.46831903
 0.497511   0.49435368 0.46831903 0.4692955  0.51496613 0.49435216
 0.46831903 0.49435225 0.49435225 0.4943522  0.4683191  0.49875322
 0.5007489  0.4692977  0.4692956  0.46831903 0.47004175 0.4692955
 0.47190112 0.46929556 0.4683191  0.51531494 0.4692956  0.5153132
 0.46831903 0.49435216]
tr_loss:[0.22140379 0.24874187 0.26046404 0.2214038  0.22140379 0.22140375
 0.22140379 0.22140376 0.22140379 0.22140379 0.3366433  0.2251266
 0.22721224 0.22140376 0.2214038  0.24874191 0.24371779 0.26536438
 0.2214034  0.22721167 0.22140387 0.2552056  0.22140375 0.22140379
 0.26261488 0.23450537 0.22721231 0.22795255 0.23997769 0.23111276
 0.22140375 0.21580033 0.26225653 0.25008613 0.2612013  0.23997764
 0.22140376 0.22140379 0.22795255 0.24400811 0.22140379 0.2440052
 0.2214038  0.26563582 0.2213892  0.26041612 0.22721231 0.26261485
 0.2626149  0.23997767]
tr_loss:[0.09588984 0.09590323 0.07676233 0.09590322 0.0767623  0.09590323
 0.09985354 0.08871476 0.08872499 0.09590323 0.10285681 0.11236441
 0.12365304 0.1136101  0.0767623  0.07676224 0.0959032  0.09590332
 0.08871473 0.09590324 0.09590322 0.07676233 0.10217686 0.09590325
 0.08871473 0.0998509  0.08871479 0.09590324 0.10334377 0.09590323
 0.08871475 0.09590323 0.09985364 0.09985355 0.09590325 0.09590324
 0.08871472 0.09590323 0.08871473 0.0887825  0.09985388 0.08519536
 0.0959032  0.09799852 0.08648951 0.09588517 0.08871476 0.0959032
 0.0998535  0.08871478]
tr_loss:[0.05456408 0.08470471 0.07698833 0.06500982 0.07111111 0.07463591
 0.08767494 0.07111259 0.07646487 0.07491368 0.06020126 0.06689884
 0.0768673  0.07491367 0.06020118 0.07698833 0.07488488 0.06000175
 0.05456513 0.09249105 0.05456523 0.06500985 0.07698832 0.07491369
 0.06500991 0.07489628 0.07185984 0.06500985 0.05456513 0.07490735
 0.08767493 0.07491368 0.07491369 0.06500984 0.0650153  0.07491367
 0.07491368 0.06058053 0.06500982 0.07491367 0.07491368 0.07698833
 0.07491368 0.05164831 0.06952824 0.06500988 0.07491367 0.05456511
 0.0749137  0.09293149]
tr_loss:[0.07272119 0.0727212  0.07272118 0.07272122 0.07272117 0.05041873
 0.06473563 0.05041872 0.06128397 0.05174804 0.05041872 0.0727212
 0.06100427 0.07272119 0.06086718 0.06100427 0.04972067 0.05041873
 0.06938729 0.0727204  0.06100424 0.04972067 0.0727212  0.04597699
 0.0727212  0.0727212  0.07272117 0.06125028 0.07272118 0.05041873
 0.04972066 0.04972067 0.0727212  0.05141042 0.05041883 0.0851924
 0.04639701 0.05041871 0.05041873 0.12406518 0.04972066 0.08519305
 0.04972066 0.06128402 0.06938744 0.04972069 0.04972067 0.06129677
 0.07192759 0.05041871]
tr_loss:[0.02409649 0.05607377 0.03716975 0.02582186 0.02409649 0.03110332
 0.04488391 0.0560738  0.03079957 0.05579194 0.03716973 0.03253259
 0.02409648 0.02409651 0.05648381 0.02409649 0.05607379 0.03716971
 0.05607377 0.05607378 0.04495191 0.0560887  0.0560738  0.05150201
 0.0560738  0.05637649 0.05607378 0.03110333 0.03080059 0.05607376
 0.05607378 0.03110335 0.05607378 0.05607376 0.02409854 0.05607378
 0.10100093 0.05607377 0.05607378 0.03110332 0.0560738  0.03079957
 0.05607378 0.03272166 0.03110331 0.03716973 0.02658355 0.03192104
 0.04001874 0.03110333]
tr_loss:[0.01342874 0.02254885 0.01312537 0.01517204 0.03821254 0.02048454
 0.01517208 0.03821253 0.03386402 0.02647303 0.03821254 0.01396156
 0.03821257 0.02647304 0.03821255 0.02048452 0.03386511 0.0131254
 0.03821252 0.01928137 0.0563624  0.03821258 0.02647302 0.00629853
 0.03388395 0.0151721  0.02647302 0.01517216 0.03821255 0.03821259
 0.03821256 0.03821256 0.03821255 0.02647303 0.0188059  0.03821257
 0.03813827 0.03821254 0.02596713 0.02647302 0.03821253 0.03821255
 0.01796586 0.0131254  0.03821259 0.01517232 0.01517209 0.00629854
 0.02647303 0.03821255]
tr_loss:[0.02849553 0.03370767 0.03156837 0.03370614 0.02031197 0.02056285
 0.03156836 0.03156842 0.03370767 0.03156839 0.03156836 0.03156836
 0.11714862 0.03156838 0.01764891 0.0176489  0.03156837 0.03156834
 0.03370771 0.01811031 0.0176489  0.03156837 0.03156837 0.03156839
 0.03156839 0.01811032 0.03156835 0.03156838 0.0337077  0.03145207
 0.03156836 0.0220414  0.0176493  0.03156837 0.03156837 0.03156837
 0.0106749  0.01764891 0.03162023 0.00509692 0.03370454 0.03370771
 0.00743738 0.03156837 0.01811222 0.03156839 0.00509956 0.0315545
 0.04423569 0.03156836]
tr_loss:[0.03372537 0.02402963 0.02450867 0.02242777 0.01979103 0.01968727
 0.01593197 0.02402963 0.01968728 0.01677578 0.11805797 0.02402295
 0.01968727 0.00846837 0.02402963 0.02366306 0.02402963 0.02367875
 0.02402909 0.02402964 0.02605906 0.11805797 0.02402962 0.02173502
 0.01968729 0.03372551 0.02374181 0.02402961 0.01968727 0.03372552
 0.01770015 0.03372552 0.01968728 0.02402962 0.02450873 0.03372549
 0.03742152 0.00536941 0.02402961 0.03370064 0.02380825 0.03372553
 0.02402964 0.02402964 0.03372548 0.02402965 0.01968729 0.02402961
 0.01596421 0.02402962]
tr_loss:[0.02449806 0.04313579 0.02174886 0.03233628 0.02531934 0.03233627
 0.02531956 0.02174884 0.0312317  0.01758606 0.02531952 0.02531951
 0.03233628 0.03123791 0.03123123 0.02531951 0.03233627 0.01359941
 0.02531955 0.02174886 0.03233584 0.02174885 0.03108194 0.02531955
 0.10962145 0.03233628 0.02174885 0.02175063 0.02531954 0.02531956
 0.01529985 0.01736319 0.04299573 0.02174885 0.03108192 0.03609359
 0.02531955 0.02531952 0.02531951 0.03081694 0.02531954 0.03233627
 0.01370088 0.02531951 0.02531956 0.03108196 0.02606639 0.01021248
 0.04268439 0.03108193]
tr_loss:[0.02628958 0.02794358 0.02794487 0.01196981 0.02794372 0.02788782
 0.02111886 0.01768137 0.0287939  0.02628956 0.04267181 0.02794374
 0.02794374 0.02628957 0.03981286 0.02628955 0.04224098 0.01481652
 0.02247261 0.02111885 0.03617074 0.02794372 0.01588299 0.03363116
 0.02794375 0.02794375 0.01197218 0.01479958 0.0262265  0.02270057
 0.04228044 0.02794372 0.03216934 0.02628955 0.02794372 0.02111886
 0.02111885 0.02794372 0.02111887 0.02794372 0.02628955 0.01588498
 0.02794375 0.02794374 0.02794372 0.01209458 0.02521618 0.02794374
 0.03213895 0.02794374]
tr_loss:[0.11496754 0.01745968 0.03212928 0.02653393 0.01745968 0.02784622
 0.02120826 0.02653388 0.03210288 0.02653388 0.01913174 0.02653389
 0.02199    0.01745969 0.01446208 0.01729876 0.02281141 0.01017473
 0.0265339  0.01745969 0.02653388 0.0265339  0.02653389 0.01745968
 0.03090412 0.0265339  0.02653389 0.0231179  0.0295183  0.01745968
 0.0265339  0.02711982 0.10894386 0.0174597  0.0278451  0.02653387
 0.01745968 0.02653389 0.01745969 0.02653389 0.03212839 0.02653437
 0.00858924 0.01745997 0.0265339  0.02653388 0.0231179  0.02711984
 0.02653404 0.0144887 ]
tr_loss:[0.02077191 0.01440759 0.02408902 0.0193832  0.02405942 0.01438336
 0.02077193 0.03285251 0.02405941 0.02620452 0.02709832 0.012553
 0.00448206 0.02405943 0.02405941 0.01438337 0.01938322 0.02683491
 0.02405941 0.02408899 0.02405943 0.01818285 0.02077191 0.02077191
 0.0240594  0.02490032 0.02077194 0.01255488 0.02405944 0.02077193
 0.02405944 0.02405943 0.00494379 0.02077192 0.01496966 0.01255485
 0.01438842 0.02077193 0.01820092 0.0240594  0.02405942 0.02405942
 0.02077191 0.01885707 0.02077193 0.02077193 0.02077189 0.02405944
 0.02405943 0.02405942]
tr_loss:[0.02131538 0.02131542 0.0251789  0.02482074 0.01403038 0.02482073
 0.02482072 0.01403037 0.02131539 0.02482073 0.02482072 0.02482498
 0.02481948 0.0213154  0.02482073 0.02482081 0.01403038 0.00300545
 0.0213154  0.00792389 0.01403035 0.01403036 0.00331463 0.02131543
 0.02482071 0.02131539 0.02131538 0.01262146 0.01403038 0.03835386
 0.02131541 0.02482074 0.01646834 0.00939471 0.00792391 0.01011533
 0.01403038 0.01257998 0.01258001 0.01403035 0.02480343 0.00331457
 0.02482074 0.02482071 0.01403037 0.00792391 0.00272405 0.02482075
 0.02482075 0.02318052]
tr_loss:[0.02193641 0.02697476 0.02697474 0.00411283 0.02697474 0.02193643
 0.04288222 0.03327782 0.02193364 0.0269747  0.01887366 0.00805386
 0.00367327 0.01280974 0.01517288 0.02156058 0.01416096 0.0219364
 0.01436335 0.00805356 0.02122105 0.02697476 0.02697476 0.02673916
 0.02697476 0.02193643 0.01436421 0.02697474 0.01517285 0.01051708
 0.00411283 0.02697475 0.02697476 0.01517289 0.01517287 0.02697474
 0.01517288 0.02697478 0.02697477 0.02697476 0.01284083 0.01764655
 0.02696934 0.02193641 0.02697475 0.02689932 0.02697473 0.0224226
 0.02697477 0.02696853]
tr_loss:[0.01712719 0.02786678 0.02786679 0.02240844 0.01393528 0.02786669
 0.01841599 0.02769729 0.02151059 0.02786671 0.02786679 0.01841598
 0.02665055 0.02786678 0.02786677 0.02786675 0.106758   0.02786679
 0.0197438  0.02786689 0.01010413 0.01842873 0.02786679 0.02223355
 0.01352195 0.01841598 0.02786679 0.01010416 0.02786643 0.02786922
 0.01869796 0.02786668 0.01841597 0.01550386 0.02786678 0.02306822
 0.0278668  0.01841598 0.01712731 0.02240844 0.02786678 0.02774557
 0.00656459 0.0150793  0.02240845 0.02786676 0.02437108 0.02306823
 0.01352194 0.01695438]
tr_loss:[0.02605282 0.01396537 0.02605278 0.02605281 0.0260528  0.01097359
 0.02605282 0.01849415 0.02605281 0.02138173 0.02138174 0.02540868
 0.02605283 0.02138175 0.02138175 0.01097359 0.00691154 0.02605281
 0.02605282 0.02605282 0.02065585 0.02605282 0.0260528  0.02605282
 0.0260528  0.01849413 0.0260528  0.01849416 0.02605283 0.01097359
 0.01274646 0.02138175 0.02605282 0.02605281 0.01849413 0.03535007
 0.02138175 0.02605283 0.02605283 0.02138174 0.02605281 0.02138173
 0.01849414 0.01849413 0.02136591 0.02793451 0.02605284 0.04043908
 0.01849952 0.01812371]
tr_loss:[0.02247803 0.02247804 0.01655971 0.02247803 0.02247803 0.02247804
 0.01185885 0.01498718 0.02247803 0.01319002 0.02247804 0.02175898
 0.02247803 0.02247803 0.0224684  0.01828132 0.01828131 0.01498718
 0.00405957 0.00408857 0.02247803 0.01828132 0.022478   0.02243044
 0.01828133 0.02247803 0.02247802 0.02247803 0.00405652 0.01498719
 0.02247805 0.01498718 0.01098787 0.02065379 0.01498718 0.02247801
 0.01498733 0.01498718 0.02247804 0.01827971 0.01170591 0.02247801
 0.0163278  0.1011849  0.01828131 0.022478   0.01848009 0.02247801
 0.01319015 0.01656092]
tr_loss:[0.01253085 0.00495189 0.02132867 0.01633524 0.01364952 0.01252868
 0.02132866 0.00495186 0.00495092 0.01630968 0.01303175 0.00495189
 0.01157228 0.00343388 0.01252866 0.02132867 0.02132868 0.1000611
 0.01633656 0.02132868 0.01252867 0.02132866 0.02132868 0.02132868
 0.02132217 0.01827464 0.01633658 0.01633658 0.02132867 0.0136497
 0.02132867 0.01396612 0.02132868 0.01633656 0.02306603 0.027032
 0.01252867 0.01252868 0.00345917 0.01303175 0.02132868 0.01633659
 0.02137906 0.01252869 0.02132868 0.01567491 0.0213288  0.02132868
 0.01303971 0.01633654]
tr_loss:[0.01837356 0.01773292 0.0134508  0.01585451 0.02251212 0.02251213
 0.01589191 0.0156922  0.02251215 0.01773289 0.02251213 0.02251215
 0.02340349 0.01569222 0.02251214 0.02251213 0.02251215 0.02546779
 0.02251212 0.01287362 0.02251214 0.01569222 0.02251213 0.0156922
 0.02251213 0.00556567 0.02251213 0.00556533 0.02251214 0.02251211
 0.0156922  0.01200511 0.01200511 0.02194936 0.02251213 0.01681502
 0.02251213 0.02661759 0.01590346 0.02251214 0.01567937 0.01569221
 0.02251213 0.01808865 0.02251213 0.01200512 0.01681501 0.01569222
 0.02226678 0.02656407]
tr_loss:[0.01633582 0.02269107 0.02312054 0.00912339 0.0169843  0.00578544
 0.02481602 0.0239433  0.01367522 0.01760717 0.0045793  0.02312056
 0.01633582 0.01461495 0.02312055 0.0231207  0.01288791 0.01932853
 0.01288791 0.01550599 0.02312056 0.0169843  0.0226366  0.02186722
 0.02312054 0.01291627 0.02489934 0.01288791 0.02312057 0.00587358
 0.02312055 0.01288792 0.01633582 0.02186913 0.02312054 0.02597368
 0.00436396 0.01699427 0.00580456 0.01366091 0.00585258 0.01288792
 0.0163358  0.00436407 0.02312055 0.0045793  0.02489949 0.01367258
 0.02597403 0.02312058]
tr_loss:[0.01673109 0.01673111 0.0231475  0.02124701 0.02314752 0.01602321
 0.01602365 0.01256281 0.01673089 0.02412875 0.01602445 0.01405428
 0.02314751 0.01673112 0.02159765 0.02314748 0.01673112 0.0231475
 0.02412217 0.02372846 0.0231475  0.02124585 0.01955    0.0231475
 0.01407248 0.02314753 0.02314776 0.01602365 0.02314754 0.01958301
 0.02314751 0.02314751 0.00318893 0.02314751 0.02314747 0.01964711
 0.01934364 0.01673111 0.02314753 0.01668396 0.02190171 0.01673112
 0.02171713 0.01769539 0.02314747 0.01673109 0.01638234 0.02288279
 0.0231475  0.02370403]
tr_loss:[0.02256871 0.10922956 0.02256871 0.00304777 0.01704737 0.01754104
 0.01173712 0.01173679 0.0117368  0.01257918 0.01173679 0.01293168
 0.01704738 0.02256872 0.02256873 0.01360739 0.02256872 0.01967897
 0.01704738 0.02254585 0.01275868 0.01173687 0.10857315 0.01704738
 0.01704739 0.02256872 0.01704737 0.01173681 0.02256869 0.02256873
 0.01267471 0.0225687  0.01704738 0.0117401  0.02111331 0.00185608
 0.0117368  0.01812859 0.01704684 0.01751715 0.01972837 0.02256872
 0.02256872 0.01751717 0.01360739 0.02256871 0.0225687  0.00185608
 0.02256869 0.02256873]
tr_loss:[0.02248136 0.01627231 0.01766911 0.00955111 0.01887567 0.01417769
 0.00955109 0.01405228 0.01727671 0.02350928 0.02248135 0.0095511
 0.02248138 0.00138464 0.02243606 0.02248136 0.01627231 0.00182848
 0.02248136 0.01329995 0.01295775 0.01405272 0.01627231 0.02351018
 0.01236221 0.02248133 0.00955111 0.00184794 0.0095511  0.01627231
 0.00955111 0.02248134 0.0095511  0.02248135 0.0095511  0.01627231
 0.02248135 0.01627223 0.0095517  0.0095511  0.0095511  0.02248136
 0.02248135 0.02248135 0.00955109 0.01759595 0.10285743 0.00959443
 0.00305055 0.01232047]
tr_loss:[0.09487595 0.01225623 0.02381242 0.02381233 0.0031741  0.00883647
 0.0031741  0.02381231 0.00894692 0.00255755 0.02381233 0.0142361
 0.02381232 0.02393517 0.01864611 0.00883648 0.00962307 0.01975714
 0.01270304 0.02381232 0.02381233 0.01318462 0.01617454 0.02381232
 0.0162592  0.00883648 0.00883649 0.02381237 0.00883649 0.02381235
 0.01270304 0.00255749 0.01370057 0.01975466 0.00255755 0.02381233
 0.02381234 0.00883648 0.0088365  0.0131296  0.02381234 0.01349876
 0.02381233 0.00238956 0.01270304 0.00317414 0.02381234 0.01776518
 0.01625917 0.01246147]
tr_loss:[0.0239833  0.00394707 0.00967147 0.02384464 0.09250987 0.01324131
 0.01221081 0.02391244 0.0033686  0.01221081 0.00967145 0.00355027
 0.01221082 0.02391084 0.02391244 0.00967145 0.02391245 0.01635208
 0.02391244 0.02391244 0.02391244 0.02391243 0.01221081 0.01221082
 0.02391242 0.02391243 0.02391242 0.00967146 0.01635206 0.0170657
 0.00967146 0.01635206 0.02391245 0.09231647 0.02391244 0.01093257
 0.09250971 0.01221081 0.01208522 0.00967146 0.01706586 0.0239124
 0.01368351 0.01692472 0.02391243 0.02391245 0.01531469 0.02391244
 0.02391246 0.02391244]
tr_loss:[0.02256293 0.01715391 0.02256374 0.0113741  0.01595068 0.01067635
 0.02256379 0.01137408 0.02256374 0.01077128 0.01067625 0.01381125
 0.01524158 0.02256374 0.00435203 0.02256373 0.00435199 0.02256376
 0.03191482 0.02256376 0.02256277 0.01137409 0.0159507  0.01595044
 0.01583688 0.02256376 0.02256373 0.02256387 0.02256375 0.0153045
 0.0113741  0.01067636 0.09355451 0.02256375 0.01067791 0.02256374
 0.02256373 0.01137409 0.01507685 0.0113741  0.01806012 0.01067636
 0.01476662 0.02256363 0.01595068 0.01067636 0.01595068 0.01137408
 0.01805682 0.02214524]
tr_loss:[0.01397241 0.00414734 0.01528179 0.02154638 0.01806923 0.0093262
 0.02154639 0.01771927 0.02154639 0.01348786 0.09820631 0.02154639
 0.01528178 0.0215464  0.00932762 0.00932762 0.0215464  0.01573362
 0.01293265 0.02154637 0.00954494 0.00662121 0.02154639 0.00420202
 0.02154636 0.0104811  0.01528179 0.02992486 0.01348788 0.01528179
 0.02154638 0.00498275 0.01291227 0.01528179 0.0152818  0.01667294
 0.01528181 0.00932762 0.01348785 0.01396273 0.02079827 0.03118158
 0.01528178 0.0215464  0.02154639 0.0215464  0.03100038 0.02154618
 0.01528181 0.00931263]
text_input.shape
(3100, 14400)
learning_input_tmp.shape
(3100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3100, 80)
learning_output.shape
(750, 80)
Model: "sequential_64"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_64 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.6347824 1.6902282 1.5605555 1.5420253 1.6399091 1.5410278 1.6549435
 1.6512522 1.6085106 1.5419672 1.6852047 1.6902359 1.5651102 1.5420239
 1.6549435 1.6450665 1.4847553 1.5420234 1.6076053 1.5415244 1.6450169
 1.6076053 1.542037  1.6075974 1.6076053 1.5659188 1.6852047 1.6903579
 1.6931368 1.6549419 1.6549171 1.6394345 1.5420252 1.4826772 1.5420254
 1.607605  1.5420253 1.6076053 1.6852049 1.6857983 1.6852047 1.6380937
 1.5420281 1.6076053 1.5420253 1.542025  1.5420309 1.607605  1.6858909
 1.5679249]
tr_loss:[0.819435   0.7708541  0.79467595 0.7708541  0.7708541  0.82945347
 0.7746243  0.77085394 0.7708542  0.7833538  0.7902986  0.8176071
 0.79853266 0.7708541  0.82637805 0.7708541  0.7710694  0.7708492
 0.7708539  0.8384348  0.7708542  0.77085406 0.77085406 0.7708374
 0.8194315  0.7708541  0.7908168  0.7833538  0.7708539  0.79048526
 0.770854   0.79413927 0.7876859  0.7654267  0.7839159  0.7708541
 0.7708541  0.7608032  0.786916   0.7891343  0.77823895 0.79250777
 0.770854   0.79473716 0.77085286 0.7832991  0.770854   0.8194351
 0.79048526 0.790485  ]
tr_loss:[0.4612503  0.41590586 0.4310847  0.4391458  0.4340856  0.4342433
 0.43408555 0.4027807  0.4164362  0.4412035  0.41590586 0.4310847
 0.41506577 0.41590595 0.4340856  0.41469193 0.43408555 0.41590577
 0.41466814 0.4025728  0.42175037 0.41590586 0.41589803 0.41590586
 0.40255946 0.3978312  0.41464025 0.4159096  0.41590586 0.4340856
 0.3979711  0.39570418 0.41590586 0.43457928 0.41590595 0.41590586
 0.41558847 0.41466814 0.4159059  0.4310847  0.43108463 0.4159112
 0.43108463 0.41469306 0.41590595 0.43408567 0.41558868 0.41590947
 0.39891887 0.42133704]
tr_loss:[0.25218755 0.25218752 0.24482843 0.25218743 0.24406989 0.26347145
 0.24291742 0.24962687 0.25218752 0.26347142 0.24275371 0.2521875
 0.25218743 0.26657724 0.29136556 0.26258022 0.25218743 0.24482855
 0.2521875  0.2521875  0.26347142 0.2521875  0.2517294  0.2665754
 0.2521875  0.26347145 0.28272808 0.25166234 0.26347148 0.26720744
 0.29098755 0.29136586 0.24957395 0.26657724 0.2665773  0.26347142
 0.26662767 0.25620598 0.25218752 0.25845775 0.26678705 0.25218743
 0.2634713  0.25218746 0.24683256 0.26657718 0.25218743 0.2665773
 0.25198242 0.25218746]
tr_loss:[0.13556613 0.11788116 0.11719258 0.12110026 0.12987623 0.1171926
 0.13016735 0.13057044 0.11680897 0.12155726 0.11878245 0.13556609
 0.13057041 0.11719258 0.13016734 0.11719263 0.13057043 0.12155731
 0.13556615 0.1355661  0.13057037 0.11719255 0.11719259 0.11719258
 0.13057043 0.13057035 0.13057041 0.12154134 0.11712591 0.11613383
 0.12031947 0.11819468 0.1171926  0.1171926  0.11719258 0.21003683
 0.12979512 0.13556612 0.11719255 0.13016018 0.11613251 0.11719257
 0.11859717 0.11719257 0.11719255 0.12031958 0.15986323 0.11719255
 0.13057104 0.13556612]
tr_loss:[0.05456866 0.05674008 0.05379155 0.065385   0.08151197 0.05674006
 0.05758335 0.05674056 0.05103554 0.0709136  0.05674008 0.06538498
 0.05674006 0.05674008 0.05674007 0.05674027 0.05674006 0.08689682
 0.06538498 0.05455799 0.07091364 0.054558   0.05674008 0.06538498
 0.07091365 0.05674006 0.05368857 0.06538499 0.05247771 0.07091365
 0.07091364 0.05673812 0.06642364 0.06538496 0.05455724 0.06538497
 0.065385   0.07086186 0.05247797 0.05709381 0.05488142 0.0709136
 0.06846578 0.05455798 0.05523406 0.0709136  0.07229278 0.06821855
 0.06641555 0.065385  ]
tr_loss:[0.03710897 0.03710898 0.02463813 0.04050009 0.02735893 0.04186372
 0.03672167 0.03710899 0.04050009 0.04050009 0.03710898 0.03660155
 0.02688633 0.11689819 0.03268786 0.03268782 0.02814697 0.03710897
 0.04049909 0.04050011 0.04319193 0.02557674 0.02258343 0.04304047
 0.02463813 0.0405001  0.02652402 0.03710898 0.04191381 0.02801381
 0.03268785 0.04334687 0.03710898 0.0405001  0.037109   0.02815872
 0.03710897 0.02886572 0.03710902 0.03710901 0.03386771 0.02456522
 0.03710899 0.03710899 0.03710898 0.03710898 0.03710899 0.04138797
 0.02736413 0.02463813]
tr_loss:[0.02807123 0.0273731  0.02807122 0.01888276 0.0188734  0.02580504
 0.02807122 0.02749463 0.02807122 0.01889298 0.02771254 0.02807122
 0.03541731 0.02807123 0.02807126 0.09355119 0.02580504 0.02810023
 0.02934135 0.02807122 0.02807122 0.01965804 0.0206297  0.02807125
 0.02632616 0.02887082 0.0280717  0.02580506 0.02807122 0.02494874
 0.0188734  0.0188734  0.02807122 0.03664542 0.01325739 0.02576923
 0.01622357 0.02807124 0.02636622 0.02580505 0.01622357 0.02807123
 0.02807122 0.02807122 0.01622355 0.02807124 0.02580504 0.02807121
 0.02807122 0.02807123]
tr_loss:[0.02545558 0.01984885 0.0280307  0.02733545 0.02866082 0.03392427
 0.02545559 0.02871552 0.01612054 0.01613166 0.02545563 0.02803069
 0.03465434 0.02803033 0.02946193 0.02233823 0.02038588 0.01984707
 0.04795073 0.02803067 0.02545562 0.02803079 0.03466322 0.02803067
 0.02803067 0.02946194 0.02803044 0.01984708 0.03465433 0.02803067
 0.01984707 0.02803067 0.02803067 0.03784005 0.02803067 0.02803067
 0.02803164 0.02545559 0.02803067 0.02053284 0.02803068 0.01984708
 0.01984708 0.02803066 0.02545564 0.02791815 0.02803067 0.02765312
 0.0280307  0.02545561]
tr_loss:[0.02765718 0.02931216 0.02765717 0.02160387 0.02765718 0.02734628
 0.02833886 0.02160384 0.02765746 0.02765716 0.02765717 0.02160383
 0.05417795 0.10852478 0.02611009 0.02765717 0.02765613 0.02297239
 0.02160385 0.05426096 0.03752845 0.02765716 0.03236787 0.03125638
 0.01880736 0.01880738 0.03752629 0.02765705 0.02765718 0.02160403
 0.0295404  0.02765718 0.04010874 0.05415757 0.02308988 0.02765718
 0.02384567 0.02765717 0.0276572  0.02837851 0.03236787 0.02734628
 0.02765699 0.02765718 0.02765717 0.01856415 0.05639306 0.02837846
 0.02734628 0.02837848]
tr_loss:[0.02856964 0.04709533 0.02329528 0.02329528 0.01817963 0.02334295
 0.02334296 0.02329518 0.01349097 0.02334293 0.02334294 0.09177885
 0.02334294 0.01818578 0.02694355 0.02334294 0.02614553 0.02475681
 0.02694323 0.01817962 0.02334294 0.01817961 0.02329528 0.02334294
 0.02312022 0.02694355 0.02475682 0.0181796  0.09178286 0.01874122
 0.02335041 0.01817962 0.02334295 0.01399645 0.01759017 0.02334294
 0.03049075 0.02334296 0.02334294 0.02334293 0.01817962 0.1051385
 0.02694355 0.01817961 0.02694358 0.02125691 0.02329666 0.02334291
 0.02334295 0.01817958]
tr_loss:[0.02489073 0.02401051 0.02693087 0.01637699 0.03607436 0.01640827
 0.01637698 0.02401113 0.01091588 0.01810571 0.03595786 0.02163848
 0.0240105  0.02401051 0.02401051 0.0269309  0.0237818  0.02693092
 0.02389972 0.02693088 0.01494383 0.01637699 0.02401051 0.02401051
 0.02693088 0.0146822  0.02475213 0.02693088 0.01091589 0.0269309
 0.02492396 0.02401051 0.02401051 0.02693089 0.02401051 0.01637698
 0.02693088 0.0240105  0.01637698 0.01637697 0.02401051 0.01637697
 0.02401051 0.01810574 0.01091586 0.02401051 0.01494383 0.02401051
 0.02172535 0.01969754]
tr_loss:[0.02986472 0.0147035  0.01655915 0.02804521 0.02789729 0.01655915
 0.02919926 0.01655916 0.02901325 0.02777727 0.04108635 0.02901326
 0.02901325 0.02799385 0.02901325 0.01421328 0.02901326 0.01663001
 0.01655915 0.02901325 0.02061352 0.02901326 0.02901325 0.01655916
 0.02804522 0.02901324 0.02949373 0.01655915 0.02901326 0.02901324
 0.02901325 0.02901325 0.02804521 0.02901325 0.02901325 0.01913791
 0.01655913 0.01421351 0.02804521 0.02804521 0.01655915 0.02804521
 0.02901326 0.02901325 0.02804522 0.01162195 0.02901325 0.02061356
 0.01008423 0.0142135 ]
tr_loss:[0.01511428 0.01528705 0.02251487 0.0286708  0.00971796 0.01528719
 0.02867081 0.02955523 0.02867081 0.0270966  0.00971778 0.02680885
 0.02079641 0.0274145  0.02867081 0.015131   0.01528706 0.01827585
 0.02867081 0.0264348  0.01528704 0.02867079 0.01534283 0.02957319
 0.01508132 0.02867081 0.02867079 0.01528704 0.02867082 0.02867079
 0.02867091 0.0096429  0.015131   0.02867081 0.0286708  0.0312414
 0.01528705 0.02643479 0.01562847 0.0286708  0.02867079 0.02867081
 0.02930039 0.02867241 0.02867081 0.015131   0.02867081 0.02867079
 0.02167143 0.02838867]
tr_loss:[0.02441463 0.02411615 0.01487884 0.00749293 0.02500722 0.01645691
 0.02138591 0.02441465 0.02009225 0.02441466 0.02500721 0.02235549
 0.02441464 0.01487885 0.01646022 0.01487884 0.01487884 0.02441465
 0.02500721 0.02500721 0.02500722 0.0250071  0.02441464 0.02500721
 0.0246396  0.02441257 0.02500722 0.02441466 0.02500721 0.02136609
 0.01645694 0.02500721 0.01487885 0.02018675 0.02460895 0.02235546
 0.02359661 0.00871343 0.02500724 0.02500721 0.02441466 0.01487885
 0.02500721 0.02734456 0.02021948 0.0250072  0.02500721 0.02441465
 0.0250072  0.02500721]
tr_loss:[0.01951727 0.01622359 0.02440066 0.02383734 0.02440068 0.02008723
 0.02440066 0.09630521 0.01055034 0.02326035 0.02414076 0.02414034
 0.02414036 0.02440068 0.02414036 0.01670083 0.02414034 0.0196784
 0.0245112  0.02059964 0.01670084 0.01670083 0.02052169 0.02243416
 0.0195331  0.02414035 0.01670084 0.02414034 0.02414036 0.02490909
 0.01670082 0.02414036 0.03387736 0.02414035 0.01670084 0.02675729
 0.02512783 0.01945335 0.02414035 0.01670082 0.02414036 0.01670084
 0.02383736 0.02414214 0.01670084 0.02414036 0.02440066 0.0244007
 0.02440066 0.02414038]
tr_loss:[0.01911372 0.02510395 0.0158406  0.02510394 0.01768747 0.0158406
 0.02510394 0.02510395 0.02510394 0.02510395 0.01584077 0.02113112
 0.02518388 0.02510395 0.02510395 0.01999859 0.04194563 0.02347498
 0.03624744 0.02510393 0.02510395 0.01584061 0.02510395 0.02510394
 0.02347495 0.02510393 0.02510396 0.02295006 0.02346806 0.02347496
 0.02512882 0.10691504 0.02340411 0.02113111 0.02510394 0.02510394
 0.02510394 0.01043156 0.10691501 0.02113111 0.0158406  0.02678999
 0.04194565 0.01042925 0.02510396 0.02532352 0.02347497 0.02510394
 0.02526725 0.02511263]
tr_loss:[0.0254719  0.02547189 0.01343566 0.02183065 0.02547187 0.01446893
 0.02547187 0.02547188 0.02183067 0.01343565 0.01343564 0.02031898
 0.02547192 0.00881455 0.0254719  0.01350107 0.01343564 0.01343565
 0.03950528 0.02351814 0.0095865  0.02547187 0.02547188 0.01343566
 0.01417822 0.02289974 0.00881457 0.02561858 0.02547186 0.01343565
 0.02541343 0.01357441 0.02547187 0.02547191 0.02547186 0.03366609
 0.01343566 0.02547188 0.02704515 0.02547189 0.02547191 0.02547187
 0.02222312 0.02547197 0.02547188 0.02349637 0.0254719  0.0254719
 0.02052778 0.00890106]
tr_loss:[0.0112437  0.02496159 0.00876977 0.02068534 0.00981567 0.02496156
 0.02102046 0.0112437  0.02600457 0.0112437  0.02496156 0.02505865
 0.01893131 0.02496156 0.02431902 0.02600458 0.02102047 0.02442416
 0.02078982 0.0112437  0.01893131 0.02382788 0.02496082 0.02102047
 0.01124371 0.00728758 0.01893122 0.01243316 0.01124371 0.02496158
 0.01124371 0.01124371 0.02233229 0.0112437  0.0112437  0.02102047
 0.02496155 0.0244242  0.02496158 0.02233394 0.02496158 0.0249616
 0.02102048 0.03374494 0.01242695 0.03096607 0.02496156 0.02218616
 0.00728757 0.02496553]
tr_loss:[0.01158116 0.01340977 0.02258941 0.02537573 0.02348278 0.02537574
 0.02226145 0.0083417  0.02537575 0.02537572 0.02537573 0.02537572
 0.0220659  0.02341529 0.02577773 0.02537571 0.09778188 0.02537573
 0.01158117 0.02228545 0.02516716 0.01158117 0.0083417  0.02257273
 0.02258942 0.0176465  0.02537573 0.01158116 0.01158117 0.02537571
 0.0225894  0.0291215  0.02537574 0.02537572 0.02247119 0.02537574
 0.01158269 0.02537572 0.02258941 0.02181817 0.02537574 0.02537576
 0.02537573 0.00834171 0.02537571 0.02537572 0.02537573 0.02258941
 0.02537572 0.02537572]
tr_loss:[0.02472179 0.01299352 0.0247218  0.01299352 0.0247218  0.02291532
 0.02472152 0.01299353 0.01299351 0.01163057 0.02472179 0.02204515
 0.0170758  0.02489652 0.01299353 0.03011602 0.023674   0.02416733
 0.02472179 0.02416732 0.02472254 0.01701956 0.02472181 0.02478651
 0.0196027  0.02103106 0.01299353 0.01707534 0.10142156 0.02416733
 0.01866699 0.02472446 0.02472179 0.01299418 0.02472179 0.02416733
 0.02416733 0.0247218  0.02309692 0.0247218  0.01299353 0.01299353
 0.0247218  0.02309936 0.02335365 0.02929386 0.0247218  0.02480648
 0.02448433 0.02472179]
tr_loss:[0.01451068 0.02272603 0.02308953 0.01449907 0.02308952 0.02308987
 0.02308953 0.1004169  0.02383337 0.01997227 0.01345005 0.02165871
 0.02383255 0.10041691 0.02308954 0.02308953 0.00874407 0.02383336
 0.01627823 0.02308953 0.01997227 0.01627826 0.02852322 0.02752855
 0.03056849 0.0319991  0.01911104 0.02308954 0.01345003 0.01627826
 0.02308953 0.02308953 0.0194481  0.02308952 0.02431217 0.02272872
 0.02853772 0.02383335 0.00877447 0.02308954 0.01910805 0.02030725
 0.02308952 0.01345003 0.02308953 0.01627826 0.02308953 0.01345044
 0.02766439 0.02308953]
tr_loss:[0.01336445 0.00774999 0.01570216 0.03315756 0.02265653 0.02265653
 0.02265654 0.02265653 0.0088912  0.02265652 0.02285931 0.0228593
 0.02686207 0.02641244 0.01570216 0.0226572  0.02265653 0.02285931
 0.01828474 0.01559007 0.02686761 0.02285929 0.02265653 0.02114426
 0.02265652 0.02265652 0.01336445 0.02285929 0.02265653 0.02265653
 0.02114809 0.03457342 0.0228593  0.02285929 0.0228593  0.0228593
 0.02265651 0.01570216 0.00775306 0.02154005 0.02265653 0.01570025
 0.02265654 0.02114524 0.0331575  0.02125293 0.02265655 0.01570216
 0.02265653 0.02265653]
tr_loss:[0.02387116 0.00740312 0.02387117 0.02387118 0.01622662 0.0129549
 0.02387116 0.02387116 0.01295488 0.02387116 0.01796579 0.02387117
 0.02252197 0.02387116 0.02179643 0.02387116 0.02387116 0.01622662
 0.03355462 0.02206573 0.03502396 0.02347226 0.02387117 0.01622662
 0.02206545 0.01973016 0.0238761  0.01502464 0.01296058 0.02473726
 0.02387117 0.01622659 0.02387116 0.02387115 0.03457818 0.0179658
 0.0220657  0.02387128 0.02206572 0.02387116 0.02387115 0.0129549
 0.02206573 0.02149007 0.02206301 0.02387116 0.02387116 0.03502204
 0.0129549  0.02533551]
tr_loss:[0.01561269 0.01209172 0.02480834 0.02133884 0.01209172 0.00798623
 0.01561282 0.02124671 0.01563191 0.02480929 0.01209172 0.02111837
 0.01703265 0.01209172 0.02480856 0.02133881 0.01209172 0.02133884
 0.02480833 0.01209172 0.02480832 0.02480833 0.01209174 0.02480833
 0.01925992 0.01561285 0.02480836 0.02133883 0.01209204 0.03443835
 0.10151988 0.01209172 0.01209171 0.02262854 0.01353232 0.01700733
 0.02480833 0.02480833 0.02133882 0.02480834 0.02480832 0.02480833
 0.01209171 0.02480834 0.02655586 0.02637519 0.02480832 0.00706093
 0.01209171 0.02480834]
tr_loss:[0.02497564 0.01080083 0.02169791 0.01724743 0.02068077 0.01080084
 0.03487169 0.02497977 0.01080082 0.01929519 0.02497564 0.03117175
 0.00588472 0.02497564 0.01724726 0.02497563 0.0217126  0.02068077
 0.02171259 0.03240247 0.01080084 0.00587402 0.00783252 0.02068078
 0.02320902 0.00728412 0.02370941 0.02068079 0.02497564 0.02497565
 0.02497564 0.10022612 0.02497566 0.02169195 0.02072079 0.02068077
 0.02400669 0.02497565 0.01724833 0.03251808 0.03487116 0.01724744
 0.02302978 0.01080083 0.02068077 0.02169935 0.03268944 0.02497563
 0.02104245 0.02497565]
tr_loss:[0.02445505 0.02025121 0.02445503 0.02104868 0.02445503 0.02529706
 0.01652141 0.02072737 0.02072735 0.09985305 0.01019695 0.02445504
 0.01634968 0.02445503 0.02072731 0.02445504 0.02445504 0.01648991
 0.02072735 0.01019694 0.02072734 0.02445505 0.01019694 0.02445503
 0.02445491 0.0273821  0.02445505 0.02445506 0.02072736 0.02060034
 0.02445503 0.02445502 0.02072732 0.02023935 0.01649266 0.02445503
 0.01649003 0.00526821 0.02445981 0.02265128 0.02445504 0.01176237
 0.02445503 0.01648939 0.01648991 0.02445503 0.02445503 0.01019695
 0.02445503 0.02445503]
tr_loss:[0.02242363 0.0215138  0.0215138  0.01094346 0.02151382 0.02316707
 0.02316707 0.02317221 0.00627669 0.02316706 0.02151382 0.02151381
 0.09541949 0.01094345 0.01530814 0.00627666 0.01746118 0.02737908
 0.01453596 0.02287238 0.019219   0.02151381 0.02151344 0.02151381
 0.02316706 0.01567871 0.02316706 0.02316706 0.02376278 0.02151379
 0.01453596 0.02316707 0.02236097 0.01453596 0.01094346 0.02151381
 0.01912606 0.02316706 0.02135587 0.00830753 0.01282312 0.0306317
 0.02316707 0.0062782  0.01095098 0.01912209 0.02108788 0.00830714
 0.02151381 0.01094344]
tr_loss:[0.01354198 0.02247286 0.02288818 0.02253577 0.01354198 0.01559441
 0.02288815 0.02253576 0.01819342 0.02288815 0.01212795 0.02288815
 0.02288825 0.02829874 0.0103612  0.02288865 0.02288824 0.0276895
 0.01212795 0.01352541 0.02878574 0.01212794 0.02213033 0.1006645
 0.02253576 0.02288816 0.02333914 0.02288815 0.02288815 0.02288815
 0.02253577 0.02253575 0.01041233 0.01354202 0.0228882  0.0276916
 0.01845744 0.02288817 0.02292878 0.02288815 0.0225358  0.02253575
 0.02288816 0.02253568 0.02288815 0.02288816 0.02253577 0.02253577
 0.01212794 0.02312391]
tr_loss:[0.02202601 0.01361424 0.02238878 0.0223115  0.01869532 0.01176681
 0.02238871 0.01869783 0.02207666 0.02238879 0.02238833 0.02238878
 0.022026   0.01176681 0.02238877 0.02770744 0.01176685 0.02238878
 0.00867548 0.01371849 0.02201848 0.02238877 0.02238878 0.01361424
 0.02238877 0.02238877 0.0302536  0.02243735 0.00942045 0.02238877
 0.01483808 0.00867802 0.01189202 0.02238877 0.02927139 0.02056274
 0.01176681 0.01178193 0.02917243 0.022026   0.01201835 0.02238877
 0.00867599 0.00877035 0.02251909 0.02387863 0.02110195 0.02238877
 0.01571507 0.02238877]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3100 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3101, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3101 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3102, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3102 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3103, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3103 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3104, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3104 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3105, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3105 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3106, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3106 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3107, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3107 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3108, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3108 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3109, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3109 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3110, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3110 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3111, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3111 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3112, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3112 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3113, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3113 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3114, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3114 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3115, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3115 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3116, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3116 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3117, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3117 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3118, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3118 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3119, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3119 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3120, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3120 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3121, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3121 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3122, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3122 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3123, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3123 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3124, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3124 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3125, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3125 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3126, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3126 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3127, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3127 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3128, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3128 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3129, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3129 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3130, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3130 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3131, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3131 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3132, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3132 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3133, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3133 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3134, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3134 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3135, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3135 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3136, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3136 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3137, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3137 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3138, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3138 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3139, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3139 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3140, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3140 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3141, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3141 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3142, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3142 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3143, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3143 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3144, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3144 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3145, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3145 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3146, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3146 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3147, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3147 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3148, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3148 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3149, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3149 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3150, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3150 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3151, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3151 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3152, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3152 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3153, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3153 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3154, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3154 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3155, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3155 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3156, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3156 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3157, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3157 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3158, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3158 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3159, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3159 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3160, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3160 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3161, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3161 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3162, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3162 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3163, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3163 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3164, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3164 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3165, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3165 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3166, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3166 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3167, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3167 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3168, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3168 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3169, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3169 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3170, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3170 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3171, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3171 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3172, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3172 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3173, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3173 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3174, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3174 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3175, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3175 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3176, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3176 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3177, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3177 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3178, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3178 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3179, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3179 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3180, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3180 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3181, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3181 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3182, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3182 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3183, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3183 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3184, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3184 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3185, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3185 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3186, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3186 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3187, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3187 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3188, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3188 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3189, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3189 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3190, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3190 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3191, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3191 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3192, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3192 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3193, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3193 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3194, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3194 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3195, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3195 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3196, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3196 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3197, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3197 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3198, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3198 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3199, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3199 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3200, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-3100
text_input.shape
(3200, 14400)
learning_input_tmp.shape
(3200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3200, 80)
learning_output.shape
(750, 80)
Model: "sequential_65"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_65 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2338803 1.2191819 1.2668191 1.1544156 1.1314939 1.2338859 1.1587546
 1.2125889 1.1314938 1.1445249 1.2125905 1.2336674 1.212589  1.1544156
 1.1314939 1.2218097 1.1314939 1.2657969 1.2338881 1.212589  1.212589
 1.1314929 1.230185  1.2142179 1.2343293 1.2656577 1.2145936 1.1544156
 1.2357275 1.1314938 1.2338775 1.2169508 1.1315296 1.2300717 1.2343295
 1.1537136 1.1544157 1.212589  1.1314939 1.2126734 1.2182581 1.1653521
 1.2338899 1.2293061 1.1544156 1.2656578 1.1286752 1.1566713 1.1315566
 1.212589 ]
tr_loss:[0.76186913 0.76217777 0.7618692  0.78974736 0.74313504 0.8048854
 0.7333131  0.7333132  0.7663749  0.76186913 0.76186913 0.7582024
 0.76637477 0.7582023  0.7618692  0.76186913 0.7333132  0.797444
 0.76194143 0.7613863  0.7618692  0.7618691  0.74722975 0.7942198
 0.76186913 0.76186913 0.7663749  0.736303   0.7472299  0.7472297
 0.7610563  0.7618698  0.76186925 0.76186913 0.7281872  0.733313
 0.75830853 0.7907935  0.733313   0.7618554  0.7333129  0.7581645
 0.7618691  0.7257264  0.73303616 0.76186925 0.7663747  0.7472297
 0.733313   0.76186913]
tr_loss:[0.37168905 0.36908776 0.37085232 0.37168902 0.4141888  0.414246
 0.3459264  0.3461156  0.37168905 0.37085232 0.4195063  0.3708524
 0.3708524  0.39008707 0.37168893 0.35555026 0.38990226 0.36591113
 0.3900868  0.37085235 0.39008898 0.41615105 0.37168902 0.41671866
 0.37168905 0.37168905 0.37168905 0.3461156  0.37168905 0.37168908
 0.39023376 0.3732624  0.39008698 0.37168905 0.41418886 0.41954452
 0.41856107 0.37326258 0.3708524  0.37168902 0.34611565 0.34611553
 0.3461156  0.3900986  0.371689   0.37168914 0.37168902 0.37168905
 0.3900871  0.35000658]
tr_loss:[0.1603308  0.15070865 0.15634422 0.16190884 0.16033074 0.1507087
 0.18764283 0.17373368 0.17373371 0.19278601 0.1603307  0.15070865
 0.16033116 0.17649949 0.19201231 0.19241107 0.17373377 0.15070868
 0.16033077 0.1603308  0.17571151 0.18695612 0.16033079 0.18710434
 0.1507087  0.16033077 0.16033076 0.18826273 0.19282635 0.17523882
 0.17373374 0.16033074 0.15466905 0.18304381 0.16033077 0.18694887
 0.16033077 0.17373374 0.16033082 0.15070838 0.19241151 0.16033073
 0.14952658 0.16046837 0.19241102 0.16033076 0.1507087  0.19278598
 0.18591833 0.18694858]
tr_loss:[0.06826504 0.06826504 0.06286529 0.06389626 0.06389624 0.06826504
 0.0585058  0.07042094 0.07042091 0.05236097 0.05853543 0.07191631
 0.06826507 0.06469587 0.09057637 0.06826508 0.07137527 0.06286527
 0.05236385 0.07137479 0.06389625 0.06826507 0.0628653  0.06286529
 0.07042173 0.06286529 0.06826504 0.06471358 0.05236098 0.0682651
 0.081277   0.06826506 0.05236097 0.06286526 0.06826504 0.06826507
 0.07103361 0.06826507 0.05236082 0.06984015 0.05797045 0.06824173
 0.052361   0.0704209  0.06249614 0.05236097 0.07191598 0.06389623
 0.06370255 0.06435858]
tr_loss:[0.04796223 0.03613369 0.04796223 0.04137924 0.02904618 0.04796223
 0.02972422 0.02904613 0.04796223 0.02904637 0.03613368 0.04137918
 0.02904617 0.04137952 0.05667026 0.04796226 0.04020729 0.04796226
 0.02933536 0.04137935 0.04780464 0.04796232 0.04736568 0.03191452
 0.04858301 0.04137922 0.04796224 0.03673162 0.04796226 0.04796225
 0.04137921 0.04796223 0.04137925 0.04137922 0.04137924 0.02902811
 0.02972263 0.02944944 0.03310227 0.04796223 0.01528255 0.04796222
 0.0294647  0.0473656  0.01518775 0.04137921 0.04796226 0.05630606
 0.02972263 0.04796225]
tr_loss:[0.03958644 0.01511809 0.01427524 0.01427522 0.04192906 0.01022466
 0.01427525 0.03958645 0.04020116 0.02437919 0.02109225 0.03958647
 0.04218997 0.03958647 0.03958644 0.03958648 0.03958645 0.0243792
 0.03958645 0.03191809 0.0288528  0.03958644 0.02884938 0.02028967
 0.03663919 0.02437919 0.02437919 0.03958647 0.02109166 0.02884934
 0.01512454 0.03958647 0.03958645 0.0151181  0.0165038  0.03958644
 0.041183   0.01022465 0.01678195 0.02884935 0.0243792  0.01022465
 0.02107432 0.04214931 0.03958639 0.03827419 0.01022466 0.01022465
 0.03815892 0.01022466]
tr_loss:[0.02256976 0.04068279 0.03612192 0.02497676 0.01812082 0.02497543
 0.0361219  0.03824103 0.01632809 0.03612191 0.03012675 0.04316431
 0.03612191 0.01478237 0.03612191 0.01576716 0.01632809 0.03612189
 0.03612191 0.01478166 0.02340351 0.03650414 0.03612191 0.01577456
 0.03612177 0.03612193 0.03612192 0.02911273 0.02273558 0.02273559
 0.02273559 0.03612161 0.02340353 0.03612191 0.03587802 0.03612193
 0.02531188 0.03612189 0.02273559 0.01632439 0.0227356  0.01632811
 0.02329667 0.01632809 0.03612191 0.01482767 0.02273558 0.04069953
 0.03612191 0.03549387]
tr_loss:[0.03966279 0.03966277 0.02529579 0.0396628  0.03966275 0.03966218
 0.03966279 0.01724628 0.01724629 0.03966277 0.02604176 0.03964952
 0.02590166 0.0238605  0.02386051 0.02386051 0.03966281 0.03966281
 0.03966278 0.0396628  0.03966279 0.03966274 0.03360072 0.03887703
 0.03966281 0.03839618 0.03112329 0.03966276 0.03966279 0.03966279
 0.04504297 0.02392241 0.01724628 0.0238605  0.04045031 0.03074043
 0.03966277 0.04045033 0.03966277 0.02120186 0.03966277 0.01673691
 0.02120193 0.0238605  0.03966278 0.0193956  0.03966276 0.02115503
 0.01449234 0.03966263]
tr_loss:[0.04119253 0.0181876  0.02585464 0.02705384 0.04119251 0.04119257
 0.0190229  0.02585465 0.04119254 0.02585465 0.02585465 0.02585465
 0.02585466 0.04119256 0.04119254 0.03810699 0.01903317 0.02585466
 0.04119254 0.04572389 0.04119253 0.02585465 0.03437437 0.03811391
 0.04119253 0.04042275 0.02440109 0.04119256 0.02796659 0.02796659
 0.04096519 0.04119252 0.01599422 0.02796658 0.01903204 0.04119252
 0.04119254 0.04119255 0.02668307 0.04119083 0.02796658 0.04119252
 0.02585464 0.04119254 0.01599598 0.02585468 0.02739797 0.01903353
 0.02716337 0.02585465]
tr_loss:[0.03852826 0.03852827 0.03852825 0.03852826 0.03852826 0.03852824
 0.0250533  0.0386738  0.03852826 0.03867915 0.02212576 0.03177831
 0.03177828 0.0164843  0.01649379 0.03852824 0.02446614 0.03852827
 0.0310628  0.03852825 0.03177831 0.03852412 0.03846828 0.01437782
 0.01657603 0.02163194 0.01437793 0.02450938 0.01649396 0.03177828
 0.03852826 0.01437793 0.02212576 0.03852825 0.03849529 0.03546246
 0.03535112 0.03177828 0.03852825 0.02212577 0.03852822 0.03699499
 0.0242369  0.02450937 0.03177828 0.02212576 0.03852045 0.01649378
 0.03557293 0.02450937]
tr_loss:[0.01534294 0.02938824 0.015405   0.02196848 0.02938827 0.01732796
 0.01732802 0.01559103 0.02938252 0.0286534  0.02938827 0.03306242
 0.02934489 0.02938828 0.02938826 0.01546929 0.01732801 0.02592999
 0.02196852 0.02938826 0.02474466 0.02938825 0.02580836 0.02865339
 0.0247447  0.03388029 0.02938825 0.03029374 0.03029327 0.02938826
 0.01656006 0.02196848 0.01559102 0.02938825 0.02348329 0.02938828
 0.02975097 0.02938824 0.0170661  0.02139813 0.02196848 0.01534289
 0.02945526 0.02938827 0.02938828 0.01732802 0.02196959 0.02938825
 0.03062074 0.01723414]
tr_loss:[0.0131786  0.02430407 0.02430408 0.02310589 0.02430407 0.01317381
 0.01194173 0.02425946 0.02425947 0.01317382 0.01317381 0.02430406
 0.02425947 0.03453119 0.02430406 0.00983873 0.02845433 0.01813136
 0.02445721 0.02430407 0.01927222 0.01315237 0.01813135 0.02103692
 0.01317381 0.01813135 0.0166266  0.01788135 0.02087863 0.02087931
 0.02372414 0.02430408 0.01813113 0.02085928 0.02425947 0.02430406
 0.02430408 0.02430408 0.02430406 0.01194221 0.02425946 0.01317268
 0.01053514 0.02427123 0.02430407 0.02430407 0.01813135 0.02430409
 0.02430408 0.01813134]
tr_loss:[0.01769211 0.0176921  0.01587473 0.02627135 0.03235324 0.0258458
 0.02584577 0.00848769 0.02584575 0.01680195 0.01606847 0.0217802
 0.02584575 0.02412192 0.00858438 0.01680016 0.02627136 0.02584578
 0.02412191 0.02584577 0.01941445 0.01680017 0.02584577 0.00858506
 0.02584577 0.02178022 0.0176921  0.00858504 0.02567975 0.02584576
 0.02584578 0.02627134 0.02568237 0.01941522 0.02584575 0.02412192
 0.03239804 0.01769207 0.02584577 0.02584578 0.02584576 0.01272513
 0.03242549 0.02584576 0.02584584 0.02584577 0.01077181 0.01606847
 0.02627134 0.01063187]
tr_loss:[0.02272752 0.00476154 0.02664084 0.02370201 0.00476279 0.023702
 0.02008336 0.02273197 0.00476153 0.02664793 0.01339277 0.00476153
 0.02370201 0.02272754 0.02272753 0.02664084 0.011183   0.00486528
 0.02664084 0.02226405 0.02272753 0.02664087 0.02402127 0.02272752
 0.01981625 0.02008336 0.02272754 0.02664079 0.00901794 0.02272754
 0.01457432 0.02272753 0.02272752 0.023702   0.01031589 0.02370198
 0.02773613 0.01335559 0.02664083 0.00475833 0.02664083 0.02664082
 0.01346617 0.00478727 0.02662082 0.0047637  0.00476155 0.02664086
 0.00476154 0.02664085]
tr_loss:[0.0194975  0.00890283 0.00520921 0.01902626 0.0251575  0.02092652
 0.02515745 0.0187332  0.02515751 0.02515746 0.02515748 0.02023095
 0.02515748 0.02515747 0.00890325 0.02143596 0.01902625 0.00520917
 0.01902626 0.01774234 0.02143502 0.02515746 0.02092652 0.02144036
 0.00531536 0.00853524 0.00581119 0.02515746 0.00520918 0.02497629
 0.02515747 0.01902626 0.00526929 0.02516352 0.02515746 0.02515745
 0.02515748 0.02515748 0.00796734 0.02085674 0.00520918 0.01906567
 0.02515745 0.00877734 0.02143592 0.02515746 0.01949757 0.02061844
 0.01902625 0.02515749]
tr_loss:[0.02250052 0.01856678 0.02562489 0.02562488 0.01856679 0.0256249
 0.02132308 0.0185668  0.02562487 0.02702287 0.02132306 0.01856682
 0.00867232 0.00967968 0.00867233 0.02562488 0.01856679 0.02562486
 0.00967969 0.01986671 0.02562486 0.00967968 0.02562489 0.0185668
 0.02562483 0.00994451 0.01856679 0.02562486 0.02562488 0.02346913
 0.01856681 0.01643844 0.01856682 0.02132307 0.02562487 0.0185668
 0.02132307 0.02562487 0.0225006  0.02562487 0.0256249  0.00867213
 0.00728045 0.02702757 0.02562488 0.00784799 0.02562486 0.00866333
 0.01643842 0.02562486]
tr_loss:[0.02139152 0.00534477 0.01787876 0.02147108 0.02147108 0.02147154
 0.02494583 0.02147109 0.01787877 0.01495773 0.02147108 0.01813532
 0.0214711  0.02494581 0.01495784 0.02496046 0.02147108 0.00534325
 0.00534476 0.00534467 0.01787877 0.01816458 0.01495772 0.01502516
 0.0214711  0.01787876 0.0053644  0.01787875 0.00567379 0.02494581
 0.02147109 0.01626047 0.02144962 0.01495774 0.02633212 0.00799806
 0.02147106 0.01495772 0.00534476 0.02440688 0.0214711  0.0149577
 0.02147108 0.01495771 0.00567379 0.02147108 0.02139152 0.01495772
 0.01495771 0.01495772]
tr_loss:[0.01797888 0.0179789  0.02232388 0.01539739 0.01924836 0.01539739
 0.01259229 0.01923866 0.01797889 0.0179789  0.01535534 0.01259227
 0.00345879 0.0179789  0.01291049 0.00602306 0.00602283 0.0179789
 0.01797888 0.02001441 0.01924833 0.01797892 0.01390397 0.00345812
 0.01797891 0.0179789  0.0179789  0.00602988 0.0179789  0.01676979
 0.00345878 0.00345877 0.01259229 0.0125923  0.00345878 0.01535534
 0.00345873 0.00603302 0.01797891 0.0153974  0.00587829 0.0179789
 0.01679786 0.00602306 0.01833979 0.0179789  0.01539738 0.01539739
 0.01539739 0.00345879]
tr_loss:[0.01561473 0.00644028 0.01561691 0.01535019 0.01812977 0.0190284
 0.00882133 0.0190284  0.01812977 0.01561473 0.00609528 0.01902839
 0.01902841 0.01561474 0.02266454 0.01781096 0.01902778 0.01561473
 0.01522302 0.01812977 0.01796728 0.01561473 0.01881559 0.01902839
 0.01881581 0.0225112  0.00890528 0.01781102 0.01781098 0.0190284
 0.0190284  0.01142038 0.01902842 0.01561474 0.00861886 0.01561472
 0.01561474 0.01902842 0.01561474 0.01407567 0.01561474 0.0190284
 0.01142044 0.00644103 0.01902841 0.0190284  0.01902839 0.01902839
 0.01902838 0.0190284 ]
tr_loss:[0.01682054 0.01381811 0.01947176 0.01667758 0.0212352  0.01947176
 0.00888308 0.01947176 0.0188104  0.01490656 0.01947175 0.01947176
 0.01947175 0.01947176 0.01881151 0.01068111 0.01703614 0.01675585
 0.01947175 0.01947175 0.02841802 0.01881151 0.01668097 0.01881151
 0.02730768 0.01682504 0.01947175 0.01675583 0.01947174 0.01947176
 0.01682029 0.02001322 0.01881151 0.01881152 0.01682029 0.00888095
 0.02386876 0.0188085  0.01682029 0.01947176 0.01947176 0.01947175
 0.01382122 0.01947174 0.01682029 0.02842742 0.01682029 0.01947176
 0.01881151 0.0168542 ]
tr_loss:[0.01915046 0.01882908 0.01882884 0.01882906 0.01882486 0.01193499
 0.01479441 0.01882907 0.01479441 0.01882906 0.00869922 0.01882907
 0.01852341 0.01882798 0.01881023 0.01882908 0.01882906 0.01882908
 0.02213531 0.02541727 0.01882909 0.02012137 0.0147944  0.00907916
 0.01365278 0.00910236 0.00871256 0.01882907 0.00877094 0.01531808
 0.0176389  0.01882907 0.0091051  0.00910235 0.01882905 0.02213536
 0.01915045 0.02474691 0.01479441 0.00869923 0.019021   0.00917357
 0.01812371 0.01882907 0.01882907 0.01882907 0.00810644 0.01882907
 0.00910318 0.01479494]
tr_loss:[0.01736375 0.01867887 0.01736375 0.01736375 0.0125228  0.01736374
 0.01736374 0.01736375 0.01789407 0.01175045 0.01736376 0.01235133
 0.0131922  0.01235133 0.01736374 0.01951711 0.01736373 0.01736373
 0.00868711 0.01789407 0.00784646 0.01235133 0.01736375 0.00748897
 0.01315188 0.01736374 0.01736374 0.0099389  0.01736376 0.01736373
 0.01182761 0.01736375 0.01736375 0.01735669 0.00748889 0.01736375
 0.01235132 0.01346131 0.00868714 0.0086871  0.01338908 0.01182057
 0.01179085 0.01736376 0.01736376 0.01735799 0.01736376 0.00868711
 0.01736374 0.01319173]
tr_loss:[0.00685098 0.016168   0.00685098 0.01055231 0.01616683 0.00685099
 0.01017668 0.01616681 0.01616682 0.02168122 0.01616681 0.01616682
 0.01042104 0.01614977 0.01102607 0.01825181 0.00597188 0.00682413
 0.0171196  0.01234884 0.01711959 0.01042104 0.01636215 0.0171196
 0.01616681 0.00685099 0.01616681 0.00685099 0.01711961 0.00743193
 0.01102593 0.01450708 0.01616682 0.02186157 0.01636288 0.01102608
 0.00796389 0.00626543 0.0161668  0.01895846 0.01474417 0.02168121
 0.00685099 0.01042102 0.00724915 0.01616679 0.01616682 0.01616687
 0.01449072 0.01042104]
tr_loss:[0.01030184 0.01658624 0.00600606 0.0217002  0.01674585 0.0217002
 0.0168739  0.01674584 0.00605378 0.00600421 0.01674585 0.0217002
 0.01674585 0.00600527 0.01674587 0.01025483 0.01687389 0.02169997
 0.01440619 0.01025485 0.01674584 0.0217002  0.00600492 0.00605378
 0.0102557  0.01674585 0.0109926  0.01674584 0.0115139  0.01025485
 0.01771145 0.01687391 0.00600493 0.005949   0.01674584 0.01674586
 0.01674586 0.00605369 0.01674587 0.0217002  0.01829318 0.01025484
 0.00605377 0.01631939 0.00605377 0.01899652 0.0060486  0.0217002
 0.01674586 0.00605375]
tr_loss:[0.00412527 0.01659708 0.01659708 0.01787614 0.01178762 0.01168143
 0.01261057 0.01659708 0.01787615 0.01167385 0.01758406 0.01641453
 0.01167386 0.01491585 0.01787614 0.01582162 0.01167385 0.01787616
 0.01787613 0.01788201 0.01795022 0.01178805 0.00419101 0.01792528
 0.01787854 0.01042809 0.01758452 0.00408106 0.01787616 0.00362742
 0.01700718 0.01742777 0.01939922 0.017876   0.00419101 0.00362741
 0.0040621  0.01167385 0.00419101 0.00373424 0.0161176  0.01149013
 0.01755252 0.004191   0.01631272 0.01788033 0.00419101 0.01167384
 0.00406224 0.00419101]
tr_loss:[0.01866652 0.0172829  0.01654741 0.01056897 0.01855283 0.01654742
 0.01728271 0.01297869 0.00248455 0.01728264 0.0024848  0.00290413
 0.01297897 0.01654742 0.00290108 0.01654742 0.01654742 0.00248455
 0.01378916 0.01178511 0.01297869 0.01360221 0.01297868 0.01728264
 0.01067899 0.01743668 0.01290976 0.01297868 0.00248458 0.00248455
 0.00251471 0.01381005 0.0024805  0.00213209 0.0139118  0.01378917
 0.012046   0.01728264 0.00290413 0.00290414 0.01712637 0.00290414
 0.0165474  0.01728265 0.01728262 0.01728265 0.01378918 0.012707
 0.0165474  0.0173446 ]
tr_loss:[0.00238446 0.01796418 0.01796418 0.00866994 0.01796419 0.00419627
 0.0179642  0.01616451 0.00238425 0.0161645  0.00238648 0.00865081
 0.00865079 0.00963332 0.01796419 0.00419622 0.01159686 0.01796418
 0.01899792 0.02011252 0.01796418 0.0173141  0.01796418 0.01073027
 0.01796419 0.01232873 0.00419626 0.01796418 0.01099682 0.01796419
 0.01616451 0.00963019 0.01796424 0.00238595 0.01796421 0.01893088
 0.01931012 0.00419678 0.00419626 0.01796419 0.0161645  0.0179642
 0.01796419 0.00957733 0.00238425 0.01616451 0.00415683 0.01796419
 0.01711897 0.01796421]
tr_loss:[0.00887654 0.01850449 0.01771634 0.0173599  0.02293897 0.01771633
 0.01846972 0.01735991 0.02212644 0.00879444 0.01689145 0.01105029
 0.0177225  0.01771632 0.00468489 0.01771628 0.01771631 0.02191331
 0.00413469 0.0173599  0.01735989 0.01689145 0.01735988 0.00470852
 0.01105029 0.01105029 0.01689144 0.01771631 0.01689152 0.00467634
 0.01333234 0.01689146 0.01735989 0.01689143 0.01771634 0.00413475
 0.01105029 0.01689144 0.01104956 0.01689146 0.00305537 0.0110506
 0.0177163  0.01771632 0.01689144 0.01771632 0.0232429  0.01771632
 0.01771632 0.00468293]
tr_loss:[0.01024874 0.01588253 0.01024999 0.01588252 0.01477353 0.01232494
 0.00345326 0.00915853 0.01204124 0.0087755  0.00339877 0.01588253
 0.01425162 0.01631906 0.01588253 0.01477352 0.0158825  0.01025001
 0.01588253 0.0034379  0.01588299 0.01588251 0.01588254 0.01588254
 0.01477352 0.01587696 0.01588253 0.01588253 0.01560853 0.01605316
 0.00339877 0.02270238 0.01588253 0.0147735  0.01588254 0.01588253
 0.01203668 0.01588253 0.00344525 0.01024999 0.00339873 0.00877548
 0.0172484  0.00877385 0.01588253 0.00344526 0.00339876 0.01686113
 0.01167399 0.00343788]
text_input.shape
(3200, 14400)
learning_input_tmp.shape
(3200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3200, 80)
learning_output.shape
(750, 80)
Model: "sequential_66"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_66 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4216608 1.4216607 1.4216607 1.4561363 1.4216607 1.4216759 1.4561362
 1.4216528 1.4593017 1.4570472 1.4969003 1.4216607 1.4561357 1.4561362
 1.4629252 1.4216654 1.4214373 1.4561363 1.4220649 1.4629265 1.4561363
 1.4593017 1.5129156 1.4545597 1.4961361 1.4261619 1.4136375 1.4631326
 1.4829285 1.4961655 1.4216607 1.496186  1.4561362 1.4265888 1.4216734
 1.4299774 1.4299777 1.4593017 1.4796623 1.4216607 1.4216608 1.4928151
 1.4629252 1.4216607 1.5129086 1.4561361 1.4629252 1.4629252 1.4216607
 1.4961771]
tr_loss:[0.79312503 0.7967761  0.77733845 0.7475826  0.7967761  0.74758244
 0.75425196 0.7475825  0.74758255 0.7967761  0.764842   0.74758255
 0.7885502  0.7844316  0.7475084  0.77520424 0.7542734  0.7475791
 0.75986844 0.7967761  0.77827626 0.74758244 0.7475825  0.7468193
 0.7591394  0.75985944 0.7475824  0.75986993 0.7684291  0.7783251
 0.74758255 0.7509123  0.74758255 0.74757993 0.7967761  0.7564163
 0.7542521  0.75610447 0.817582   0.7763974  0.7659062  0.7475825
 0.7675545  0.76484203 0.74758255 0.74758255 0.7475826  0.762632
 0.74758255 0.7475825 ]
tr_loss:[0.35544738 0.35528654 0.356042   0.35604137 0.35603362 0.34082493
 0.35604134 0.35290608 0.34082532 0.3830242  0.3514672  0.34120616
 0.3560349  0.34082532 0.3516017  0.34210095 0.35224396 0.35290602
 0.35807484 0.34955662 0.36887807 0.3560415  0.3640731  0.34722248
 0.35290605 0.35290605 0.36895946 0.36407143 0.3560413  0.35218403
 0.35604134 0.34722298 0.3560434  0.34107596 0.35528117 0.34082532
 0.3643853  0.36422586 0.36496753 0.35160202 0.356042   0.35290608
 0.35604137 0.35604134 0.3560413  0.34967005 0.35533804 0.35604137
 0.36071688 0.34762487]
tr_loss:[0.15384379 0.14221403 0.13379201 0.16886151 0.16886148 0.16886146
 0.1422194  0.1412219  0.16886154 0.1538442  0.14218226 0.16428852
 0.16886148 0.1538438  0.14221457 0.16886151 0.12848821 0.16886154
 0.15582809 0.15384386 0.15684655 0.16886155 0.15684593 0.12848768
 0.14221409 0.15684006 0.16886151 0.15257967 0.15385874 0.13910365
 0.16886151 0.16886151 0.16886151 0.14448252 0.16020724 0.1602073
 0.15006198 0.1528049  0.141221   0.12848738 0.14223032 0.16886146
 0.16886148 0.16886154 0.12847582 0.16883442 0.12848763 0.16886154
 0.1602073  0.15684673]
tr_loss:[0.07166485 0.07628517 0.07120659 0.08380885 0.08380885 0.08380885
 0.07166488 0.05237187 0.08380883 0.07560264 0.07694392 0.06393035
 0.08490577 0.07628515 0.07628516 0.08380882 0.06202079 0.07387915
 0.07166485 0.08380886 0.07628517 0.07566952 0.07008173 0.07170363
 0.0523719  0.06190516 0.05237255 0.07118353 0.08380882 0.07387916
 0.06205517 0.07387914 0.08380887 0.08380885 0.07753315 0.05237188
 0.06444613 0.07387915 0.0716649  0.08380889 0.07714017 0.06205398
 0.07628518 0.0838085  0.08380888 0.06190516 0.07628515 0.07287835
 0.05237272 0.07166488]
tr_loss:[0.0621266  0.06212659 0.04225797 0.06212656 0.03726359 0.03724966
 0.06212654 0.02960585 0.06212659 0.0382319  0.03303654 0.04225798
 0.03823305 0.02601635 0.03303621 0.03851135 0.06212664 0.03057721
 0.06212658 0.03012831 0.04842758 0.0621266  0.06212668 0.04644081
 0.06212658 0.06212527 0.03974    0.02960585 0.06212663 0.02618831
 0.04225797 0.04948461 0.02958965 0.04225798 0.06212661 0.04225799
 0.0382319  0.06212663 0.03823189 0.06212663 0.03824908 0.02618834
 0.03230305 0.03541057 0.02618833 0.06212661 0.06212657 0.02618832
 0.02693557 0.06212655]
tr_loss:[0.02016612 0.04248966 0.01915157 0.01799625 0.04964455 0.04322318
 0.04964459 0.04964457 0.04964454 0.03857228 0.04964454 0.02443809
 0.04964454 0.04964456 0.03125905 0.02454708 0.04964457 0.04964456
 0.03857226 0.04964917 0.04964457 0.03857232 0.0186491  0.01434248
 0.02678557 0.02500146 0.01800505 0.03125905 0.04964454 0.01768959
 0.02443805 0.01800505 0.03125904 0.03857227 0.04964457 0.02639728
 0.02131361 0.04875598 0.01769059 0.04964456 0.01800505 0.01846399
 0.01800506 0.04964451 0.04964456 0.04964456 0.04964458 0.04968567
 0.03125904 0.01800507]
tr_loss:[0.02197957 0.04341988 0.03804046 0.02598595 0.05028423 0.04341989
 0.04248644 0.04341989 0.04248586 0.04341989 0.04936171 0.04341991
 0.03206794 0.03206793 0.03206794 0.04248583 0.03133425 0.04248586
 0.04248583 0.04936171 0.03804062 0.04341989 0.02953119 0.04248584
 0.04341989 0.04248586 0.03973938 0.04341989 0.04341991 0.04264773
 0.04341992 0.0542566  0.02605559 0.03206794 0.04255673 0.04341988
 0.04248615 0.04936174 0.04248585 0.0434199  0.04341988 0.04341992
 0.04248584 0.04341989 0.03134271 0.04341986 0.04341994 0.04341991
 0.04341992 0.04936174]
tr_loss:[0.02090039 0.02393881 0.0378851  0.02393757 0.02047025 0.02050913
 0.03788511 0.03605875 0.01789868 0.03788508 0.03699834 0.03740111
 0.03738781 0.03788511 0.0378851  0.03788508 0.03788508 0.03465638
 0.02159731 0.03013487 0.02157187 0.03699836 0.03213581 0.02047016
 0.03544682 0.03788523 0.02406439 0.01927834 0.0378851  0.03788508
 0.0239377  0.02047015 0.02047016 0.02393758 0.03465637 0.04095223
 0.02047017 0.03465659 0.03995423 0.02142153 0.02484703 0.03788509
 0.037887   0.03788511 0.03788509 0.02484393 0.03738774 0.03465638
 0.03302374 0.02792856]
tr_loss:[0.02564312 0.04615584 0.04334847 0.03609472 0.03571744 0.02610272
 0.02200971 0.02110466 0.04334849 0.03885436 0.03571744 0.03717623
 0.04334849 0.02186711 0.04334851 0.03609471 0.03571745 0.02186242
 0.02143999 0.03571747 0.02181909 0.02561907 0.04334849 0.03609472
 0.04002204 0.04335599 0.04334849 0.02553613 0.04334848 0.03571744
 0.02186714 0.04793993 0.03609468 0.02551079 0.0433485  0.03572692
 0.02186713 0.02186713 0.04334849 0.04679834 0.03421056 0.0360947
 0.02110466 0.04334848 0.04334851 0.0433485  0.0433485  0.04793992
 0.04017012 0.04334848]
tr_loss:[0.04507135 0.02214617 0.03388048 0.03388036 0.02128097 0.02265422
 0.02385805 0.03428804 0.02386588 0.04507133 0.04507133 0.02095135
 0.03388038 0.03388037 0.02385804 0.0238583  0.02443525 0.02164746
 0.0381861  0.02859167 0.02127508 0.04507134 0.04507133 0.04063844
 0.03388036 0.04507134 0.03565663 0.01990695 0.03384346 0.02128097
 0.03868197 0.03388037 0.04507134 0.03388036 0.0450713  0.02128096
 0.03388036 0.04507133 0.04507873 0.02127967 0.03388038 0.03384359
 0.03388036 0.03388037 0.04507125 0.04507133 0.03802194 0.02128088
 0.04507133 0.0443118 ]
tr_loss:[0.03140868 0.02288053 0.04447944 0.02819612 0.04447948 0.02819613
 0.02819613 0.04447946 0.01811527 0.01846932 0.02388029 0.04447947
 0.03159609 0.03159612 0.04447949 0.01813479 0.02819613 0.01816111
 0.01851455 0.04447945 0.03140865 0.01854995 0.04447945 0.01816061
 0.04447947 0.01436269 0.01805037 0.04447945 0.01436267 0.01436269
 0.02359731 0.0315961  0.04447947 0.04447945 0.04447945 0.04447944
 0.02819612 0.0346178  0.04447946 0.04447804 0.04447947 0.03159608
 0.0315961  0.04447947 0.01805073 0.03159609 0.01805039 0.01816065
 0.04682299 0.019047  ]
tr_loss:[0.00785842 0.04283102 0.01543771 0.02309975 0.02972404 0.042831
 0.0270963  0.02830805 0.042831   0.04283101 0.00788939 0.04283558
 0.02667016 0.0300485  0.02309975 0.02309975 0.01321698 0.02482747
 0.0300485  0.0428881  0.04283103 0.04194144 0.04312295 0.04283101
 0.01263213 0.01831671 0.04283098 0.01139607 0.01543797 0.0300485
 0.00785842 0.04283101 0.01261731 0.02309974 0.04283102 0.00785842
 0.01543797 0.01715266 0.01543797 0.03004849 0.0248269  0.0300485
 0.04441974 0.04283146 0.04302049 0.00785842 0.04283102 0.02477451
 0.02800482 0.042831  ]
tr_loss:[0.03635275 0.01474659 0.03635279 0.00953784 0.03635275 0.03635276
 0.01027945 0.01986717 0.03187676 0.03635279 0.02375575 0.03635279
 0.03635278 0.00987403 0.03715928 0.02044387 0.01470982 0.03191061
 0.01470391 0.01986716 0.00369095 0.0363528  0.02829554 0.03505179
 0.02305233 0.03635278 0.03635277 0.01986718 0.01352356 0.01967889
 0.01986717 0.03635281 0.03635279 0.00987403 0.01087059 0.0198672
 0.03336843 0.01470981 0.01470982 0.00369045 0.04097954 0.01470983
 0.02016849 0.00987403 0.03635281 0.03298252 0.03187677 0.03635278
 0.03637635 0.00369054]
tr_loss:[0.00879223 0.01906217 0.03237958 0.03237962 0.01482962 0.04025838
 0.02379461 0.0323796  0.02379463 0.02354359 0.03143809 0.01904639
 0.02310637 0.0237475  0.02379462 0.01904641 0.00879223 0.00760456
 0.04025837 0.04025837 0.00879223 0.01950338 0.00592754 0.03237959
 0.03237962 0.02379461 0.0323796  0.0323796  0.0323796  0.03237959
 0.00875938 0.0323796  0.02379461 0.02379462 0.03237958 0.02962444
 0.02379462 0.01926674 0.02379461 0.03237958 0.0323796  0.01482947
 0.00732373 0.02478588 0.03394386 0.01511451 0.03255374 0.0237946
 0.04025837 0.03237962]
tr_loss:[0.03339285 0.0116854  0.03107695 0.03141692 0.03339779 0.02790398
 0.03141692 0.03141692 0.02331143 0.03141692 0.00869071 0.03141692
 0.0316105  0.03141692 0.0231436  0.02314365 0.02331204 0.03141693
 0.02790397 0.04427421 0.02790396 0.02790397 0.00801146 0.04427423
 0.03141691 0.02790399 0.02723216 0.02313184 0.00869467 0.02314341
 0.0314169  0.03141689 0.01517386 0.03141692 0.02316761 0.02314364
 0.0203862  0.03141694 0.02314321 0.03141692 0.04427422 0.02790398
 0.03141693 0.04427421 0.03141692 0.04427422 0.03335725 0.03141692
 0.02790399 0.03141692]
tr_loss:[0.02862744 0.04210833 0.01812599 0.03090451 0.03090449 0.0309045
 0.02488974 0.02488343 0.03090447 0.03161576 0.0309045  0.0309045
 0.0314213  0.0309045  0.03090452 0.03090453 0.02862745 0.02862744
 0.01812602 0.01706145 0.01816061 0.02862742 0.02862744 0.02488974
 0.0309045  0.02862745 0.03090446 0.02862744 0.00867875 0.03090452
 0.03090447 0.03090453 0.0286314  0.02481674 0.02862745 0.01912175
 0.0314213  0.03090561 0.03090451 0.0316501  0.00982556 0.01895809
 0.01812597 0.02545254 0.018126   0.03090448 0.02862744 0.00867855
 0.03090451 0.03090448]
tr_loss:[0.01288283 0.02726829 0.02882006 0.03135674 0.03258609 0.01647373
 0.02513286 0.0196585  0.02698328 0.00811942 0.03126959 0.01288285
 0.00749653 0.03126954 0.03520777 0.03126954 0.02075836 0.03520776
 0.01652646 0.02513286 0.02075839 0.03126955 0.03126957 0.02513286
 0.02066484 0.03258547 0.03126954 0.01288286 0.00813475 0.01811502
 0.03520776 0.0207584  0.01288284 0.03126954 0.02514971 0.03126955
 0.03126954 0.00736474 0.03126954 0.03520775 0.03126954 0.02513287
 0.00811138 0.01288285 0.02513286 0.03230991 0.0137555  0.03520776
 0.03520776 0.01375545]
tr_loss:[0.00520309 0.0201943  0.01357033 0.03223573 0.03223621 0.02019428
 0.00779283 0.02125323 0.03223578 0.03223578 0.01253946 0.0213271
 0.03227987 0.03223576 0.01330754 0.03223576 0.0201943  0.03223578
 0.0201943  0.03223574 0.02845501 0.03234238 0.00885235 0.0201943
 0.02665007 0.02111955 0.0133071  0.03223578 0.00885247 0.00757443
 0.02052094 0.00885246 0.03223579 0.0201943  0.02019429 0.03223576
 0.02648698 0.00753413 0.03223945 0.01330754 0.03223575 0.03223576
 0.03223576 0.02302499 0.02845502 0.0201943  0.028455   0.03223579
 0.03223578 0.01330826]
tr_loss:[0.01926698 0.03603932 0.03603929 0.03603932 0.01260973 0.00472149
 0.03746467 0.00996706 0.00960944 0.03603929 0.03603932 0.0274612
 0.03603933 0.0274612  0.03603932 0.03604276 0.00472147 0.02746121
 0.03178141 0.01897061 0.00930298 0.00645092 0.00646665 0.00472146
 0.02857854 0.03023721 0.0128039  0.00472147 0.02746121 0.0360393
 0.00930298 0.03023943 0.01897061 0.03603929 0.0274612  0.02196152
 0.0360393  0.02856241 0.0128044  0.0360341  0.00472143 0.03603928
 0.02746123 0.0360393  0.03603927 0.02198562 0.03603932 0.0360393
 0.03178176 0.03603927]
tr_loss:[0.03161957 0.01614124 0.03813801 0.01972091 0.03813805 0.01218624
 0.02022956 0.03813805 0.00802842 0.03290249 0.01218624 0.03813806
 0.00871767 0.03813808 0.01218629 0.03813804 0.01969373 0.03290257
 0.03813805 0.03813805 0.00847656 0.0202261  0.00881492 0.02108694
 0.03813807 0.01218603 0.0109225  0.00511663 0.01218547 0.00511663
 0.0329026  0.01202076 0.03813805 0.01218625 0.01006454 0.00871783
 0.03480818 0.00511663 0.01969373 0.02329028 0.03799097 0.03813806
 0.03660564 0.01218618 0.02318169 0.00704803 0.0087193  0.03813807
 0.03778385 0.02108219]
tr_loss:[0.00830288 0.03577123 0.03121031 0.03577112 0.03577112 0.00827552
 0.03577112 0.0357715  0.00521293 0.00827537 0.0357711  0.01976995
 0.0230486  0.03577111 0.03189157 0.01976999 0.03012477 0.00530762
 0.03577109 0.03632238 0.0333547  0.03012478 0.00827538 0.03577111
 0.01976996 0.0357711  0.01023092 0.02425761 0.03577109 0.00827537
 0.03577111 0.03577111 0.01275009 0.01976995 0.01085928 0.02277003
 0.0235477  0.00869966 0.03036838 0.01976996 0.03012481 0.03577112
 0.03591157 0.0053076  0.01976997 0.03577191 0.01976997 0.01397307
 0.02310632 0.00827537]
tr_loss:[0.03148536 0.01293214 0.01992536 0.03148948 0.03148124 0.00870928
 0.02292321 0.00882697 0.03148128 0.03148127 0.031549   0.0087116
 0.03148126 0.00882572 0.01293212 0.01293215 0.00532467 0.00636779
 0.01992581 0.03148128 0.03263078 0.03148126 0.03148126 0.00884212
 0.02892337 0.03148126 0.00636779 0.01293319 0.03148127 0.03148128
 0.00636779 0.03110466 0.02562543 0.03148128 0.00888294 0.03110469
 0.00434784 0.0299016  0.01992535 0.01320548 0.01992536 0.01179003
 0.03148128 0.01179003 0.03148126 0.03110468 0.02086244 0.03148907
 0.03110468 0.01992536]
tr_loss:[0.02085942 0.0050245  0.02813651 0.01006324 0.01234275 0.02755045
 0.02813646 0.00793293 0.02414264 0.01296833 0.01296831 0.02813646
 0.00793884 0.00870649 0.02085943 0.02085941 0.00806617 0.03160002
 0.00870602 0.02813647 0.0281365  0.01299458 0.02813646 0.02085941
 0.03210538 0.01297665 0.02813646 0.02813644 0.03160001 0.02726132
 0.02813642 0.02085943 0.02813644 0.03160005 0.02813646 0.02813645
 0.00870649 0.01115147 0.01296832 0.03160001 0.00864319 0.03160002
 0.03160001 0.02813644 0.02813644 0.00530216 0.02813642 0.01234224
 0.02840302 0.01296832]
tr_loss:[0.00738619 0.0218769  0.01428154 0.02713957 0.02471925 0.02713955
 0.02158936 0.01425452 0.01262306 0.00586918 0.02713954 0.0271395
 0.01060086 0.01428178 0.00736052 0.01262023 0.01262097 0.02737764
 0.02713958 0.02713956 0.02713956 0.02713956 0.02202865 0.02187713
 0.01060086 0.03374814 0.01060086 0.01262018 0.02713959 0.02159235
 0.01081646 0.02187689 0.02713955 0.03170949 0.0074708  0.02187689
 0.01372889 0.00747052 0.02713959 0.02713955 0.02187788 0.03011708
 0.01061478 0.0142791  0.02713958 0.02713956 0.02713956 0.0218769
 0.02713956 0.0126202 ]
tr_loss:[0.02764772 0.02764772 0.02418545 0.02764769 0.01445854 0.03301676
 0.02063433 0.01223103 0.02764772 0.02764772 0.02764772 0.02204073
 0.02918122 0.01639887 0.01434265 0.02764772 0.02204072 0.02640171
 0.0276477  0.01233563 0.01438689 0.02764773 0.02764773 0.01228626
 0.02204073 0.00662683 0.01054207 0.01222104 0.02764771 0.02597342
 0.02764772 0.01472644 0.02764773 0.00695424 0.01248236 0.02764772
 0.01054229 0.0105423  0.02204072 0.03301286 0.01222104 0.03153146
 0.03153144 0.01639725 0.03153147 0.02204073 0.0105423  0.02204074
 0.01054231 0.02764772]
tr_loss:[0.02821402 0.00780428 0.02821406 0.02821402 0.00780428 0.0059552
 0.01540596 0.02021183 0.028214   0.01410194 0.02821403 0.02820944
 0.02020787 0.00496605 0.02821402 0.01538076 0.028214   0.01413712
 0.02821403 0.00496605 0.01127661 0.02169553 0.02020787 0.02821402
 0.02821402 0.0112968  0.00780428 0.01532422 0.02020971 0.00779068
 0.01127684 0.02821405 0.00601771 0.02821402 0.03024561 0.02821403
 0.0282141  0.01127757 0.0302456  0.02821402 0.028214   0.02821403
 0.01127664 0.02020794 0.02020788 0.028214   0.02722941 0.00780619
 0.02020788 0.02821403]
tr_loss:[0.02865899 0.01227213 0.02920761 0.02373731 0.00410949 0.01732038
 0.02865899 0.00410955 0.028659   0.02865898 0.00409995 0.01055496
 0.028659   0.02865899 0.02865897 0.02920757 0.01055652 0.0033524
 0.02980231 0.01773319 0.01773319 0.01055496 0.01227212 0.0177832
 0.01227171 0.02920755 0.02865896 0.01773318 0.01055547 0.01773319
 0.01778997 0.01190758 0.02865902 0.00410376 0.028659   0.01773319
 0.02865897 0.00963789 0.028659   0.0110828  0.02289402 0.0173284
 0.02920756 0.02865897 0.028659   0.00410376 0.01773319 0.01722755
 0.0122713  0.02866062]
tr_loss:[0.03009537 0.03009539 0.01094441 0.00318565 0.00318605 0.01090068
 0.03009539 0.01573157 0.03009539 0.0293443  0.00319657 0.03009538
 0.03009536 0.03530687 0.02638304 0.0293443  0.01960281 0.03009536
 0.00352361 0.01699603 0.01750684 0.02638513 0.02569088 0.00318565
 0.01569713 0.03009538 0.03009539 0.00975037 0.01695169 0.03009538
 0.03009502 0.03009535 0.01014279 0.03009539 0.01695169 0.02934429
 0.01749696 0.03009954 0.03009567 0.02575364 0.03009537 0.0300954
 0.01094441 0.0169517  0.0169517  0.03009536 0.01704464 0.01569742
 0.01695167 0.02611645]
tr_loss:[0.00930984 0.02974104 0.01719166 0.01719166 0.00861063 0.01719167
 0.00399485 0.01164941 0.01719166 0.00861113 0.01719173 0.03080242
 0.01719166 0.03080247 0.02974103 0.03080246 0.00399648 0.00764847
 0.03080244 0.00925626 0.00399512 0.01159926 0.02590263 0.0232715
 0.01719165 0.01164941 0.03080245 0.0116494  0.00763233 0.00399513
 0.01719167 0.00861087 0.01872041 0.02974104 0.03094552 0.03080245
 0.01719167 0.00399513 0.01164941 0.00861067 0.01164561 0.0116494
 0.03080249 0.03080244 0.03080242 0.00861063 0.01719166 0.03080091
 0.00861063 0.01719165]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3200 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3201, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3201 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3202, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3202 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3203, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3203 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3204, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3204 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3205, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3205 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3206, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3206 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3207, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3207 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3208, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3208 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3209, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3209 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3210, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3210 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3211, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3211 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3212, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3212 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3213, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3213 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3214, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3214 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3215, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3215 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3216, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3216 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3217, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3217 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3218, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3218 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3219, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3219 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3220, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3220 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3221, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3221 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3222, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3222 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3223, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3223 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3224, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3224 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3225, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3225 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3226, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3226 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3227, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3227 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3228, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3228 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3229, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3229 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3230, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3230 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3231, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3231 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3232, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3232 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3233, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3233 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3234, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3234 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3235, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3235 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3236, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3236 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3237, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3237 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3238, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3238 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3239, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3239 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3240, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3240 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3241, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3241 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3242, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3242 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3243, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3243 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3244, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3244 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3245, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3245 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3246, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3246 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3247, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3247 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3248, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3248 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3249, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3249 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3250, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3250 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3251, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3251 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3252, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3252 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3253, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3253 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3254, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3254 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3255, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3255 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3256, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3256 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3257, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3257 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3258, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3258 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3259, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3259 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3260, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3260 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3261, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3261 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3262, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3262 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3263, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3263 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3264, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3264 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3265, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3265 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3266, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3266 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3267, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3267 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3268, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3268 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3269, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3269 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3270, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3270 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3271, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3271 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3272, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3272 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3273, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3273 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3274, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3274 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3275, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3275 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3276, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3276 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3277, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3277 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3278, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3278 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3279, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3279 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3280, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3280 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3281, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3281 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3282, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3282 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3283, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3283 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3284, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3284 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3285, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3285 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3286, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3286 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3287, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3287 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3288, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3288 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3289, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3289 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3290, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3290 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3291, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3291 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3292, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3292 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3293, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3293 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3294, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3294 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3295, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3295 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3296, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3296 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3297, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3297 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3298, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3298 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3299, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3299 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3300, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-3200
text_input.shape
(3300, 14400)
learning_input_tmp.shape
(3300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3300, 80)
learning_output.shape
(750, 80)
Model: "sequential_67"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_67 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4397705 1.5348601 1.5868468 1.6132581 1.4397705 1.4397705 1.6113489
 1.5645331 1.586847  1.4397703 1.586847  1.4397705 1.570393  1.586847
 1.4397688 1.6124207 1.5703931 1.5702164 1.5348601 1.4397705 1.6181866
 1.586847  1.4397705 1.5868468 1.6108999 1.4397706 1.586847  1.6108999
 1.5868468 1.4397705 1.5348601 1.5868529 1.4397705 1.4397705 1.4397706
 1.5703919 1.5652955 1.53486   1.586847  1.6224676 1.5348339 1.4397959
 1.6151673 1.4397706 1.5351075 1.5868467 1.5362989 1.5616924 1.4397705
 1.5494913]
tr_loss:[0.8114451  0.8119785  0.83726394 0.8854521  0.88543683 0.8438846
 0.81144524 0.8854356  0.87824976 0.896969   0.8114441  0.8393421
 0.8393425  0.8854519  0.8984151  0.885452   0.81144524 0.8771898
 0.8133443  0.83934224 0.88919526 0.90855104 0.9066256  0.8393423
 0.81144524 0.8393421  0.8973907  0.8393423  0.90578765 0.81144524
 0.87824976 0.85591125 0.8084013  0.88919526 0.87733346 0.8689947
 0.81144536 0.8380333  0.80790216 0.8393423  0.892321   0.88526297
 0.89696896 0.81144524 0.81144524 0.81144524 0.8782487  0.81144536
 0.87850064 0.90673906]
tr_loss:[0.49152318 0.4933138  0.49425387 0.4915226  0.4890357  0.47068915
 0.46320993 0.47131628 0.47131675 0.49043912 0.5155243  0.51674306
 0.49043903 0.4915226  0.48621884 0.48449883 0.49152264 0.48994207
 0.4890327  0.49416503 0.46046767 0.46049923 0.48921227 0.47131628
 0.4915227  0.48903275 0.4904391  0.49427605 0.4915227  0.49043903
 0.4690945  0.48903266 0.46398607 0.48903266 0.49427614 0.49043912
 0.4675766  0.4890327  0.49043912 0.49043903 0.48903266 0.49935007
 0.49427623 0.48903283 0.5167147  0.49043912 0.49078542 0.49935016
 0.49043903 0.51552486]
tr_loss:[0.26530874 0.24164224 0.2653087  0.24168308 0.28350824 0.2653087
 0.26530868 0.24087672 0.24810982 0.24199255 0.26530868 0.24199252
 0.2653087  0.26530868 0.24672322 0.2580111  0.24672313 0.2653087
 0.24199255 0.26530874 0.24087684 0.25191253 0.24995191 0.25721645
 0.26530868 0.24087682 0.26530868 0.24701838 0.2776516  0.24168308
 0.2463977  0.24199256 0.2419925  0.2467235  0.24608639 0.27764544
 0.2776513  0.24199252 0.24199197 0.24087682 0.24272946 0.24643536
 0.27592915 0.2653087  0.26530868 0.26530844 0.24168308 0.24672313
 0.24168317 0.24087682]
tr_loss:[0.14885148 0.13508734 0.1350873  0.14885145 0.13508734 0.13508756
 0.14885148 0.13537286 0.14885147 0.13241501 0.15455146 0.14114992
 0.14885147 0.14885136 0.14153315 0.13774864 0.13509488 0.14742899
 0.13241498 0.13241497 0.13508737 0.1454196  0.13508734 0.14541915
 0.14885107 0.14885147 0.14541705 0.1377542  0.13635547 0.1488515
 0.13528025 0.14885148 0.16299537 0.13775751 0.13241501 0.14885147
 0.14885148 0.14541915 0.14541888 0.13576499 0.1365749  0.13241506
 0.13508734 0.14885148 0.15517876 0.14885148 0.14885144 0.13508734
 0.13635552 0.15460393]
tr_loss:[0.0951084  0.09389566 0.09510837 0.09508999 0.09510841 0.08572148
 0.0951084  0.09510839 0.08651409 0.08572146 0.093433   0.0934393
 0.08572146 0.10714219 0.08572147 0.08572148 0.09343937 0.09335004
 0.09510839 0.0951084  0.0951084  0.09221052 0.08569014 0.09560934
 0.09510837 0.09507336 0.08572152 0.09510839 0.09510841 0.09201402
 0.09510839 0.08630543 0.08572148 0.09510839 0.09334785 0.08572152
 0.09667642 0.09510841 0.10714217 0.09201466 0.08572148 0.09509518
 0.09510843 0.09266428 0.09510839 0.09343942 0.09217779 0.09201661
 0.09337161 0.10111908]
tr_loss:[0.06867691 0.07363166 0.06521507 0.0677075  0.06867691 0.07026553
 0.06961061 0.06628469 0.06521507 0.06652094 0.06867689 0.07332762
 0.07909179 0.06867687 0.07332764 0.07026543 0.0686769  0.07026787
 0.06701423 0.0662037  0.06521507 0.07332763 0.06867693 0.0686769
 0.07333024 0.07330877 0.07790161 0.0686769  0.06527103 0.06679489
 0.06521507 0.06867688 0.06867693 0.06867693 0.06620369 0.07789291
 0.0686769  0.07332762 0.0733273  0.06867691 0.0652151  0.06521507
 0.07273082 0.07332762 0.07789294 0.06585473 0.06867691 0.06867689
 0.07332762 0.06867687]
tr_loss:[0.06083255 0.05408167 0.05408166 0.05945788 0.05147423 0.06071932
 0.05176687 0.05921144 0.05921146 0.05921147 0.0551833  0.05147579
 0.05844777 0.05945718 0.05147573 0.04842697 0.05921148 0.05921146
 0.05921147 0.05775457 0.05775454 0.05950379 0.06723048 0.05921143
 0.05147576 0.05147574 0.05921143 0.06727238 0.05921143 0.05921146
 0.05147574 0.05921143 0.05921146 0.05408218 0.05147578 0.06421184
 0.05921146 0.05921146 0.04479633 0.05727369 0.05945789 0.05921144
 0.05663932 0.05921146 0.05921144 0.0594565  0.05921144 0.05945788
 0.06071927 0.05147573]
tr_loss:[0.04444565 0.04236959 0.04444567 0.05445383 0.04079312 0.04301994
 0.04301991 0.04298553 0.03256247 0.0437009  0.04444565 0.05132406
 0.032563   0.04444565 0.05504348 0.04297803 0.05446576 0.03256298
 0.05132466 0.04444563 0.04444565 0.05034964 0.04287047 0.05168198
 0.03256304 0.03256299 0.042978   0.05132407 0.04444565 0.03256299
 0.02873058 0.05132406 0.02837899 0.03256297 0.04297831 0.04444567
 0.03542615 0.04297806 0.03256302 0.04146584 0.04300562 0.04444565
 0.04301976 0.04444563 0.05034966 0.02873054 0.03256298 0.04297801
 0.04444564 0.04334728]
tr_loss:[0.03326962 0.03326962 0.01558201 0.03326963 0.01412459 0.01558199
 0.0214199  0.01906875 0.01558199 0.01412458 0.01558329 0.0155753
 0.03326964 0.03292809 0.03326964 0.0146328  0.03292796 0.02585549
 0.03326964 0.01558199 0.0332696  0.01412458 0.03326964 0.02180412
 0.02949874 0.02585549 0.03326965 0.02585529 0.02949874 0.03326963
 0.0214199  0.03326964 0.01412459 0.03326963 0.02949874 0.02141989
 0.03326962 0.02141987 0.02949874 0.02949874 0.03326963 0.03140097
 0.02455456 0.03152055 0.03326965 0.02949874 0.02572054 0.01555648
 0.01558201 0.03326964]
tr_loss:[0.02085187 0.00573029 0.00979663 0.03717048 0.01930783 0.00882317
 0.01598143 0.00979131 0.02882859 0.00577214 0.00601304 0.0371705
 0.01607015 0.00979133 0.0344911  0.02210856 0.01005006 0.01544895
 0.01607016 0.01804117 0.01005005 0.03717048 0.03717051 0.01607016
 0.01809738 0.02211123 0.03717049 0.0371705  0.02437138 0.03449895
 0.02085187 0.02210322 0.01005007 0.01005006 0.0371705  0.01005006
 0.01005661 0.03717049 0.01005006 0.02962962 0.03711016 0.0100501
 0.01607016 0.01005008 0.03717048 0.0097913  0.03717049 0.01005005
 0.01606908 0.00573029]
tr_loss:[0.00525538 0.00523588 0.01136861 0.00525539 0.00332508 0.04053176
 0.04012248 0.04053178 0.00794953 0.00526167 0.04049731 0.01136861
 0.04053178 0.01342846 0.00331794 0.02465315 0.0113686  0.00331271
 0.01530336 0.01574794 0.00794988 0.04053176 0.00525539 0.04053178
 0.01574795 0.01136861 0.03320116 0.01594102 0.01136927 0.04053178
 0.01136862 0.04093203 0.02089377 0.01136861 0.04053177 0.0113686
 0.04053177 0.04053176 0.01574795 0.01525524 0.02710941 0.01868065
 0.00342349 0.04053177 0.01530375 0.04052298 0.00802968 0.01136861
 0.02456401 0.04053177]
tr_loss:[0.03799776 0.02279257 0.03799776 0.01269074 0.0023709  0.01274486
 0.02353394 0.03798936 0.01405833 0.01267888 0.03799775 0.03269599
 0.03799777 0.03799735 0.02065037 0.01265111 0.03799776 0.0023709
 0.00274449 0.03799774 0.01268445 0.03799775 0.01269074 0.03799777
 0.03799777 0.03799776 0.01299405 0.00241597 0.03799777 0.00600236
 0.00600237 0.01269074 0.01277198 0.03799774 0.02353376 0.03799777
 0.02066176 0.00600237 0.01561681 0.01269073 0.03799776 0.02332269
 0.03799776 0.01249204 0.00593805 0.00237089 0.01269074 0.02186316
 0.03799772 0.03799773]
tr_loss:[0.03203471 0.00463757 0.01383503 0.03203905 0.01383503 0.00463763
 0.00463854 0.00463757 0.0138466  0.03203472 0.01093069 0.00493602
 0.00665516 0.00666386 0.00667852 0.00669974 0.00669738 0.03203472
 0.00463757 0.00493443 0.01383503 0.03203472 0.00669653 0.00464156
 0.02389107 0.00480943 0.03203469 0.00968325 0.02138148 0.00463756
 0.01945011 0.004638   0.02602462 0.03203471 0.0096869  0.01383503
 0.00463777 0.03203471 0.00669931 0.00463757 0.03203471 0.00669974
 0.00463757 0.00315531 0.00463757 0.0046423  0.00463758 0.00967656
 0.01383502 0.0212667 ]
tr_loss:[0.01930535 0.00572148 0.01229517 0.01930535 0.00692247 0.01229517
 0.00692247 0.01930536 0.02743592 0.02743592 0.0274359  0.00716951
 0.00889292 0.01821477 0.01930535 0.00777551 0.01229517 0.00691279
 0.01229517 0.02743589 0.00572147 0.00692235 0.00692247 0.00692247
 0.01229515 0.02506266 0.02743591 0.02743595 0.02743834 0.02743593
 0.02743593 0.00692246 0.01930536 0.02743832 0.02743593 0.02481046
 0.01949854 0.01229517 0.02743592 0.01984899 0.02743592 0.02743592
 0.01229757 0.02743592 0.00692248 0.02743591 0.02743592 0.0075367
 0.00692247 0.02743592]
tr_loss:[0.02575821 0.00885037 0.01671552 0.01028675 0.00992065 0.02457619
 0.02575822 0.01671552 0.01028676 0.02457609 0.01671552 0.02575817
 0.00973533 0.02575821 0.0257582  0.01024565 0.01028678 0.00885037
 0.00652912 0.0245761  0.0066247  0.02575819 0.02682984 0.0257582
 0.02575819 0.0257582  0.01671552 0.00885048 0.01612328 0.00885037
 0.02575819 0.0257582  0.00930304 0.01671235 0.01028676 0.00992
 0.02575817 0.01024369 0.0153794  0.01028539 0.02457609 0.0089038
 0.01672271 0.02457611 0.0245761  0.01028676 0.0289673  0.02575819
 0.03168857 0.02575822]
tr_loss:[0.00859846 0.00678432 0.02494642 0.00910837 0.02497988 0.01159554
 0.02121083 0.00859846 0.00541007 0.02494645 0.02830083 0.02494645
 0.01472124 0.02494641 0.00910831 0.00859814 0.02250551 0.02494641
 0.02244273 0.02244271 0.02494644 0.02494641 0.02494644 0.02123949
 0.01982189 0.02830084 0.01979966 0.02601608 0.00859847 0.02494644
 0.00911178 0.01473492 0.00910829 0.0086092  0.00859847 0.02244272
 0.00859845 0.02244272 0.03180762 0.02494644 0.00859382 0.02494642
 0.0091083  0.02244273 0.00547283 0.02244273 0.00910829 0.02244273
 0.01589367 0.01963441]
tr_loss:[0.00332158 0.00772223 0.02427644 0.00300571 0.02427644 0.00338643
 0.01465756 0.01465758 0.02427642 0.00309856 0.02320113 0.01465758
 0.0229287  0.00300631 0.01058965 0.01465756 0.02427643 0.01465758
 0.01235084 0.02427641 0.00629881 0.01659077 0.02427644 0.02427643
 0.01149724 0.02309493 0.02427643 0.00332158 0.00755325 0.00627782
 0.00333633 0.0242764  0.01465763 0.00332158 0.00330184 0.02525434
 0.0077202  0.02427642 0.01465755 0.02427644 0.00338738 0.00338625
 0.01235081 0.00627781 0.01465758 0.02427645 0.01845045 0.02427642
 0.0030058  0.00332164]
tr_loss:[0.00567715 0.00674686 0.00971963 0.02707303 0.0017001  0.02707306
 0.02707303 0.01625063 0.00685052 0.00974296 0.01588248 0.01754375
 0.02707301 0.00971962 0.02664688 0.00170009 0.02707304 0.0017001
 0.02862033 0.00170241 0.00169985 0.02707304 0.02707304 0.00159561
 0.00170013 0.0100077  0.02707303 0.00674686 0.02707304 0.01591269
 0.00673727 0.02707304 0.01284883 0.02102424 0.02707304 0.02707301
 0.01627754 0.00169913 0.02707304 0.00971963 0.00971963 0.02707304
 0.02707303 0.02707303 0.02707304 0.02707304 0.02707302 0.02707301
 0.0017001  0.00972428]
tr_loss:[0.00844713 0.00391093 0.01472868 0.01699755 0.02191811 0.00844712
 0.01472904 0.0086502  0.02877725 0.01699758 0.02971727 0.02971726
 0.00276673 0.03112712 0.02087073 0.02971727 0.02971728 0.00276673
 0.00864202 0.01297585 0.02971726 0.01870658 0.02106925 0.0086502
 0.00276683 0.01702209 0.01297584 0.0086502  0.00844712 0.0129753
 0.01934535 0.01297585 0.01297621 0.02971727 0.02015782 0.00392656
 0.00276824 0.00844713 0.02971724 0.00844713 0.02971724 0.01539844
 0.02971727 0.01090877 0.02589949 0.00864923 0.01297517 0.0086502
 0.01472346 0.01297585]
tr_loss:[0.00835326 0.00666043 0.01407689 0.01603676 0.02988473 0.00813705
 0.02988473 0.00442586 0.00817448 0.00304687 0.00410276 0.00299942
 0.00835326 0.00410275 0.01707619 0.00309306 0.02988473 0.02988472
 0.02988474 0.00309627 0.00615872 0.02988471 0.00321257 0.01707907
 0.00309627 0.01504978 0.02988479 0.02988474 0.02089083 0.00835325
 0.00472704 0.00410276 0.01323194 0.02988475 0.00817217 0.00310714
 0.01407705 0.01505502 0.02988474 0.00835325 0.00326429 0.03098429
 0.02526408 0.02988474 0.01322459 0.02526315 0.00309665 0.00417469
 0.00309627 0.01355446]
tr_loss:[0.02860492 0.01570999 0.00702872 0.012951   0.02860538 0.00568213
 0.00319736 0.00314925 0.00459844 0.02860492 0.00314928 0.02860493
 0.00314928 0.00315862 0.00414037 0.02860495 0.00314928 0.02860495
 0.02860492 0.02860491 0.02860493 0.0028296  0.00485736 0.00314928
 0.02860493 0.00314929 0.02934664 0.00314934 0.02860494 0.00544478
 0.00940184 0.01257628 0.00478564 0.00314929 0.00314928 0.02860492
 0.00314928 0.02860493 0.02860494 0.00940184 0.00702874 0.02860492
 0.02860491 0.009403   0.00701611 0.012951   0.0031493  0.01366773
 0.00940185 0.00702873]
tr_loss:[0.0107225  0.02571166 0.01339194 0.00590137 0.02571161 0.00520164
 0.0169731  0.00268357 0.00590267 0.02571164 0.02571163 0.02571162
 0.00255472 0.00520138 0.01072249 0.00268608 0.02571163 0.01212775
 0.00268357 0.02571161 0.01072249 0.0128049  0.00520138 0.00590279
 0.01072249 0.01242949 0.00268358 0.00590278 0.01374723 0.02571164
 0.02022614 0.02571165 0.0052014  0.00590279 0.00590276 0.02025096
 0.01339646 0.02571164 0.02571164 0.00268357 0.00268358 0.01212774
 0.00268358 0.01212774 0.01361139 0.01212774 0.01072249 0.01212774
 0.01072249 0.02571164]
tr_loss:[0.02350169 0.02350167 0.02350169 0.00266034 0.0235017  0.02350167
 0.01248715 0.02350173 0.00266035 0.01248713 0.01248713 0.01434414
 0.02350168 0.00557887 0.01035518 0.01124411 0.01248714 0.00266035
 0.01124408 0.02350167 0.00266032 0.02350167 0.01248714 0.01248715
 0.02350171 0.02350169 0.00266034 0.0095719  0.02350169 0.02350178
 0.02350169 0.01132961 0.01035455 0.00957181 0.01248714 0.00266035
 0.01248714 0.0235017  0.01663385 0.02350167 0.01124411 0.01124411
 0.01248713 0.00266035 0.00541134 0.01124411 0.02350167 0.02391374
 0.02350167 0.00557675]
tr_loss:[0.02206703 0.00236248 0.00446412 0.00446413 0.02028415 0.01344319
 0.01344318 0.02206703 0.02206702 0.00962785 0.02206782 0.02206703
 0.00962694 0.00962784 0.00446413 0.00841986 0.00371539 0.00846485
 0.00450287 0.00221041 0.02206703 0.022067   0.0019863  0.02206701
 0.02206703 0.01344318 0.01344318 0.00446413 0.01356501 0.00236206
 0.02206702 0.02206703 0.00198626 0.00479744 0.00236248 0.01344318
 0.0044646  0.00236248 0.00236248 0.01344316 0.01345114 0.02284172
 0.02206703 0.01344318 0.01344319 0.00479743 0.00479744 0.00236301
 0.0146165  0.00962784]
tr_loss:[0.02204413 0.01386715 0.00333742 0.00340981 0.02201283 0.02201284
 0.02245948 0.02201285 0.00848076 0.02201284 0.01386689 0.02201281
 0.02201282 0.00235657 0.02201283 0.02201284 0.02201993 0.02201283
 0.00235657 0.00373397 0.00233105 0.00235725 0.02201283 0.02201381
 0.00849007 0.01386689 0.02201303 0.01386689 0.01386742 0.0138669
 0.00340981 0.02201283 0.01075661 0.01775721 0.00849096 0.02251917
 0.00341906 0.01386796 0.02201283 0.00340981 0.02201283 0.00374642
 0.00849099 0.00235656 0.00838851 0.01030693 0.00340982 0.01386688
 0.00235656 0.02201283]
tr_loss:[0.00904877 0.00336432 0.01662145 0.02278208 0.02278207 0.00311011
 0.00336432 0.01490326 0.02278208 0.00336432 0.00311001 0.00336427
 0.0035     0.00336432 0.02538711 0.02278209 0.02278206 0.02278206
 0.00904877 0.02278208 0.00904877 0.01370828 0.01318893 0.0227821
 0.00904877 0.01490324 0.02813399 0.00997929 0.00397754 0.00336431
 0.01490325 0.00904881 0.01806376 0.02278209 0.0038622  0.00311002
 0.01766543 0.02278209 0.01490324 0.00336432 0.00397754 0.00397254
 0.00336629 0.00336431 0.01806377 0.02278209 0.01318895 0.0227821
 0.00719771 0.02278208]
tr_loss:[0.01556438 0.01556435 0.02248549 0.00312106 0.02248547 0.02248545
 0.00307869 0.00221169 0.02248548 0.00323297 0.01556327 0.00353683
 0.0144278  0.01762622 0.02248549 0.00299231 0.02248548 0.01442779
 0.00917981 0.0091802  0.00307871 0.01496831 0.0030787  0.0030787
 0.00221174 0.02248545 0.00235416 0.00353675 0.02248546 0.01762623
 0.02247864 0.00221175 0.01442779 0.0035368  0.02248548 0.02248549
 0.01509921 0.0144278  0.0091802  0.0091802  0.0224855  0.01848089
 0.01760488 0.01442779 0.02248548 0.02248548 0.02248549 0.00303067
 0.00307864 0.02248547]
tr_loss:[0.00107356 0.00107357 0.00135991 0.02079405 0.01548474 0.00849831
 0.02079405 0.02079402 0.01626834 0.01208108 0.01189136 0.01208108
 0.01208108 0.01237878 0.00159689 0.02079405 0.00135991 0.01058156
 0.02079402 0.02079404 0.00107359 0.00107357 0.01114538 0.01208107
 0.00135991 0.02043154 0.02170868 0.02079402 0.00135991 0.02168216
 0.01114814 0.01117178 0.00135991 0.01549296 0.01208107 0.02079404
 0.00135984 0.00159756 0.00135991 0.00107357 0.01208107 0.02079404
 0.02079404 0.00235986 0.02079405 0.01549297 0.01208106 0.02079405
 0.02126139 0.00107435]
tr_loss:[0.0145548  0.01764406 0.02073182 0.0034378  0.01166406 0.00981445
 0.00102763 0.00102763 0.01084296 0.00085115 0.02073182 0.02073182
 0.02073181 0.01070353 0.02073181 0.02073181 0.01084611 0.00102763
 0.00102767 0.00335738 0.01070353 0.01070354 0.01070353 0.00981443
 0.00145559 0.00085115 0.01358377 0.01070353 0.00209296 0.02073182
 0.02073181 0.02073182 0.01142672 0.01427428 0.02073181 0.02073182
 0.00328359 0.01465795 0.02073184 0.01630253 0.02073181 0.02073181
 0.01430275 0.02073183 0.02073182 0.00343404 0.00102763 0.00213593
 0.00123617 0.00102475]
text_input.shape
(3300, 14400)
learning_input_tmp.shape
(3300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3300, 80)
learning_output.shape
(750, 80)
Model: "sequential_68"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_68 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3698355 1.3424242 1.3931189 1.3607461 1.3607461 1.3731267 1.3931189
 1.3931187 1.3607419 1.3162658 1.3162658 1.369835  1.3120587 1.3162658
 1.3607461 1.387268  1.3731264 1.3162658 1.4014399 1.3162658 1.3727099
 1.3161796 1.3718355 1.3931209 1.3162658 1.3162658 1.3731264 1.3731266
 1.3162658 1.3162658 1.3586466 1.3729718 1.3301992 1.4014393 1.3162658
 1.3162658 1.3815367 1.3607461 1.3162658 1.3718355 1.342504  1.3224745
 1.3162657 1.3162658 1.3162658 1.4015763 1.3251798 1.354335  1.3713702
 1.3931189]
tr_loss:[0.51239073 0.54410845 0.54410857 0.527342   0.5273407  0.5123906
 0.5123906  0.52734196 0.5123905  0.51239055 0.5123905  0.5187914
 0.51239014 0.5269438  0.52356786 0.527342   0.5441085  0.527342
 0.5123907  0.5441087  0.5561844  0.51038444 0.52371126 0.5123906
 0.5330514  0.54410857 0.5123906  0.5272547  0.5123905  0.5188571
 0.5123906  0.5327097  0.52782595 0.5441085  0.5302025  0.52740854
 0.51144826 0.51886064 0.5326679  0.51145124 0.5260069  0.5123906
 0.5114206  0.53266805 0.5114484  0.5123905  0.52149445 0.5114484
 0.5289752  0.51038456]
tr_loss:[0.27210394 0.27299553 0.27529258 0.25749204 0.25511622 0.25511625
 0.28107306 0.2604201  0.27299556 0.27168038 0.25547048 0.26041478
 0.26041475 0.26264906 0.2554691  0.27529266 0.26548094 0.23814873
 0.26041478 0.25512943 0.27299556 0.26041478 0.2602457  0.25511622
 0.27061096 0.2729955  0.25511628 0.23811483 0.27529258 0.25749207
 0.27529234 0.26041478 0.25511622 0.25511622 0.25546578 0.2602724
 0.27529258 0.27529258 0.26041478 0.26041475 0.25749207 0.27174854
 0.2731925  0.27299553 0.2739601  0.2639149  0.2809268  0.2594286
 0.281073   0.2752926 ]
tr_loss:[0.10713442 0.11313562 0.11205733 0.12359057 0.11351719 0.1265796
 0.10713444 0.1323123  0.10809629 0.11351399 0.10713444 0.1236449
 0.10713439 0.13265419 0.13269171 0.10713442 0.12363969 0.12364328
 0.13286003 0.10713442 0.1101858  0.13286002 0.12345854 0.10713442
 0.10713445 0.13286    0.10713442 0.1197044  0.10713442 0.12364493
 0.11487035 0.10713439 0.11645269 0.11351404 0.11031775 0.12046893
 0.10713442 0.13286002 0.11645272 0.1101858  0.11361476 0.11645272
 0.1071346  0.11351398 0.10713442 0.12364192 0.13286003 0.1071344
 0.13269167 0.10713436]
tr_loss:[0.04554043 0.05518769 0.05518766 0.06196952 0.05518768 0.05225269
 0.05391911 0.06196465 0.06196463 0.04305513 0.06196466 0.05383817
 0.06196465 0.05518765 0.05518766 0.05657702 0.05037728 0.0527132
 0.05428706 0.04553779 0.04494489 0.04306025 0.0525356  0.06196463
 0.04734343 0.08790071 0.05518766 0.0538364  0.05518769 0.05518765
 0.04257622 0.04833809 0.0525356  0.04833809 0.05038971 0.06196471
 0.05253558 0.05518768 0.05518768 0.06196467 0.0525356  0.05229199
 0.05518766 0.05253562 0.05518767 0.04553864 0.05518771 0.04587536
 0.05518768 0.04515649]
tr_loss:[0.04002745 0.03185552 0.02605821 0.03945041 0.02814254 0.03945055
 0.04002747 0.03352152 0.02635662 0.03945046 0.04002745 0.04002743
 0.03648693 0.03220178 0.04002744 0.06748693 0.02814305 0.0400015
 0.03220177 0.03352147 0.03220177 0.06871617 0.03945046 0.02814669
 0.0400274  0.03328513 0.05253981 0.04002745 0.02833467 0.02607899
 0.03945044 0.02814306 0.04002742 0.0400274  0.04002742 0.03947166
 0.03352039 0.02635897 0.04002742 0.03945043 0.02834247 0.04002742
 0.04002742 0.02839586 0.04002745 0.03220178 0.03945038 0.03482712
 0.03220177 0.04002741]
tr_loss:[0.03884726 0.03748378 0.04445737 0.04418165 0.04446934 0.03381588
 0.03976775 0.03884729 0.03976773 0.02929641 0.03976674 0.03976769
 0.07446112 0.03884728 0.04418162 0.03976773 0.03884726 0.04445793
 0.03976761 0.04418164 0.02856088 0.03884725 0.03884725 0.03976773
 0.04445793 0.03976772 0.02679567 0.03976773 0.03884728 0.03819484
 0.04418161 0.03381503 0.03884729 0.04418162 0.03884727 0.04445793
 0.03976773 0.03748376 0.03884729 0.04360799 0.0388473  0.03884725
 0.03884729 0.04092165 0.0442669  0.03884727 0.04418161 0.03884729
 0.04499148 0.03884728]
tr_loss:[0.0347364  0.04205757 0.02976125 0.03473638 0.03473638 0.04172541
 0.03337508 0.04165006 0.03473636 0.03473607 0.03602127 0.04175015
 0.03504519 0.04172539 0.0347364  0.0347364  0.03662169 0.03091814
 0.04028393 0.04172621 0.04174392 0.03473636 0.04028392 0.03473636
 0.03473635 0.04028393 0.02145871 0.03473641 0.04174392 0.04174393
 0.04174434 0.04127251 0.03443614 0.04028392 0.0366213  0.04167923
 0.03337507 0.02798683 0.04175608 0.03473638 0.0417254  0.04028393
 0.06369322 0.0347364  0.03473636 0.0347364  0.01985411 0.04174201
 0.04174088 0.03473639]
tr_loss:[0.02860644 0.01894485 0.03649256 0.05452058 0.03649253 0.03649253
 0.03558347 0.03649253 0.02940291 0.03649252 0.03861547 0.02925847
 0.0568261  0.01603242 0.03558332 0.04385263 0.03652637 0.04025346
 0.03003109 0.04025345 0.03649256 0.02884528 0.03649253 0.03081819
 0.04025343 0.04025346 0.02199168 0.02852573 0.03319648 0.04025344
 0.03649252 0.04025346 0.03649255 0.02967151 0.02880555 0.05435659
 0.03558334 0.02860643 0.01595053 0.03649251 0.01576148 0.03558334
 0.01603545 0.03649254 0.03558328 0.0355839  0.03649255 0.03558334
 0.03649256 0.02199471]
tr_loss:[0.02739812 0.02730555 0.03627529 0.01863004 0.02739899 0.03313502
 0.03313504 0.03313921 0.02739898 0.033135   0.02739853 0.01004756
 0.03313502 0.04743601 0.03313502 0.02399687 0.01863004 0.03313503
 0.01108015 0.02739897 0.01500774 0.01496365 0.03313504 0.02739898
 0.0134231  0.02525534 0.03313502 0.02291868 0.03313502 0.01498277
 0.02978358 0.03313892 0.03627528 0.0262963  0.02739898 0.03627526
 0.03627528 0.02739896 0.02739737 0.01863858 0.03627528 0.02739873
 0.03313503 0.03627561 0.03015905 0.03313501 0.02740089 0.01863004
 0.01109545 0.01499221]
tr_loss:[0.03801045 0.01543497 0.039009   0.00965923 0.03701071 0.01536576
 0.01536265 0.03701072 0.01536143 0.03701069 0.0370107  0.00965695
 0.01536141 0.02885487 0.02888374 0.03701069 0.02885547 0.01104482
 0.01104481 0.00965924 0.01536141 0.03701071 0.01104482 0.03701066
 0.03701069 0.03701069 0.02106874 0.01536142 0.01151563 0.01793213
 0.03659297 0.01539773 0.0132019  0.01634429 0.0153614  0.02015843
 0.0153614  0.01893077 0.01536143 0.03705395 0.01035562 0.03701069
 0.02972567 0.03701071 0.01104482 0.02885487 0.01320056 0.02885489
 0.01887158 0.02092656]
tr_loss:[0.01605221 0.01670749 0.04601065 0.01655893 0.0163192  0.03281605
 0.04601067 0.04601064 0.0162444  0.04601065 0.04601062 0.04601063
 0.01269089 0.0162444  0.01652811 0.04601066 0.04601065 0.01113858
 0.04601063 0.04601065 0.01565808 0.01113902 0.01670751 0.02846791
 0.02796622 0.04624426 0.03416777 0.04601064 0.01269091 0.01649498
 0.0284679  0.0284679  0.04601067 0.01269111 0.0284679  0.015409
 0.01269067 0.0393936  0.01269089 0.04601067 0.02697734 0.01624442
 0.0284679  0.04601061 0.01370688 0.0126909  0.01538683 0.0284679
 0.01624571 0.01624441]
tr_loss:[0.04556655 0.04556655 0.01977893 0.04556654 0.01670872 0.01987846
 0.04556649 0.02401547 0.04556654 0.01425037 0.01991028 0.01377801
 0.04556654 0.01150745 0.0198785  0.02571871 0.01150743 0.02571871
 0.01455991 0.01150744 0.03890615 0.04556656 0.01150743 0.02571872
 0.01150742 0.03045646 0.04556655 0.01377813 0.0142502  0.02627743
 0.03890628 0.01776638 0.02456462 0.01987867 0.01425037 0.04556657
 0.0198785  0.01425029 0.01229303 0.01455985 0.03054755 0.02762967
 0.01150743 0.01399313 0.01967406 0.01150744 0.02571873 0.04556653
 0.01150743 0.01425032]
tr_loss:[0.02100198 0.04500727 0.01220185 0.00878634 0.04500728 0.04500716
 0.02305796 0.01095001 0.02305797 0.04500727 0.0450073  0.04500726
 0.03221858 0.04500729 0.02305798 0.04500728 0.01095001 0.02222561
 0.02101336 0.012347   0.04500725 0.04196605 0.01725603 0.04500727
 0.01095001 0.01095001 0.0224671  0.02101331 0.02305797 0.01773763
 0.04500729 0.04500725 0.02101335 0.04500725 0.02305795 0.04500727
 0.02305794 0.04500731 0.02306091 0.02101336 0.02101337 0.04500729
 0.01095    0.03204225 0.02305796 0.02305795 0.04500728 0.04500728
 0.04500728 0.00878634]
tr_loss:[0.02251803 0.01235153 0.04129251 0.02251801 0.04129249 0.04129253
 0.02051667 0.02251803 0.03068077 0.01817321 0.02051668 0.00637591
 0.02251802 0.017162   0.01716383 0.02834594 0.01235153 0.04129253
 0.02268733 0.0181732  0.01817317 0.02251803 0.02251802 0.02027042
 0.03068402 0.02466523 0.0412925  0.04129249 0.0181732  0.01815483
 0.04067715 0.0412925  0.04129251 0.04129253 0.04129253 0.04129254
 0.02251803 0.01878285 0.02454511 0.01084064 0.04129253 0.02051667
 0.02251803 0.03521912 0.03737609 0.01463267 0.02040089 0.04129253
 0.0063698  0.04129251]
tr_loss:[0.01553231 0.03549997 0.03550001 0.02584763 0.03549991 0.00546986
 0.02093073 0.01309053 0.01553232 0.0355     0.02713229 0.0209306
 0.02282062 0.03549998 0.0131752  0.02093062 0.0104931  0.01421109
 0.01553231 0.01553237 0.03549999 0.01515293 0.03550001 0.0209306
 0.03550001 0.01309052 0.02234007 0.01388543 0.0209306  0.01318205
 0.03549999 0.0209306  0.03550001 0.03019804 0.00547028 0.03549998
 0.03549998 0.01309053 0.03550001 0.02453315 0.01418434 0.03549998
 0.00529458 0.00512375 0.02766792 0.02691238 0.03549995 0.01828934
 0.03549998 0.03549997]
tr_loss:[0.0178289  0.0163499  0.02618459 0.03258717 0.03258715 0.03258716
 0.01398723 0.03182236 0.01398723 0.01398724 0.03258719 0.03258716
 0.03561901 0.0163499  0.01784697 0.02433458 0.01398722 0.00691797
 0.01398724 0.01398722 0.03258714 0.03258714 0.03258713 0.01782892
 0.02344507 0.0178289  0.01782892 0.01398723 0.03258716 0.01782891
 0.03258717 0.01634987 0.01401376 0.02344508 0.03258713 0.01782892
 0.03258712 0.01607321 0.01390819 0.02056835 0.03381808 0.02344778
 0.02048181 0.02373321 0.01635529 0.03258719 0.02344508 0.01129338
 0.03258719 0.0234457 ]
tr_loss:[0.0299129  0.01386744 0.03048429 0.02044616 0.02044616 0.03048428
 0.01386767 0.02044615 0.03048425 0.03048425 0.02337613 0.01470241
 0.01548897 0.01388518 0.02497725 0.02044614 0.03048429 0.021052
 0.01020474 0.02044613 0.02497727 0.03048424 0.01836816 0.02497726
 0.01652723 0.03048429 0.03556579 0.01652723 0.02497727 0.02044615
 0.02044615 0.01410479 0.00670038 0.03048425 0.02044615 0.02044581
 0.02369414 0.02497731 0.02044616 0.02369412 0.03048428 0.01839413
 0.03048426 0.01285364 0.02558845 0.01021238 0.03048423 0.03048427
 0.02370842 0.00762069]
tr_loss:[0.02613128 0.01938492 0.02613128 0.02613279 0.01938492 0.02613127
 0.01884941 0.01938492 0.02393729 0.02393728 0.01432537 0.02613129
 0.01938074 0.02393728 0.03220662 0.0261313  0.03171241 0.02613127
 0.02613128 0.02613127 0.0239373  0.02393729 0.02613125 0.01494871
 0.02393729 0.01882066 0.00629577 0.02613125 0.02613126 0.01432545
 0.02613126 0.03181841 0.01976983 0.01994717 0.00629592 0.02613201
 0.02613127 0.00629591 0.01432545 0.02030114 0.01432537 0.01456561
 0.01494872 0.02614993 0.02613128 0.02613131 0.01938492 0.02613129
 0.02613126 0.02407662]
tr_loss:[0.02552741 0.01427627 0.02002502 0.02552742 0.01865919 0.0165798
 0.02220362 0.00630531 0.02552744 0.02554664 0.02552745 0.02552745
 0.01948026 0.0405903  0.0186587  0.0165798  0.03213939 0.01678975
 0.01865919 0.02552741 0.01467364 0.01973408 0.0330145  0.02552744
 0.01679009 0.03423391 0.01467366 0.02552743 0.02214291 0.00864918
 0.02552743 0.02552743 0.02552747 0.02552744 0.02219186 0.03063739
 0.02554663 0.02220038 0.02220667 0.00648394 0.01467366 0.01865919
 0.01870944 0.01865921 0.02552744 0.02552744 0.02554663 0.0165798
 0.02554663 0.02552744]
tr_loss:[0.02517032 0.0105872  0.02914984 0.02914986 0.02517033 0.02517032
 0.00631113 0.02916474 0.02517031 0.02932489 0.01800302 0.01387822
 0.02914985 0.02386821 0.01190368 0.02914983 0.01666976 0.01324168
 0.02787284 0.0245608  0.02914983 0.02979468 0.01388166 0.00687742
 0.01412056 0.02517036 0.02517031 0.01058721 0.01412059 0.01387819
 0.02914985 0.01956028 0.01387917 0.02914981 0.02914987 0.02459626
 0.01188554 0.01412117 0.01796115 0.02914982 0.02915565 0.01412058
 0.02914984 0.01190194 0.02914983 0.01960259 0.01387819 0.01058328
 0.02914983 0.02914984]
tr_loss:[0.03226339 0.03226337 0.0322634  0.03226336 0.02456046 0.02456044
 0.02456045 0.03226338 0.0322635  0.02456044 0.02456046 0.03226338
 0.02456043 0.01136837 0.01143354 0.02456044 0.01176251 0.03226338
 0.0114179  0.02456046 0.01136838 0.00812894 0.01141799 0.01141799
 0.01143354 0.03226339 0.01309715 0.02456046 0.01213703 0.00768389
 0.02456043 0.02398305 0.0322634  0.03226339 0.00812895 0.03285442
 0.01141808 0.02456046 0.01348753 0.02456044 0.00631919 0.01348754
 0.03226339 0.03226336 0.02456047 0.02456045 0.01061071 0.03226338
 0.03226338 0.00936245]
tr_loss:[0.02183437 0.00930246 0.03106878 0.00794421 0.00825286 0.01003279
 0.03106905 0.02183434 0.02143594 0.03106882 0.0077696  0.03106879
 0.00930242 0.03106881 0.03106879 0.02183439 0.0218346  0.02410364
 0.00930336 0.00985615 0.00840344 0.03107275 0.0310688  0.03116746
 0.00985183 0.0310688  0.00930241 0.00985881 0.0310688  0.03174168
 0.0310688  0.02183438 0.0310688  0.0310688  0.00930242 0.02183437
 0.03106879 0.00977503 0.02183438 0.00794299 0.00985671 0.03106881
 0.00985616 0.00986222 0.02143593 0.0073124  0.00930439 0.00930241
 0.03106881 0.00958577]
tr_loss:[0.02055443 0.01121925 0.00970363 0.00566619 0.02794247 0.02794244
 0.01993345 0.00983624 0.00970364 0.01016716 0.02794247 0.00988342
 0.01121929 0.00743481 0.02794245 0.00983918 0.00539506 0.02055443
 0.00970364 0.00539505 0.00970364 0.00779717 0.02055442 0.01022841
 0.00970364 0.02794248 0.00983623 0.02794244 0.0098096  0.0112193
 0.00957676 0.02058215 0.02794245 0.02055443 0.00553597 0.02794248
 0.02096068 0.01121928 0.02794244 0.02055441 0.02055443 0.02055442
 0.02794246 0.02372194 0.01121528 0.00552897 0.0200383  0.01121929
 0.02794243 0.00970364]
tr_loss:[0.02829236 0.02829242 0.02143697 0.01220662 0.02577839 0.02411741
 0.02829236 0.02143695 0.02829238 0.02829239 0.00996977 0.01357481
 0.0055252  0.01399327 0.01405494 0.01368208 0.02829235 0.01220667
 0.01405494 0.01220661 0.0282924  0.01357481 0.0257789  0.02214935
 0.02837324 0.02829237 0.02829234 0.01219701 0.02296031 0.02143697
 0.02143697 0.01220662 0.02829235 0.00772362 0.00545475 0.01357481
 0.01220654 0.02829237 0.02829237 0.0055252  0.00965841 0.0110118
 0.02829235 0.01220662 0.01220661 0.01357479 0.01395167 0.02779614
 0.01220681 0.02143696]
tr_loss:[0.02016602 0.01614529 0.02811111 0.01275334 0.01206472 0.01207896
 0.01276849 0.02017118 0.02811108 0.0127708  0.0281111  0.02811109
 0.02602065 0.01276818 0.01276848 0.0281111  0.01276827 0.0127708
 0.02811109 0.01187595 0.01206334 0.01276848 0.01614552 0.0052991
 0.02016602 0.01277081 0.02811112 0.01206332 0.02016603 0.02811109
 0.01614528 0.00947295 0.02016602 0.02944199 0.0281111  0.0093306
 0.02811109 0.01277073 0.01207096 0.02016602 0.02811109 0.01206333
 0.02811109 0.00976365 0.00530581 0.01276848 0.00534984 0.02811111
 0.02811112 0.02251151]
tr_loss:[0.02380847 0.02861341 0.02861341 0.01870306 0.0286134  0.00510687
 0.02861341 0.02386634 0.02861341 0.02861343 0.00871966 0.00994667
 0.02861341 0.01024751 0.01020684 0.01870306 0.00603682 0.0286134
 0.02861344 0.01020208 0.02861345 0.01870307 0.01081886 0.02861341
 0.01081888 0.01024752 0.01020619 0.01919353 0.02386633 0.01870306
 0.01082168 0.01081887 0.01020622 0.02861342 0.02861342 0.01081888
 0.01081887 0.02861342 0.03305551 0.02994102 0.01870306 0.01870306
 0.01870306 0.0296913  0.02213239 0.02017155 0.005107   0.0330591
 0.02861342 0.0108544 ]
tr_loss:[0.01012887 0.00995728 0.0276023  0.00990961 0.00351349 0.02760233
 0.00763581 0.02088871 0.00443155 0.01890641 0.01776503 0.02866955
 0.00600549 0.00990959 0.0085571  0.02760232 0.01776502 0.00855742
 0.00593585 0.00597603 0.0085571  0.00348847 0.00990961 0.00855527
 0.02760233 0.00971635 0.01783651 0.0085571  0.01890974 0.0099096
 0.02760257 0.0099096  0.02760232 0.02760234 0.0099096  0.01776501
 0.01211516 0.01776502 0.00918663 0.00621076 0.0211186  0.02760232
 0.02488408 0.02111836 0.00919236 0.02760232 0.02760232 0.02760233
 0.02760233 0.00443254]
tr_loss:[0.02614912 0.02341822 0.02614914 0.01011081 0.02313162 0.010115
 0.01005152 0.0261491  0.01774769 0.00813377 0.02176794 0.01774769
 0.02614912 0.010115   0.01981021 0.02614912 0.01011128 0.00372843
 0.0172807  0.010115   0.02614911 0.00813367 0.00813308 0.01005154
 0.01801873 0.00813367 0.01011499 0.0101053  0.01011456 0.00489543
 0.010115   0.010115   0.01774836 0.010115   0.00842459 0.02614912
 0.01011883 0.00790157 0.02111967 0.010115   0.00813367 0.01011502
 0.00544006 0.00963725 0.00813367 0.01801851 0.00842457 0.0261491
 0.01775563 0.00356738]
tr_loss:[0.01899429 0.01102248 0.00534352 0.01102803 0.0262141  0.01102692
 0.02621413 0.01102497 0.01102692 0.00859032 0.01744087 0.0110823
 0.0106834  0.02621414 0.01102691 0.0262141  0.0262141  0.02621411
 0.01163361 0.00858819 0.01102692 0.00431921 0.02621411 0.02684985
 0.0262141  0.01163361 0.011069   0.01102692 0.01102691 0.01899428
 0.01067109 0.01787172 0.01102691 0.01102693 0.01899428 0.01114791
 0.0110269  0.0262141  0.01899428 0.0116336  0.02621407 0.01163361
 0.01899429 0.02621411 0.00533611 0.02621411 0.02621409 0.02684976
 0.0268521  0.01899429]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3300 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3301, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3301 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3302, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3302 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3303, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3303 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3304, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3304 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3305, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3305 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3306, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3306 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3307, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3307 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3308, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3308 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3309, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3309 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3310, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3310 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3311, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3311 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3312, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3312 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3313, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3313 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3314, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3314 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3315, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3315 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3316, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3316 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3317, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3317 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3318, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3318 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3319, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3319 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3320, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3320 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3321, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3321 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3322, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3322 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3323, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3323 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3324, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3324 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3325, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3325 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3326, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3326 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3327, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3327 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3328, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3328 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3329, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3329 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3330, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3330 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3331, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3331 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3332, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3332 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3333, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3333 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3334, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3334 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3335, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3335 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3336, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3336 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3337, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3337 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3338, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3338 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3339, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3339 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3340, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3340 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3341, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3341 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3342, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3342 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3343, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3343 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3344, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3344 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3345, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3345 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3346, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3346 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3347, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3347 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3348, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3348 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3349, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3349 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3350, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3350 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3351, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3351 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3352, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3352 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3353, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3353 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3354, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3354 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3355, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3355 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3356, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3356 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3357, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3357 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3358, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3358 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3359, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3359 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3360, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3360 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3361, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3361 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3362, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3362 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3363, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3363 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3364, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3364 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3365, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3365 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3366, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3366 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3367, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3367 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3368, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3368 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3369, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3369 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3370, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3370 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3371, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3371 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3372, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3372 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3373, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3373 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3374, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3374 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3375, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3375 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3376, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3376 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3377, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3377 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3378, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3378 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3379, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3379 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3380, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3380 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3381, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3381 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3382, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3382 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3383, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3383 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3384, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3384 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3385, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3385 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3386, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3386 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3387, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3387 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3388, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3388 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3389, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3389 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3390, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3390 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3391, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3391 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3392, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3392 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3393, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3393 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3394, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3394 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3395, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3395 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3396, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3396 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3397, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3397 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3398, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3398 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3399, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3399 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3400, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-3300
text_input.shape
(3400, 14400)
learning_input_tmp.shape
(3400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3400, 80)
learning_output.shape
(750, 80)
Model: "sequential_69"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_69 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4185498 1.3156865 1.4235127 1.4235126 1.2990948 1.4060565 1.398133
 1.4184272 1.42195   1.4145902 1.4235127 1.4279639 1.4169017 1.3981303
 1.4235092 1.418427  1.4184272 1.4260261 1.3561224 1.4219497 1.4066137
 1.4184269 1.4215846 1.4235125 1.3980561 1.4235127 1.2990974 1.3045366
 1.4353831 1.4184268 1.4169022 1.3062998 1.416506  1.4184269 1.4235127
 1.2990974 1.4219499 1.4219497 1.42195   1.4131461 1.4235127 1.42195
 1.3981303 1.2990973 1.4170525 1.4184295 1.4235126 1.4372084 1.42195
 1.4218519]
tr_loss:[0.81040686 0.8024601  0.80595076 0.7995226  0.7995302  0.7869592
 0.7961687  0.7869593  0.81995857 0.79952586 0.7791218  0.8059578
 0.8020161  0.79952586 0.78695923 0.7961667  0.7869592  0.7961686
 0.78153723 0.8060497  0.8059511  0.78695923 0.7868644  0.78695923
 0.79952586 0.8020161  0.7961686  0.77912176 0.79001564 0.7995259
 0.8020161  0.7869591  0.8059613  0.80585706 0.799526   0.8057421
 0.79616374 0.78701717 0.78695905 0.8020161  0.80595005 0.80601406
 0.7815558  0.80596924 0.7869576  0.8104819  0.80595094 0.8020161
 0.80026495 0.78695923]
tr_loss:[0.47980675 0.47980675 0.5270301  0.5193746  0.50908726 0.49986506
 0.5369131  0.49040222 0.4798068  0.5099906  0.49407855 0.51937455
 0.51937467 0.47980675 0.53695524 0.5628812  0.5193818  0.50908726
 0.509463   0.51945865 0.47980672 0.47980672 0.5193752  0.4940864
 0.47472596 0.51485866 0.49407855 0.5148994  0.5027289  0.5270655
 0.49040222 0.53695595 0.502731   0.49791557 0.48233277 0.5085154
 0.47980672 0.5148587  0.5148586  0.49620104 0.48233286 0.51937467
 0.51485854 0.49040237 0.4798068  0.47980672 0.5009918  0.49712548
 0.53693235 0.5341695 ]
tr_loss:[0.22707173 0.22904715 0.22945662 0.21764842 0.21864626 0.24700192
 0.21864617 0.23248152 0.2764588  0.23248152 0.22956479 0.23248155
 0.24700189 0.21865165 0.21864621 0.23248152 0.24698901 0.22078462
 0.22476259 0.2186462  0.2170223  0.23248155 0.22476253 0.2297843
 0.22945695 0.22895607 0.22620043 0.2294569  0.22945686 0.24700184
 0.22476256 0.23248157 0.22935097 0.24700204 0.2362591  0.21864621
 0.22689958 0.21929696 0.23248151 0.23437135 0.27987885 0.23612316
 0.2411464  0.22686502 0.22945699 0.21922669 0.2307919  0.22078463
 0.23248148 0.22945699]
tr_loss:[0.11509943 0.11752434 0.11208905 0.09336808 0.11407308 0.09775094
 0.13834605 0.11407304 0.10463544 0.11208925 0.1120893  0.11407306
 0.11135218 0.09872211 0.09337506 0.13786066 0.09775095 0.09872173
 0.10173814 0.13469364 0.13834597 0.09336807 0.10465965 0.11407302
 0.09337075 0.10463543 0.13838626 0.09775091 0.11407306 0.10207276
 0.13834597 0.09872177 0.11752933 0.11757135 0.10207275 0.09775297
 0.11208928 0.10355189 0.13834605 0.10207285 0.10207276 0.11208929
 0.13834605 0.11575933 0.11407305 0.10586798 0.12522137 0.13834405
 0.11407304 0.1383399 ]
tr_loss:[0.10774361 0.10624588 0.10774361 0.10774356 0.06560694 0.08533935
 0.10458796 0.06942753 0.06560731 0.08517845 0.08533936 0.08533935
 0.08533929 0.10774358 0.06560693 0.08533934 0.06292865 0.07055166
 0.10774362 0.08328624 0.07476471 0.10774358 0.06966909 0.08533935
 0.07979774 0.06292863 0.06559744 0.08533935 0.07491989 0.10597088
 0.08533935 0.08533934 0.06292865 0.08328624 0.07436687 0.05989968
 0.08533932 0.06462212 0.06560694 0.06352113 0.07055166 0.1077436
 0.1077436  0.08319472 0.05989967 0.10458789 0.10597031 0.06560694
 0.06198213 0.08533933]
tr_loss:[0.05808564 0.05898667 0.05898662 0.03812472 0.03812473 0.04836652
 0.0589866  0.03479789 0.03812477 0.04756218 0.06455229 0.0348007
 0.04735738 0.03833726 0.0589866  0.05898661 0.0347979  0.0805345
 0.03812472 0.04756222 0.03501219 0.03812468 0.03479822 0.08053451
 0.04756222 0.0589866  0.0805345  0.06499369 0.04756222 0.03533632
 0.03812471 0.0517627  0.08053452 0.08053453 0.06455053 0.03812474
 0.04756221 0.0475624  0.07401393 0.08053453 0.0589866  0.03501221
 0.06647147 0.05808564 0.0805345  0.05898662 0.03501219 0.05808381
 0.03501394 0.04301599]
tr_loss:[0.01818204 0.02607703 0.02488632 0.02705403 0.03748558 0.02725008
 0.05354838 0.01817804 0.01244273 0.02748402 0.02607704 0.02743944
 0.01244272 0.01916155 0.01925258 0.03292524 0.01244629 0.05354841
 0.04987749 0.01244274 0.05306513 0.03560247 0.02743826 0.02609662
 0.03361468 0.02488772 0.01817804 0.02607704 0.01244275 0.019208
 0.02607701 0.03350154 0.02487424 0.02743943 0.02488684 0.02488684
 0.0535484  0.02607703 0.01820376 0.02743943 0.03977958 0.0535484
 0.02662099 0.05354836 0.02607704 0.02607702 0.01817804 0.01250826
 0.02609501 0.02730503]
tr_loss:[0.05099667 0.0106536  0.01490869 0.01490869 0.01490869 0.02222637
 0.01660101 0.03018368 0.05099667 0.01489407 0.0106536  0.01440351
 0.03252307 0.01940434 0.02291151 0.05099664 0.02291148 0.02226522
 0.05099666 0.01940434 0.02291149 0.02735861 0.05099668 0.02222638
 0.02989584 0.02297973 0.01483789 0.04356208 0.01491023 0.01940434
 0.04741666 0.0106536  0.02291149 0.02291149 0.01069741 0.01940434
 0.05099669 0.02291152 0.01940434 0.01490847 0.02735382 0.0149087
 0.05099668 0.05099665 0.01660087 0.01064157 0.01490868 0.05099665
 0.02193706 0.02291151]
tr_loss:[0.02588234 0.02588236 0.02588235 0.04398183 0.00905138 0.00905126
 0.04151411 0.00905125 0.04398187 0.02588236 0.04220761 0.01331919
 0.01331937 0.02025808 0.02332337 0.0446881  0.02025674 0.00905128
 0.03106972 0.02588236 0.02025662 0.02025654 0.01331919 0.01331921
 0.01780643 0.01518748 0.02085475 0.02588236 0.00905126 0.01920578
 0.02365229 0.04220067 0.01930285 0.00908426 0.04639778 0.04398187
 0.01331921 0.02588237 0.04398187 0.02588235 0.02650617 0.01680427
 0.00905126 0.02025627 0.01780968 0.00903318 0.04398187 0.02588363
 0.02588238 0.0133192 ]
tr_loss:[0.02559627 0.01991774 0.01828819 0.01918966 0.01513155 0.00840146
 0.01991209 0.03971507 0.01918937 0.01991772 0.03971509 0.03971504
 0.04964847 0.01513161 0.01513155 0.03598183 0.03971507 0.03971508
 0.00840148 0.04113449 0.02559628 0.02559626 0.03971506 0.01828819
 0.03971507 0.03971505 0.01513155 0.03971508 0.01513149 0.02559626
 0.03971509 0.01513155 0.05056432 0.00840146 0.01513155 0.01513156
 0.01513156 0.02559627 0.01918937 0.02559627 0.01828809 0.00840148
 0.00840148 0.00840147 0.01936342 0.01513155 0.01863345 0.00840146
 0.01490424 0.02559627]
tr_loss:[0.04485958 0.02068622 0.02068623 0.00963875 0.0342913  0.03873682
 0.01593526 0.03870895 0.04345769 0.00963873 0.02068622 0.04345769
 0.03873682 0.02068622 0.01269395 0.01236266 0.00963874 0.02068623
 0.01593584 0.03873682 0.02068619 0.03873684 0.01175581 0.00963875
 0.0387368  0.03873684 0.01227364 0.01998111 0.01701919 0.01593583
 0.02753367 0.01593586 0.01227227 0.01707612 0.02068622 0.03873682
 0.01227376 0.01593586 0.01227375 0.0387361  0.03873683 0.04025794
 0.02068624 0.0162969  0.01621704 0.01227375 0.02068622 0.01227376
 0.01617395 0.02068705]
tr_loss:[0.02384477 0.01706059 0.01111041 0.04335951 0.02856171 0.01706059
 0.01010184 0.01706057 0.01471754 0.04335937 0.01471863 0.01612755
 0.01010121 0.01471755 0.01613563 0.01612662 0.02991021 0.01710772
 0.01710737 0.01710736 0.01010185 0.01010184 0.01111079 0.02025081
 0.01010213 0.03833687 0.01601433 0.04335959 0.01471753 0.01710737
 0.04335956 0.03647063 0.01152707 0.04127073 0.01010184 0.04335957
 0.01720455 0.01710738 0.02530845 0.04335956 0.01010184 0.01613563
 0.03558401 0.01613561 0.01710736 0.0433397  0.01613564 0.01471753
 0.02847208 0.01480018]
tr_loss:[0.01728166 0.02869467 0.00827062 0.0306339  0.03192287 0.02803588
 0.00828649 0.01618344 0.00660668 0.01871366 0.01361724 0.04581382
 0.03024529 0.0188656  0.01947089 0.02165362 0.02799446 0.01361723
 0.04506911 0.04506911 0.0081989  0.02976409 0.00825242 0.01671329
 0.01675908 0.00827062 0.01361723 0.01361723 0.01361723 0.00827061
 0.01946408 0.00605691 0.04506909 0.0162154  0.02818716 0.01361724
 0.01361724 0.0194709  0.01979755 0.02869129 0.00613856 0.01361724
 0.01947091 0.02317485 0.01577717 0.01361724 0.01361723 0.02813742
 0.01726948 0.01744001]
tr_loss:[0.01735975 0.02539731 0.02477292 0.0106566  0.04219051 0.0244777
 0.0421905  0.0421905  0.01114988 0.01034634 0.02447771 0.00810756
 0.0106566  0.00795967 0.02477302 0.04219034 0.01623227 0.01736301
 0.00810754 0.03671783 0.03319894 0.00810742 0.04219051 0.01736314
 0.00810755 0.02477238 0.02535434 0.02952974 0.01736277 0.01037534
 0.0244777  0.02447769 0.00810755 0.00810702 0.04219049 0.02447769
 0.0244777  0.00810755 0.02447771 0.03548768 0.03539457 0.0106566
 0.04218378 0.00810756 0.02447769 0.02892933 0.03483707 0.0106566
 0.01065659 0.00811279]
tr_loss:[0.00908528 0.01830909 0.01830896 0.02674875 0.00518914 0.0051888
 0.01255474 0.02066236 0.02704286 0.02628349 0.01830911 0.01830912
 0.03347114 0.0198877  0.01255473 0.02066828 0.00947892 0.0089169
 0.03347114 0.00811738 0.00951481 0.02705614 0.0051613  0.0095443
 0.00811737 0.00811737 0.00521347 0.00947862 0.026585   0.00927954
 0.00518916 0.01255473 0.02067882 0.01830911 0.00518915 0.00518897
 0.01830912 0.00811738 0.01990156 0.00811737 0.01254817 0.00518915
 0.01830911 0.03347114 0.00518915 0.03347113 0.01255474 0.01255473
 0.00518916 0.01830913]
tr_loss:[0.0069464  0.0069464  0.00774054 0.01467603 0.02246924 0.02639649
 0.00860259 0.0248504  0.00626186 0.00256808 0.01481983 0.01133076
 0.02639649 0.02639648 0.02683961 0.00467222 0.0029327  0.01174787
 0.00277643 0.0069464  0.00390495 0.02639646 0.00631641 0.00293271
 0.00860261 0.02639647 0.00860261 0.01686441 0.00626173 0.01572228
 0.02639648 0.00291445 0.02232619 0.00293271 0.00292818 0.00626172
 0.00694641 0.00774058 0.0069464  0.00860261 0.01224976 0.00626173
 0.01158273 0.02639446 0.02568395 0.01174787 0.02510658 0.02639649
 0.0024612  0.00626173]
tr_loss:[0.01176899 0.00920503 0.00882181 0.00957167 0.0183559  0.00748187
 0.01122332 0.03167124 0.03122085 0.01122324 0.01888172 0.00748041
 0.00917933 0.01812014 0.01122324 0.027813   0.03122086 0.02328784
 0.01888173 0.01835649 0.00935575 0.01331717 0.01122288 0.00676904
 0.01122193 0.01888172 0.03122083 0.00922439 0.00920504 0.03167137
 0.01120406 0.03122086 0.01122873 0.01888174 0.00748042 0.01331717
 0.00942601 0.02837337 0.01888173 0.00748041 0.03122086 0.00921567
 0.03122084 0.02779085 0.03122083 0.01331717 0.01331859 0.00882347
 0.03167427 0.00748043]
tr_loss:[0.02199713 0.01282802 0.02164411 0.00711723 0.01016994 0.01282802
 0.0127604  0.03446979 0.02199714 0.00711724 0.01339643 0.01282802
 0.0127604  0.03446981 0.01017    0.01269471 0.01939303 0.00711722
 0.02743964 0.02008117 0.01016973 0.01276137 0.02743962 0.02744373
 0.0127145  0.01083175 0.00838134 0.00711722 0.01000742 0.02199792
 0.01282802 0.0092187  0.01016974 0.02199715 0.02199714 0.00711722
 0.03446981 0.03446979 0.02662877 0.02199713 0.02199712 0.01282801
 0.01197099 0.02267756 0.02199714 0.01282802 0.01284739 0.0344698
 0.01017058 0.01282803]
tr_loss:[0.02687823 0.03451398 0.0076159  0.00816028 0.034514   0.00816037
 0.00688366 0.00722991 0.00816028 0.00688366 0.00721827 0.01068666
 0.01684557 0.03451395 0.03451397 0.03491313 0.00759739 0.00741603
 0.01684557 0.00816028 0.00688366 0.00695505 0.00610042 0.03451397
 0.00688368 0.01684557 0.01068669 0.01684558 0.00816026 0.01684557
 0.00382371 0.02052948 0.01908128 0.00816028 0.01684556 0.01684557
 0.01135164 0.01684557 0.00688366 0.00761582 0.03451393 0.0038237
 0.0038237  0.00721984 0.01684556 0.01684557 0.00382371 0.03451398
 0.00703376 0.00688366]
tr_loss:[0.03502585 0.03502584 0.03502586 0.00441604 0.00463775 0.00463749
 0.01289876 0.02877029 0.01289875 0.00463749 0.01289876 0.03502817
 0.00441409 0.01015576 0.00769245 0.00463745 0.00792874 0.01289876
 0.03502619 0.00792872 0.01344664 0.00699888 0.00347778 0.00347778
 0.00757767 0.00463749 0.03502588 0.03502585 0.03541061 0.01327829
 0.00394258 0.00769239 0.00470629 0.03502585 0.00464236 0.01901106
 0.00347872 0.01289876 0.03502588 0.00769244 0.0289824  0.00463748
 0.00769173 0.00347778 0.03506351 0.00769244 0.00463748 0.01289875
 0.012227   0.00463052]
tr_loss:[0.0201645  0.01007815 0.00873319 0.01007803 0.0038556  0.02790912
 0.00740722 0.01007806 0.01048978 0.03349406 0.01048448 0.01883651
 0.02907212 0.02020423 0.00740723 0.02842607 0.01008015 0.01007804
 0.01883266 0.03349406 0.02020422 0.01319838 0.03349406 0.00740776
 0.03349406 0.03394187 0.00302303 0.00740723 0.00873321 0.01127092
 0.01014383 0.01048447 0.00246083 0.03349404 0.03345172 0.01850492
 0.01007802 0.00740723 0.00246083 0.00740722 0.01298028 0.02907223
 0.02789823 0.00755702 0.01007802 0.00246083 0.00740722 0.01007803
 0.02192044 0.0087332 ]
tr_loss:[0.00267194 0.00267194 0.00267194 0.00325477 0.01075999 0.0091402
 0.02914918 0.00267195 0.00854973 0.01075998 0.00727139 0.00267195
 0.01899133 0.01075998 0.01899132 0.02060432 0.02914919 0.01075998
 0.02914917 0.02914916 0.01075998 0.02914918 0.00918242 0.00491453
 0.01446903 0.00267195 0.00676021 0.02914917 0.01075997 0.01075998
 0.01446865 0.02914912 0.00569903 0.02914916 0.00267195 0.02356852
 0.01075999 0.00267159 0.0032302  0.0072714  0.00918187 0.02353724
 0.00569936 0.01591293 0.02914918 0.01075998 0.01873162 0.02365749
 0.029057   0.01075999]
tr_loss:[0.0044305  0.01331226 0.00503907 0.01907079 0.01002641 0.01002642
 0.00998834 0.0048886  0.00505082 0.00492849 0.00719787 0.0050508
 0.02559379 0.02559377 0.0100264  0.01075626 0.00719787 0.00719793
 0.00719787 0.01075002 0.01063858 0.00719788 0.02559381 0.0262148
 0.01002074 0.00505082 0.00719787 0.02559367 0.00505082 0.02559382
 0.00505032 0.02021108 0.01331227 0.01331227 0.01823619 0.02559382
 0.0050508  0.00436521 0.01823619 0.00719787 0.01823619 0.01331227
 0.00505082 0.00443051 0.02559381 0.01331228 0.01539195 0.02559381
 0.01331227 0.0156913 ]
tr_loss:[0.0266669  0.0149246  0.01684266 0.00832217 0.02346451 0.00548912
 0.02348256 0.00832217 0.01154508 0.01159945 0.0168428  0.0168428
 0.00716366 0.02013994 0.00548911 0.00832218 0.00548911 0.01153317
 0.02346451 0.00548912 0.00548913 0.02010272 0.02799161 0.00716367
 0.01365347 0.02346449 0.01152463 0.01159945 0.0234645  0.02346449
 0.00426714 0.01159945 0.01153336 0.02346453 0.01361162 0.01159944
 0.00548912 0.01366635 0.01399889 0.01684405 0.02346452 0.00716366
 0.01153336 0.01684282 0.01159945 0.01584766 0.01153335 0.00548903
 0.01159944 0.02013994]
tr_loss:[0.02381769 0.00492277 0.00813529 0.00766767 0.01049518 0.00492277
 0.0085491  0.00810432 0.02381773 0.00505196 0.0238177  0.00813529
 0.00437658 0.00492277 0.00752058 0.00752058 0.02381771 0.00662968
 0.00424861 0.00425157 0.00424862 0.00752497 0.00662948 0.02381771
 0.00662946 0.00836743 0.02152752 0.01106953 0.00662946 0.00424863
 0.0049228  0.01106953 0.0197832  0.00752058 0.00492176 0.00737752
 0.01940673 0.00662946 0.00859183 0.00752058 0.00752057 0.00504727
 0.02381769 0.00662902 0.00752058 0.00660407 0.0067782  0.0042468
 0.00492277 0.00813221]
tr_loss:[0.00567725 0.02770003 0.00767869 0.00819239 0.01048701 0.00479229
 0.0053245  0.00873294 0.02770001 0.00479228 0.01048702 0.00767864
 0.01409586 0.0033482  0.0053245  0.01409583 0.02073445 0.01048702
 0.01838867 0.00479228 0.02144918 0.0053245  0.00532434 0.00479228
 0.00534416 0.00711575 0.02770004 0.00532451 0.02770005 0.00479227
 0.00458375 0.00532449 0.00819239 0.00479227 0.00532449 0.01048702
 0.00819239 0.00753833 0.0053245  0.01048702 0.00479227 0.00873359
 0.00532449 0.00479227 0.00710731 0.01943054 0.02770003 0.02770001
 0.0277001  0.00532555]
tr_loss:[0.0123852  0.01711208 0.030304   0.00622497 0.005937   0.01238498
 0.030304   0.012385   0.02324109 0.03030399 0.00835461 0.0178124
 0.0041443  0.00717353 0.01238498 0.02451153 0.005937   0.0041443
 0.00623597 0.03030398 0.012385   0.00835453 0.00620713 0.00622523
 0.00622499 0.03030397 0.00755825 0.030304   0.005937   0.00622548
 0.00397759 0.00414429 0.03030398 0.00414429 0.00414429 0.00622499
 0.01238498 0.00627477 0.03100028 0.00798297 0.005937   0.01687963
 0.00711609 0.03030398 0.00755825 0.0303227  0.012385   0.005937
 0.0041443  0.03097578]
tr_loss:[0.00742003 0.02854552 0.02363072 0.00557635 0.02895764 0.00557614
 0.00210188 0.01063385 0.00557635 0.00740087 0.02896002 0.00210189
 0.0055764  0.01064061 0.00805555 0.00558278 0.00210189 0.0073997
 0.02895764 0.02895764 0.02895762 0.00723583 0.01063385 0.01063385
 0.00716843 0.02895762 0.00210189 0.01063418 0.00210188 0.0140704
 0.01063385 0.02895764 0.00557635 0.00557635 0.02895762 0.01818998
 0.01063385 0.00557635 0.02895765 0.02895763 0.01063386 0.01063385
 0.02895764 0.00210189 0.00740088 0.00723593 0.0286594  0.01752813
 0.00638802 0.00723594]
tr_loss:[0.00914482 0.00680286 0.00863583 0.00914482 0.00135097 0.00135097
 0.00135098 0.01006335 0.00864991 0.00606055 0.00863582 0.00863581
 0.01030161 0.00831943 0.00554574 0.00772242 0.00727668 0.00555044
 0.02793972 0.02793968 0.00666356 0.00554574 0.02793969 0.00863583
 0.02793973 0.02793975 0.00554574 0.00936609 0.00554577 0.02793973
 0.01006282 0.02793971 0.00554574 0.00554574 0.00863582 0.00135098
 0.01006334 0.00135093 0.00913843 0.00914482 0.00863582 0.00554574
 0.01006334 0.00163442 0.01356831 0.00554574 0.00826036 0.00672849
 0.00554579 0.0219895 ]
text_input.shape
(3400, 14400)
learning_input_tmp.shape
(3400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3400, 80)
learning_output.shape
(750, 80)
Model: "sequential_70"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_70 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.7473408 1.747329  1.7106234 1.7415661 1.8319972 1.8292156 1.7022674
 1.7106234 1.7566783 1.7122428 1.807476  1.7625313 1.7864082 1.8183205
 1.7566477 1.7022674 1.7625294 1.8292181 1.7010517 1.6472225 1.7473167
 1.7022676 1.7947754 1.7473294 1.7418064 1.7106235 1.7864087 1.8183174
 1.6671177 1.7022674 1.809172  1.6598953 1.7625294 1.7012393 1.8292179
 1.7625153 1.7864087 1.7621822 1.7106234 1.6580105 1.7473301 1.8292181
 1.8259827 1.8183571 1.7106235 1.7066818 1.7022674 1.7106234 1.6472218
 1.7827327]
tr_loss:[0.8122961  0.91063106 0.95046407 0.9105881  0.93456924 0.93456936
 0.85200804 0.9344219  0.8779391  0.8520082  0.9106313  0.8277251
 0.8664068  0.86583483 0.8851218  0.85200787 0.86585224 0.8292694
 0.84858495 0.85125095 0.8658476  0.8721331  0.8842161  0.8236645
 0.88520145 0.8292696  0.93456936 0.86585224 0.8657161  0.8292695
 0.85200804 0.8292696  0.85208255 0.93456954 0.88521403 0.86882097
 0.7991166  0.8520082  0.86585236 0.85200804 0.9345667  0.93456936
 0.8477724  0.8237789  0.85200804 0.88520163 0.8188373  0.8637161
 0.9106224  0.9106312 ]
tr_loss:[0.55109376 0.5589565  0.57140666 0.5992209  0.55674314 0.5714066
 0.6041285  0.5992209  0.5992209  0.54994583 0.5772163  0.58172655
 0.5817532  0.59922093 0.563609   0.58161575 0.5714066  0.60394967
 0.54994583 0.5714065  0.57140666 0.5987445  0.5714066  0.5439422
 0.572242   0.5817548  0.58166474 0.5433277  0.5992209  0.6039747
 0.556743   0.60394967 0.6041287  0.57140666 0.5714066  0.5772164
 0.54990417 0.5567431  0.5992209  0.57140666 0.55484635 0.59535015
 0.5992209  0.5817339  0.5625183  0.54994583 0.5992208  0.58175355
 0.556743   0.5567431 ]
tr_loss:[0.28149644 0.2941141  0.30932823 0.29363263 0.2814964  0.28149638
 0.30934364 0.27552658 0.28149638 0.28149644 0.28088206 0.28765187
 0.30932817 0.28149644 0.29411408 0.2934995  0.2808827  0.30932885
 0.29411405 0.30932826 0.29373422 0.28149644 0.29818052 0.28088206
 0.32391906 0.28149647 0.2804849  0.29359418 0.28149647 0.30932823
 0.30932826 0.29359412 0.30932826 0.28717393 0.28088206 0.29359412
 0.29411325 0.2935949  0.323919   0.28088212 0.28088206 0.28094697
 0.29411405 0.2815704  0.30932823 0.2941141  0.28677917 0.28149638
 0.29359412 0.2814964 ]
tr_loss:[0.10229488 0.12353711 0.10929269 0.09282634 0.12353714 0.12563321
 0.12353716 0.102383   0.1253696  0.11510184 0.10227557 0.11176759
 0.10461364 0.13031724 0.12353714 0.12563723 0.11510181 0.11893196
 0.11183888 0.11151105 0.09282633 0.11510184 0.11246672 0.11509939
 0.12986207 0.09282633 0.1119879  0.11510186 0.11764409 0.11262522
 0.10229345 0.12353714 0.10461891 0.1256189  0.10229345 0.12353714
 0.12669031 0.12353711 0.12353715 0.11152096 0.10691597 0.1118389
 0.12561893 0.12321019 0.09282632 0.12984414 0.1118389  0.11893199
 0.12353716 0.09282633]
tr_loss:[0.04337098 0.04937696 0.03920002 0.04263118 0.04504814 0.06616404
 0.05187692 0.05838626 0.05126693 0.05210868 0.04414231 0.06616406
 0.0518904  0.06616402 0.06378591 0.04414229 0.06616406 0.06616403
 0.0451633  0.04504817 0.04337037 0.06616417 0.0520734  0.04349676
 0.06606804 0.06363241 0.04504823 0.04724008 0.06616402 0.06616406
 0.04414228 0.04469847 0.06616406 0.04337035 0.0518904  0.04504817
 0.06616405 0.04516331 0.04516327 0.04337031 0.04337053 0.04376093
 0.04516331 0.04472736 0.04504818 0.05189041 0.04337167 0.04860973
 0.04504817 0.03920066]
tr_loss:[0.02595787 0.063411   0.02783259 0.06341094 0.02783458 0.06341098
 0.03129213 0.03992712 0.0352645  0.06286071 0.068495   0.02989358
 0.06341098 0.04037549 0.02783458 0.02813364 0.03599808 0.03598047
 0.06341099 0.04134301 0.02596616 0.03526451 0.02783458 0.02783461
 0.02783461 0.06341171 0.02783458 0.02253314 0.02821155 0.03129215
 0.03129216 0.02611757 0.03618716 0.02253126 0.03129216 0.02253095
 0.02599838 0.063411   0.02783569 0.06341098 0.03129213 0.03821242
 0.0278346  0.02782022 0.063411   0.03526447 0.03577353 0.03129213
 0.03129213 0.02783463]
tr_loss:[0.0634611  0.01675599 0.0121563  0.02536429 0.02851883 0.02851892
 0.02480364 0.02480366 0.02476916 0.02600995 0.01877339 0.01265339
 0.01740678 0.05760552 0.02480366 0.02600992 0.02252595 0.02600992
 0.02480366 0.01906307 0.06346111 0.01877339 0.01693567 0.01877339
 0.02480363 0.03637077 0.0381019  0.02440554 0.02600994 0.01740201
 0.02600993 0.02851892 0.01891368 0.01307485 0.06264986 0.02480366
 0.03569666 0.02480366 0.02480365 0.03044524 0.06353448 0.02851807
 0.02600991 0.02383441 0.06346111 0.06346111 0.01740645 0.0304452
 0.0634611  0.02277667]
tr_loss:[0.02126256 0.02279342 0.02278993 0.02278992 0.02300655 0.01594841
 0.02715632 0.0329871  0.06587894 0.02854827 0.06587897 0.02278993
 0.03216997 0.02715632 0.0271563  0.04104682 0.0271566  0.0283796
 0.02111929 0.06587897 0.06587896 0.01594851 0.06587896 0.065879
 0.06587899 0.02550174 0.06268875 0.01724292 0.0110846  0.02715615
 0.02300654 0.02278994 0.01594841 0.02420636 0.05034331 0.02715633
 0.06587896 0.04045791 0.02278994 0.02715631 0.02278992 0.06590146
 0.02715632 0.02278994 0.02739581 0.02715629 0.00904668 0.02854699
 0.02710469 0.0283796 ]
tr_loss:[0.01903831 0.06249305 0.00824335 0.02703946 0.02655298 0.05735565
 0.026641   0.06249307 0.01903829 0.02703922 0.01318123 0.02489835
 0.06249303 0.02431218 0.00919771 0.0190383  0.01318123 0.03842754
 0.0190399  0.02679118 0.02505267 0.02745628 0.02489859 0.01318124
 0.01903831 0.02489835 0.04018299 0.02655297 0.02655298 0.02489824
 0.05719907 0.01903828 0.06249303 0.02655299 0.02655297 0.03253286
 0.01320797 0.0082204  0.02662459 0.02504026 0.06249306 0.01903912
 0.02703946 0.02655298 0.02655298 0.02703946 0.02737477 0.02703946
 0.01915805 0.01318185]
tr_loss:[0.00968994 0.02366101 0.02508161 0.05395593 0.0148951  0.00968992
 0.05647779 0.00863758 0.01489509 0.02366101 0.056476   0.0267766
 0.02409232 0.01489509 0.0148951  0.00884774 0.02508161 0.00855512
 0.0148951  0.01489516 0.00968994 0.0275947  0.0232696  0.03630523
 0.0148951  0.05647777 0.01142976 0.02366101 0.05647777 0.0267766
 0.00980179 0.02552658 0.0085551  0.02677671 0.05647484 0.01489508
 0.00968994 0.00963414 0.00969465 0.02506745 0.05232116 0.02508158
 0.02366102 0.00968995 0.01489511 0.0267766  0.00855531 0.05647781
 0.01489511 0.00855511]
tr_loss:[0.02919548 0.05077136 0.01372747 0.02058703 0.05077134 0.05077133
 0.02504581 0.05077135 0.05077135 0.00881615 0.02058702 0.02924123
 0.02683056 0.02058705 0.05077134 0.02477167 0.00877827 0.00879704
 0.02923619 0.01372748 0.02058705 0.05077128 0.02134698 0.01735849
 0.02924122 0.0113753  0.02058476 0.00765024 0.0250512  0.0135174
 0.05077135 0.0292264  0.02924118 0.05077134 0.00877825 0.03520672
 0.01584062 0.00877827 0.01372977 0.02505148 0.00877827 0.01372746
 0.02058704 0.02060332 0.00877795 0.02623155 0.05077137 0.03690953
 0.0138532  0.05077134]
tr_loss:[0.00968033 0.01621881 0.04248089 0.0294893  0.01443958 0.02672878
 0.00968259 0.01434813 0.00968258 0.01214776 0.04262872 0.01616065
 0.01616063 0.02201835 0.0426287  0.00968258 0.00968258 0.01444899
 0.02638823 0.02833005 0.01444902 0.01214752 0.00962765 0.03813956
 0.02675824 0.02613702 0.02672886 0.01616063 0.00968373 0.02973303
 0.04261634 0.02613714 0.04262869 0.02672887 0.01616065 0.04262869
 0.03111675 0.00968258 0.00968259 0.00968324 0.03124877 0.01617173
 0.0426287  0.02387315 0.01444899 0.01616064 0.02416585 0.01434938
 0.02672887 0.04248087]
tr_loss:[0.01923029 0.01923026 0.00884616 0.02081066 0.01964485 0.02080031
 0.03611932 0.03611929 0.03677294 0.00884615 0.00884617 0.02281866
 0.01466421 0.00884617 0.00884615 0.01023    0.01964486 0.01923027
 0.02548314 0.03611933 0.01023001 0.01023001 0.03312547 0.01923027
 0.02428039 0.03677293 0.03386985 0.01023    0.01023    0.03386918
 0.02081066 0.03611932 0.00884615 0.01964484 0.01023001 0.00879484
 0.00884616 0.02431173 0.01923027 0.01962942 0.03611933 0.01923029
 0.01923029 0.02281739 0.02693971 0.01023001 0.01923027 0.03611934
 0.01315967 0.02547364]
tr_loss:[0.01514883 0.01514883 0.02473927 0.03623482 0.01991476 0.01514882
 0.018267   0.02473871 0.01046054 0.01822077 0.0247387  0.02489068
 0.03623495 0.01046055 0.01991429 0.0247387  0.01514882 0.01045899
 0.01514875 0.02775716 0.02473872 0.02131444 0.01514883 0.0151488
 0.01759046 0.01510976 0.03623495 0.02473872 0.03623494 0.0151488
 0.01826701 0.03333334 0.03961008 0.02473871 0.01991432 0.03623492
 0.02409543 0.02473872 0.02440071 0.01514883 0.0248237  0.02473872
 0.01046055 0.0248237  0.01514882 0.01991432 0.03623493 0.01514883
 0.0362349  0.01043707]
tr_loss:[0.0182117  0.0110741  0.036307   0.03256137 0.0110741  0.0229482
 0.03256211 0.01432942 0.01767978 0.01432944 0.0229482  0.03630698
 0.04029832 0.01432759 0.01767977 0.03630697 0.03630698 0.01524923
 0.01107411 0.0152446  0.02294819 0.01432944 0.01769733 0.03630698
 0.0229482  0.02294818 0.03630696 0.03630697 0.02294821 0.01767977
 0.0110741  0.01873978 0.03630699 0.01107412 0.01432944 0.01761828
 0.01432944 0.02333211 0.01495348 0.02294821 0.01524925 0.01767979
 0.0229482  0.02121429 0.03813715 0.01767977 0.01432939 0.03630687
 0.01767976 0.02298343]
tr_loss:[0.01072213 0.01199006 0.01516602 0.0171147  0.01711468 0.01711469
 0.02612987 0.01072214 0.0171147  0.0368182  0.02130632 0.01522566
 0.01522518 0.01072214 0.01199007 0.01711469 0.01199006 0.02133776
 0.01072211 0.02612986 0.02133815 0.01711469 0.01526543 0.01720394
 0.01199007 0.01072214 0.02133815 0.01199005 0.02685521 0.02133814
 0.0171147  0.01072217 0.01719224 0.01072211 0.01072212 0.02132752
 0.03682553 0.02613003 0.01073237 0.01072214 0.02133808 0.03682553
 0.03682552 0.03682553 0.01711469 0.01199005 0.03682553 0.01072201
 0.01720392 0.01197225]
tr_loss:[0.01477232 0.00699223 0.02054557 0.01407239 0.01407239 0.0387652
 0.01982863 0.01248754 0.03876519 0.01643115 0.00699223 0.00588946
 0.00600618 0.01407237 0.03876516 0.02885108 0.01248754 0.03876519
 0.00586547 0.01642919 0.01248757 0.01982872 0.01982863 0.00699317
 0.04031947 0.01248755 0.0387652  0.01982863 0.01248755 0.0387652
 0.03876509 0.01407238 0.03465469 0.01477232 0.01982862 0.00699223
 0.01982863 0.01345916 0.04031944 0.01407239 0.00699221 0.02619484
 0.02861017 0.00614238 0.01248755 0.0387652  0.00699223 0.01248755
 0.01248755 0.00863001]
tr_loss:[0.00760519 0.02933239 0.01306598 0.02131022 0.01820389 0.00753949
 0.01872855 0.01306598 0.04369576 0.04369574 0.04369576 0.04369574
 0.00775609 0.01872856 0.01872855 0.04369576 0.01092448 0.01872855
 0.02135389 0.01872854 0.01306599 0.03930236 0.02228106 0.01872855
 0.00754502 0.00754003 0.03060347 0.02847104 0.04156629 0.00763073
 0.01872855 0.00760519 0.00753961 0.01872855 0.04369574 0.02257332
 0.03450579 0.01872855 0.04369574 0.04369574 0.03215345 0.01306598
 0.04482096 0.01306611 0.02228105 0.00753949 0.01306599 0.00760519
 0.01306599 0.01820451]
tr_loss:[0.01339084 0.01339084 0.01784785 0.01829643 0.017848   0.01339084
 0.0133997  0.01339084 0.01591223 0.01829575 0.00717934 0.00725317
 0.01339083 0.01784801 0.01829642 0.02151513 0.01784796 0.01574022
 0.01737561 0.00979818 0.00698795 0.04425712 0.04425708 0.04425712
 0.02646676 0.04425713 0.04425713 0.017848   0.01784801 0.01829641
 0.01670949 0.01829569 0.00698932 0.04425712 0.0306516  0.03041412
 0.01829643 0.02151501 0.04425712 0.04425712 0.029102   0.01745881
 0.01785891 0.02523133 0.01784807 0.02522534 0.01784892 0.01339085
 0.01829642 0.04425713]
tr_loss:[0.006099   0.02273674 0.0049765  0.04066534 0.01780896 0.00497657
 0.01780703 0.00498098 0.02659705 0.00498529 0.0126037  0.00415555
 0.01336592 0.0055554  0.03722586 0.02309503 0.01596659 0.02442524
 0.01336595 0.01566056 0.01336594 0.01336592 0.00452024 0.0265971
 0.04028077 0.01259025 0.00555539 0.01780825 0.01566074 0.00497676
 0.01258896 0.01336593 0.01919121 0.02273664 0.01259025 0.0156606
 0.00553188 0.01259026 0.00497658 0.00497657 0.01259026 0.04066537
 0.01336594 0.0049788  0.00497657 0.04066535 0.0190034  0.04066524
 0.04066534 0.00497658]
tr_loss:[0.0374961  0.00459971 0.01604521 0.00991543 0.01604521 0.01604761
 0.01605244 0.03749608 0.00861298 0.02240042 0.00588899 0.00459971
 0.03749586 0.03438098 0.01943385 0.01604521 0.01418252 0.0374961
 0.01425092 0.00459973 0.01604521 0.03749608 0.02353944 0.01317855
 0.01380341 0.01606707 0.00861311 0.01425086 0.02494779 0.03749608
 0.01699755 0.03805851 0.02185171 0.00595492 0.0045997  0.02221293
 0.0045997  0.02106924 0.0140152  0.01490308 0.00459977 0.03842039
 0.00459971 0.01448816 0.0374958  0.00627906 0.01604521 0.02898633
 0.0045997  0.03749609]
tr_loss:[0.00789508 0.01511948 0.03779909 0.03673714 0.00703843 0.01836346
 0.03673157 0.00877836 0.00704796 0.02183352 0.0183645  0.03782245
 0.0186786  0.01836347 0.01744244 0.01836347 0.01836345 0.00789508
 0.00750072 0.01836345 0.00704794 0.01957549 0.00789509 0.03673711
 0.02183018 0.01836346 0.0070478  0.01512346 0.01160624 0.00789507
 0.03782228 0.03673713 0.01836346 0.01917687 0.02169879 0.03673714
 0.02916983 0.03673714 0.00789509 0.01779141 0.02751965 0.01744244
 0.00789508 0.01744242 0.03673711 0.03673711 0.00789507 0.00704794
 0.00704481 0.03782228]
tr_loss:[0.02004706 0.02029677 0.03412421 0.03837748 0.03690656 0.0369066
 0.00908794 0.00994329 0.00930403 0.03158296 0.0093041  0.00930403
 0.02090974 0.01173656 0.03830122 0.01645821 0.00908794 0.0112041
 0.0369066  0.00908794 0.02004707 0.02029163 0.02926238 0.03690597
 0.03690657 0.02290148 0.03830439 0.02726161 0.03690658 0.00930403
 0.03690659 0.01017885 0.03397467 0.03690658 0.02004708 0.00930403
 0.00930403 0.03443234 0.01121384 0.00931478 0.03404977 0.02029161
 0.02090963 0.01017737 0.00908793 0.03690658 0.01317597 0.02029163
 0.02029164 0.03690659]
tr_loss:[0.0328185  0.03282082 0.03291393 0.02066644 0.02031431 0.01829799
 0.01555213 0.0081673  0.00930239 0.00816729 0.01793111 0.00816729
 0.0081673  0.03577729 0.01555213 0.00930239 0.01808108 0.0155521
 0.03221432 0.0179995  0.01793111 0.03097538 0.00930239 0.02277936
 0.01005749 0.01005822 0.00930239 0.01793112 0.0357773  0.01793112
 0.02274768 0.00930238 0.0081673  0.0081673  0.00816729 0.00930239
 0.00930239 0.01793111 0.00930237 0.00894167 0.01793112 0.00816783
 0.03577731 0.02031434 0.02621304 0.01001886 0.0155521  0.0357773
 0.00930237 0.01793111]
tr_loss:[0.00695287 0.03461703 0.03461701 0.03461704 0.03461701 0.03456733
 0.00521253 0.01345551 0.00921464 0.00921462 0.01058602 0.00921464
 0.01632659 0.00521254 0.03461702 0.00521253 0.02401006 0.03461703
 0.02472649 0.00921464 0.02223529 0.00521254 0.03461702 0.02200672
 0.03461703 0.03461703 0.00921464 0.03461704 0.01967533 0.03157963
 0.00521103 0.01362118 0.02200642 0.02200642 0.03461701 0.00695633
 0.00521252 0.010419   0.00921462 0.02705492 0.01345551 0.01362556
 0.01345551 0.00520962 0.00921463 0.01345551 0.00521254 0.00521252
 0.0136235  0.0190178 ]
tr_loss:[0.00695404 0.0220336  0.00421837 0.01102821 0.02504136 0.00573845
 0.03536817 0.01279897 0.01364204 0.01135611 0.00421835 0.03317928
 0.03531573 0.01102819 0.01893524 0.00611132 0.00421836 0.01102821
 0.03536817 0.01893526 0.00611131 0.01893526 0.00421834 0.03536819
 0.03536819 0.00611131 0.01102821 0.03536819 0.02146312 0.01135618
 0.01102821 0.01893527 0.01705339 0.01102819 0.01135611 0.0234541
 0.03536816 0.00422291 0.00421835 0.01102821 0.0313306  0.01522793
 0.0136306  0.01102821 0.0343268  0.01135612 0.00421834 0.03536819
 0.01102821 0.0237061 ]
tr_loss:[0.03744402 0.03744934 0.01228102 0.01286825 0.00489762 0.02451748
 0.0144386  0.01471856 0.01471856 0.02617652 0.0374449  0.00489815
 0.01894732 0.01471953 0.03744488 0.0048975  0.01471225 0.02487257
 0.0116818  0.01471856 0.00490144 0.02487161 0.02169788 0.01286825
 0.00511629 0.02617647 0.01168152 0.01286825 0.0061335  0.02531614
 0.00495142 0.01168152 0.03397209 0.02416151 0.01286826 0.01471856
 0.01286826 0.0061335  0.0185356  0.03744489 0.03744492 0.00486708
 0.0374449  0.01168208 0.00687428 0.01809938 0.01448501 0.00495298
 0.02522143 0.00489811]
tr_loss:[0.01248641 0.01488543 0.00678953 0.02108403 0.0126359  0.00537466
 0.00767061 0.012631   0.012631   0.03851341 0.00363939 0.00537466
 0.01488544 0.00760443 0.01766343 0.0148854  0.02500916 0.01263099
 0.00748575 0.01248641 0.02097113 0.00759675 0.00537465 0.01488546
 0.02439277 0.03482084 0.00543453 0.0347568  0.01488345 0.01488546
 0.01248642 0.01258558 0.00760441 0.02132995 0.01327559 0.00543452
 0.00537466 0.03509014 0.02500914 0.01488544 0.01248643 0.03851341
 0.00537466 0.012631   0.00524336 0.01263102 0.02486582 0.02486411
 0.03851342 0.01248643]
tr_loss:[0.01073326 0.01598074 0.00530613 0.00543223 0.01051477 0.01405032
 0.01931876 0.00530395 0.01405015 0.01306252 0.01869825 0.01306248
 0.00530613 0.0130625  0.01405032 0.00530613 0.01073326 0.0130625
 0.03781862 0.0244651  0.0130625  0.01405034 0.00455442 0.01085508
 0.00782229 0.01598389 0.00530613 0.01405032 0.01073325 0.01306483
 0.03781859 0.0378186  0.03391261 0.01516371 0.01073249 0.00535477
 0.03781863 0.03781862 0.01405032 0.0130625  0.00506684 0.0130625
 0.01073326 0.03781863 0.00530502 0.0130625  0.03781863 0.0130625
 0.01598389 0.0160575 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3400 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3401, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3401 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3402, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3402 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3403, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3403 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3404, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3404 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3405, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3405 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3406, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3406 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3407, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3407 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3408, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3408 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3409, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3409 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3410, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3410 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3411, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3411 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3412, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3412 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3413, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3413 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3414, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3414 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3415, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3415 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3416, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3416 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3417, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3417 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3418, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3418 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3419, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3419 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3420, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3420 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3421, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3421 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3422, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3422 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3423, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3423 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3424, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3424 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3425, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3425 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3426, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3426 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3427, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3427 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3428, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3428 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3429, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3429 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3430, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3430 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3431, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3431 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3432, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3432 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3433, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3433 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3434, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3434 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3435, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3435 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3436, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3436 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3437, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3437 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3438, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3438 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3439, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3439 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3440, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3440 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3441, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3441 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3442, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3442 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3443, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3443 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3444, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3444 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3445, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3445 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3446, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3446 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3447, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3447 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3448, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3448 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3449, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3449 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3450, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3450 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3451, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3451 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3452, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3452 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3453, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3453 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3454, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3454 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3455, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3455 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3456, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3456 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3457, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3457 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3458, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3458 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3459, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3459 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3460, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3460 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3461, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3461 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3462, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3462 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3463, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3463 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3464, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3464 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3465, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3465 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3466, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3466 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3467, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3467 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3468, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3468 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3469, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3469 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3470, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3470 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3471, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3471 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3472, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3472 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3473, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3473 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3474, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3474 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3475, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3475 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3476, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3476 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3477, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3477 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3478, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3478 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3479, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3479 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3480, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3480 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3481, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3481 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3482, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3482 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3483, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3483 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3484, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3484 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3485, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3485 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3486, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3486 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3487, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3487 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3488, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3488 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3489, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3489 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3490, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3490 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3491, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3491 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3492, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3492 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3493, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3493 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3494, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3494 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3495, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3495 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3496, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3496 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3497, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3497 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3498, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3498 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3499, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3499 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3500, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-3400
text_input.shape
(3500, 14400)
learning_input_tmp.shape
(3500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3500, 80)
learning_output.shape
(750, 80)
Model: "sequential_71"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_71 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3062103 1.307647  1.3632288 1.225592  1.3003762 1.3362136 1.3632288
 1.2972775 1.3140479 1.3369348 1.3632288 1.2908845 1.3093703 1.1800339
 1.3198842 1.3632387 1.35754   1.1800337 1.3093702 1.3081071 1.2040427
 1.3112795 1.3448474 1.3112797 1.3093698 1.1800336 1.3462633 1.3448478
 1.1804197 1.3202878 1.2259642 1.2096651 1.1800333 1.1805905 1.3632288
 1.3448478 1.3632289 1.3140479 1.2943778 1.2363263 1.3093703 1.2943773
 1.308111  1.3682487 1.3152527 1.3193033 1.3088448 1.3632288 1.3632287
 1.3575054]
tr_loss:[0.7687855  0.6465923  0.7324749  0.72621435 0.7230053  0.730645
 0.7014826  0.7244649  0.7315021  0.732475   0.7014824  0.7251453
 0.75777686 0.768644   0.7306514  0.7235266  0.7235465  0.73783195
 0.7573872  0.7014824  0.69490486 0.7368782  0.7324749  0.730645
 0.6520961  0.7378321  0.7250841  0.6949049  0.6949048  0.69490635
 0.7594175  0.72506976 0.6693555  0.6949049  0.6431595  0.65605146
 0.7324749  0.7014824  0.7262038  0.6416562  0.7110473  0.72514737
 0.72438955 0.6559874  0.72514737 0.72514725 0.73247504 0.6416548
 0.72354645 0.6418165 ]
tr_loss:[0.27734736 0.32881123 0.2572891  0.2955719  0.3079733  0.29769892
 0.2980897  0.2730511  0.3029687  0.30581138 0.3080748  0.25892788
 0.29557163 0.27734718 0.2913541  0.29892495 0.29808968 0.3081081
 0.2819329  0.29191583 0.29979867 0.30810803 0.29557186 0.298356
 0.2980897  0.3081081  0.2741393  0.28133535 0.29808968 0.2601592
 0.27712828 0.29892498 0.29814205 0.2773562  0.3287878  0.29524058
 0.29808974 0.29808968 0.30810806 0.29415435 0.281336   0.29892498
 0.29808968 0.2980897  0.2813354  0.32200354 0.25728914 0.2731617
 0.29980034 0.28133535]
tr_loss:[0.1312408  0.12509494 0.15067275 0.1348359  0.12909904 0.14429656
 0.133998   0.14988284 0.14429662 0.14988288 0.1442966  0.14287582
 0.14429656 0.15067606 0.15067299 0.13479595 0.1442966  0.15067299
 0.14538768 0.12508085 0.15067223 0.16125712 0.13493565 0.1442966
 0.13483596 0.13134624 0.16197632 0.1508336  0.14287686 0.1505484
 0.1442966  0.14429304 0.13483596 0.13123915 0.14538762 0.13483599
 0.14166555 0.12509501 0.13399799 0.1442966  0.15811487 0.12509502
 0.15067294 0.14988288 0.161976   0.12487935 0.16125712 0.14429657
 0.14285326 0.12509501]
tr_loss:[0.04264512 0.0696248  0.05488033 0.05445629 0.06024111 0.0470382
 0.05488034 0.05471191 0.04264626 0.06196815 0.05632482 0.04631404
 0.06182794 0.05488032 0.05884143 0.05393007 0.04652941 0.05488034
 0.05125126 0.0548803  0.05393008 0.05632483 0.0470382  0.0468311
 0.05124301 0.05459959 0.06182794 0.06962477 0.05528556 0.05488034
 0.04637297 0.05868596 0.05868593 0.05632482 0.05218145 0.05632483
 0.051243   0.05868596 0.05868594 0.0470382  0.05632211 0.05528557
 0.05393171 0.05868596 0.05486912 0.05488035 0.05632467 0.06196774
 0.05126694 0.04631403]
tr_loss:[0.03613541 0.02770559 0.03268839 0.02642307 0.02916652 0.06957822
 0.06957819 0.02698567 0.02824244 0.02977824 0.02251037 0.03109984
 0.02622985 0.06445244 0.04178414 0.02918962 0.04387382 0.0262298
 0.02622983 0.02770803 0.02824246 0.04178883 0.03674449 0.03109981
 0.03613541 0.0695782  0.02622986 0.02622772 0.02622875 0.06957825
 0.03613537 0.02395535 0.0367445  0.03109983 0.03109984 0.02623039
 0.0695782  0.02707596 0.01499702 0.02913038 0.02623123 0.02622983
 0.0279441  0.02919099 0.06957817 0.02644021 0.03613539 0.02622985
 0.03143866 0.03109983]
tr_loss:[0.03600505 0.0360041  0.08027866 0.03281    0.02351219 0.02980625
 0.05033751 0.03599862 0.03600504 0.03980367 0.03600501 0.03980365
 0.08106913 0.04040097 0.0270541  0.03980364 0.02257385 0.03980365
 0.03980363 0.04782451 0.03980367 0.04871847 0.05172889 0.02980624
 0.03980368 0.03330941 0.03582112 0.01415073 0.0298073  0.01422001
 0.03502245 0.03281    0.02705364 0.08036453 0.0270536  0.02705362
 0.03980363 0.03281001 0.02980625 0.03980365 0.02586202 0.03436922
 0.03203421 0.03980365 0.03280998 0.02696927 0.03980365 0.03436308
 0.03169966 0.05245499]
tr_loss:[0.03305275 0.04097889 0.02784169 0.03500694 0.03304247 0.08214186
 0.0424934  0.03776937 0.03305488 0.03500696 0.08114408 0.03776938
 0.03776931 0.03513564 0.03400538 0.03500696 0.03140482 0.0376909
 0.03776591 0.03305487 0.04097865 0.03305488 0.03902868 0.01469146
 0.05006216 0.02784172 0.03776938 0.01472635 0.03500696 0.01742669
 0.01759185 0.01732939 0.02783559 0.04197086 0.0377694  0.03305482
 0.01469308 0.03224598 0.02793537 0.03776916 0.07448097 0.03400537
 0.02784171 0.03305194 0.08187955 0.0409789  0.02784167 0.0500626
 0.03400538 0.04248552]
tr_loss:[0.0319444  0.02691438 0.02692584 0.02759005 0.02460721 0.07869568
 0.07450126 0.03610986 0.03194444 0.04031566 0.03052863 0.03910584
 0.01597068 0.03035531 0.0786957  0.04080187 0.03306038 0.07450074
 0.01423944 0.02692584 0.03194444 0.02825088 0.02692586 0.02692586
 0.03610908 0.01510488 0.03610988 0.05162295 0.02692583 0.04068068
 0.03473292 0.0391058  0.02692682 0.03306039 0.07869567 0.02692586
 0.07869568 0.0331028  0.03910583 0.0330604  0.0141006  0.03910583
 0.02156937 0.03910581 0.03610967 0.03054709 0.04794852 0.02692591
 0.06774648 0.0331028 ]
tr_loss:[0.06340794 0.04298532 0.02494634 0.01326221 0.06279768 0.02865464
 0.02865462 0.03093904 0.02494526 0.02792062 0.07022469 0.02933972
 0.07186304 0.07022468 0.0360435  0.03459839 0.02494509 0.0345984
 0.01299835 0.02328033 0.02494504 0.04603662 0.02933909 0.03177356
 0.03093905 0.02792063 0.07015465 0.02905011 0.0702247  0.02933972
 0.02490713 0.02278937 0.07022468 0.07022469 0.01300346 0.02791112
 0.0416226  0.0249732  0.04734296 0.07022412 0.02494473 0.03459847
 0.07022466 0.03933191 0.02494505 0.02494507 0.01299836 0.04302668
 0.03604376 0.02523371]
tr_loss:[0.0601049  0.02690836 0.01158434 0.03874259 0.03072977 0.02469863
 0.02786796 0.02928254 0.02444498 0.06010494 0.02575698 0.0369113
 0.02444495 0.02989075 0.05722784 0.02787691 0.0601049  0.02543919
 0.02990017 0.02698766 0.06010438 0.02575698 0.02444498 0.05723041
 0.02990141 0.02789492 0.03913583 0.02444497 0.02990017 0.02688668
 0.02444503 0.06009509 0.02782509 0.02331673 0.02990016 0.02444498
 0.01350841 0.02990019 0.02444497 0.03660123 0.02491336 0.02444496
 0.02444493 0.06010492 0.02051241 0.02990017 0.03072977 0.04310906
 0.02575697 0.0257569 ]
tr_loss:[0.02859314 0.01824394 0.05142392 0.02136975 0.04438622 0.02364773
 0.05418665 0.02184248 0.032631   0.02364762 0.02364771 0.02172284
 0.03310075 0.02195931 0.01867086 0.01823317 0.03559165 0.02188758
 0.02136977 0.05100732 0.02188757 0.01867078 0.02188755 0.02136979
 0.04953597 0.02184311 0.02184313 0.02355093 0.03355109 0.05418665
 0.03688501 0.0213698  0.02280569 0.02188758 0.02158162 0.00861074
 0.03310075 0.02188758 0.0215864  0.05142405 0.05142391 0.0087658
 0.02188768 0.01603441 0.01867084 0.02136979 0.02188758 0.00763285
 0.02244023 0.0487201 ]
tr_loss:[0.01716955 0.02273879 0.03733671 0.05441324 0.03057652 0.04649296
 0.03290354 0.01475026 0.05441324 0.03057651 0.02650863 0.03290351
 0.0451846  0.02650923 0.02650862 0.04861747 0.03983692 0.05441324
 0.05441324 0.03057652 0.0171697  0.05441325 0.05761967 0.02699642
 0.05441322 0.02713456 0.02271231 0.05441322 0.03053129 0.0603251
 0.04856079 0.03290292 0.03290023 0.02699745 0.02650861 0.05752428
 0.04124496 0.02699741 0.02835295 0.03057641 0.03057652 0.05441322
 0.03289194 0.05750478 0.03057647 0.0305765  0.05840335 0.03731587
 0.03731573 0.0373157 ]
tr_loss:[0.02411236 0.02351582 0.02409619 0.04991136 0.02351581 0.0247957
 0.04102777 0.04094673 0.02679953 0.0409467  0.02015824 0.02409807
 0.0272705  0.04094671 0.02409616 0.02841973 0.02841973 0.03929391
 0.02855861 0.038845   0.02405261 0.04094668 0.04947099 0.02472584
 0.05810624 0.02766933 0.02766895 0.01247365 0.04094671 0.04947095
 0.0267996  0.02841973 0.02765504 0.02479572 0.02408957 0.02479569
 0.02015822 0.02015824 0.04094672 0.04094673 0.02409619 0.03516478
 0.02409619 0.02409619 0.02351579 0.02841973 0.02679964 0.05602694
 0.02410493 0.02534163]
tr_loss:[0.01961924 0.03478244 0.01961923 0.01896841 0.05805312 0.01875558
 0.01961923 0.018759   0.05088329 0.03478242 0.01875553 0.01962275
 0.03478241 0.02137048 0.02195379 0.03478242 0.0187556  0.05805315
 0.00942503 0.01963234 0.02137048 0.05805312 0.05959951 0.0218808
 0.01658024 0.01961922 0.05525448 0.02137048 0.01876234 0.01961921
 0.00942503 0.03478241 0.01875558 0.01845946 0.05805315 0.0219538
 0.05805315 0.02065031 0.01875557 0.02195383 0.0187556  0.0219538
 0.03775092 0.05805315 0.05805316 0.03096844 0.05547919 0.02137048
 0.0196192  0.03478238]
tr_loss:[0.02673804 0.022872   0.02285595 0.02082747 0.00637689 0.022872
 0.01677506 0.02287201 0.0580905  0.01690088 0.00951688 0.03159607
 0.0228815  0.01144452 0.02288431 0.05807511 0.01947583 0.03632098
 0.02035072 0.022872   0.05807514 0.0191638  0.00951688 0.01677498
 0.0228722  0.03549773 0.00637684 0.02288447 0.02242608 0.05943561
 0.022872   0.05807512 0.022872   0.02673802 0.01677499 0.00951688
 0.05507051 0.01677499 0.01677499 0.01500452 0.00978527 0.02204993
 0.05807528 0.02673802 0.00638263 0.00639235 0.01947584 0.017044
 0.022872   0.03396806]
tr_loss:[0.02361243 0.04048848 0.05660658 0.02904145 0.02904147 0.03892859
 0.02904145 0.02373149 0.02049309 0.05981231 0.02608244 0.027431
 0.03513436 0.02905051 0.02549571 0.03892881 0.01860422 0.02549571
 0.0598116  0.02904138 0.02549571 0.02904147 0.02520382 0.02904146
 0.02256875 0.03792517 0.03192007 0.0236124  0.02361242 0.00951709
 0.02743099 0.01861083 0.02608117 0.05660397 0.00853905 0.0598123
 0.02608239 0.01861372 0.01134894 0.0236124  0.02262154 0.03792502
 0.05981231 0.00973732 0.04045524 0.03792502 0.02904147 0.02361242
 0.02285483 0.02904144]
tr_loss:[0.02528729 0.02102213 0.0213089  0.02468901 0.0172142  0.01720957
 0.03005341 0.02528728 0.0172144  0.01721422 0.0213089  0.01721409
 0.02530343 0.03005336 0.01721425 0.01721424 0.02099615 0.00959044
 0.03005336 0.02291897 0.03005334 0.02291897 0.01721424 0.02468833
 0.0171271  0.02468899 0.02247529 0.02528729 0.05620029 0.01171269
 0.02101158 0.02468901 0.01721423 0.05772299 0.02468843 0.03005337
 0.02037876 0.01735334 0.01294099 0.02291897 0.02468901 0.01109865
 0.04264186 0.01721186 0.02528728 0.02460028 0.01721425 0.05620028
 0.02468899 0.03005333]
tr_loss:[0.01458758 0.02840922 0.01936056 0.03088721 0.05240304 0.0154505
 0.01015585 0.05075973 0.0524295  0.018522   0.02996918 0.01458661
 0.05075762 0.03088723 0.01777743 0.01458659 0.03484237 0.03592256
 0.02841158 0.01502621 0.03239356 0.018522   0.01458661 0.04661821
 0.02210157 0.02210933 0.0101714  0.0145866  0.02210932 0.0240953
 0.04995487 0.02210933 0.05075978 0.0284111  0.03088723 0.03590979
 0.01936055 0.03088722 0.03392984 0.03088721 0.0350218  0.01849784
 0.02210931 0.03088542 0.03088721 0.01461557 0.02209598 0.04970504
 0.00705677 0.00958076]
tr_loss:[0.0136631  0.0484502  0.01275452 0.0159373  0.01909563 0.02591499
 0.0366393  0.01188792 0.02591501 0.01366311 0.01367526 0.01606964
 0.04271583 0.03638365 0.01356409 0.01366308 0.01611639 0.01366311
 0.01909557 0.02143365 0.04845022 0.01909547 0.02560937 0.00641449
 0.01188793 0.01366328 0.01563026 0.01188794 0.0256094  0.01366468
 0.03638505 0.03834265 0.03638359 0.01366311 0.02143365 0.01191159
 0.01563027 0.01188794 0.01366307 0.01366311 0.04845018 0.02560939
 0.01366311 0.02560939 0.02591501 0.0161164  0.04270045 0.01366224
 0.01275497 0.03103812]
tr_loss:[0.05274938 0.0158419  0.01895067 0.04418197 0.02825282 0.02825283
 0.01548427 0.0056277  0.03669762 0.05069264 0.0345166  0.0134527
 0.02048337 0.05069264 0.0225259  0.02825284 0.00562769 0.02188072
 0.0159475  0.05069264 0.05218033 0.02825282 0.0204827  0.05069264
 0.01584572 0.05069265 0.01595038 0.01594747 0.01526912 0.00563583
 0.0282528  0.01594729 0.05069263 0.03072452 0.02048335 0.02188216
 0.0159562  0.02048335 0.01895085 0.0159475  0.03317016 0.02149228
 0.03284391 0.02048337 0.03065514 0.05069268 0.03026367 0.02185972
 0.02048333 0.01594749]
tr_loss:[0.052958   0.03362806 0.01999927 0.01878458 0.02000579 0.0348975
 0.02000638 0.0551232  0.02000555 0.02089724 0.01797715 0.02089724
 0.01816717 0.01690691 0.02000638 0.01649541 0.01797712 0.03362609
 0.03180355 0.01932335 0.03180358 0.01797715 0.04599141 0.01797715
 0.01799773 0.01878456 0.02089719 0.05470958 0.01878458 0.0384265
 0.052958   0.02096322 0.04591654 0.01878458 0.01797939 0.01802147
 0.01797712 0.0166772  0.05295801 0.03958483 0.01878458 0.01998104
 0.03180357 0.01797714 0.01878458 0.03939001 0.03180355 0.05295799
 0.006872   0.04599144]
tr_loss:[0.00541579 0.05286347 0.01903415 0.01948844 0.03671893 0.00645551
 0.05286342 0.01366959 0.01903415 0.02641605 0.01814724 0.01714105
 0.01903602 0.03325221 0.0195599  0.05501046 0.01790105 0.01751208
 0.05293568 0.04577105 0.01714064 0.01713518 0.02445153 0.03894122
 0.03927589 0.05410229 0.01714104 0.03504309 0.01903416 0.0343977
 0.01627172 0.01814722 0.05286344 0.02978742 0.05286342 0.01903415
 0.01814718 0.02978739 0.01714101 0.05410069 0.01381342 0.01814722
 0.01366959 0.01903415 0.01814723 0.01963272 0.0201909  0.01814724
 0.02978741 0.01903415]
tr_loss:[0.01840281 0.05228644 0.01060516 0.01963132 0.02522163 0.01059066
 0.02655491 0.01999997 0.01639315 0.02887586 0.00506312 0.03407618
 0.03504321 0.03623607 0.01639315 0.00680891 0.01329041 0.01639321
 0.03372969 0.02655491 0.02522173 0.01999995 0.01945045 0.01945044
 0.01945046 0.01945046 0.00506286 0.01999995 0.01952939 0.01059098
 0.03268715 0.01840318 0.01951135 0.02552072 0.01384285 0.01059064
 0.01688242 0.01639317 0.01945153 0.01840318 0.04936237 0.05435791
 0.01999471 0.01999996 0.01647488 0.01639439 0.03623604 0.02552057
 0.01639317 0.01945046]
tr_loss:[0.05252811 0.01119418 0.02220068 0.05252806 0.0218702  0.05252912
 0.05252811 0.0322286  0.00925532 0.02187021 0.02552282 0.01616315
 0.0218702  0.0525281  0.02457351 0.03422396 0.01950529 0.02187022
 0.01616314 0.0218702  0.00810837 0.01389473 0.03411599 0.01950528
 0.03222839 0.01622268 0.0218702  0.01616321 0.0092518  0.02103794
 0.02608766 0.01939007 0.02103745 0.01740542 0.02457351 0.01616312
 0.0161343  0.01391826 0.02103785 0.01939009 0.05252808 0.01809642
 0.01740542 0.02076739 0.0092518  0.01951114 0.01433974 0.0195124
 0.0525281  0.01616314]
tr_loss:[0.04079079 0.05118977 0.00883755 0.05118978 0.01456484 0.04843848
 0.02059348 0.02188903 0.00883578 0.01675711 0.01695467 0.0236952
 0.02188904 0.02188903 0.01411902 0.02358627 0.02188905 0.03148199
 0.02054754 0.03453513 0.02188905 0.02057418 0.0236952  0.02369521
 0.03453515 0.01456545 0.03661941 0.02059352 0.0289086  0.0205935
 0.02369519 0.05290864 0.02188904 0.03148196 0.01456483 0.01493835
 0.05118977 0.02188904 0.02369521 0.02369521 0.03274911 0.05118974
 0.05118973 0.01456482 0.02053123 0.0236952  0.02369517 0.0145648
 0.0236952  0.05118977]
tr_loss:[0.03076912 0.02023651 0.02004139 0.00815446 0.01949258 0.02366525
 0.01067896 0.01593319 0.02591937 0.05050184 0.0194926  0.00921333
 0.02663955 0.01638607 0.0266395  0.02663304 0.03371195 0.00531724
 0.01331508 0.03120273 0.01638617 0.01283686 0.04624055 0.05050185
 0.01290404 0.01283685 0.03371985 0.04686475 0.0202365  0.01283699
 0.03371705 0.02023649 0.03105639 0.01283685 0.01092836 0.01283686
 0.01330935 0.00531704 0.04489679 0.01593321 0.00532055 0.0202365
 0.01638617 0.01369931 0.01283686 0.01283679 0.01137248 0.02663952
 0.01949258 0.01282149]
tr_loss:[0.01179979 0.01952895 0.02574673 0.01953236 0.02574182 0.01244372
 0.00746119 0.02574673 0.01266069 0.0253591  0.02535908 0.01592697
 0.01266066 0.02535906 0.01955845 0.04562204 0.04147588 0.02047899
 0.02535908 0.02057015 0.01266069 0.05034987 0.03062178 0.01551053
 0.00745944 0.03996134 0.01175467 0.02574673 0.05037902 0.02574672
 0.02574766 0.02743121 0.02535911 0.02574672 0.01551055 0.01266069
 0.03063148 0.0495561  0.02579264 0.05034622 0.01266097 0.03228983
 0.02056926 0.01410542 0.01551055 0.01953238 0.05034989 0.05034991
 0.0503499  0.01953238]
tr_loss:[0.01393062 0.01113587 0.04618719 0.00431406 0.02829661 0.01393107
 0.01235496 0.023948   0.02109573 0.02051264 0.01748901 0.02394799
 0.01393063 0.01113602 0.02016577 0.02016967 0.01235503 0.05024838
 0.01113586 0.01393063 0.0281777  0.01801028 0.00606198 0.03221723
 0.01393062 0.01518373 0.04662473 0.03390151 0.01518373 0.01658816
 0.02016577 0.02837428 0.0438853  0.02149257 0.01658637 0.02016577
 0.01393059 0.01393061 0.01235496 0.02051261 0.03178896 0.02394798
 0.05024841 0.01388014 0.01393063 0.02016573 0.01857775 0.01857893
 0.0316409  0.02016575]
tr_loss:[0.00477493 0.05127762 0.04166203 0.01767603 0.01153663 0.01155843
 0.05127763 0.0512776  0.01857703 0.05079904 0.01824193 0.0265014
 0.01824196 0.01857703 0.01857702 0.03372097 0.0200472  0.01580672
 0.00615826 0.03263559 0.02347659 0.04813187 0.0265014  0.00477484
 0.03362041 0.01887283 0.04492435 0.0512776  0.05127765 0.01158961
 0.00480456 0.0265014  0.02650143 0.01913606 0.0265098  0.01567712
 0.01567709 0.01902338 0.01863549 0.01877275 0.01877283 0.01824196
 0.01857702 0.01153069 0.01245593 0.02650142 0.02650141 0.01854289
 0.01913606 0.02650142]
text_input.shape
(3500, 14400)
learning_input_tmp.shape
(3500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3500, 80)
learning_output.shape
(750, 80)
Model: "sequential_72"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_72 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1866636 1.2522104 1.2256374 1.2452171 1.2256371 1.2744154 1.2992221
 1.2511288 1.2744157 1.3020782 1.2676691 1.2255046 1.2522103 1.3020782
 1.274442  1.2256374 1.2385411 1.2522104 1.2522103 1.2522103 1.2497375
 1.2719944 1.3020782 1.2744154 1.2522104 1.2476165 1.2053262 1.274435
 1.2744154 1.2940816 1.2744154 1.2969716 1.2969096 1.216937  1.2476168
 1.3020782 1.27441   1.2314703 1.2451799 1.2306315 1.2744154 1.2744199
 1.2256373 1.2476169 1.2451823 1.1835127 1.2498564 1.2582169 1.3020782
 1.2050898]
tr_loss:[0.80180943 0.74875206 0.79806346 0.84125125 0.8036593  0.748752
 0.8057121  0.82035    0.7487521  0.8342625  0.804385   0.79806346
 0.7980636  0.8412512  0.8297213  0.7985072  0.80571043 0.8057122
 0.80365944 0.8036593  0.81259763 0.79806346 0.79806346 0.838867
 0.7980634  0.8412512  0.84125125 0.7978637  0.80347335 0.74875206
 0.798854   0.84125125 0.7980634  0.74875206 0.8068838  0.748752
 0.7569805  0.81636775 0.8036593  0.84125125 0.79806346 0.7985169
 0.84125197 0.8427515  0.7985155  0.77145183 0.79806167 0.80365944
 0.75186336 0.7978208 ]
tr_loss:[0.44007176 0.45677394 0.4582573  0.48703367 0.45677525 0.45132655
 0.45132732 0.48703378 0.4513228  0.45132655 0.45132655 0.4595737
 0.45132655 0.44138885 0.45320415 0.46053234 0.45903927 0.44323093
 0.45802316 0.48703355 0.43254477 0.45827428 0.4870337  0.48310906
 0.45802203 0.44007167 0.43673867 0.4636553  0.479858   0.45856994
 0.44363737 0.45132655 0.4437008  0.44594288 0.44112673 0.44229594
 0.45664424 0.4760124  0.43655616 0.45782247 0.44007176 0.45015854
 0.45232573 0.43656826 0.45132652 0.45692897 0.43296418 0.44760996
 0.45829344 0.4513266 ]
tr_loss:[0.22303319 0.23550758 0.2230473  0.21990684 0.23550764 0.22324762
 0.22887592 0.2253795  0.23105195 0.23550315 0.22128586 0.25612488
 0.23550761 0.22256634 0.22256634 0.22887592 0.21865389 0.25340733
 0.22777477 0.22777501 0.23501775 0.25010544 0.23501706 0.22927988
 0.22886232 0.23360458 0.24893217 0.2220316  0.23357296 0.23128064
 0.22887595 0.22256637 0.2534074  0.22038636 0.23550764 0.22203021
 0.25344783 0.23550764 0.21482614 0.22303534 0.22303537 0.22887507
 0.2230353  0.21865389 0.23357299 0.22887595 0.22887595 0.23357782
 0.22096343 0.22361079]
tr_loss:[0.1360173  0.17271656 0.13537124 0.14622214 0.17271654 0.13300984
 0.13300991 0.13300972 0.13537124 0.13301042 0.13653417 0.12940449
 0.14622328 0.17271656 0.17271657 0.1353769  0.13653418 0.13473795
 0.13537125 0.17156458 0.12500195 0.14177004 0.1420027  0.12500195
 0.17271657 0.14200251 0.17340896 0.17261095 0.13300984 0.13601701
 0.13653417 0.12844746 0.17271635 0.12940449 0.13300985 0.13300982
 0.13596109 0.13300979 0.14621326 0.1420027  0.13537125 0.13718115
 0.14201945 0.13718131 0.14200264 0.13508463 0.17242292 0.13206187
 0.14410612 0.17271659]
tr_loss:[0.0904181  0.13070185 0.09394491 0.09553712 0.09248424 0.1307019
 0.11008525 0.09553711 0.09813745 0.08963996 0.08636901 0.10617101
 0.0980726  0.08963995 0.08586754 0.10529737 0.08963992 0.10444963
 0.09147684 0.08963993 0.08984103 0.13070133 0.09813799 0.09248428
 0.09147684 0.09809627 0.08436961 0.13070185 0.10365373 0.09479164
 0.09204541 0.09473045 0.08966129 0.09813802 0.08964022 0.13085172
 0.09147684 0.09248427 0.08436278 0.09248427 0.1307019  0.10444985
 0.08918406 0.09809653 0.08964486 0.09553713 0.09829798 0.08963994
 0.09813799 0.09147684]
tr_loss:[0.05950907 0.06030331 0.05973179 0.06029993 0.05743576 0.06172149
 0.06036142 0.07190122 0.05950909 0.06240014 0.06459884 0.06488203
 0.05950908 0.06175618 0.06028185 0.07192107 0.05950909 0.06003959
 0.05998323 0.08153199 0.07985894 0.06170838 0.06030283 0.08836542
 0.06172148 0.06525283 0.08999826 0.06459884 0.06877573 0.09000057
 0.06210633 0.05662696 0.06833624 0.06459884 0.0883654  0.05950909
 0.07136353 0.06239836 0.06168677 0.0599546  0.06238646 0.06030331
 0.06170558 0.06030567 0.0603033  0.08955859 0.0604709  0.05950908
 0.0645988  0.06239789]
tr_loss:[0.05290701 0.04753506 0.04678715 0.04682533 0.04967027 0.05473307
 0.04677571 0.0430318  0.04619709 0.05290701 0.04619709 0.04703251
 0.05442946 0.06427921 0.05255003 0.04903219 0.04906103 0.04905948
 0.06427921 0.06352628 0.05473309 0.05473308 0.04906103 0.04906105
 0.04338904 0.0468135  0.04678734 0.04753484 0.05468839 0.04678734
 0.06427921 0.05705534 0.04667863 0.04338906 0.04906102 0.04692023
 0.06427921 0.04679655 0.06427918 0.05473303 0.06474974 0.04338392
 0.04619709 0.06427252 0.05420832 0.04619709 0.05473309 0.0642792
 0.05290701 0.04796504]
tr_loss:[0.01262664 0.01519105 0.01519103 0.03533608 0.02556915 0.02556915
 0.01762555 0.01217842 0.02560594 0.01007305 0.01762555 0.01049053
 0.0244476  0.01745826 0.01762553 0.02444762 0.03533606 0.01007304
 0.0176255  0.0244476  0.01519102 0.01148005 0.01518399 0.03533605
 0.01007306 0.01007305 0.01007304 0.01007305 0.03183504 0.01348591
 0.02445082 0.01219441 0.01762554 0.01762554 0.03380359 0.02444761
 0.01007306 0.01007331 0.03533607 0.02641466 0.01519105 0.03295896
 0.02444761 0.02555207 0.0166805  0.02444761 0.01519105 0.02444762
 0.0318213  0.01148001]
tr_loss:[0.01162189 0.03723329 0.01037154 0.02944652 0.00678505 0.00679115
 0.03883937 0.02010934 0.03834537 0.01267572 0.02944654 0.02826643
 0.02873918 0.02825659 0.01055532 0.00881508 0.0282566  0.01055966
 0.01267658 0.00678505 0.02305657 0.00687117 0.02944652 0.02016221
 0.00892637 0.01097682 0.01211158 0.03883938 0.02944655 0.02944652
 0.0131542  0.01035987 0.03913612 0.02989857 0.03882847 0.00678505
 0.02305655 0.01039521 0.00678505 0.01272569 0.03883936 0.03913417
 0.02010934 0.02589944 0.02944652 0.02944654 0.03883936 0.00678505
 0.02944653 0.01035168]
tr_loss:[0.02909285 0.02104415 0.02885694 0.03635177 0.0363513  0.02237362
 0.02010102 0.00698358 0.02102331 0.00699232 0.02102331 0.0210233
 0.02102329 0.00961286 0.00897605 0.02013508 0.00698329 0.0363287
 0.02915235 0.02870207 0.00842717 0.03631861 0.02580794 0.02915242
 0.03635173 0.02865759 0.03236003 0.01103447 0.0210233  0.02101267
 0.01103448 0.03635176 0.00897601 0.03133851 0.00698358 0.03635173
 0.02102331 0.02102331 0.02102332 0.00698358 0.00698358 0.02102334
 0.02028549 0.00928086 0.01031202 0.02102332 0.00843006 0.01031202
 0.02102333 0.02580794]
tr_loss:[0.00300296 0.0064072  0.01004564 0.01488262 0.03629247 0.00658659
 0.0064072  0.01820533 0.0064072  0.00692025 0.01488255 0.01004562
 0.01991763 0.01004562 0.03242017 0.03241885 0.01820633 0.01484678
 0.01993023 0.03539834 0.0064072  0.03539834 0.03629246 0.01820513
 0.00733342 0.01482998 0.01815411 0.01488143 0.01820534 0.00641132
 0.00640719 0.00733448 0.01687391 0.0071171  0.01472298 0.01467404
 0.03306619 0.022661   0.00740855 0.00640721 0.01472663 0.01847327
 0.03618226 0.00268327 0.01470834 0.0182035  0.03361298 0.00373021
 0.03539835 0.01687391]
tr_loss:[0.0111227  0.00742894 0.00523676 0.0074297  0.01067702 0.01393391
 0.00742894 0.00742894 0.01079926 0.03657857 0.01067699 0.00451077
 0.00742893 0.00451078 0.02338385 0.0111227  0.02806823 0.01067702
 0.00451044 0.00742892 0.01079926 0.01420022 0.01112271 0.01666236
 0.03813862 0.01079926 0.01393388 0.02338384 0.01393395 0.01393389
 0.02338384 0.00742894 0.01666236 0.01419945 0.0111227  0.00742894
 0.03657857 0.0145936  0.0365776  0.02338384 0.01067696 0.03246544
 0.00742894 0.00334184 0.00523676 0.01079934 0.03656833 0.01049733
 0.01067701 0.01067702]
tr_loss:[0.0391538  0.03924025 0.03911014 0.01435109 0.01435108 0.02580748
 0.01541303 0.01435109 0.01435086 0.00715283 0.00727317 0.03419425
 0.00727318 0.01208153 0.02580749 0.02580749 0.01435107 0.04055211
 0.03915379 0.0056616  0.01541302 0.03915379 0.01206998 0.01541272
 0.02580751 0.00727315 0.03915427 0.00727329 0.00727317 0.00727317
 0.0126278  0.00361353 0.02580748 0.01262782 0.01676054 0.00361267
 0.01204016 0.00566214 0.01676055 0.02580747 0.01435114 0.01435109
 0.00545158 0.04386069 0.00715282 0.03915378 0.01541303 0.03896284
 0.01966874 0.04185876]
tr_loss:[0.04385627 0.01600636 0.01283608 0.01483975 0.00741103 0.0200181
 0.0088079  0.01675784 0.01107721 0.00614494 0.00741106 0.01283608
 0.00741105 0.02085593 0.01484889 0.0340491  0.02382989 0.0110853
 0.04120043 0.01108395 0.00741104 0.00741106 0.01242659 0.01242659
 0.02001905 0.04407629 0.02176532 0.04227114 0.00753982 0.00741106
 0.01484924 0.0238299  0.01672774 0.02232594 0.02382989 0.01484924
 0.01101385 0.01584399 0.04227116 0.00305586 0.00305586 0.01108395
 0.0369611  0.00741099 0.01108542 0.01484924 0.01484708 0.01283749
 0.01108393 0.01242661]
tr_loss:[0.00636472 0.01008234 0.02208048 0.01750052 0.00660984 0.01217589
 0.01611007 0.00885465 0.00885464 0.00248653 0.04394308 0.02208048
 0.00248638 0.04657651 0.01785247 0.03568114 0.00199658 0.01618064
 0.00199754 0.00257278 0.00885466 0.00885466 0.01008234 0.01108847
 0.01618121 0.00636446 0.01008232 0.00636442 0.01618121 0.00636443
 0.0161812  0.01218739 0.01217588 0.01217589 0.0121896  0.01217589
 0.04533854 0.00991955 0.04476826 0.02208051 0.00885465 0.02287806
 0.01008232 0.02208048 0.00886645 0.00660984 0.01008234 0.00660985
 0.0216258  0.02287802]
tr_loss:[0.02071481 0.01005605 0.0115827  0.04735992 0.04735999 0.04639523
 0.00927874 0.01005605 0.01773152 0.00839887 0.00927878 0.04295757
 0.02071481 0.01688521 0.00196657 0.04144612 0.00196665 0.00486503
 0.01005606 0.01168565 0.01260292 0.04639522 0.01005605 0.0074942
 0.00820925 0.0207148  0.02936392 0.01005604 0.01260292 0.04732779
 0.01688327 0.0155685  0.01204579 0.01688521 0.00927875 0.04638597
 0.02071481 0.02071481 0.02393622 0.01005605 0.00927875 0.01168566
 0.00504438 0.01688521 0.00928893 0.00928125 0.01205095 0.00927875
 0.01260357 0.00196607]
tr_loss:[0.00811244 0.00841971 0.00811245 0.00812081 0.00404523 0.00309025
 0.02684287 0.02224583 0.00811245 0.00546031 0.0402126  0.01035781
 0.00404177 0.01035769 0.01004711 0.01315606 0.01938101 0.04466356
 0.0434636  0.01004712 0.01316319 0.00404322 0.00546031 0.04466372
 0.0081314  0.01666724 0.00811245 0.00476815 0.00811245 0.01938097
 0.0100471  0.02869971 0.01315606 0.00811245 0.01004713 0.00806704
 0.019381   0.0164836  0.00199331 0.01004712 0.00811249 0.01314504
 0.00546031 0.01004712 0.01315606 0.00811245 0.01649855 0.01004713
 0.01004712 0.02987508]
tr_loss:[0.02200756 0.04149147 0.00922123 0.03754036 0.01866657 0.0374331
 0.00709169 0.01866657 0.01540699 0.0070923  0.01866656 0.00922122
 0.00709169 0.00417004 0.01540712 0.04149145 0.00723446 0.00709198
 0.00872461 0.00922122 0.02201911 0.01540712 0.0074585  0.00538198
 0.0070917  0.00922122 0.00274183 0.02093537 0.01430942 0.01535132
 0.01540714 0.04149147 0.00417004 0.04149147 0.04148983 0.00921925
 0.03887332 0.03112423 0.01370551 0.01517513 0.00538239 0.00538248
 0.02798579 0.00274183 0.00409682 0.01488317 0.01489919 0.01866657
 0.04149143 0.01305973]
tr_loss:[0.01395951 0.0065082  0.01854801 0.01871767 0.00510594 0.01395941
 0.00280173 0.00771192 0.00258585 0.00650833 0.0365563  0.01262251
 0.00301015 0.00771101 0.03768819 0.03653332 0.03278129 0.00650837
 0.03278128 0.00771103 0.00771101 0.01854802 0.00771102 0.00514487
 0.01854801 0.00771102 0.00928811 0.00771101 0.01259593 0.02503094
 0.01260856 0.00254153 0.00259169 0.01260856 0.01181935 0.01260858
 0.00514435 0.02503002 0.00771102 0.018548   0.00771102 0.00650837
 0.03768812 0.01854801 0.01260858 0.00371166 0.03655632 0.03655631
 0.01260688 0.00771101]
tr_loss:[0.03237528 0.01637546 0.00636143 0.03112038 0.00660229 0.00636141
 0.00636143 0.00660228 0.03112038 0.00660229 0.00861479 0.00638306
 0.02248246 0.0166117  0.00492198 0.00639303 0.00660134 0.00636141
 0.03564392 0.03112038 0.00247985 0.01847673 0.01444644 0.00660228
 0.00310052 0.00660229 0.00636144 0.03562955 0.00310433 0.00660229
 0.03111559 0.00310432 0.00861482 0.00636144 0.00465739 0.01847672
 0.01367758 0.03112039 0.00660229 0.02860407 0.01847671 0.00663031
 0.02769513 0.01847672 0.00639154 0.00660228 0.00636143 0.02860426
 0.00649398 0.0034943 ]
tr_loss:[0.00593816 0.00514089 0.00485218 0.01160567 0.0031861  0.00305963
 0.00593816 0.00591182 0.02510157 0.00329254 0.00661944 0.00514089
 0.00416948 0.00555577 0.00514089 0.01642166 0.02510125 0.01642166
 0.01642167 0.01044184 0.01350542 0.00730698 0.00514088 0.01533498
 0.00329257 0.00514085 0.00514089 0.00329255 0.01160567 0.00514089
 0.01642166 0.02510156 0.00514089 0.00343628 0.02510158 0.00514089
 0.00630076 0.0066196  0.02179808 0.01123215 0.00329216 0.02509998
 0.00514082 0.02626943 0.02510158 0.02493723 0.00593816 0.00329255
 0.00661961 0.00584078]
tr_loss:[0.01503583 0.01503584 0.0096758  0.00978831 0.00967579 0.02198336
 0.01768486 0.00614218 0.01503584 0.01206672 0.00063671 0.00614219
 0.00967614 0.00700558 0.0219834  0.00614219 0.01109477 0.0219834
 0.00505224 0.01119262 0.00614219 0.01109475 0.02198337 0.00614414
 0.00861715 0.00609049 0.00614219 0.01119385 0.00858431 0.01119384
 0.01347933 0.01295718 0.00967579 0.00714586 0.01744622 0.00894573
 0.00505222 0.00063671 0.02198339 0.01115878 0.02198336 0.00063734
 0.02198337 0.00967579 0.02248188 0.01503582 0.02198021 0.00893292
 0.00967579 0.01744583]
tr_loss:[0.01815688 0.01296915 0.00618057 0.01372648 0.01112525 0.01372649
 0.02270119 0.0136031  0.01354744 0.01313764 0.01279989 0.0136029
 0.01101684 0.0227012  0.00455601 0.01848296 0.00368015 0.01221085
 0.0061839  0.02270119 0.01805496 0.00617896 0.00455601 0.01356692
 0.00367065 0.01360309 0.00545116 0.00368007 0.01815594 0.0137265
 0.00618058 0.01279987 0.01372648 0.02270121 0.01653704 0.01048666
 0.01241321 0.01372648 0.01117737 0.01372584 0.01102336 0.02283834
 0.0184506  0.01279989 0.00545001 0.0184506  0.004556   0.00367999
 0.01652124 0.01354747]
tr_loss:[0.00402133 0.02545128 0.01415284 0.00402585 0.00402585 0.00402585
 0.01495001 0.00676415 0.00283633 0.00876789 0.01590322 0.00402585
 0.01384528 0.00402597 0.01026908 0.0095729  0.01454062 0.01242176
 0.014541   0.00402553 0.01374345 0.00647092 0.01374344 0.01454062
 0.01026906 0.00378726 0.01374346 0.00402586 0.00900452 0.01374345
 0.01495    0.00283631 0.01920808 0.01454066 0.00283632 0.01454062
 0.00159323 0.01489399 0.00402585 0.00957028 0.00685756 0.01374345
 0.02228227 0.01374335 0.01454061 0.00900546 0.01374345 0.02545127
 0.00402607 0.00955247]
tr_loss:[0.00166147 0.0087333  0.00166147 0.01644155 0.00173521 0.00735922
 0.02810819 0.01480825 0.01478499 0.00749556 0.00144716 0.00979623
 0.00166147 0.01587316 0.00166147 0.01242477 0.00453402 0.0056363
 0.00979622 0.00453402 0.01373503 0.00222589 0.01581054 0.00166148
 0.00979623 0.01242479 0.0056839  0.01373503 0.00749542 0.00557482
 0.02810819 0.0016963  0.00565146 0.00166147 0.01242392 0.00166149
 0.01242885 0.00166148 0.01614393 0.02800226 0.01373502 0.00268912
 0.00979621 0.00749556 0.0075563  0.00924628 0.00749556 0.00749555
 0.01507279 0.00166147]
tr_loss:[0.0067364  0.0049014  0.01213398 0.01238615 0.02940467 0.02602165
 0.00234747 0.00147783 0.01553954 0.00147767 0.00199817 0.0181258
 0.01813791 0.00222791 0.00673641 0.02940464 0.00195004 0.01024458
 0.00589424 0.0132272  0.0067364  0.00948231 0.00147771 0.00271656
 0.00222791 0.00683117 0.00673641 0.00589423 0.02940465 0.00589424
 0.00588797 0.00673641 0.01024458 0.00147679 0.01237077 0.0294032
 0.0014834  0.00148043 0.00589424 0.01024458 0.00589423 0.00980406
 0.01086169 0.01634271 0.00196291 0.00980421 0.00980421 0.00980421
 0.02550046 0.00589425]
tr_loss:[0.00266365 0.00405193 0.00260289 0.00860441 0.0081064  0.0035729
 0.01612953 0.00357291 0.01280062 0.00405196 0.02953441 0.00540494
 0.00260676 0.00266365 0.02212979 0.00405193 0.00618675 0.0035729
 0.02203379 0.01280061 0.00860902 0.00618962 0.00357373 0.0035729
 0.0295344  0.00618859 0.0035729  0.02494925 0.00405194 0.00541688
 0.00860902 0.00357378 0.00383045 0.00405194 0.00364992 0.00357293
 0.00405193 0.00405194 0.01053152 0.02470264 0.00810535 0.00266365
 0.00405193 0.00970347 0.00640198 0.00405194 0.00358173 0.00433505
 0.00408127 0.00354593]
tr_loss:[0.02549067 0.00624342 0.00582371 0.00582372 0.03040853 0.00582373
 0.00624342 0.02490329 0.00582373 0.00430741 0.00627209 0.00425517
 0.0043074  0.00742062 0.00399109 0.00652763 0.02553309 0.00739783
 0.03027948 0.0058237  0.00430741 0.03027951 0.03027951 0.03027955
 0.00582372 0.03027951 0.01780011 0.00624342 0.00399109 0.0062515
 0.03027948 0.00522595 0.01578077 0.00399109 0.00582372 0.00742061
 0.00742063 0.01578075 0.03116474 0.00423267 0.01578074 0.00652312
 0.00826473 0.0057724  0.01744057 0.00582303 0.00399108 0.00399109
 0.01578076 0.0302795 ]
tr_loss:[0.00341596 0.02257313 0.00877763 0.02954715 0.00695393 0.00695394
 0.00877763 0.00695395 0.0075082  0.03071145 0.00709275 0.00496433
 0.00704034 0.00866471 0.00695393 0.00695394 0.00754132 0.02623518
 0.00858086 0.02257508 0.00341596 0.00386901 0.01693487 0.03071147
 0.00589165 0.00608101 0.00695394 0.00364067 0.00859142 0.01821246
 0.00451979 0.00877763 0.01693486 0.03071144 0.03032819 0.00451979
 0.00927352 0.00877763 0.00877763 0.01867709 0.03071142 0.00608535
 0.00877764 0.00709276 0.00858725 0.03071145 0.00866474 0.00341596
 0.00608545 0.00341697]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3500 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3501, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3501 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3502, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3502 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3503, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3503 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3504, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3504 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3505, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3505 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3506, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3506 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3507, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3507 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3508, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3508 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3509, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3509 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3510, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3510 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3511, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3511 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3512, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3512 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3513, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3513 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3514, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3514 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3515, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3515 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3516, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3516 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3517, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3517 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3518, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3518 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3519, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3519 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3520, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3520 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3521, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3521 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3522, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3522 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3523, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3523 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3524, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3524 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3525, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3525 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3526, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3526 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3527, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3527 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3528, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3528 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3529, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3529 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3530, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3530 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3531, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3531 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3532, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3532 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3533, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3533 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3534, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3534 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3535, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3535 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3536, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3536 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3537, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3537 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3538, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3538 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3539, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3539 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3540, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3540 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3541, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3541 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3542, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3542 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3543, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3543 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3544, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3544 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3545, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3545 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3546, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3546 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3547, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3547 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3548, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3548 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3549, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3549 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3550, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3550 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3551, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3551 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3552, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3552 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3553, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3553 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3554, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3554 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3555, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3555 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3556, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3556 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3557, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3557 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3558, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3558 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3559, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3559 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3560, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3560 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3561, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3561 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3562, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3562 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3563, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3563 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3564, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3564 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3565, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3565 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3566, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3566 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3567, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3567 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3568, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3568 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3569, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3569 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3570, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3570 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3571, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3571 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3572, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3572 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3573, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3573 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3574, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3574 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3575, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3575 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3576, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3576 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3577, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3577 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3578, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3578 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3579, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3579 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3580, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3580 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3581, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3581 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3582, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3582 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3583, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3583 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3584, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3584 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3585, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3585 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3586, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3586 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3587, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3587 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3588, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3588 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3589, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3589 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3590, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3590 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3591, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3591 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3592, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3592 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3593, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3593 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3594, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3594 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3595, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3595 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3596, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3596 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3597, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3597 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3598, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3598 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3599, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3599 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3600, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-3500
text_input.shape
(3600, 14400)
learning_input_tmp.shape
(3600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3600, 80)
learning_output.shape
(750, 80)
Model: "sequential_73"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_73 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3557684 1.3396097 1.4361515 1.3714801 1.3533485 1.3045477 1.3607057
 1.304632  1.3594096 1.3607059 1.332227  1.293924  1.3361626 1.360706
 1.281715  1.2939241 1.3480955 1.2843132 1.3237841 1.374286  1.3642954
 1.3618085 1.360706  1.3594058 1.3480971 1.360706  1.3606373 1.293924
 1.3396189 1.4361517 1.2935135 1.2784178 1.3481052 1.4361514 1.3593884
 1.36052   1.3384647 1.3480989 1.3594096 1.3553551 1.4361515 1.361313
 1.2939342 1.3661999 1.360706  1.3725766 1.3594095 1.3530874 1.3560358
 1.360725 ]
tr_loss:[0.7025377  0.7252511  0.70830905 0.7079301  0.713425   0.7361461
 0.7361456  0.715145   0.7487794  0.7381382  0.7360905  0.6710609
 0.6998747  0.76164675 0.7361341  0.725251   0.7487794  0.8001747
 0.7802674  0.7539459  0.72559404 0.72545797 0.736146   0.7365449
 0.7597699  0.73614216 0.7252674  0.72524834 0.70792973 0.7992144
 0.74877936 0.7363766  0.7417137  0.73435545 0.7487794  0.69989514
 0.76594645 0.7487792  0.73614603 0.7543006  0.7487793  0.725251
 0.7539458  0.7557252  0.66144645 0.7551678  0.79149324 0.7488565
 0.7252512  0.8001564 ]
tr_loss:[0.43216085 0.45888868 0.43245277 0.40657672 0.4494841  0.46528727
 0.47806662 0.43348637 0.46528727 0.47847685 0.43348962 0.43241963
 0.44948387 0.43245277 0.44097584 0.44861993 0.4279956  0.474905
 0.43683434 0.4281485  0.44948387 0.4512012  0.44948387 0.44097847
 0.45888862 0.4652873  0.43071556 0.4728592  0.44641623 0.44361383
 0.43246746 0.44097838 0.43245283 0.43245277 0.4494838  0.45888868
 0.4728592  0.47286186 0.45420542 0.44948387 0.45888862 0.46026555
 0.4588887  0.45888862 0.43671665 0.4511741  0.4436191  0.47285813
 0.43245286 0.47285908]
tr_loss:[0.315523   0.2780362  0.2805118  0.32443112 0.28103516 0.27503103
 0.28982848 0.27503118 0.28384468 0.27503115 0.27687365 0.27503118
 0.27966163 0.2750312  0.28192267 0.27503124 0.28118736 0.28118736
 0.28296104 0.2914608  0.28321862 0.31534547 0.2877851  0.32443112
 0.2856554  0.28118736 0.2868607  0.32363734 0.28048328 0.28118736
 0.3236374  0.28118736 0.2785132  0.28118736 0.29522878 0.2780405
 0.32590166 0.27507594 0.2877851  0.32363734 0.28636384 0.3201044
 0.3020862  0.27862844 0.30208412 0.27503127 0.2834515  0.32037622
 0.32443112 0.27503067]
tr_loss:[0.14523172 0.14600626 0.14436147 0.18260172 0.18065839 0.15450104
 0.1449303  0.15007107 0.14600754 0.18260175 0.14517948 0.18260173
 0.14517948 0.14436083 0.14436495 0.14914897 0.15105495 0.1479797
 0.14517948 0.14600737 0.14260027 0.14436081 0.15450099 0.14517948
 0.14914897 0.1460316  0.16818228 0.14600377 0.14493033 0.14517981
 0.14493029 0.15239105 0.15450105 0.14524801 0.15450099 0.14746049
 0.14523172 0.18260184 0.14517944 0.14493027 0.15450124 0.14355859
 0.14523174 0.14434175 0.14919022 0.1425986  0.14436083 0.14436083
 0.14355859 0.1452317 ]
tr_loss:[0.06405105 0.07137579 0.07137579 0.06408111 0.08972567 0.06528733
 0.06405102 0.06805421 0.07030295 0.06405105 0.06411783 0.06405102
 0.06405103 0.06411819 0.07567403 0.06411819 0.07030289 0.0640957
 0.0641182  0.06810346 0.06568959 0.06405144 0.06694715 0.06568962
 0.06405105 0.06694715 0.06411821 0.06405105 0.09721254 0.07052009
 0.06493962 0.06357553 0.0706466  0.1015379  0.06411824 0.05064759
 0.06411348 0.0656896  0.06357552 0.06357552 0.09610853 0.06988446
 0.0625181  0.06560769 0.07064657 0.06694383 0.07137577 0.07064237
 0.05050004 0.06259897]
tr_loss:[0.02266048 0.02162425 0.02133988 0.03288937 0.03274862 0.02266048
 0.03274862 0.06004252 0.03274862 0.02266045 0.02175689 0.02133988
 0.02371222 0.02266048 0.02140253 0.02133989 0.02133988 0.05279525
 0.02143954 0.03274862 0.02279689 0.02162425 0.02496352 0.02162425
 0.02266048 0.01841648 0.03274862 0.02161465 0.02204705 0.06059198
 0.02266045 0.02133988 0.04883944 0.0214025  0.06059201 0.02133955
 0.02133988 0.0215475  0.02133988 0.03274862 0.02133988 0.02375795
 0.02266048 0.02266046 0.02265788 0.02640258 0.02266048 0.02942599
 0.02162425 0.06059202]
tr_loss:[0.03659831 0.0196573  0.01758405 0.01569873 0.02762429 0.01758405
 0.0196573  0.05069309 0.02457993 0.02625883 0.01570312 0.04229096
 0.02724933 0.0125168  0.01758405 0.02457993 0.02190374 0.0196573
 0.05745875 0.05745876 0.01569879 0.03544595 0.01965729 0.01717538
 0.01265478 0.02423827 0.01569868 0.01569882 0.02762427 0.02762428
 0.02457993 0.02457993 0.02733328 0.01921763 0.05346728 0.01965729
 0.01742328 0.0217612  0.0276243  0.0196573  0.01569874 0.05745878
 0.01251681 0.0574588  0.0125168  0.01744307 0.01921762 0.02047572
 0.01717539 0.01741053]
tr_loss:[0.02402014 0.00681372 0.01185765 0.01440129 0.03370062 0.04912838
 0.02403107 0.01894694 0.01190239 0.02774695 0.01492935 0.02140774
 0.01885044 0.01894692 0.01185764 0.01894695 0.0068278  0.01893865
 0.01894693 0.01492935 0.01894691 0.01492935 0.05539924 0.01185748
 0.03446254 0.0068817  0.05541639 0.01185765 0.01492935 0.02404547
 0.0254909  0.05541638 0.0190727  0.0148526  0.01185764 0.01481258
 0.00684232 0.01185765 0.00681697 0.01185765 0.01047521 0.02270462
 0.0148526  0.05541639 0.0148526  0.01894702 0.01185878 0.05541642
 0.01185513 0.05541641]
tr_loss:[0.00933834 0.01478833 0.01997974 0.02126477 0.01644079 0.00971464
 0.00933834 0.01939964 0.00973914 0.01939967 0.01317177 0.01478835
 0.00867664 0.01997973 0.0199797  0.01644078 0.00974214 0.01517799
 0.00933834 0.00503979 0.01318226 0.00503936 0.00868857 0.02908011
 0.02633124 0.01379838 0.00867666 0.01939967 0.00971465 0.00867667
 0.01992137 0.01310533 0.01376288 0.00971465 0.02252389 0.0054095
 0.01969599 0.015178   0.01939967 0.01379838 0.00933834 0.02251888
 0.01379468 0.04761215 0.00819229 0.05235996 0.01379838 0.0521531
 0.01939966 0.01379838]
tr_loss:[0.00961847 0.01861541 0.01074054 0.01234659 0.01845496 0.0085204
 0.01545942 0.01074053 0.05304606 0.05304607 0.03034588 0.05304605
 0.05304604 0.00961824 0.0159365  0.0085202  0.01356842 0.01860967
 0.02176211 0.01783997 0.01238083 0.05233527 0.03038009 0.01545941
 0.05304606 0.02176213 0.00961824 0.01499    0.01392554 0.02176209
 0.00961824 0.02628235 0.02176212 0.0158908  0.00961823 0.01238089
 0.03727219 0.00961824 0.00961826 0.00961913 0.02910621 0.01027787
 0.01861234 0.01861545 0.00972623 0.03094746 0.00961888 0.02176211
 0.01861545 0.05233527]
tr_loss:[0.01471564 0.01961212 0.04814313 0.01733834 0.03244491 0.05304601
 0.0133235  0.05304857 0.01092714 0.01471563 0.01735785 0.03244653
 0.01331951 0.01332442 0.053046   0.0121425  0.02268028 0.01092716
 0.01093824 0.02268026 0.01787585 0.01471564 0.01322955 0.05304875
 0.053046   0.0133187  0.01322977 0.01735785 0.01812268 0.01471564
 0.01444258 0.01092721 0.01092756 0.01387758 0.01769922 0.01769922
 0.01492181 0.02268029 0.01097796 0.03102075 0.0121418  0.01306903
 0.02667388 0.0097868  0.01471564 0.02268025 0.0266744  0.01471564
 0.02667418 0.01589016]
tr_loss:[0.01224259 0.02486652 0.01330345 0.04965992 0.01356223 0.01690328
 0.01386939 0.02380509 0.02541948 0.01398931 0.01155222 0.01167683
 0.00962625 0.0095263  0.01356223 0.01161704 0.00951257 0.01690607
 0.04965995 0.01515478 0.01573378 0.01356222 0.01797128 0.01797128
 0.01797126 0.00951262 0.02066916 0.01154775 0.01167682 0.04965999
 0.00997017 0.01249303 0.04965995 0.04284428 0.00962492 0.02486914
 0.01167684 0.04971929 0.01797128 0.04965995 0.01400119 0.01570377
 0.01249303 0.01690606 0.01637515 0.04421739 0.01167375 0.01249303
 0.02392539 0.00951262]
tr_loss:[0.01239785 0.01440099 0.00695331 0.02417545 0.01167783 0.04472096
 0.00695527 0.01239931 0.01146926 0.01440113 0.0144009  0.01670241
 0.0123663  0.01354231 0.03819831 0.01440113 0.01236631 0.01167782
 0.01239785 0.02416749 0.00926818 0.02306017 0.0123663  0.01167783
 0.04398664 0.01177701 0.02058101 0.00695332 0.01167783 0.00695331
 0.04472101 0.01440099 0.00863816 0.01167783 0.01167783 0.01167783
 0.01440113 0.00922263 0.00695329 0.00932975 0.00524743 0.04472098
 0.01025203 0.01433592 0.01025242 0.01236631 0.00863787 0.01861946
 0.01236631 0.03850598]
tr_loss:[0.01149694 0.0352504  0.011497   0.00868019 0.03525033 0.011497
 0.0102324  0.00455742 0.00595996 0.00595996 0.00616058 0.02090095
 0.01312367 0.00438989 0.0352504  0.00595996 0.01037779 0.02140212
 0.00768521 0.01271518 0.03178323 0.01456928 0.0352504  0.011497
 0.00768522 0.00595986 0.02140145 0.03547013 0.03525036 0.00595996
 0.01141956 0.00699095 0.00768489 0.00768521 0.01257577 0.03525014
 0.01271226 0.00768522 0.0352504  0.01824487 0.03033202 0.00768522
 0.00596355 0.01271209 0.00595996 0.00598534 0.00595996 0.00759849
 0.01141969 0.00768522]
tr_loss:[0.01367934 0.00915282 0.04415016 0.04069122 0.01323766 0.00737151
 0.01270545 0.01380334 0.01379966 0.01367932 0.01379815 0.02451501
 0.00915283 0.0136793  0.01367933 0.01272373 0.01364211 0.01389819
 0.01077726 0.01379965 0.00914556 0.0184813  0.0126051  0.01367931
 0.01077727 0.01852323 0.02639862 0.03102756 0.0137984  0.04069116
 0.01367846 0.01367932 0.00915284 0.01248075 0.00730653 0.01848132
 0.01323765 0.04065947 0.00737152 0.01367959 0.01035778 0.01303323
 0.00915284 0.01133006 0.00915229 0.0091529  0.01367932 0.01367902
 0.01270275 0.01379992]
tr_loss:[0.02821238 0.01211541 0.01209743 0.01214316 0.00693404 0.01342159
 0.01089174 0.01320294 0.00927904 0.01089193 0.01250889 0.01392614
 0.02821238 0.01211542 0.01338665 0.01675391 0.01339136 0.00927903
 0.01339137 0.01675391 0.01211541 0.02821235 0.00562209 0.02821291
 0.01675391 0.01200415 0.01675392 0.00927902 0.00935359 0.0130471
 0.02476818 0.01339554 0.00922992 0.0068278  0.04123737 0.00682781
 0.01211541 0.01200414 0.01675391 0.04427785 0.04130953 0.01339136
 0.01339113 0.01337283 0.01339136 0.0133925  0.02821138 0.01407789
 0.00927903 0.00927903]
tr_loss:[0.00456622 0.00456622 0.00456623 0.00754717 0.003759   0.012682
 0.02496428 0.02860039 0.00460931 0.00389338 0.0177963  0.00893311
 0.00754719 0.01268103 0.00720962 0.00754717 0.00754717 0.02496822
 0.02498084 0.02663498 0.02496432 0.00456623 0.00341622 0.01407726
 0.00630075 0.00306408 0.003414   0.01453039 0.00456623 0.02108965
 0.00265631 0.0043649  0.00737131 0.02577054 0.02315008 0.01912737
 0.00456621 0.00893311 0.00341622 0.0192928  0.00630074 0.00456583
 0.00741121 0.02496426 0.00341622 0.02643687 0.0249643  0.00754717
 0.00450781 0.00453913]
tr_loss:[0.03254363 0.00963819 0.00476449 0.00557335 0.03223363 0.03150743
 0.01052381 0.00476448 0.01300205 0.01599087 0.00476032 0.01599087
 0.01599086 0.00476451 0.01277604 0.03254362 0.01598952 0.03253575
 0.01277667 0.00586943 0.01300205 0.01093507 0.01527679 0.01093371
 0.01051168 0.01599088 0.01277666 0.01599584 0.0104888  0.03254362
 0.0127766  0.01092232 0.0047645  0.00756257 0.01599088 0.03047889
 0.00476449 0.03069591 0.01300205 0.00547037 0.01599087 0.00547035
 0.01093505 0.00963819 0.03254362 0.03254361 0.01093506 0.03254361
 0.01073866 0.00808885]
tr_loss:[0.00444668 0.01457919 0.02762484 0.0145792  0.01047665 0.0166008
 0.0321392  0.01004226 0.00933552 0.03232657 0.00526986 0.00971128
 0.00519689 0.01265895 0.00526953 0.00961054 0.00968473 0.00450404
 0.01265895 0.01059552 0.01457917 0.03232655 0.00967787 0.01457919
 0.00450436 0.00933552 0.02983    0.01457918 0.01265895 0.00450405
 0.01265895 0.02761665 0.00539542 0.01265895 0.00849674 0.00450507
 0.00450527 0.0145792  0.00450404 0.00450404 0.00849786 0.0209056
 0.00450404 0.01265895 0.03232658 0.0096313  0.00963089 0.00450374
 0.03232655 0.01265895]
tr_loss:[0.02635912 0.00390717 0.00267683 0.00792053 0.011043   0.00750021
 0.01356397 0.01360666 0.00511811 0.00267684 0.00686329 0.00686329
 0.02633552 0.01252756 0.00792206 0.00462569 0.00686328 0.0031851
 0.01316178 0.0055116  0.00553692 0.00390717 0.00267683 0.00422978
 0.00267684 0.00318111 0.0068633  0.00462571 0.00553694 0.00988201
 0.02272091 0.00274076 0.01360669 0.00792052 0.00267684 0.0056566
 0.02635897 0.00686329 0.00686329 0.00364963 0.00258876 0.00364962
 0.0031851  0.00686329 0.01206448 0.02635893 0.01257733 0.0042262
 0.02635896 0.00318482]
tr_loss:[0.00549398 0.00749562 0.00363195 0.00465235 0.00363196 0.00436824
 0.00574615 0.00844366 0.02674429 0.00549397 0.00550562 0.00465236
 0.00574615 0.00465235 0.00429826 0.00550594 0.02674257 0.00465236
 0.00436877 0.00492919 0.00549422 0.003718   0.00844366 0.00465235
 0.00574688 0.00844366 0.00465339 0.00574604 0.00574615 0.00436874
 0.00465236 0.00638875 0.00549397 0.00844383 0.01977677 0.02674233
 0.00574615 0.00429554 0.00363194 0.00436347 0.0043685  0.00465236
 0.00465235 0.00091352 0.00465619 0.0268138  0.00094314 0.00688897
 0.02674233 0.02805336]
tr_loss:[0.00791539 0.00477755 0.01056165 0.00613706 0.02350689 0.02982584
 0.00477767 0.00477767 0.00633476 0.0235069  0.00477767 0.00614706
 0.00614705 0.00785506 0.00774556 0.00469206 0.00477767 0.03143765
 0.0105623  0.02980713 0.0043012  0.00175031 0.03143764 0.0298071
 0.00949395 0.0079154  0.01056162 0.00949395 0.00380111 0.00626124
 0.0248793  0.00785493 0.00934371 0.0079154  0.00633477 0.0043012
 0.00477767 0.00792078 0.00785492 0.02486055 0.00791197 0.00175031
 0.00934371 0.00791539 0.02477557 0.02947166 0.00563001 0.00561905
 0.00684521 0.00175031]
tr_loss:[0.0040191  0.0049551  0.0039043  0.0040191  0.00756926 0.00390431
 0.03164852 0.03164853 0.00702437 0.02700712 0.00795058 0.01086635
 0.01058916 0.0040191  0.00756926 0.03164854 0.00202061 0.00466815
 0.00487863 0.00795058 0.00487863 0.01086632 0.0040191  0.00495604
 0.0107957  0.02382388 0.03164854 0.00401909 0.01086631 0.00702358
 0.02482885 0.00202061 0.0236634  0.00785106 0.01121133 0.03164851
 0.00757004 0.00917062 0.03164854 0.01086631 0.00402584 0.03668115
 0.00495606 0.0040191  0.01086632 0.0040191  0.00495411 0.01083787
 0.03164852 0.0040191 ]
tr_loss:[0.00276879 0.00275883 0.00381943 0.00275883 0.02208929 0.00372277
 0.03166942 0.00667108 0.03500816 0.00372302 0.00639812 0.00543002
 0.00150667 0.00986646 0.00633031 0.03166937 0.00275883 0.00150668
 0.03166939 0.00340752 0.00372278 0.00543002 0.00634094 0.00631124
 0.00631125 0.00275883 0.0220218  0.00631124 0.00631124 0.00690438
 0.00632011 0.00783079 0.00631124 0.00764363 0.00543002 0.02310727
 0.02215296 0.00986647 0.00690439 0.02061778 0.00150667 0.02358823
 0.02707432 0.00631123 0.00631124 0.00556493 0.02212912 0.00986644
 0.00381944 0.03166937]
tr_loss:[0.00166813 0.00626289 0.00633182 0.01983416 0.00406743 0.00702031
 0.00878261 0.00406744 0.00406744 0.02196938 0.0028288  0.00626285
 0.01035588 0.00406743 0.00282881 0.00626285 0.00626282 0.03168912
 0.00275766 0.01034219 0.00943815 0.03168914 0.00406743 0.00406744
 0.03276915 0.01975661 0.00492991 0.0028288  0.00406744 0.00406744
 0.00167396 0.00626634 0.02023313 0.03168914 0.00964169 0.00415137
 0.00125268 0.00691807 0.00406743 0.00167396 0.03274262 0.00363431
 0.0049299  0.00702091 0.00706916 0.03276915 0.03168915 0.02783914
 0.00882283 0.00878261]
tr_loss:[0.00450476 0.00688207 0.01860456 0.00410097 0.00867552 0.0320209
 0.00545564 0.00748196 0.03201729 0.01859384 0.00748195 0.00805823
 0.00748134 0.00820431 0.00450476 0.01024537 0.00410097 0.00245174
 0.00245173 0.00806938 0.0080693  0.03168356 0.00410096 0.00684304
 0.03201721 0.00410097 0.00748196 0.00747292 0.00410097 0.00450512
 0.00785084 0.00545564 0.01859436 0.01010961 0.01227026 0.03201718
 0.00748196 0.01010961 0.00450476 0.00450476 0.00410098 0.00806938
 0.00705637 0.00410093 0.00450476 0.004101   0.00580723 0.00683842
 0.00410097 0.00748196]
tr_loss:[0.00814105 0.00875449 0.00243391 0.0317516  0.00732736 0.00814105
 0.00243391 0.0162794  0.00480351 0.0081413  0.00732733 0.00654624
 0.00814105 0.0192777  0.00480352 0.00243391 0.03175161 0.00862725
 0.00722198 0.0086272  0.00480353 0.00243296 0.03297243 0.00814108
 0.00814105 0.0078043  0.01926714 0.00814105 0.00243391 0.0317516
 0.00480352 0.00942215 0.00243391 0.01004052 0.00732735 0.02692818
 0.00879103 0.02014042 0.00875448 0.00990615 0.02604673 0.00732735
 0.00732735 0.00780482 0.00775043 0.00488306 0.00814104 0.00654238
 0.00480352 0.00942117]
tr_loss:[0.00411203 0.00569788 0.00115603 0.00411202 0.00411203 0.02999723
 0.00721545 0.00683892 0.00557913 0.00721545 0.00544081 0.0045819
 0.00620888 0.00731761 0.00721545 0.02999642 0.03134728 0.00551165
 0.00721545 0.00627327 0.00627213 0.00411202 0.00543815 0.00411203
 0.00721546 0.00721545 0.00627326 0.00601736 0.00721546 0.0081008
 0.00411244 0.01947665 0.00769663 0.00627326 0.00115603 0.00537371
 0.00411202 0.00411203 0.0045819  0.00498226 0.00721545 0.00569745
 0.00115602 0.00709651 0.00115603 0.0045819  0.01976708 0.00256287
 0.00721546 0.00683893]
tr_loss:[0.00782778 0.00525493 0.00522412 0.02019155 0.0062838  0.00251896
 0.00525547 0.02780765 0.00525548 0.00522412 0.00628389 0.02780765
 0.0052641  0.00340714 0.00522413 0.00402055 0.00340713 0.00522413
 0.01857183 0.00628389 0.02780762 0.00340714 0.00727541 0.00402054
 0.00014835 0.00014835 0.00402054 0.00777706 0.00325817 0.00628381
 0.00274152 0.00628058 0.00325818 0.00536001 0.02274243 0.00561591
 0.01856358 0.00568191 0.02266857 0.00014835 0.00402054 0.00402054
 0.02780762 0.00522412 0.00274152 0.00274152 0.00782776 0.00325439
 0.00014832 0.0062835 ]
text_input.shape
(3600, 14400)
learning_input_tmp.shape
(3600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3600, 80)
learning_output.shape
(750, 80)
Model: "sequential_74"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_74 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.6120148 1.6697805 1.5961721 1.5957172 1.5961676 1.6126261 1.6209943
 1.5961722 1.5961722 1.6276112 1.5961722 1.6883103 1.6126261 1.6339203
 1.6801484 1.6755259 1.6237638 1.6783438 1.6783438 1.5900447 1.6697773
 1.6533312 1.7035868 1.6783438 1.6237637 1.6339204 1.6226044 1.5943557
 1.678344  1.6120155 1.6126263 1.5961716 1.6126258 1.6339207 1.6120188
 1.6115224 1.6339085 1.6047258 1.6783438 1.5961684 1.6115227 1.5961721
 1.6663074 1.6372433 1.6698269 1.6115224 1.6115242 1.6226065 1.5961721
 1.589909 ]
tr_loss:[0.96650255 0.973633   0.9877186  0.9666611  0.94987583 0.97024804
 0.9666727  0.96279955 0.97025985 0.9886023  0.97157204 0.9463062
 0.96650136 0.9705025  0.9715719  0.99786246 0.97157204 0.9856674
 0.9856674  0.9598811  0.94556653 0.97329503 0.9856674  0.9466567
 0.9715689  0.9731995  0.9856674  0.97317755 0.9856674  0.9665159
 0.9786599  0.9825598  0.9491585  0.97075063 0.97309655 0.97362596
 0.9715744  0.99678504 0.9696991  0.96950424 0.9695028  0.9695047
 0.9715721  0.96650237 0.96950436 0.98566735 0.97327614 0.9786612
 0.9856672  0.9852022 ]
tr_loss:[0.5148731  0.50788033 0.55746377 0.5453961  0.5078702  0.5078803
 0.5504459  0.5309426  0.53094256 0.5373646  0.5151127  0.5371376
 0.50383365 0.5094221  0.5301967  0.5504521  0.53683805 0.53019834
 0.5355221  0.5083531  0.5299584  0.5301983  0.50717515 0.5148727
 0.5309426  0.53571576 0.53094256 0.5041019  0.50198877 0.53695416
 0.5368382  0.5574637  0.53552043 0.5574597  0.55697995 0.5453961
 0.5309426  0.5078796  0.5182984  0.50788033 0.5377908  0.5309426
 0.53094256 0.5284414  0.53094256 0.5373587  0.50788033 0.50926465
 0.530934   0.53019834]
tr_loss:[0.2879027  0.28968185 0.26069012 0.27746055 0.2789596  0.2774606
 0.2848614  0.27574882 0.27895957 0.2939552  0.29616922 0.2664255
 0.29381555 0.27746063 0.2789596  0.26602164 0.27746058 0.27746063
 0.27531108 0.29590824 0.28968176 0.28446183 0.2881909  0.2961701
 0.26069012 0.28658932 0.2881913  0.26223654 0.28368202 0.27895966
 0.28968194 0.27745572 0.28818798 0.2606902  0.28968194 0.29381555
 0.2867857  0.27746058 0.28674453 0.26069015 0.2789596  0.26770148
 0.27942717 0.3085471  0.28356427 0.27746058 0.2896819  0.2728185
 0.2774606  0.27746016]
tr_loss:[0.1373233  0.13880248 0.13880247 0.11343322 0.13209477 0.13880199
 0.1199127  0.13297588 0.13880064 0.13731226 0.13731226 0.13880241
 0.1115165  0.11345883 0.13880244 0.11343317 0.13903098 0.13953827
 0.12703621 0.11991481 0.13493098 0.13581099 0.1141933  0.13581112
 0.13883093 0.14052942 0.11358738 0.13066414 0.13880222 0.13284966
 0.13209482 0.13880242 0.13886034 0.11343317 0.135811   0.11408474
 0.11419313 0.12016828 0.13581097 0.11343317 0.1319448  0.12016831
 0.13066226 0.11315961 0.17175202 0.11692397 0.13266192 0.13881658
 0.12016829 0.13578182]
tr_loss:[0.03564119 0.04677084 0.04677085 0.0441045  0.04677088 0.0402495
 0.03578357 0.04002251 0.04677086 0.03564119 0.03940489 0.04714788
 0.04677085 0.04714789 0.03564119 0.03578358 0.05502297 0.03644749
 0.05734723 0.04002247 0.04872658 0.03451668 0.04002247 0.04677086
 0.04690336 0.03564119 0.03578354 0.03578376 0.05749727 0.03443318
 0.04677033 0.03451668 0.04677134 0.03578417 0.04676909 0.03579337
 0.04002246 0.0356412  0.04677088 0.03644749 0.04677079 0.06452952
 0.04677089 0.03490102 0.04677088 0.04002246 0.03981337 0.0402495
 0.04667022 0.04410445]
tr_loss:[0.0116709  0.01030881 0.01823332 0.01823336 0.00992492 0.01716999
 0.02131069 0.02027061 0.02473198 0.0309896  0.02026339 0.02086714
 0.02027064 0.01874449 0.01664645 0.01030881 0.01801297 0.00954027
 0.01717004 0.00954027 0.02027061 0.04673935 0.01664647 0.02400931
 0.01381774 0.0213107  0.01664647 0.00990483 0.01664647 0.01357956
 0.01785775 0.01030881 0.04673042 0.04673936 0.00991947 0.0182233
 0.01030881 0.01030881 0.04819226 0.02999894 0.02027062 0.011595
 0.01029229 0.04167305 0.02601528 0.00954027 0.01381777 0.02033964
 0.01381774 0.02601535]
tr_loss:[0.06078699 0.01770164 0.06067737 0.05367946 0.01417087 0.02107365
 0.02107365 0.02495756 0.01770166 0.01103392 0.00564165 0.01417085
 0.02107697 0.01770166 0.01080316 0.00826086 0.03074383 0.01772669
 0.01770165 0.00564165 0.02077278 0.01770157 0.02107365 0.00907727
 0.02361882 0.01417088 0.01384967 0.01874899 0.06090386 0.01770165
 0.01386569 0.01417085 0.00801403 0.02107316 0.06078699 0.00786893
 0.00907745 0.01751326 0.03210836 0.03074855 0.01770165 0.00564165
 0.01417086 0.0607761  0.06078697 0.01103162 0.02919851 0.05346537
 0.02107365 0.00564167]
tr_loss:[0.0135953  0.03528237 0.01285228 0.03297084 0.01359528 0.00666119
 0.00500651 0.01285228 0.01285233 0.0208148  0.01359531 0.06056075
 0.0135953  0.01059421 0.05369214 0.01285228 0.0135953  0.0135953
 0.00666119 0.01359531 0.02081421 0.06056117 0.02081474 0.01359529
 0.03621065 0.00666119 0.01396501 0.00950974 0.01285207 0.02067969
 0.01573075 0.06056105 0.05083225 0.01573075 0.02223024 0.0208148
 0.00772642 0.01284683 0.0050065  0.01359531 0.0135953  0.01118709
 0.01851247 0.01651923 0.01396455 0.02657711 0.0135953  0.01951221
 0.01773386 0.00666119]
tr_loss:[0.01535972 0.01183928 0.0236512  0.0116363  0.03570096 0.05784868
 0.01535965 0.00712301 0.05785092 0.01127532 0.00705204 0.01533795
 0.00710569 0.05785095 0.01743451 0.01189384 0.01744531 0.01189384
 0.01781179 0.01535964 0.05785086 0.05244138 0.01127532 0.01127533
 0.0164391  0.01131297 0.0524414  0.02702696 0.01535966 0.01127531
 0.05785091 0.05785093 0.02307871 0.02781176 0.02365122 0.00868491
 0.01775816 0.01364785 0.00719371 0.01127582 0.00705169 0.0278644
 0.00705169 0.01127533 0.01535965 0.01124603 0.01127532 0.01191392
 0.01127532 0.02365122]
tr_loss:[0.0158316  0.02812397 0.01253617 0.0359443  0.05409735 0.04619625
 0.01341235 0.02551686 0.01257434 0.02047569 0.0267698  0.01398165
 0.01253017 0.02551685 0.02737666 0.01253631 0.01253632 0.05409732
 0.05439596 0.01253631 0.01042998 0.05409734 0.02551685 0.02676979
 0.01583163 0.0540057  0.05409734 0.01583163 0.02676979 0.02546906
 0.0267698  0.01253631 0.02830164 0.02462867 0.01583161 0.01104113
 0.01253633 0.01042455 0.01116094 0.05409734 0.0139731  0.01398432
 0.01341236 0.05409732 0.02676979 0.02715767 0.01397346 0.02551412
 0.01583161 0.01253686]
tr_loss:[0.04567154 0.0456715  0.01055405 0.02003962 0.02721802 0.00996173
 0.00957193 0.04495408 0.02070176 0.04566886 0.00957195 0.01055425
 0.01055449 0.01055449 0.01113388 0.02660119 0.00957277 0.02973489
 0.00667754 0.0066276  0.00957195 0.01515678 0.04495408 0.01087916
 0.02003961 0.01055449 0.0105545  0.00662759 0.01055449 0.01515673
 0.04495408 0.01990798 0.01293493 0.00957193 0.01087987 0.04495407
 0.04495408 0.01808027 0.01074234 0.01076873 0.04233305 0.02704324
 0.01980585 0.01808031 0.00662759 0.00875153 0.02660119 0.04260616
 0.0066775  0.01808026]
tr_loss:[0.01062769 0.02416997 0.01035737 0.00343701 0.03321515 0.0034421
 0.0330626  0.01216801 0.00491361 0.00277749 0.0027775  0.03308413
 0.02516987 0.00284271 0.02416999 0.0027775  0.00920194 0.02416998
 0.00343701 0.00343702 0.01035735 0.00277749 0.036184   0.00277749
 0.00440251 0.03618401 0.02403303 0.01300794 0.00920195 0.0027775
 0.00343701 0.012168   0.00439292 0.02416998 0.01035108 0.02403999
 0.00907645 0.03618397 0.00920197 0.01035735 0.0307108  0.02416996
 0.00343701 0.0027775  0.0027775  0.01216799 0.00442903 0.01071909
 0.01035737 0.01035735]
tr_loss:[0.03747746 0.00866502 0.03747747 0.01023724 0.03747744 0.00507575
 0.00942543 0.01731811 0.00532506 0.02580914 0.00533041 0.01621423
 0.03412464 0.02486211 0.010777   0.03747744 0.00865748 0.0374826
 0.02490689 0.01618491 0.03747746 0.02671349 0.03748155 0.01916555
 0.01621426 0.00532507 0.01007315 0.00532508 0.03747744 0.01048148
 0.01313872 0.0170052  0.03747747 0.01621374 0.01008714 0.01048149
 0.01621378 0.03881793 0.01621424 0.00749471 0.01916615 0.02486211
 0.02586817 0.03793425 0.00532506 0.0107644  0.03793431 0.00532507
 0.01009715 0.01006821]
tr_loss:[0.02287673 0.00613315 0.00786004 0.03789402 0.00956315 0.00957332
 0.02287672 0.00797753 0.00785759 0.03778032 0.01271011 0.00785764
 0.01957315 0.0078576  0.01804774 0.01361112 0.02883534 0.00785777
 0.02014544 0.01926547 0.01459977 0.00955803 0.01255461 0.00800175
 0.00613315 0.03778007 0.0200504  0.03778007 0.03936793 0.00613351
 0.0078576  0.0228767  0.03778006 0.01620827 0.03778009 0.01588823
 0.02287673 0.01803613 0.01453208 0.0078576  0.02287673 0.01803613
 0.0079938  0.03388081 0.01803614 0.01620863 0.01620827 0.03778005
 0.02287672 0.02311767]
tr_loss:[0.01281461 0.00621214 0.01281461 0.02499643 0.03622453 0.00674191
 0.01037263 0.00676707 0.03379115 0.0062177  0.01281461 0.01975511
 0.00455938 0.02091645 0.03528593 0.0105701  0.03622467 0.00656224
 0.03436381 0.03619011 0.00674191 0.01281461 0.01149993 0.01025397
 0.03530807 0.01037237 0.03436384 0.02632149 0.00621769 0.01025399
 0.00756136 0.01281461 0.01281461 0.0086546  0.00599051 0.01149096
 0.02716161 0.01281461 0.01037493 0.01127566 0.00674191 0.00753651
 0.0062177  0.0062177  0.00260565 0.01063995 0.00621769 0.00621769
 0.002586   0.00674195]
tr_loss:[0.00609139 0.00526376 0.00832663 0.0191648  0.00732382 0.00712952
 0.01154427 0.01748679 0.00474328 0.01154425 0.03656707 0.00682049
 0.00526376 0.01154427 0.00526376 0.0191648  0.01154427 0.03466719
 0.01872458 0.01971876 0.01154426 0.03466716 0.00712951 0.00681695
 0.01872457 0.02402343 0.01145915 0.01748907 0.03466716 0.01154694
 0.03127297 0.00720103 0.02569308 0.02421807 0.01154428 0.00712951
 0.02622772 0.03035681 0.00526375 0.00580122 0.03466716 0.02362185
 0.00446378 0.00526376 0.00832519 0.00824135 0.02402347 0.00712951
 0.02403243 0.00824135]
tr_loss:[0.00512376 0.00512326 0.00512326 0.0048805  0.00972458 0.00489687
 0.01753215 0.00487808 0.0367194  0.00547089 0.01753215 0.00514173
 0.03671937 0.01753216 0.03282986 0.00487809 0.00512332 0.00773458
 0.00956042 0.01908754 0.00459294 0.00487808 0.00511002 0.02055591
 0.01753215 0.03096405 0.0174681  0.02242157 0.01746794 0.00583232
 0.0048781  0.00972456 0.00773459 0.01746789 0.00512325 0.00736357
 0.0049149  0.03095267 0.01042941 0.00773458 0.03671939 0.00583232
 0.0051138  0.03671937 0.0070759  0.01038602 0.03823791 0.00773458
 0.00736378 0.00773458]
tr_loss:[0.03032127 0.00335622 0.00498995 0.00370591 0.00488547 0.00267591
 0.01413368 0.00668097 0.00479598 0.01413368 0.00335619 0.01413368
 0.00335617 0.0391511  0.03915109 0.01413368 0.01247571 0.00571037
 0.00974074 0.01650413 0.00335618 0.00336064 0.04033189 0.00973193
 0.00335619 0.01413371 0.00335619 0.03561124 0.00335619 0.00974106
 0.02258642 0.00336289 0.01413368 0.01409544 0.03915045 0.00335618
 0.01413369 0.00335619 0.01413368 0.00974113 0.00612232 0.00733269
 0.00335619 0.00733269 0.00335619 0.00370592 0.01531885 0.00844304
 0.00202171 0.00263394]
tr_loss:[0.00816932 0.00774334 0.00213509 0.03868148 0.00816932 0.01565232
 0.00816932 0.03868151 0.00899843 0.00303197 0.00774334 0.00213504
 0.0128516  0.00303195 0.00678299 0.01344129 0.00289301 0.00303195
 0.00333808 0.03868151 0.00899843 0.00411673 0.00816933 0.00774334
 0.00899843 0.00899843 0.00213504 0.0174438  0.00899843 0.00816919
 0.00899844 0.00415942 0.00774312 0.01744365 0.01774747 0.00774334
 0.01455887 0.00303195 0.00333614 0.00774334 0.03855975 0.00333339
 0.00774332 0.00272305 0.00303195 0.00774333 0.03275394 0.00774334
 0.00303195 0.01744504]
tr_loss:[0.0051593  0.03321603 0.00541808 0.00515931 0.00407566 0.00515932
 0.01909979 0.00815146 0.00518129 0.0196992  0.03699497 0.03007706
 0.00815146 0.00540312 0.00784085 0.00578342 0.037092   0.00881988
 0.037092   0.01213506 0.00380669 0.00515935 0.00515931 0.00516027
 0.005558   0.00542967 0.005161   0.03322199 0.00464298 0.03709199
 0.00815147 0.00515932 0.01577441 0.00515932 0.00542975 0.00516023
 0.00716143 0.00515932 0.00515931 0.00464298 0.00542972 0.00628088
 0.0071614  0.00515931 0.01576129 0.00464298 0.00464299 0.01577441
 0.00533966 0.01983591]
tr_loss:[0.00348712 0.00588852 0.00627584 0.01025774 0.00460799 0.02845815
 0.00677926 0.01560612 0.03401424 0.03401425 0.00460799 0.00677767
 0.00677546 0.02236126 0.00460798 0.00623314 0.00433788 0.01052659
 0.00911246 0.00677767 0.00854212 0.02236127 0.00398247 0.00460778
 0.01135131 0.01985581 0.00460798 0.02236127 0.00459324 0.00677767
 0.00398403 0.00460798 0.00615097 0.03404482 0.00677766 0.00972265
 0.00590062 0.00398243 0.00460798 0.02215503 0.00615098 0.00615599
 0.00851701 0.00803464 0.02236127 0.00898698 0.00677757 0.01528303
 0.00460797 0.00460797]
tr_loss:[0.00666975 0.00860954 0.0204544  0.00282214 0.03106411 0.00667785
 0.0094765  0.00971341 0.03106409 0.00934589 0.00894883 0.00666992
 0.01830111 0.00949199 0.00666992 0.00947014 0.0310641  0.00570698
 0.03106409 0.02303605 0.00834572 0.03106411 0.00359806 0.00623129
 0.00947018 0.00282255 0.00888633 0.00570822 0.00992383 0.00947013
 0.00679983 0.00670193 0.00472893 0.02990746 0.02644897 0.00359807
 0.00992266 0.00947536 0.00867104 0.00282214 0.00834561 0.00666992
 0.00359807 0.00566754 0.02303605 0.00359807 0.00282213 0.00470914
 0.00285307 0.00860725]
tr_loss:[0.00494015 0.00687149 0.00494015 0.00494016 0.02914186 0.0180972
 0.00814855 0.01004099 0.00404624 0.02876832 0.02914172 0.00494016
 0.00814855 0.00494016 0.0291417  0.00150157 0.00150157 0.00494016
 0.00286094 0.0040623  0.00482538 0.00469652 0.02914174 0.00923481
 0.00796858 0.02914174 0.00482538 0.02914171 0.02463923 0.00494016
 0.00482504 0.00509774 0.03024952 0.01886057 0.00688796 0.010041
 0.00286094 0.00482537 0.00654714 0.00482537 0.01809721 0.01049994
 0.00286094 0.00817404 0.00814856 0.00494016 0.00482539 0.00654028
 0.01004494 0.01798429]
tr_loss:[0.01010804 0.02010874 0.00565818 0.00261504 0.00282673 0.00585286
 0.00585287 0.01654198 0.00585287 0.00261506 0.00565839 0.02817661
 0.0126144  0.00565817 0.01010001 0.00261744 0.00134152 0.02817639
 0.01122223 0.01122223 0.01555384 0.01122223 0.00253521 0.00239372
 0.01122223 0.00075795 0.0048322  0.0155538  0.02817751 0.0281764
 0.00565818 0.00585287 0.00282642 0.00242592 0.01122223 0.00278445
 0.002907   0.0056491  0.00282644 0.01160049 0.0205716  0.00282644
 0.00264877 0.00565816 0.00282644 0.02945347 0.00242592 0.00585287
 0.00334783 0.00565826]
tr_loss:[0.00413551 0.00740396 0.01608333 0.00740396 0.02459046 0.00321249
 0.01725182 0.00313892 0.00321249 0.00385045 0.00526586 0.00943737
 0.01286535 0.01543123 0.00945888 0.00943731 0.03018841 0.00476656
 0.00413551 0.0263602  0.03018836 0.00321249 0.01524644 0.00476656
 0.00519889 0.00321249 0.00321244 0.00943737 0.02459059 0.00321281
 0.01520977 0.02246507 0.00321249 0.00561914 0.01495659 0.0032212
 0.00385043 0.00321249 0.00284286 0.00944368 0.00321249 0.02188164
 0.00412735 0.00476656 0.00357533 0.00276457 0.00526602 0.015012
 0.00948601 0.00943737]
tr_loss:[0.01022957 0.00450292 0.00528138 0.00511883 0.00604185 0.00578687
 0.00507547 0.03221364 0.00408514 0.0284124  0.00604046 0.00524885
 0.00416878 0.0044346  0.00604043 0.03221365 0.03221367 0.00604046
 0.0058145  0.01022957 0.004097   0.00578741 0.03222086 0.03221368
 0.00373653 0.0102293  0.00414297 0.0169913  0.01022957 0.00408513
 0.03221367 0.00408512 0.00579532 0.00557012 0.01022972 0.00512378
 0.00413706 0.00443461 0.00408524 0.00511889 0.00604046 0.03221365
 0.0135045  0.01022958 0.00578741 0.00450814 0.00456914 0.00408512
 0.00578741 0.0167851 ]
tr_loss:[0.02595612 0.03237173 0.00441983 0.00799374 0.01161448 0.03237172
 0.00427222 0.00409445 0.01634597 0.00340415 0.01635129 0.00799373
 0.01091872 0.01084981 0.00769995 0.00441989 0.00433358 0.00441989
 0.00491459 0.00490535 0.0044199  0.01064719 0.00797797 0.00799374
 0.00486197 0.00799374 0.00799374 0.00409445 0.00340416 0.0044197
 0.00507252 0.03237171 0.00507252 0.004862   0.00520746 0.004862
 0.00507252 0.03237173 0.0051292  0.00799373 0.00520746 0.0109212
 0.03381817 0.00520745 0.00354018 0.00481298 0.00507252 0.03237172
 0.00510393 0.00799373]
tr_loss:[0.00385406 0.00612846 0.00612846 0.00434745 0.00536943 0.0189202
 0.00143993 0.0050221  0.00634846 0.00612846 0.00385405 0.00634846
 0.00371877 0.03124711 0.00536944 0.00536944 0.0050221  0.0050221
 0.00502099 0.00612846 0.0312514  0.00536943 0.00612846 0.00612846
 0.00612846 0.00502209 0.00634846 0.00143993 0.00267093 0.0050221
 0.00634839 0.03124989 0.00612845 0.00434745 0.03124996 0.00536944
 0.00143993 0.0050221  0.00612846 0.00267094 0.0312499  0.00399919
 0.01889773 0.00918998 0.03124988 0.00690013 0.00513561 0.03124988
 0.01771294 0.00827886]
tr_loss:[0.00441161 0.0032521  0.02407071 0.00590829 0.00723773 0.00230685
 0.00512135 0.00625454 0.00590848 0.00590829 0.01910232 0.03006383
 0.00896501 0.00627237 0.00379846 0.00896912 0.0240707  0.00532731
 0.00512016 0.00230694 0.02948902 0.00512135 0.03006383 0.00512135
 0.00532732 0.01002622 0.0053273  0.00474656 0.00625261 0.00590829
 0.00532731 0.00896501 0.03006383 0.0032521  0.00590829 0.00574805
 0.00107416 0.00896501 0.00532729 0.00107416 0.00590829 0.00896501
 0.00107416 0.00911289 0.00107416 0.00107416 0.00532719 0.0059079
 0.00590829 0.00896501]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3600 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3601, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3601 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3602, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3602 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3603, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3603 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3604, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3604 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3605, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3605 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3606, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3606 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3607, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3607 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3608, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3608 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3609, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3609 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3610, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3610 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3611, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3611 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3612, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3612 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3613, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3613 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3614, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3614 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3615, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3615 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3616, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3616 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3617, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3617 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3618, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3618 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3619, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3619 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3620, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3620 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3621, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3621 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3622, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3622 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3623, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3623 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3624, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3624 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3625, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3625 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3626, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3626 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3627, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3627 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3628, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3628 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3629, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3629 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3630, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3630 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3631, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3631 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3632, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3632 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3633, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3633 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3634, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3634 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3635, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3635 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3636, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3636 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3637, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3637 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3638, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3638 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3639, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3639 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3640, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3640 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3641, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3641 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3642, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3642 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3643, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3643 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3644, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3644 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3645, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3645 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3646, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3646 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3647, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3647 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3648, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3648 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3649, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3649 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3650, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3650 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3651, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3651 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3652, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3652 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3653, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3653 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3654, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3654 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3655, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3655 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3656, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3656 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3657, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3657 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3658, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3658 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3659, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3659 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3660, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3660 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3661, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3661 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3662, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3662 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3663, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3663 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3664, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3664 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3665, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3665 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3666, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3666 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3667, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3667 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3668, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3668 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3669, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3669 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3670, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3670 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3671, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3671 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3672, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3672 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3673, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3673 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3674, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3674 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3675, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3675 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3676, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3676 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3677, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3677 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3678, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3678 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3679, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3679 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3680, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3680 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3681, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3681 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3682, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3682 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3683, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3683 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3684, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3684 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3685, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3685 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3686, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3686 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3687, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3687 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3688, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3688 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3689, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3689 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3690, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3690 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3691, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3691 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3692, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3692 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3693, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3693 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3694, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3694 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3695, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3695 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3696, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3696 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3697, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3697 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3698, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3698 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3699, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3699 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3700, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-3600
text_input.shape
(3700, 14400)
learning_input_tmp.shape
(3700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3700, 80)
learning_output.shape
(750, 80)
Model: "sequential_75"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_75 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.5811218 1.5865163 1.5556173 1.5535862 1.5829942 1.6140983 1.5751745
 1.5518764 1.5519159 1.5556173 1.597892  1.6071068 1.598139  1.5520165
 1.5519159 1.5905014 1.5979365 1.6074082 1.5519215 1.6070973 1.6070973
 1.5588423 1.5905975 1.418594  1.424989  1.5391661 1.5519161 1.6076868
 1.5815912 1.454128  1.5533019 1.5681854 1.6076868 1.5905974 1.4222685
 1.5525362 1.5748138 1.551916  1.5461953 1.5905929 1.5519162 1.5391649
 1.5747036 1.5905979 1.6076841 1.5496423 1.5514059 1.5941294 1.5519161
 1.551916 ]
tr_loss:[0.85287744 0.85287476 0.8422392  0.87934333 0.8463066  0.83506095
 0.829806   0.85287744 0.8461976  0.8461976  0.8570236  0.8489281
 0.85698605 0.8570236  0.8343685  0.8570236  0.85287744 0.8273964
 0.8735674  0.8461207  0.84285    0.8570236  0.8350609  0.83506125
 0.84619504 0.8461977  0.85287744 0.8570237  0.8528775  0.8350609
 0.83500606 0.8563541  0.8793432  0.8257952  0.8570236  0.8538437
 0.84411746 0.842451   0.8257952  0.8518751  0.85703534 0.8570236
 0.8703991  0.85287744 0.8257952  0.85287726 0.8570237  0.8461982
 0.8350582  0.85023946]
tr_loss:[0.48946065 0.4937018  0.4943006  0.526363   0.5105063  0.5277095
 0.4927432  0.48518008 0.5019355  0.506716   0.50381833 0.5095732
 0.5105063  0.4894596  0.5167442  0.5095747  0.51688254 0.52770835
 0.5019355  0.48945957 0.499923   0.51339483 0.48393688 0.5095733
 0.52770835 0.50193536 0.5018717  0.5224615  0.48347148 0.5019355
 0.48733893 0.5277083  0.4850893  0.52249527 0.5019355  0.5019355
 0.50957316 0.5095733  0.50060064 0.48507375 0.5105063  0.5019355
 0.49121445 0.5135035  0.5105063  0.5105063  0.50193965 0.48347148
 0.48347148 0.4907965 ]
tr_loss:[0.24846096 0.23759417 0.22403455 0.22259521 0.23773816 0.22403455
 0.22426018 0.2240345  0.23773813 0.22259355 0.23786943 0.23773816
 0.22658281 0.23783283 0.24845996 0.22658864 0.22658253 0.24845996
 0.23773809 0.23878765 0.2387439  0.2240344  0.22658277 0.2315782
 0.24845996 0.23773816 0.22658281 0.22658285 0.2387876  0.22403452
 0.22403494 0.22379756 0.2194705  0.23773818 0.23158486 0.22042637
 0.22403455 0.23874387 0.23773813 0.2387876  0.23773816 0.21946526
 0.23773813 0.23158593 0.24845996 0.22954333 0.22483873 0.22375432
 0.2240345  0.24800238]
tr_loss:[0.07507937 0.08274683 0.08287197 0.08287362 0.07498258 0.07535404
 0.07507938 0.0903296  0.08274678 0.08274802 0.08386929 0.07853983
 0.08287361 0.07629064 0.09033079 0.09964167 0.07892552 0.09032957
 0.07412282 0.07629066 0.07615934 0.10512364 0.07615934 0.0736549
 0.07628164 0.08274678 0.10512392 0.08274684 0.0741228  0.07365486
 0.08116104 0.08120251 0.07628962 0.07853983 0.0834642  0.07365488
 0.08274684 0.08344672 0.07598627 0.07365488 0.07365511 0.08335662
 0.0789257  0.07629067 0.08274684 0.08294769 0.09030403 0.08274678
 0.10560157 0.07365487]
tr_loss:[0.0192354  0.02139646 0.06149586 0.01922311 0.01414062 0.01417282
 0.02713441 0.02094222 0.0299283  0.02139646 0.02139647 0.0209423
 0.03041119 0.01414063 0.01416931 0.01428601 0.01416731 0.02713896
 0.02713894 0.05444421 0.02139648 0.02713897 0.02087923 0.02416936
 0.0141673  0.02094222 0.02437516 0.02094223 0.02416935 0.02139648
 0.02102616 0.02094223 0.02416933 0.01414062 0.01944906 0.01923539
 0.01414026 0.02437514 0.01766721 0.02094222 0.02713895 0.01944864
 0.06139238 0.021087   0.02139646 0.01413784 0.02139647 0.01414062
 0.02713894 0.01414063]
tr_loss:[0.00670841 0.02042711 0.0325137  0.01700918 0.01650751 0.00684434
 0.02063417 0.01378787 0.05608894 0.02042713 0.02063389 0.01378786
 0.02055332 0.01689553 0.02316469 0.00670841 0.02051693 0.00676817
 0.02042711 0.00714042 0.02042711 0.01228901 0.00511293 0.02042713
 0.01378788 0.01693071 0.00932713 0.01665627 0.02501977 0.01378789
 0.00346194 0.01693075 0.01389754 0.02042715 0.01378786 0.02042712
 0.02063417 0.02063405 0.01378789 0.01228901 0.01877027 0.01378817
 0.06080282 0.02501978 0.01696746 0.02316491 0.01693074 0.05608894
 0.02042713 0.012289  ]
tr_loss:[0.00759436 0.01278264 0.01330661 0.01849489 0.01278272 0.00759487
 0.01786533 0.00264968 0.01557573 0.04771013 0.01335217 0.0133527
 0.02138489 0.04756659 0.01335271 0.00950866 0.00759487 0.05506458
 0.01335271 0.02401302 0.01876204 0.02622912 0.01583254 0.00759487
 0.05588857 0.01278273 0.00792591 0.01177207 0.01335718 0.0095009
 0.00759487 0.00950884 0.01278273 0.00792577 0.01758572 0.00950867
 0.01335255 0.00491376 0.00264968 0.01791071 0.02100426 0.0133527
 0.00264968 0.00458866 0.01790068 0.01278272 0.0475684  0.00759487
 0.01335243 0.0550646 ]
tr_loss:[0.00865185 0.00865186 0.01408713 0.00865185 0.00647927 0.00865186
 0.04988625 0.01816933 0.01408712 0.02211306 0.00647834 0.02198547
 0.01911919 0.01816937 0.02211742 0.00865184 0.01884291 0.00865187
 0.00865187 0.01766022 0.01801213 0.01911916 0.01886508 0.00866181
 0.01408712 0.01798356 0.017984   0.00837254 0.01408712 0.00865185
 0.02275654 0.01408712 0.00829967 0.05127763 0.00829966 0.01899921
 0.01814002 0.01899647 0.01886511 0.01816276 0.00912618 0.01911916
 0.00837191 0.00837262 0.01845517 0.00912595 0.00865186 0.0056048
 0.01798354 0.01092988]
tr_loss:[0.04839511 0.04839512 0.01391839 0.01900803 0.01900803 0.01645814
 0.00649892 0.01117361 0.00751135 0.00649892 0.00649889 0.01839182
 0.01764554 0.01764569 0.01900805 0.0191693  0.00649892 0.00971843
 0.00751135 0.00829976 0.00640565 0.01117362 0.04967353 0.01900882
 0.00751135 0.00649889 0.0064989  0.01764569 0.01764874 0.01764569
 0.00649891 0.00649889 0.01916941 0.01117362 0.01765226 0.0139184
 0.01885608 0.01832678 0.00649781 0.0139184  0.0176456  0.01916941
 0.00649891 0.01661024 0.0176457  0.01900813 0.0139184  0.04839512
 0.0064989  0.01800328]
tr_loss:[0.01432038 0.0129664  0.00804716 0.01327163 0.01451869 0.00427326
 0.01295161 0.0080472  0.01130745 0.04807543 0.01336487 0.01683356
 0.01332234 0.01683358 0.00622526 0.01332256 0.0046515  0.01387597
 0.01371183 0.0046515  0.00804716 0.01395561 0.00804716 0.00804717
 0.01432027 0.0138794  0.0168336  0.00804716 0.01295302 0.01332235
 0.01387939 0.00854659 0.00427326 0.00804716 0.01267618 0.0129516
 0.01844102 0.00427327 0.01387922 0.00568354 0.04108356 0.0129842
 0.00427327 0.01130744 0.00812664 0.04733162 0.01130745 0.00427326
 0.01332233 0.00427327]
tr_loss:[0.00435366 0.04811499 0.01011918 0.00642083 0.01048267 0.00918331
 0.01444153 0.04797336 0.00286304 0.0091833  0.00547288 0.00918331
 0.01417696 0.00928105 0.00286304 0.01252959 0.00286304 0.01252959
 0.0091833  0.0098672  0.00642085 0.00918448 0.00286304 0.00421293
 0.00421294 0.00286305 0.00286304 0.01252959 0.00642085 0.01252959
 0.01599662 0.0091833  0.00435366 0.00642084 0.00421295 0.04420562
 0.00435366 0.00642084 0.04797338 0.00520632 0.01252959 0.00766907
 0.0091833  0.00544649 0.01252959 0.04217657 0.00520624 0.00547287
 0.00917944 0.00286304]
tr_loss:[0.01420601 0.00158094 0.00579261 0.00158094 0.02010613 0.01583458
 0.04449198 0.00834603 0.00158094 0.00602875 0.02063825 0.00158094
 0.00669965 0.00602875 0.00730781 0.01420601 0.00602875 0.01583456
 0.00834602 0.01086607 0.01494817 0.01583458 0.01583376 0.04892623
 0.00738743 0.00550832 0.04449529 0.00933692 0.00834669 0.0088619
 0.01583218 0.01088076 0.01872034 0.00158094 0.00602875 0.04892623
 0.00158094 0.01542464 0.00602875 0.04488532 0.00602875 0.00820968
 0.01088075 0.00950965 0.01420601 0.00735135 0.00158389 0.00738744
 0.01088076 0.00158094]
tr_loss:[0.00228348 0.01371991 0.00529423 0.01248541 0.03995175 0.01371918
 0.01293395 0.01047761 0.00228348 0.01638532 0.00825947 0.01293432
 0.01248545 0.00645274 0.00529422 0.00825339 0.00228348 0.01567385
 0.01837156 0.00228499 0.00772908 0.01292902 0.01293433 0.00529423
 0.04500241 0.00958301 0.00830682 0.00571944 0.0089372  0.00846576
 0.00830655 0.03926327 0.01235639 0.01248544 0.00893721 0.00825337
 0.00572094 0.00830295 0.01248543 0.01567385 0.00779989 0.01293413
 0.00572094 0.00825389 0.00691531 0.00228348 0.01567385 0.01293432
 0.0082534  0.00893721]
tr_loss:[0.01450446 0.00990805 0.00851932 0.0189618  0.01007129 0.00966305
 0.00548645 0.00990207 0.00990805 0.00966305 0.01526486 0.00966305
 0.01078893 0.01235888 0.00987879 0.01526487 0.00966303 0.00676046
 0.01450448 0.00998391 0.0189618  0.00966304 0.00548645 0.00675893
 0.00990805 0.00966364 0.00548644 0.01450447 0.01457193 0.01896179
 0.00605037 0.00990805 0.00966304 0.00851942 0.01458383 0.01526552
 0.00860299 0.00727659 0.00966305 0.01450449 0.00966305 0.01896179
 0.01375524 0.0145045  0.01896179 0.01405207 0.0155985  0.0189618
 0.00990521 0.00966302]
tr_loss:[0.03701705 0.00744278 0.03701705 0.01439776 0.01272194 0.01272195
 0.01272192 0.004673   0.00745502 0.03031795 0.00624988 0.03701702
 0.00744277 0.00760032 0.004673   0.02991    0.01272203 0.00432444
 0.00624989 0.00723316 0.004673   0.01587096 0.03701705 0.01272195
 0.00744277 0.00744277 0.00744278 0.01267519 0.03765205 0.00627247
 0.01272194 0.00432444 0.01587097 0.004673   0.00720034 0.00738503
 0.00744287 0.01272191 0.03765204 0.01233574 0.00708643 0.004673
 0.00625078 0.0147011  0.00739537 0.004673   0.00715432 0.00971008
 0.01272194 0.00645774]
tr_loss:[0.00318207 0.00753112 0.00241081 0.00318077 0.01145137 0.00501812
 0.00164448 0.00753111 0.0050178  0.0037061  0.00308806 0.00517062
 0.00241081 0.00164448 0.00241471 0.0016444  0.00341569 0.00293206
 0.00122327 0.00428426 0.00517092 0.00753111 0.00501817 0.00318207
 0.00318213 0.00517092 0.00136226 0.00515262 0.0114513  0.00241081
 0.0075311  0.00517092 0.00516902 0.01206719 0.0026973  0.00164448
 0.0114513  0.00501817 0.00494727 0.0024108  0.01391144 0.00517095
 0.00494212 0.00241081 0.00342745 0.0075311  0.01257841 0.00517092
 0.03319984 0.00189369]
tr_loss:[0.01939738 0.0121967  0.0118439  0.00498664 0.00544738 0.00376268
 0.0121967  0.03564039 0.00544737 0.00840407 0.00376248 0.0121967
 0.00498664 0.03564039 0.00423634 0.00825771 0.03092592 0.0121967
 0.0121967  0.00823556 0.01899199 0.01645763 0.03060259 0.00423662
 0.0121967  0.00357239 0.0121967  0.00247233 0.00825769 0.00881841
 0.01219668 0.00357239 0.00376252 0.00544738 0.00376247 0.0299024
 0.00221538 0.00376249 0.00825769 0.0033871  0.00498664 0.0082577
 0.00376247 0.00376248 0.00881839 0.00811649 0.00881838 0.0082587
 0.00544737 0.00412353]
tr_loss:[0.00764578 0.00764579 0.00568029 0.01249418 0.00764579 0.01249418
 0.00555073 0.005596   0.00555058 0.03253568 0.01093442 0.03310467
 0.01249418 0.01249418 0.00648334 0.00555058 0.00764579 0.00764578
 0.00764578 0.00869788 0.03301515 0.00764804 0.01249418 0.00648334
 0.00869789 0.02132662 0.00382587 0.00869773 0.00764578 0.00568272
 0.0056827  0.00648334 0.00648334 0.03301516 0.00869789 0.00648233
 0.0086979  0.03800764 0.01052509 0.00382587 0.00384677 0.00645254
 0.00368842 0.00648334 0.00764578 0.0380077  0.0056827  0.01093441
 0.01249418 0.0036922 ]
tr_loss:[0.00909847 0.00254757 0.00579362 0.00589956 0.03652848 0.00626575
 0.00591269 0.00578295 0.00907332 0.0045282  0.00664566 0.00579362
 0.00277129 0.00452713 0.00233673 0.03652848 0.0033419  0.00256367
 0.0058994  0.00579357 0.00452062 0.03154977 0.0087256  0.00233673
 0.00907331 0.00330493 0.03652848 0.0058704  0.00587041 0.00907332
 0.00938081 0.00589939 0.0058704  0.00936897 0.00590111 0.00907331
 0.00664565 0.0058704  0.03155151 0.00813268 0.00233673 0.0058704
 0.0058704  0.00938231 0.00585628 0.0046136  0.0058994  0.0058994
 0.0090733  0.00579362]
tr_loss:[0.00386369 0.00806013 0.0053652  0.00672215 0.00686988 0.00210617
 0.0053749  0.00806013 0.00652343 0.00386368 0.0069964  0.00538077
 0.00806013 0.00386368 0.01015889 0.02876076 0.01309722 0.00386368
 0.00536521 0.00675452 0.00536518 0.00537233 0.00440283 0.00536519
 0.03457494 0.00548721 0.03457496 0.00404752 0.00210618 0.00210613
 0.0053652  0.00696531 0.00125069 0.00537491 0.00806013 0.00386368
 0.0053563  0.00125045 0.00544197 0.00537306 0.00806013 0.00125069
 0.00537491 0.0053563  0.0053652  0.00386368 0.0069964  0.0053749
 0.00675459 0.00537491]
tr_loss:[0.00489735 0.00457249 0.03623998 0.00449597 0.00471014 0.00824347
 0.00489736 0.0082921  0.02962245 0.00742611 0.0048965  0.00363063
 0.00616577 0.00245432 0.00755695 0.02962244 0.00529883 0.00489735
 0.00748213 0.00616568 0.00462471 0.00529499 0.00224314 0.00755694
 0.03545751 0.00363063 0.00489736 0.00829163 0.00616077 0.00139044
 0.02962244 0.0082921  0.00489736 0.0082921  0.00489735 0.00755696
 0.00480623 0.00489712 0.00710331 0.00489735 0.0135744  0.00449365
 0.00224314 0.00473575 0.00755694 0.00489772 0.01355884 0.00489767
 0.00909584 0.00489736]
tr_loss:[0.00770072 0.00489669 0.00135947 0.00320452 0.00679195 0.00489671
 0.00391214 0.00679092 0.00991132 0.00991134 0.00991135 0.0017168
 0.00990923 0.00171677 0.00991133 0.0034658  0.01059327 0.0067918
 0.01059327 0.00516941 0.00172632 0.01059327 0.00892178 0.00679196
 0.00345844 0.00479812 0.00991135 0.00489783 0.00171677 0.00541486
 0.00171677 0.00679195 0.00266778 0.0029909  0.0048999  0.00489671
 0.00171677 0.00490125 0.0048967  0.00991134 0.00725733 0.00725696
 0.01059327 0.0048964  0.00266778 0.00991135 0.00991134 0.00991134
 0.00802688 0.00973401]
tr_loss:[0.01025624 0.00278406 0.00424072 0.00424071 0.00071633 0.00320198
 0.01438658 0.00071633 0.00504276 0.00688515 0.00424072 0.00424078
 0.0007164  0.00424109 0.03767478 0.00798951 0.00424072 0.00071645
 0.00798951 0.01198141 0.00320198 0.00071633 0.00504306 0.00071633
 0.00777454 0.00319776 0.00424071 0.00976354 0.00794712 0.00424072
 0.00976353 0.00425215 0.00976352 0.00360867 0.00976352 0.00976354
 0.00317197 0.01023233 0.00798952 0.03180417 0.00320198 0.00071633
 0.00976353 0.00777404 0.00295958 0.00446815 0.00071633 0.00976354
 0.00424072 0.00976352]
tr_loss:[0.00043099 0.00312826 0.00312826 0.00312825 0.00371172 0.00882052
 0.01347415 0.00810686 0.01305377 0.03685549 0.00366926 0.00043147
 0.00810684 0.00810686 0.00230754 0.00774499 0.00598725 0.00598723
 0.00371142 0.00823046 0.00378584 0.00386745 0.00882052 0.00371172
 0.00043102 0.00043099 0.01347434 0.00371172 0.00331676 0.00230754
 0.01305554 0.00312826 0.00043099 0.00043099 0.01305377 0.00043099
 0.00043099 0.01347428 0.0056856  0.00810684 0.00882051 0.00665225
 0.00568561 0.00386745 0.00402343 0.00810685 0.00402337 0.01305377
 0.01104751 0.00366246]
tr_loss:[0.00165285 0.01147952 0.00851949 0.0093268  0.01234147 0.00098922
 0.0085195  0.00569643 0.01234147 0.00642655 0.00098922 0.00642655
 0.00335913 0.0085909  0.00165285 0.00098922 0.00466973 0.03485934
 0.00642654 0.01132641 0.00642656 0.00857362 0.00876247 0.00932853
 0.01234147 0.00466972 0.00338415 0.00851948 0.01479033 0.0085195
 0.00162718 0.00642656 0.0096642  0.00466971 0.00098922 0.01234147
 0.00262169 0.00442525 0.00358735 0.00105502 0.00098922 0.00338437
 0.01367938 0.00335079 0.00466923 0.00098922 0.00165285 0.00642655
 0.00338436 0.02008786]
tr_loss:[0.03193443 0.00337505 0.00076347 0.03261232 0.00076485 0.0319344
 0.00524815 0.00354394 0.00524815 0.01076079 0.00524815 0.00524816
 0.00218547 0.00342725 0.01023052 0.00377264 0.00524816 0.00524815
 0.00712538 0.00712511 0.00524816 0.01315874 0.00524816 0.02723085
 0.01023052 0.0021855  0.00354397 0.00365361 0.00524817 0.03193439
 0.00218546 0.00218546 0.00361399 0.00524816 0.00337565 0.00354395
 0.00712538 0.00337507 0.00354395 0.00356105 0.00076485 0.00218546
 0.005537   0.0070586  0.01023051 0.00712539 0.00354394 0.00985733
 0.00711018 0.00712536]
tr_loss:[0.00566308 0.00447544 0.00433857 0.00461562 0.00433857 0.00872135
 0.03047654 0.00186955 0.00566308 0.0043386  0.00405375 0.00566349
 0.00406141 0.01085547 0.02530721 0.00296571 0.00296313 0.00406834
 0.00434479 0.0043386  0.00566308 0.00566307 0.00405375 0.00405376
 0.0067907  0.01324185 0.0043386  0.00502346 0.00412515 0.00436187
 0.00434491 0.00331034 0.00609068 0.00872134 0.01061818 0.0043386
 0.00447345 0.00608551 0.00681779 0.01085807 0.01399905 0.01324185
 0.00427527 0.00566308 0.0043386  0.00412514 0.00608543 0.00566307
 0.0060841  0.01342985]
tr_loss:[0.00433106 0.00488403 0.00432591 0.00762196 0.00432653 0.01384936
 0.00432623 0.00762196 0.01007169 0.00762197 0.00644566 0.00432591
 0.00644566 0.00406071 0.00762197 0.00540389 0.02549099 0.00540389
 0.00443938 0.00260712 0.00762197 0.00633788 0.00647179 0.00432591
 0.00762197 0.00204607 0.00540596 0.00644565 0.00432677 0.00443938
 0.00644566 0.00467503 0.01384859 0.00644566 0.00432591 0.00644465
 0.03198959 0.00762197 0.00762197 0.00434717 0.00432591 0.00644566
 0.00644566 0.00762196 0.00488406 0.00540389 0.00412841 0.00488407
 0.02549054 0.00540389]
tr_loss:[0.00521322 0.00390556 0.0048612  0.00409859 0.00485401 0.00409859
 0.00409858 0.0022947  0.00409924 0.0022947  0.00518857 0.0040986
 0.00681922 0.00409858 0.03303631 0.00390556 0.00553979 0.00409859
 0.00708091 0.00409858 0.00390556 0.01089658 0.00390557 0.00390556
 0.00397108 0.00409861 0.00554038 0.00434742 0.00501645 0.00521326
 0.01270992 0.00474384 0.00409858 0.00409858 0.00491193 0.03303634
 0.00394192 0.00381044 0.00921619 0.00409858 0.00409874 0.03323023
 0.00521326 0.00681921 0.00381043 0.00434823 0.0022947  0.00409857
 0.00390556 0.00409859]
text_input.shape
(3700, 14400)
learning_input_tmp.shape
(3700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3700, 80)
learning_output.shape
(750, 80)
Model: "sequential_76"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_76 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3568318 1.3571823 1.356835  1.3181281 1.3064991 1.3673232 1.3568397
 1.3362707 1.3362721 1.2831279 1.3495796 1.3571824 1.2866434 1.3317735
 1.3181282 1.1955297 1.3567642 1.3181281 1.3583851 1.2871931 1.3181281
 1.3181041 1.2866507 1.3363279 1.3236437 1.293906  1.2873421 1.3362706
 1.3325725 1.3181267 1.3362706 1.3238223 1.3308027 1.3571823 1.3181281
 1.3181274 1.3673334 1.2953424 1.2913321 1.3181283 1.3362709 1.1927221
 1.3236419 1.3870317 1.3870317 1.1925594 1.3236437 1.3816917 1.318128
 1.3236437]
tr_loss:[0.9067696  0.86976016 0.9037506  0.9237258  0.8926657  0.8869341
 0.8928342  0.88665086 0.88117427 0.9309127  0.8959532  0.8928331
 0.8652714  0.8697599  0.9212205  0.85641897 0.9067696  0.87493706
 0.90603006 0.8888348  0.86976016 0.89266664 0.88127935 0.9089384
 0.8874532  0.9028017  0.9204956  0.8748964  0.9204956  0.89283293
 0.9309124  0.8563732  0.89725053 0.92799723 0.8928329  0.89283276
 0.9067491  0.89266473 0.85861284 0.86976004 0.9309126  0.88745344
 0.9199416  0.8697793  0.89266413 0.8749367  0.86976004 0.9204952
 0.87179816 0.90792465]
tr_loss:[0.4832995  0.4816597  0.48119467 0.49702168 0.5036295  0.49654636
 0.4785462  0.48119467 0.48329955 0.49654636 0.48119467 0.49701047
 0.49654636 0.49206376 0.4811946  0.48119467 0.4785041  0.5134865
 0.49701038 0.4920644  0.4964455  0.5114067  0.49206614 0.49654636
 0.49654636 0.5021504  0.47863045 0.4832995  0.48119536 0.48119467
 0.48329943 0.48329943 0.4920562  0.4832995  0.4936873  0.5021504
 0.48329124 0.4970104  0.48119563 0.4970104  0.49654636 0.4970104
 0.48117894 0.4980913  0.48166013 0.49701038 0.51351947 0.4970104
 0.50139034 0.4970104 ]
tr_loss:[0.24626485 0.25758305 0.24897632 0.2530693  0.24626485 0.2807862
 0.24897635 0.24626482 0.27728185 0.24626537 0.2495408  0.24626485
 0.24897632 0.26946005 0.24599862 0.28173846 0.25307202 0.25758302
 0.24626479 0.27994734 0.26201352 0.24626482 0.26521516 0.28143072
 0.24592777 0.2526327  0.24583416 0.26536652 0.27915883 0.24626482
 0.24626479 0.2620135  0.24626482 0.28041333 0.26292017 0.28143343
 0.26238808 0.27637234 0.26201355 0.26305848 0.26201352 0.27937418
 0.26201397 0.26536196 0.28143343 0.2575832  0.24626327 0.2620135
 0.2771054  0.28041336]
tr_loss:[0.1512378  0.16126922 0.16361654 0.14891438 0.16112193 0.17757067
 0.18208742 0.14697285 0.1489148  0.14891443 0.16126919 0.14925584
 0.148854   0.18028103 0.15154414 0.16126922 0.1584616  0.14925583
 0.14891441 0.16126919 0.1636146  0.17757067 0.1653124  0.16004623
 0.161122   0.160046   0.15154408 0.15981102 0.17757067 0.1512376
 0.14891443 0.14891437 0.16362384 0.18215461 0.14891441 0.14891443
 0.14891438 0.15154383 0.17852738 0.17757066 0.15154412 0.14891902
 0.15815353 0.16126963 0.16101643 0.1489146  0.16126922 0.16004601
 0.17667761 0.16531241]
tr_loss:[0.07047832 0.06946205 0.05593996 0.06947836 0.09765939 0.05831901
 0.06282392 0.06106623 0.06109771 0.05218447 0.06109586 0.05537362
 0.06282394 0.06282391 0.06073102 0.05831905 0.05537362 0.06080695
 0.05916004 0.08125223 0.07841355 0.08125226 0.07291768 0.06109767
 0.05831856 0.05831901 0.06109768 0.06941063 0.06080704 0.05831915
 0.05537362 0.06109769 0.05832016 0.06252043 0.09767361 0.0610977
 0.05734303 0.10131298 0.05752301 0.0600032  0.05916088 0.05863689
 0.06073112 0.05925231 0.05537362 0.10276876 0.06948116 0.05863688
 0.06948115 0.06080704]
tr_loss:[0.01562427 0.02014067 0.02888717 0.01585073 0.01585074 0.0163212
 0.02889237 0.01585073 0.02458066 0.01653617 0.01646415 0.0457247
 0.00969924 0.00969939 0.01585073 0.02031055 0.01585074 0.01471434
 0.01069993 0.01471435 0.01069991 0.02031055 0.02498555 0.01653617
 0.01585074 0.01653617 0.01646414 0.02031055 0.01968082 0.00969482
 0.0248188  0.01588977 0.01178402 0.02031056 0.06116369 0.02480973
 0.02490328 0.0117026  0.01583974 0.00969939 0.01070001 0.02031053
 0.06116369 0.01264053 0.01585075 0.02498553 0.01824401 0.00969939
 0.01824398 0.01264602]
tr_loss:[0.02578996 0.02880929 0.00993879 0.02216841 0.0221221  0.02216842
 0.00798449 0.05986908 0.00798448 0.01789837 0.01759133 0.00779106
 0.00798449 0.00798449 0.05966517 0.00779106 0.01509784 0.02216843
 0.00776979 0.00798449 0.00798449 0.00798449 0.00798449 0.0151146
 0.00779106 0.00769491 0.00798449 0.00798449 0.02216841 0.00798449
 0.00814456 0.01786815 0.03733147 0.02188144 0.00779106 0.02216842
 0.01509267 0.01509232 0.00798449 0.02212207 0.03471269 0.02216843
 0.05966515 0.01493919 0.02215986 0.02212209 0.01509241 0.01509232
 0.02281029 0.02216841]
tr_loss:[0.01777061 0.01895623 0.01895721 0.0106232  0.01768508 0.01777059
 0.01591185 0.01162512 0.01162512 0.01777061 0.01162501 0.0177706
 0.01162512 0.01895722 0.02727712 0.01162373 0.01162512 0.05076417
 0.01783561 0.01697976 0.02435015 0.01780465 0.01795984 0.05129789
 0.01973099 0.01772259 0.01776981 0.02435016 0.00990407 0.04477385
 0.01777245 0.01077058 0.05123556 0.01800758 0.01077054 0.03673903
 0.0284945  0.00990407 0.01162511 0.00990407 0.01162508 0.0189048
 0.03712454 0.01777063 0.00990409 0.05076417 0.01776904 0.00990407
 0.05076419 0.01162441]
tr_loss:[0.02050308 0.01587484 0.01015682 0.01916135 0.02194907 0.01587486
 0.01312967 0.02194906 0.01587486 0.04636407 0.01289123 0.01240243
 0.01433637 0.0107222  0.01015682 0.01331344 0.01916135 0.01240241
 0.02194907 0.00758683 0.03326833 0.01933965 0.01064886 0.01916163
 0.02748569 0.01015682 0.01916391 0.01433637 0.04282012 0.01896302
 0.02075205 0.01328485 0.01312592 0.02075064 0.01240241 0.02194909
 0.01333497 0.01240243 0.01916135 0.02194908 0.01916121 0.02707474
 0.04634541 0.02075064 0.01916133 0.01250704 0.04862396 0.04993733
 0.02050307 0.01240244]
tr_loss:[0.00943422 0.00987148 0.00986863 0.00943422 0.01887252 0.016307
 0.01630702 0.00925252 0.01657578 0.04581667 0.00925252 0.0104533
 0.016307   0.01657579 0.01657581 0.01843471 0.01243559 0.01675192
 0.0092525  0.01243565 0.01630702 0.01630701 0.0171478  0.00943421
 0.01657577 0.02382766 0.00925252 0.00987148 0.01657578 0.00836946
 0.01152827 0.01045333 0.01045333 0.01657581 0.00925254 0.00987148
 0.00836946 0.01045284 0.00925252 0.02611979 0.02662906 0.0167582
 0.00742675 0.00987148 0.02659557 0.00742675 0.02279614 0.0165758
 0.01630702 0.01045333]
tr_loss:[0.01256032 0.00764963 0.0059859  0.0059859  0.01613625 0.00480999
 0.01613685 0.01350059 0.04301343 0.01613373 0.0059859  0.01613683
 0.00546216 0.00764961 0.01256309 0.04507368 0.00599024 0.01256606
 0.01305722 0.01256032 0.01613687 0.0059859  0.0127926  0.01256784
 0.01735773 0.01613648 0.00854966 0.01305723 0.00854965 0.01256032
 0.00598591 0.04619519 0.01049762 0.00598589 0.0059859  0.00669476
 0.01807437 0.00668088 0.01613687 0.0059859  0.0059859  0.01049761
 0.00764961 0.0059859  0.00486042 0.01254727 0.00598862 0.00854971
 0.01613685 0.0059859 ]
tr_loss:[0.0130459  0.01760315 0.0495216  0.00702633 0.01226696 0.0051134
 0.01295653 0.01854463 0.00701172 0.01854461 0.01828766 0.0061592
 0.01304589 0.00702633 0.00773715 0.01018475 0.00703289 0.01217347
 0.01304598 0.0061592  0.00702633 0.01079164 0.00643911 0.00643911
 0.01304589 0.01363331 0.00643912 0.01854469 0.01762709 0.01079165
 0.0061592  0.04467215 0.01854461 0.00702635 0.01277082 0.00632114
 0.01304589 0.0130459  0.01356726 0.0130459  0.01493238 0.01316281
 0.01303734 0.01854464 0.00702634 0.00702633 0.01079164 0.01854463
 0.02296543 0.00441665]
tr_loss:[0.00759625 0.00759625 0.00759719 0.01346636 0.01526274 0.00896853
 0.00869058 0.01353992 0.00896855 0.00759625 0.00759625 0.00759625
 0.05579908 0.01346637 0.00896852 0.01432505 0.00869058 0.05456948
 0.00700187 0.02156411 0.00896854 0.00896855 0.00896952 0.02501836
 0.00700187 0.05579904 0.00869058 0.02175702 0.01036511 0.01110895
 0.02156414 0.01653201 0.00977753 0.01526276 0.05579908 0.01432374
 0.00977783 0.01458659 0.0165371  0.00759625 0.05009738 0.01432373
 0.01346637 0.02156414 0.00896854 0.00896853 0.00759625 0.00977785
 0.00896852 0.00759625]
tr_loss:[0.02123634 0.01182491 0.01037951 0.00595561 0.00987235 0.01109302
 0.00646894 0.01432993 0.00674368 0.0129643  0.00987235 0.00595561
 0.00987235 0.02124373 0.01433053 0.0199641  0.01282651 0.00595561
 0.00987234 0.01037951 0.00658757 0.01110532 0.0129643  0.01182491
 0.01182491 0.01296431 0.02449613 0.01301728 0.02123623 0.01896684
 0.00595561 0.00875518 0.01182491 0.01109247 0.0132565  0.0203927
 0.0118249  0.0087553  0.00987236 0.01296425 0.0118249  0.0129643
 0.02123635 0.00595561 0.00987271 0.00595561 0.02449599 0.01037952
 0.00875518 0.01192289]
tr_loss:[0.00758946 0.0036606  0.00506316 0.00810126 0.0036606  0.05556257
 0.00810126 0.05555254 0.01101076 0.01349609 0.02690304 0.01932376
 0.00506317 0.01096086 0.00758946 0.0036606  0.01349606 0.01076844
 0.00723152 0.00826366 0.05319599 0.01932379 0.0036606  0.00723155
 0.01822658 0.01101076 0.00429259 0.00976046 0.01076834 0.05556255
 0.05556257 0.01824476 0.00758946 0.01349635 0.01816726 0.01101074
 0.01101074 0.00758946 0.01101075 0.00723477 0.01076838 0.02694261
 0.01076843 0.00723228 0.00723151 0.01925866 0.00429258 0.01824475
 0.01648491 0.00758946]
tr_loss:[0.02754434 0.01050352 0.0125589  0.00566091 0.00977484 0.0125589
 0.00471808 0.01247547 0.00809507 0.00328866 0.01032047 0.00808067
 0.00569848 0.00789456 0.00346105 0.01038101 0.01036392 0.00508357
 0.01036347 0.01806797 0.01118229 0.01734098 0.01031843 0.01255889
 0.01028413 0.01806805 0.04750782 0.02602053 0.00809507 0.01255889
 0.00508357 0.01806802 0.01036347 0.00328873 0.00567007 0.01822496
 0.00327315 0.01860939 0.0125589  0.00809507 0.00961134 0.00328873
 0.01176643 0.01036345 0.01806802 0.00569935 0.01255888 0.00328873
 0.02552216 0.00809507]
tr_loss:[0.01019378 0.003674   0.00629247 0.00326696 0.02193612 0.01750742
 0.00576222 0.01548498 0.01145109 0.00331363 0.01019359 0.00368169
 0.01547424 0.01019378 0.00331363 0.00550992 0.01019079 0.0114511
 0.01020801 0.00455128 0.00493245 0.04764979 0.01464192 0.01195315
 0.01019682 0.01145111 0.00455127 0.00840763 0.01145111 0.01014107
 0.01019378 0.00331362 0.01019379 0.01145117 0.00550909 0.00455127
 0.01181198 0.04077994 0.01005011 0.00331363 0.04702037 0.00331363
 0.01145109 0.01019995 0.01019378 0.01044371 0.00455126 0.00455127
 0.01181198 0.0114511 ]
tr_loss:[0.009851   0.03855204 0.01028395 0.00644125 0.03157751 0.00853897
 0.00988006 0.00645452 0.00793459 0.00324048 0.00713975 0.00324053
 0.00964002 0.00964    0.00394815 0.00394817 0.00799189 0.00963994
 0.00985258 0.00324053 0.00394817 0.03275423 0.00716009 0.0083952
 0.01344613 0.00985259 0.00852912 0.00838332 0.00839518 0.00394817
 0.00853021 0.00963584 0.01344595 0.00394817 0.00841502 0.00964001
 0.00394817 0.00964001 0.00847418 0.00644133 0.00716008 0.00839518
 0.005748   0.03855203 0.00324053 0.01001206 0.00324053 0.00985258
 0.0085302  0.00839439]
tr_loss:[0.00237314 0.01146088 0.0065998  0.01146087 0.00573107 0.0354761
 0.00870931 0.00637953 0.01146087 0.00870931 0.00236136 0.01115986
 0.00659982 0.01115102 0.01116001 0.0087093  0.00870749 0.01146087
 0.00679961 0.01146087 0.0073532  0.00573108 0.01115962 0.00659981
 0.00573108 0.00659982 0.01116    0.009675   0.00660029 0.00781451
 0.0087093  0.00589377 0.00659981 0.0104854  0.00870931 0.00926926
 0.02956925 0.01116001 0.00573108 0.00659982 0.01115696 0.00659957
 0.00659982 0.00573107 0.00573107 0.00874169 0.00926956 0.01130431
 0.00913703 0.00870997]
tr_loss:[0.01156295 0.01182797 0.01190598 0.00418177 0.00209693 0.0093298
 0.00607224 0.00607223 0.03483199 0.00721219 0.00607229 0.00607224
 0.01122369 0.00418178 0.00418176 0.01122388 0.01156298 0.01156297
 0.00607223 0.01156295 0.0050063  0.01156371 0.00607224 0.01190592
 0.0072003  0.03616529 0.0093298  0.01190204 0.00418177 0.0093298
 0.0093298  0.00607223 0.03616727 0.01156295 0.00895948 0.00413011
 0.00418177 0.01190597 0.00607223 0.01190865 0.01190597 0.01156296
 0.01156297 0.00500732 0.00607225 0.01092503 0.0093298  0.01267864
 0.00418177 0.00449404]
tr_loss:[0.00210514 0.01110641 0.00272948 0.0104798  0.0111064  0.00782097
 0.0111174  0.01110641 0.0015426  0.01098426 0.0107726  0.00273077
 0.00808557 0.0111064  0.00272948 0.0027343  0.00537614 0.00537614
 0.00954493 0.0111064  0.00538581 0.01145182 0.01145178 0.00537614
 0.00954493 0.00971211 0.0105963  0.02979476 0.01145182 0.01110698
 0.01110673 0.00879446 0.00808516 0.0111064  0.00272949 0.00537646
 0.00954493 0.00954493 0.00272949 0.00272948 0.03609259 0.01110641
 0.00272949 0.01145182 0.0111064  0.01064512 0.01151084 0.00954493
 0.03654755 0.00272948]
tr_loss:[0.00539095 0.00225329 0.00822042 0.0085983  0.00832549 0.00053797
 0.00528325 0.00882229 0.00822043 0.0022533  0.00822043 0.00879038
 0.00539095 0.00882731 0.00882229 0.00882226 0.00846024 0.03831946
 0.00761096 0.00225329 0.00721032 0.00225329 0.00539095 0.00882348
 0.00822163 0.0022533  0.00882229 0.00053797 0.00882229 0.00742709
 0.00882228 0.00356902 0.03859527 0.00721382 0.00744148 0.00882228
 0.00225329 0.01128743 0.00822042 0.00356903 0.00882229 0.00053797
 0.00806931 0.00832548 0.00857965 0.0090407  0.00356902 0.00356902
 0.0022533  0.00053809]
tr_loss:[0.01067085 0.00882522 0.0084447  0.01347543 0.01067085 0.00698633
 0.03576066 0.04224451 0.00882523 0.0045486  0.04224453 0.00454858
 0.0073319  0.04224453 0.01347542 0.00678377 0.0045486  0.00339541
 0.00339528 0.00882527 0.00877266 0.00751124 0.00882522 0.00882521
 0.00339528 0.00454859 0.00869547 0.00215302 0.00869547 0.00263195
 0.00869547 0.03487418 0.00454858 0.00432451 0.00454859 0.03536478
 0.01347543 0.00733188 0.00731359 0.01347542 0.04200707 0.00454859
 0.00881864 0.00454922 0.01067085 0.00882547 0.00778047 0.00339527
 0.04224455 0.00454859]
tr_loss:[0.00578914 0.0050407  0.00561459 0.00780375 0.00780376 0.01295241
 0.0057208  0.01129455 0.00443075 0.00960555 0.01036968 0.00780376
 0.00554004 0.00443075 0.00708813 0.00780376 0.00181472 0.00161763
 0.01337851 0.00443076 0.01129455 0.00795609 0.01105415 0.00572084
 0.00780376 0.01296722 0.00780376 0.00572078 0.00840467 0.01104902
 0.03541962 0.00161763 0.03576282 0.00443075 0.00443076 0.0078038
 0.01129473 0.00565204 0.01337663 0.005652   0.00250628 0.00565136
 0.00221036 0.00565204 0.00841252 0.00161764 0.01197462 0.00926854
 0.00161822 0.00780376]
tr_loss:[0.00479096 0.00576189 0.04274129 0.00560909 0.00560909 0.01457829
 0.00812318 0.00735616 0.00735617 0.00157121 0.00560908 0.00341938
 0.00576189 0.00560909 0.04274128 0.00341933 0.00909185 0.00956639
 0.00560908 0.01212445 0.00813916 0.0047911  0.00506602 0.00434268
 0.00560909 0.00531567 0.00812318 0.01457952 0.0117623  0.00157111
 0.00157118 0.00735617 0.01593347 0.01129506 0.01285245 0.00812318
 0.00812318 0.00909185 0.00251555 0.01457828 0.00735616 0.01285204
 0.00735617 0.00560909 0.00735634 0.00812182 0.01285245 0.00812377
 0.01272974 0.03949558]
tr_loss:[0.00266458 0.00787459 0.00491979 0.01052981 0.00787459 0.00569687
 0.04082    0.00904359 0.00149631 0.00404065 0.0056964  0.03753033
 0.03752873 0.03440502 0.00787459 0.00364078 0.00787459 0.01242921
 0.03753022 0.01172026 0.00787422 0.01171977 0.00525914 0.00490707
 0.0078746  0.00525913 0.01056612 0.00569687 0.01171978 0.00903927
 0.03430918 0.04082    0.00569688 0.00511146 0.01171742 0.00981172
 0.00904356 0.00149631 0.00511146 0.00394921 0.00518509 0.00149631
 0.00876841 0.00266457 0.00149631 0.00787495 0.00149631 0.00981176
 0.00525913 0.00266458]
tr_loss:[0.00430285 0.00558021 0.00429637 0.00781617 0.00924604 0.00795599
 0.00396823 0.00441882 0.00924641 0.00183889 0.00429633 0.01033847
 0.00512715 0.03063853 0.00452515 0.0018389  0.00784918 0.00781617
 0.0055802  0.00781637 0.00440589 0.0018389  0.00125537 0.00781304
 0.0035646  0.00452487 0.00452487 0.00512715 0.00429636 0.03295439
 0.00429637 0.00781617 0.0055802  0.00818256 0.00183889 0.0018389
 0.00781617 0.00440459 0.0055802  0.0055802  0.00749167 0.00781617
 0.00781616 0.00429637 0.03734129 0.00781616 0.00818257 0.00828485
 0.03734129 0.01104667]
tr_loss:[0.0088903  0.00662578 0.00095024 0.00440949 0.00647705 0.00541557
 0.00332234 0.00645254 0.00889042 0.00541556 0.00889042 0.00541558
 0.00662923 0.00647706 0.03646053 0.00332235 0.00332235 0.00095024
 0.00541556 0.00889042 0.00889042 0.03646012 0.00541557 0.0078343
 0.00585921 0.00332234 0.00332235 0.00889038 0.00332235 0.00889042
 0.00333911 0.00743453 0.00541558 0.00860246 0.01559929 0.00785641
 0.00332234 0.00990699 0.00440948 0.00332235 0.00332235 0.00743453
 0.00889042 0.00822244 0.00889041 0.0044095  0.00889041 0.00463302
 0.00889042 0.00332234]
tr_loss:[0.00405616 0.00417798 0.00594605 0.00405616 0.00773182 0.00093763
 0.00961987 0.00793758 0.00405616 0.00405615 0.00871314 0.00417798
 0.00791942 0.00417797 0.00417797 0.00417798 0.00871314 0.00754941
 0.00093763 0.00954561 0.00773191 0.00405616 0.0089689  0.00093763
 0.00093763 0.00961987 0.00417801 0.00093763 0.00405616 0.00405662
 0.00405616 0.00706073 0.00871314 0.00961988 0.03556502 0.00960845
 0.00093764 0.00901897 0.00605375 0.00978084 0.00721724 0.00784182
 0.00773194 0.00405616 0.00773195 0.00871314 0.00792362 0.00417798
 0.00497232 0.00093763]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3700 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3701, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3701 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3702, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3702 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3703, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3703 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3704, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3704 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3705, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3705 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3706, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3706 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3707, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3707 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3708, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3708 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3709, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3709 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3710, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3710 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3711, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3711 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3712, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3712 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3713, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3713 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3714, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3714 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3715, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3715 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3716, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3716 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3717, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3717 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3718, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3718 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3719, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3719 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3720, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3720 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3721, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3721 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3722, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3722 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3723, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3723 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3724, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3724 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3725, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3725 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3726, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3726 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3727, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3727 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3728, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3728 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3729, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3729 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3730, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3730 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3731, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3731 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3732, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3732 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3733, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3733 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3734, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3734 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3735, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3735 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3736, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3736 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3737, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3737 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3738, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3738 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3739, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3739 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3740, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3740 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3741, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3741 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3742, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3742 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3743, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3743 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3744, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3744 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3745, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3745 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3746, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3746 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3747, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3747 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3748, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3748 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3749, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3749 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3750, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3750 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3751, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3751 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3752, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3752 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3753, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3753 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3754, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3754 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3755, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3755 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3756, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3756 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3757, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3757 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3758, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3758 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3759, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3759 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3760, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3760 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3761, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3761 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3762, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3762 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3763, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3763 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3764, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3764 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3765, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3765 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3766, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3766 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3767, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3767 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3768, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3768 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3769, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3769 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3770, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3770 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3771, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3771 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3772, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3772 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3773, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3773 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3774, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3774 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3775, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3775 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3776, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3776 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3777, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3777 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3778, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3778 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3779, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3779 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3780, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3780 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3781, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3781 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3782, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3782 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3783, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3783 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3784, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3784 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3785, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3785 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3786, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3786 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3787, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3787 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3788, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3788 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3789, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3789 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3790, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3790 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3791, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3791 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3792, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3792 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3793, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3793 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3794, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3794 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3795, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3795 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3796, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3796 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3797, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3797 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3798, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3798 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3799, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3799 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3800, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-3700
text_input.shape
(3800, 14400)
learning_input_tmp.shape
(3800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3800, 80)
learning_output.shape
(750, 80)
Model: "sequential_77"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_77 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4238833 1.420583  1.4405968 1.4076853 1.40774   1.4405965 1.3949962
 1.4138993 1.3952646 1.4077399 1.4435221 1.4204143 1.3545988 1.4174582
 1.4204143 1.4083494 1.4204143 1.3952646 1.4176022 1.3952646 1.4077492
 1.4096657 1.3818527 1.420552  1.3952647 1.3818527 1.3818527 1.4300879
 1.4204143 1.430088  1.4405965 1.420508  1.4146318 1.4327885 1.4197851
 1.4405966 1.4196389 1.3998222 1.4076674 1.4405966 1.4204144 1.4300879
 1.4405965 1.4213667 1.4168011 1.4328212 1.4205519 1.4225618 1.3844924
 1.4219697]
tr_loss:[0.8878275  0.8878274  0.8878275  0.8758508  0.8878275  0.8766028
 0.8626625  0.8873669  0.8626625  0.8579916  0.87660277 0.87660277
 0.88138044 0.8626626  0.84735376 0.87660277 0.8882478  0.8591436
 0.8626625  0.8878275  0.87660277 0.88783777 0.88676757 0.8878279
 0.86689234 0.87660277 0.87401235 0.8742819  0.86368525 0.86539954
 0.8766028  0.8591815  0.85799044 0.8473505  0.87585104 0.8878275
 0.8878276  0.87649584 0.8766028  0.8827364  0.8878275  0.87401235
 0.8653923  0.86757696 0.8665563  0.85678244 0.88466704 0.8665563
 0.8626625  0.8626626 ]
tr_loss:[0.5117655  0.49908838 0.50785756 0.48931503 0.5023836  0.49908844
 0.47986084 0.5006348  0.5005086  0.51767075 0.5002333  0.48931107
 0.4992234  0.48931104 0.5078575  0.5210312  0.5006199  0.52103114
 0.49908835 0.4997592  0.48931107 0.49908838 0.50785756 0.50371987
 0.50061995 0.5210311  0.5190137  0.48525858 0.5006199  0.49908838
 0.49137837 0.50061977 0.5117594  0.50061995 0.52288187 0.5228855
 0.48931104 0.5190126  0.50769657 0.50061995 0.50393254 0.48931107
 0.4798607  0.5079094  0.49908838 0.49908838 0.5228731  0.5006199
 0.49908838 0.5117594 ]
tr_loss:[0.2450066  0.26920822 0.2348353  0.24042931 0.24500656 0.24734607
 0.24042933 0.27262038 0.2695945  0.2514841  0.24042931 0.2596742
 0.23616156 0.2726203  0.24734612 0.2726203  0.2726203  0.2692082
 0.25553212 0.2726203  0.25457484 0.25967416 0.24734607 0.25967416
 0.27262035 0.23468137 0.25078052 0.27262035 0.24042933 0.24042444
 0.2613615  0.2514841  0.254575   0.25967422 0.24734613 0.24466196
 0.2345748  0.27262026 0.2692082  0.24042931 0.24042973 0.263618
 0.24734616 0.25967416 0.24499102 0.24930112 0.24042931 0.2514841
 0.2436798  0.24392292]
tr_loss:[0.11336169 0.13332053 0.11312775 0.11327598 0.11327218 0.11336169
 0.1132722  0.14511831 0.10949501 0.11235343 0.11552465 0.12408833
 0.12403784 0.11778533 0.13439319 0.12403788 0.11336169 0.14090285
 0.13439307 0.1133617  0.11336169 0.12022619 0.1132722  0.11333875
 0.11336092 0.11336169 0.12404412 0.12370761 0.12403784 0.12666006
 0.12168284 0.11331596 0.11737986 0.11331755 0.11708824 0.11336169
 0.1240906  0.11326724 0.13433416 0.11298718 0.11320879 0.1240906
 0.12403782 0.12399919 0.11336169 0.12197177 0.13439314 0.12022622
 0.11336166 0.11492507]
tr_loss:[0.06127704 0.07232153 0.06521583 0.06036767 0.06127705 0.06128757
 0.06151106 0.06151106 0.06660056 0.06742483 0.06127704 0.06037172
 0.07660478 0.07660476 0.06127701 0.07224288 0.07943567 0.06127704
 0.07660477 0.06127704 0.06699309 0.06742483 0.06127702 0.07660477
 0.06127705 0.06127705 0.07235213 0.06660096 0.07660477 0.07235165
 0.06127704 0.06742483 0.06116946 0.06130536 0.06127703 0.06699309
 0.07598455 0.07660478 0.06127704 0.07660478 0.07660476 0.07235195
 0.07660477 0.07660477 0.0625518  0.06583863 0.06258239 0.06699308
 0.0794361  0.06127533]
tr_loss:[0.04605312 0.03870202 0.05976676 0.04301996 0.03870201 0.04730143
 0.03870149 0.05059204 0.04922388 0.0473168  0.03870199 0.04156067
 0.05976675 0.04411377 0.04636174 0.04767637 0.05976675 0.04722162
 0.0507928  0.03824803 0.03870196 0.04714752 0.0460533  0.04420157
 0.04722134 0.04882444 0.03993089 0.04636172 0.03992913 0.04722134
 0.04577207 0.03864877 0.04422688 0.04767649 0.04153947 0.0472213
 0.04605312 0.03861837 0.038702   0.04605312 0.04636169 0.03867323
 0.05030056 0.04605312 0.04422715 0.03847067 0.05064131 0.04722134
 0.04422716 0.04422659]
tr_loss:[0.02417888 0.01573987 0.03907805 0.02339677 0.03907805 0.02296526
 0.02844119 0.01841464 0.01781142 0.01841464 0.02339676 0.02339725
 0.02418035 0.01652454 0.03907806 0.01900541 0.02417888 0.02339676
 0.02333795 0.02417887 0.01841464 0.02417886 0.0233278  0.02497722
 0.0240758  0.01841464 0.02509058 0.02497724 0.03907808 0.01841539
 0.01573843 0.02339676 0.02417889 0.02101042 0.01651899 0.01851286
 0.0249772  0.02339606 0.02497724 0.01851284 0.02497721 0.02101044
 0.02417887 0.01651899 0.02497725 0.03907805 0.03907805 0.01841464
 0.02417887 0.03907826]
tr_loss:[0.00815612 0.00747433 0.01810207 0.01790934 0.01415683 0.00678448
 0.00678448 0.01382773 0.00921872 0.00809425 0.00815756 0.00670683
 0.00678446 0.00801387 0.01380089 0.01400484 0.01397747 0.0138009
 0.01397747 0.01397731 0.00959956 0.00678452 0.00936205 0.00678448
 0.01810208 0.01401466 0.01400442 0.01790933 0.01790932 0.00932143
 0.01188993 0.01810206 0.0181021  0.00678448 0.01810207 0.01400482
 0.00959956 0.01790932 0.01380088 0.0138009  0.01400484 0.01400485
 0.01810209 0.00846031 0.01397749 0.01790934 0.01790932 0.00678448
 0.01810207 0.00678447]
tr_loss:[0.0205345  0.00726274 0.01812525 0.01564247 0.00926428 0.02192805
 0.01419563 0.02192805 0.01609907 0.02192801 0.0131472  0.01362272
 0.00701939 0.02192801 0.00846634 0.01101179 0.01254503 0.01362658
 0.01177587 0.02192801 0.02192805 0.00726274 0.00726263 0.01609907
 0.00726317 0.00846634 0.01179434 0.01361793 0.00726274 0.02192802
 0.00726197 0.01419576 0.01564247 0.01101385 0.00726268 0.02192803
 0.0205344  0.00726274 0.00726394 0.02192804 0.02105361 0.00726274
 0.01609907 0.00726274 0.00846636 0.01363976 0.00475904 0.02192804
 0.00846634 0.00846634]
tr_loss:[0.01659784 0.01183628 0.01160401 0.00681861 0.00681861 0.00407548
 0.01068331 0.01854207 0.01209183 0.0150054  0.00681857 0.01209175
 0.01329255 0.01851368 0.01068331 0.01528623 0.01209177 0.01851366
 0.01457791 0.0068189  0.01529855 0.01209176 0.01209177 0.01207136
 0.00995244 0.01209237 0.01209175 0.01658119 0.01325892 0.01348125
 0.00703755 0.01068331 0.01208119 0.00681861 0.01068331 0.00681861
 0.00682095 0.01437506 0.0068186  0.01068331 0.01206538 0.00681865
 0.01529696 0.00761772 0.01659696 0.00407547 0.01529845 0.01499467
 0.00407547 0.00698656]
tr_loss:[0.01343636 0.01055248 0.01792293 0.0123246  0.01274366 0.01336211
 0.01219935 0.01221043 0.01343638 0.00959647 0.01343637 0.01343822
 0.00446153 0.01407838 0.01343538 0.01407865 0.01437764 0.01343637
 0.01055354 0.0170677  0.00959647 0.01055413 0.01586767 0.01409134
 0.02190333 0.01407867 0.01055353 0.00446153 0.01218027 0.00754968
 0.01485138 0.00959647 0.00959647 0.01407863 0.01343636 0.01407866
 0.01485139 0.0158674  0.00959647 0.01940211 0.02664831 0.01049775
 0.01706782 0.00582657 0.01271266 0.0122545  0.01055354 0.01586768
 0.01057113 0.01294821]
tr_loss:[0.00683076 0.01199408 0.01484092 0.0098118  0.01199408 0.01650592
 0.00692635 0.01484093 0.01484093 0.01484293 0.01484093 0.01199407
 0.00796743 0.00683076 0.01775432 0.01484093 0.0078313  0.00981179
 0.01484182 0.01199408 0.01650249 0.00683076 0.01484093 0.01459486
 0.01484093 0.00983212 0.00981179 0.00826014 0.00683076 0.01200277
 0.01195826 0.00832306 0.02176513 0.0153721  0.0165054  0.00683074
 0.01199407 0.01571316 0.01057466 0.01199408 0.01537208 0.01484093
 0.00683076 0.00981178 0.01484095 0.00981182 0.01199402 0.00683075
 0.0165054  0.00795738]
tr_loss:[0.0145783  0.01036099 0.01342314 0.00678197 0.010361   0.01036101
 0.00476958 0.00664928 0.00678545 0.01036102 0.00396793 0.01146007
 0.01036116 0.00677205 0.00678546 0.00678482 0.00583868 0.00675843
 0.01145995 0.01104941 0.00345629 0.00678546 0.00376495 0.00493636
 0.01183444 0.010361   0.00678547 0.010361   0.00786182 0.01036101
 0.00678546 0.00396501 0.00396502 0.00493675 0.0081097  0.00396502
 0.00810971 0.01096791 0.00396501 0.01037476 0.00376575 0.01145092
 0.00396501 0.01145996 0.010361   0.0118344  0.01133961 0.00678546
 0.01145997 0.00810971]
tr_loss:[0.00424519 0.00417542 0.00671214 0.00547452 0.00423638 0.00930906
 0.0041754  0.00548846 0.01402843 0.01041211 0.00930879 0.00423638
 0.00417543 0.01026347 0.01232288 0.00548821 0.00671214 0.00671221
 0.01026347 0.0041754  0.01282891 0.00671213 0.00671213 0.00862713
 0.00548845 0.00423638 0.01172592 0.01172594 0.00671214 0.00423638
 0.01026347 0.01870509 0.00671196 0.00423638 0.01402766 0.00548845
 0.00671214 0.00548847 0.01024994 0.00699331 0.00671213 0.00548845
 0.00548845 0.00411739 0.01148669 0.00548134 0.01334778 0.00906473
 0.00589611 0.00671213]
tr_loss:[0.01164457 0.0060631  0.0228177  0.0062445  0.01138284 0.00624451
 0.00551193 0.01069679 0.02281769 0.00905732 0.02281769 0.00624451
 0.00641283 0.00624848 0.01048937 0.01218764 0.00624451 0.01244153
 0.00517127 0.01069681 0.00624239 0.01069679 0.01138284 0.01211039
 0.01069679 0.01265751 0.01244151 0.00624451 0.01165483 0.01414135
 0.0228177  0.00624451 0.00624236 0.00623974 0.01117602 0.0102638
 0.00628773 0.00624451 0.01142159 0.00624451 0.01173546 0.00598679
 0.01165594 0.01138283 0.01244165 0.01069679 0.01072529 0.01069682
 0.01219961 0.01138284]
tr_loss:[0.00807943 0.00366493 0.01475864 0.01484425 0.00672663 0.00664812
 0.0034077  0.00672828 0.00630503 0.00235259 0.00319095 0.00535447
 0.00232615 0.00595734 0.01484424 0.00598524 0.0034077  0.00299403
 0.00598524 0.01484425 0.00934234 0.00804227 0.00672827 0.00808878
 0.006729   0.00350819 0.00231792 0.00350819 0.00934234 0.00235254
 0.01484424 0.00807917 0.00235254 0.00675914 0.00235254 0.00300351
 0.00738613 0.00235238 0.00678734 0.01484423 0.00672828 0.00350819
 0.00934234 0.00434818 0.00235254 0.01484425 0.00934234 0.00719632
 0.00934234 0.00585715]
tr_loss:[0.00949696 0.00402322 0.00276255 0.00134955 0.00355843 0.00151185
 0.00951731 0.00402323 0.00447995 0.00151183 0.00151185 0.00402321
 0.01037791 0.00421967 0.01642633 0.00382178 0.00275383 0.00949696
 0.00151185 0.0060054  0.00270043 0.0039683  0.00151185 0.00134127
 0.00365358 0.00155447 0.00501108 0.00092419 0.00151186 0.00402277
 0.00363376 0.00151184 0.00270613 0.00355757 0.00949694 0.00950848
 0.00151185 0.00405028 0.00402322 0.00151185 0.00270613 0.00151182
 0.00949695 0.01642618 0.00270613 0.0060054  0.00480324 0.00565602
 0.00151185 0.00276253]
tr_loss:[0.00524579 0.00731336 0.00459057 0.00731337 0.00541833 0.00523441
 0.01252192 0.00561302 0.00440285 0.01252193 0.00731342 0.00456211
 0.00562493 0.00113032 0.00459057 0.00439846 0.00515378 0.00731153
 0.01252204 0.00581717 0.00658718 0.00524597 0.00524598 0.00562494
 0.00447613 0.00562179 0.00459057 0.00649877 0.00562152 0.00515379
 0.00807441 0.00581717 0.00459057 0.00730963 0.00459006 0.01441658
 0.00730685 0.0011302  0.00459057 0.00459057 0.00524598 0.00524597
 0.00675845 0.00524597 0.0073134  0.00816584 0.00581717 0.00857928
 0.00809902 0.00562493]
tr_loss:[0.01458926 0.00667693 0.0142777  0.01458925 0.00890511 0.00890273
 0.00591946 0.0019002  0.00657912 0.00890548 0.01458925 0.01596942
 0.01458926 0.01244589 0.00605819 0.00713774 0.00668588 0.01458927
 0.01569481 0.01012683 0.00668691 0.00640028 0.00787253 0.00672641
 0.00993704 0.00668587 0.00890549 0.0059193  0.01115821 0.00591931
 0.00657912 0.00668725 0.00668588 0.00657912 0.01458925 0.0059193
 0.00779567 0.00591931 0.00669989 0.0059193  0.00737317 0.00787272
 0.00668658 0.00890548 0.00668588 0.00591962 0.00779363 0.00713689
 0.00883937 0.0059193 ]
tr_loss:[0.00631236 0.0133784  0.0063084  0.0086877  0.00726673 0.01735058
 0.0133838  0.0133784  0.0086877  0.00610741 0.01337839 0.00631236
 0.0086877  0.00869956 0.00766585 0.0133784  0.00531527 0.01942695
 0.00868708 0.00531828 0.00506182 0.00609239 0.00505935 0.00631233
 0.00531827 0.00868192 0.00531828 0.00531828 0.01337817 0.0086877
 0.00728015 0.00531828 0.00631236 0.00610741 0.00728015 0.00604465
 0.01336527 0.00868725 0.00649398 0.00631236 0.00631236 0.00604466
 0.0133784  0.00505934 0.00868761 0.00153988 0.00949746 0.00852052
 0.00666288 0.00493845]
tr_loss:[0.00471968 0.00888284 0.00512731 0.00369561 0.01709474 0.00512731
 0.00369516 0.00478602 0.01205177 0.00472032 0.00369517 0.0064365
 0.00382175 0.00512731 0.00379653 0.01705769 0.00379653 0.0064365
 0.0064365  0.00039045 0.00372372 0.0064365  0.00369517 0.00369516
 0.00039045 0.00369525 0.00653465 0.00888282 0.0064365  0.00381832
 0.00379653 0.00888283 0.00888282 0.00512731 0.00375607 0.00379652
 0.00382175 0.01321223 0.00379653 0.00382175 0.01200073 0.01204841
 0.00038766 0.00369516 0.01532501 0.00643643 0.00369517 0.00371576
 0.00379653 0.00369605]
tr_loss:[0.00225619 0.00475371 0.00719673 0.00336635 0.00352395 0.00336646
 0.00491016 0.00306149 0.00133488 0.01141249 0.00336658 0.00188374
 0.00336634 0.00336634 0.0047587  0.00141067 0.00306143 0.00403617
 0.0047587  0.00133516 0.00133487 0.00073453 0.00336634 0.00133488
 0.00491016 0.003368   0.0016197  0.00336635 0.00719674 0.00336635
 0.0047587  0.00336635 0.00491016 0.00133486 0.00490876 0.00719673
 0.00133487 0.00719673 0.00292266 0.00306142 0.00100387 0.00306174
 0.00133488 0.00133488 0.00073453 0.00336634 0.00719674 0.00133152
 0.00719674 0.0008694 ]
tr_loss:[0.00526028 0.00526027 0.00246808 0.00525142 0.00474352 0.00526134
 0.01090782 0.00163549 0.00474351 0.00198501 0.00608451 0.00179933
 0.00714814 0.00608452 0.00608451 0.00608451 0.00553929 0.01272018
 0.00179933 0.00179933 0.00549737 0.00595304 0.01271682 0.00608452
 0.00179933 0.00608453 0.01271682 0.00699305 0.00474352 0.00198501
 0.00179934 0.00608453 0.01271682 0.00608452 0.00472542 0.00246808
 0.00608453 0.00246808 0.00570759 0.00608463 0.00608452 0.00250828
 0.00608453 0.00250838 0.00494779 0.00198501 0.01271682 0.00570763
 0.01271682 0.01271693]
tr_loss:[0.00259781 0.00691012 0.00259781 0.00259781 0.00672923 0.00673199
 0.00673199 0.00246936 0.00297996 0.00619203 0.00477426 0.00696288
 0.00259781 0.01376321 0.00691013 0.00619204 0.00246935 0.00780451
 0.00246936 0.00619202 0.00619204 0.00546278 0.01376416 0.00259781
 0.00821451 0.00259781 0.00203947 0.0025302  0.00673199 0.00259781
 0.00619203 0.00825459 0.00203951 0.00543541 0.00532439 0.00247072
 0.00247068 0.00297996 0.00259765 0.00673199 0.00673198 0.0026042
 0.00674427 0.00142752 0.00260077 0.00673199 0.00259781 0.00532439
 0.01376417 0.00259781]
tr_loss:[0.00713932 0.00591433 0.00179353 0.00105244 0.00463821 0.00452847
 0.00155022 0.00179353 0.00179353 0.00452849 0.00580422 0.00591474
 0.00179353 0.00935007 0.00452848 0.00179353 0.0071722  0.00177348
 0.00100887 0.00179353 0.00580422 0.00105244 0.00140226 0.00713933
 0.00421798 0.00452848 0.0011725  0.00223652 0.00591474 0.00571167
 0.00337074 0.00591477 0.00452848 0.00591474 0.00713932 0.00179353
 0.00452849 0.00179353 0.00155022 0.00591444 0.00591475 0.00337074
 0.00155022 0.00591475 0.00713933 0.00223658 0.00533299 0.00105244
 0.00452848 0.00178352]
tr_loss:[0.00173112 0.00228218 0.0040052  0.00267744 0.00549941 0.0040052
 0.00549299 0.00495727 0.00539678 0.00170834 0.00400519 0.00400519
 0.00515338 0.01233207 0.00064127 0.01113421 0.00173112 0.00483479
 0.00666727 0.00539663 0.00173112 0.00171415 0.00175222 0.00515337
 0.00515338 0.00515338 0.00228218 0.00064127 0.00400519 0.00495951
 0.00257322 0.00064127 0.00173278 0.00308516 0.00524596 0.00267745
 0.00173112 0.0040052  0.00098235 0.00539663 0.0040061  0.00267745
 0.00515338 0.00157021 0.00400519 0.00400519 0.00539664 0.0049595
 0.00549127 0.01067925]
tr_loss:[0.00270338 0.00422597 0.00270339 0.00584361 0.00422597 0.00270366
 0.00270339 0.0036193  0.00293127 0.00584361 0.00584357 0.00270339
 0.00478471 0.00518869 0.00234275 0.00518998 0.00270339 0.00145668
 0.00584362 0.00307731 0.00713542 0.00478473 0.00422597 0.00584361
 0.00270339 0.01365293 0.00302462 0.00422597 0.0036193  0.01219839
 0.00584361 0.0036193  0.00584193 0.0036193  0.00583799 0.00589361
 0.00270339 0.00584361 0.00478471 0.0027014  0.00270339 0.00270339
 0.00584361 0.0026957  0.00170642 0.00234304 0.00270334 0.00620772
 0.00633056 0.00270338]
tr_loss:[0.00244822 0.00618741 0.00618741 0.00734459 0.00434595 0.00572697
 0.0042912  0.00525712 0.00244822 0.00418056 0.00418195 0.00246352
 0.00331782 0.00331782 0.00618741 0.00734459 0.01150832 0.00618742
 0.00331783 0.0061874  0.01036464 0.00226367 0.00244822 0.00734416
 0.00704091 0.00618741 0.00618742 0.00572697 0.0068121  0.00512851
 0.00331782 0.00248806 0.00219402 0.0061874  0.00418429 0.00512854
 0.00483681 0.00244821 0.00331783 0.00226367 0.00512556 0.00369793
 0.00331783 0.00244822 0.00618743 0.00251898 0.00572697 0.01347934
 0.00244822 0.00733668]
tr_loss:[0.00640792 0.00640793 0.00396824 0.0039726  0.00164138 0.00322343
 0.00164129 0.00633974 0.00455486 0.00084104 0.00640793 0.00640793
 0.00633974 0.00352133 0.00322563 0.00411205 0.00084103 0.00323981
 0.00633968 0.0016441  0.00640823 0.00164129 0.00322565 0.00640794
 0.00164128 0.00620263 0.00640793 0.00164137 0.00633975 0.00164129
 0.00435024 0.00640794 0.0039726  0.0039726  0.00322343 0.00580886
 0.00633974 0.00385739 0.00625598 0.0039726  0.00322586 0.00164125
 0.0020148  0.00323365 0.00322567 0.00633975 0.01056229 0.00204108
 0.00634079 0.00633974]
text_input.shape
(3800, 14400)
learning_input_tmp.shape
(3800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3800, 80)
learning_output.shape
(750, 80)
Model: "sequential_78"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_78 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3248701 1.3299463 1.3291872 1.3055063 1.3299652 1.3024242 1.3403602
 1.3024207 1.3276567 1.3299652 1.3403602 1.2895794 1.3403606 1.3008544
 1.3291584 1.3248909 1.2934935 1.3291476 1.3325117 1.3403602 1.3403602
 1.2901336 1.3163477 1.34036   1.3024242 1.34036   1.3057582 1.3291466
 1.3248701 1.316508  1.3403602 1.3246098 1.3136129 1.3246098 1.34036
 1.3240888 1.294322  1.3248701 1.3403602 1.3246098 1.3014767 1.3303858
 1.3299177 1.3054068 1.2944764 1.34036   1.2944376 1.3136079 1.3299651
 1.34036  ]
tr_loss:[0.8734997  0.83295345 0.83230543 0.81394416 0.8791157  0.8566777
 0.83309305 0.83309305 0.83297557 0.83309305 0.86471665 0.84270734
 0.8647167  0.8947285  0.8790504  0.8345642  0.8967492  0.82477045
 0.8947285  0.8947285  0.8328996  0.8647162  0.8951561  0.8647167
 0.816764   0.83309305 0.89674914 0.8647068  0.8647167  0.8647167
 0.8647135  0.86471665 0.8647167  0.8671869  0.8208679  0.816764
 0.8647167  0.8484024  0.89675    0.86735785 0.8330914  0.8794693
 0.88630265 0.8967492  0.879105   0.88311327 0.84003055 0.8967492
 0.8947285  0.8852359 ]
tr_loss:[0.47201055 0.47720337 0.47260252 0.492704   0.44444522 0.43605804
 0.47386098 0.45467654 0.4370783  0.47260237 0.4370788  0.4739069
 0.49722332 0.48724452 0.46383485 0.46169168 0.49270386 0.48381242
 0.4744566  0.46446496 0.48724547 0.43722296 0.4706544  0.4738613
 0.4626233  0.45463237 0.49737778 0.49737778 0.47795945 0.48724437
 0.49270397 0.47514296 0.5009454  0.4528702  0.47386128 0.472452
 0.47074956 0.46383315 0.46383485 0.44784102 0.4725996  0.45467234
 0.4359723  0.4738613  0.49270386 0.4742833  0.4370788  0.47385293
 0.4969141  0.4720059 ]
tr_loss:[0.3054021  0.2591527  0.30540207 0.29084903 0.29084882 0.286798
 0.3054021  0.28871143 0.2874321  0.29259348 0.2886242  0.28679818
 0.28846306 0.3101436  0.25881168 0.29084906 0.2591527  0.29084906
 0.29084906 0.28435796 0.26106268 0.2757493  0.3051533  0.3064825
 0.2874369  0.28679824 0.3048841  0.292347   0.30648234 0.28870717
 0.28679818 0.29084903 0.3054021  0.28860766 0.2911702  0.2591527
 0.29084906 0.29084906 0.25915256 0.2868014  0.3054021  0.2888171
 0.3054021  0.25913325 0.28679818 0.28871143 0.3054021  0.29083756
 0.2591526  0.30515343]
tr_loss:[0.14064229 0.15070339 0.15640813 0.16051224 0.1808787  0.16300088
 0.1600621  0.16006017 0.15748693 0.15283921 0.1421097  0.15640709
 0.16820192 0.16300109 0.16300091 0.16006015 0.16886309 0.15640709
 0.1630009  0.1630009  0.16006014 0.17926507 0.15112145 0.14211956
 0.15640697 0.1630009  0.16820279 0.16043937 0.15335838 0.16006011
 0.16300091 0.15640765 0.15640712 0.14211957 0.1630009  0.15640709
 0.1792651  0.17926508 0.15283921 0.16051397 0.15641996 0.16006012
 0.15283915 0.15317133 0.15112147 0.15640712 0.15640733 0.15640712
 0.1421196  0.17926507]
tr_loss:[0.09814549 0.10333019 0.09813154 0.09858938 0.09858938 0.09858938
 0.09858938 0.09766787 0.10333012 0.09817209 0.10363873 0.1036355
 0.09834389 0.103649   0.09817247 0.09597901 0.10333023 0.12820585
 0.10264041 0.10364334 0.09891099 0.09858938 0.09597901 0.09858938
 0.10363553 0.10130115 0.09891129 0.09597901 0.0985894  0.10292081
 0.1036355  0.10363551 0.09597901 0.1011953  0.12820585 0.09817247
 0.12820587 0.10333022 0.10130124 0.12028532 0.09858938 0.10333025
 0.09679703 0.09858938 0.10087568 0.10264043 0.09858938 0.12820585
 0.09806712 0.12820587]
tr_loss:[0.09029976 0.08059061 0.08154304 0.09245522 0.08197118 0.08653858
 0.0993015  0.09245526 0.1149567  0.0842253  0.12862015 0.09302334
 0.0805906  0.092907   0.09029982 0.09302326 0.09302334 0.09029978
 0.08832936 0.09245509 0.09245557 0.09657545 0.08059061 0.08422532
 0.09253703 0.09245521 0.08154304 0.08059062 0.08059061 0.0991387
 0.09302333 0.08059065 0.0823108  0.09245522 0.09253709 0.11313601
 0.08241191 0.08231074 0.0883294  0.09898182 0.08238278 0.08154313
 0.07457708 0.08231165 0.09302334 0.08231077 0.09245522 0.09029977
 0.09302335 0.08637859]
tr_loss:[0.06945273 0.07623424 0.08833146 0.06913342 0.07697376 0.0762342
 0.08747929 0.08805145 0.09420487 0.07623419 0.10743624 0.07697375
 0.08395954 0.08805008 0.08833181 0.08747938 0.0791693  0.08833166
 0.0942039  0.07697425 0.10793247 0.08540638 0.07697378 0.08833095
 0.08838969 0.08388741 0.08833146 0.07623423 0.10990013 0.08805007
 0.10989933 0.08388741 0.07626604 0.10990012 0.08388817 0.0907954
 0.08805007 0.07623418 0.08810354 0.10961512 0.08388741 0.08081834
 0.08833146 0.12218877 0.07646837 0.07623439 0.07697402 0.08833146
 0.12218847 0.08833154]
tr_loss:[0.10872921 0.08221518 0.07733785 0.08294417 0.1087292  0.10881933
 0.08221519 0.07734378 0.0839375  0.08405192 0.1087292  0.08221518
 0.08376409 0.08120583 0.07734378 0.08393935 0.07486591 0.0814984
 0.07734346 0.0839375  0.10872921 0.07318994 0.08188708 0.07483288
 0.08590083 0.07734378 0.0839375  0.07734379 0.10181858 0.10872921
 0.07734378 0.08393754 0.0839375  0.0839375  0.07282174 0.08221518
 0.06862804 0.07201557 0.08221518 0.08590086 0.07411991 0.07282175
 0.08393753 0.07897396 0.10872921 0.10872927 0.08221518 0.07717547
 0.0839375  0.0773438 ]
tr_loss:[0.08260155 0.08064903 0.07080914 0.0685671  0.08064903 0.09720661
 0.07329285 0.07995357 0.09720661 0.08232568 0.07087553 0.08260153
 0.07192092 0.08064903 0.08260153 0.07087556 0.07142495 0.08064903
 0.07782534 0.07109231 0.07329284 0.08070359 0.08232696 0.07087557
 0.07995357 0.08064903 0.09720661 0.07782535 0.07089269 0.08063789
 0.07093405 0.07782536 0.09644035 0.08064903 0.09641381 0.08260152
 0.07191989 0.08064903 0.09720661 0.07093405 0.07789045 0.08260153
 0.09643213 0.08260153 0.08232712 0.08064903 0.08070362 0.08064903
 0.08063307 0.07087557]
tr_loss:[0.06136671 0.06358326 0.06486128 0.07059145 0.06136454 0.0612654
 0.07636397 0.06882528 0.07636397 0.06982479 0.06882528 0.07051622
 0.06126543 0.06991833 0.07853302 0.07051603 0.06865737 0.0584756
 0.0613667  0.06982481 0.06126541 0.06136637 0.06486129 0.0613667
 0.07853289 0.0705621  0.07853128 0.07636394 0.05892573 0.06486131
 0.07070555 0.06882528 0.07051604 0.06993261 0.05712747 0.07051603
 0.0648613  0.07636396 0.06121563 0.07051605 0.07051605 0.06931738
 0.06486131 0.06914856 0.07051694 0.07636397 0.0590059  0.07083412
 0.0590059  0.06486131]
tr_loss:[0.05780751 0.05998107 0.06802754 0.0651031  0.05620274 0.06245885
 0.05720175 0.06262344 0.06510275 0.05998106 0.06510276 0.06468324
 0.05875583 0.05956583 0.06262346 0.06386416 0.05956586 0.0626472
 0.05998107 0.05898232 0.05956591 0.05670035 0.06262346 0.06386605
 0.05998106 0.06386604 0.06262152 0.06386599 0.05956584 0.05720183
 0.06262346 0.0626207  0.06262346 0.05898231 0.05898229 0.05956584
 0.06483619 0.06584152 0.05670035 0.05681396 0.06394923 0.06713401
 0.06565964 0.05670035 0.06428149 0.06802118 0.06259526 0.06262346
 0.06262345 0.06262346]
tr_loss:[0.06065124 0.06006381 0.06168675 0.06577151 0.05818354 0.05632265
 0.06006385 0.05997902 0.05635355 0.06249795 0.06006385 0.06006384
 0.06046564 0.06058304 0.06577148 0.06480335 0.05818572 0.05394211
 0.06047128 0.06249797 0.06047126 0.0581852  0.05477862 0.06249797
 0.05560955 0.06047128 0.05982614 0.05529646 0.06004222 0.06048155
 0.06259214 0.05477861 0.05818525 0.05635375 0.0641542  0.05818523
 0.05477862 0.05456934 0.05632265 0.06249885 0.06047124 0.06249797
 0.0657715  0.05477861 0.05997911 0.05818524 0.05477296 0.06249795
 0.06047126 0.07360209]
tr_loss:[0.05831449 0.06798877 0.0571432  0.05277424 0.05650599 0.05911554
 0.05277429 0.06031274 0.06275903 0.05911554 0.05822191 0.05614603
 0.05610772 0.05911554 0.05277428 0.06275905 0.05650599 0.06031274
 0.06798887 0.05614603 0.06798887 0.06031274 0.05911554 0.056506
 0.06202782 0.0527375  0.05277425 0.05277424 0.06422348 0.06029378
 0.0543747  0.05277425 0.06031274 0.05277425 0.06031274 0.05277522
 0.05277425 0.06275903 0.05277305 0.05277427 0.05277424 0.05277426
 0.07657561 0.06276064 0.05277425 0.05362018 0.06275904 0.05277425
 0.06275903 0.06234436]
tr_loss:[0.06316396 0.05435044 0.05952736 0.06316395 0.06316395 0.07620474
 0.05754723 0.06316394 0.07255559 0.05435048 0.06052044 0.05854396
 0.06316395 0.05754476 0.05816109 0.06584217 0.06316385 0.05916349
 0.05435044 0.05950897 0.06584214 0.06026042 0.05919058 0.05435044
 0.06584217 0.06316397 0.06026081 0.06316394 0.06631182 0.06316395
 0.06993756 0.07277504 0.0575472  0.05952755 0.05435418 0.07261229
 0.06584217 0.06464212 0.06584217 0.06993756 0.07277505 0.06315799
 0.06584218 0.05435012 0.05950389 0.06993755 0.06583961 0.06316296
 0.05620292 0.06316394]
tr_loss:[0.05223573 0.05706028 0.06063287 0.06063286 0.05223573 0.05223574
 0.07071269 0.06975639 0.05223574 0.05672331 0.07175057 0.05855315
 0.05223582 0.07045176 0.05223574 0.06063286 0.07071269 0.06338513
 0.07067785 0.06060371 0.06065891 0.06213995 0.07071271 0.07417808
 0.06881224 0.06971115 0.05855314 0.07071271 0.06788839 0.06063286
 0.05728962 0.06063171 0.06346445 0.07070568 0.06063275 0.05233302
 0.05715013 0.06062701 0.06338511 0.05579499 0.05579495 0.06338511
 0.06214013 0.07071269 0.05706028 0.05222555 0.06387836 0.06788839
 0.05223573 0.05715694]
tr_loss:[0.04563807 0.0507871  0.0438098  0.04276734 0.0507871  0.0507871
 0.04478201 0.04572904 0.04478199 0.04539988 0.04273525 0.05695323
 0.04273526 0.05676394 0.05120686 0.04811114 0.05120687 0.05078711
 0.04602279 0.04395642 0.05078712 0.05078712 0.05801906 0.0569532
 0.05080377 0.04273526 0.05695001 0.05120687 0.05007371 0.04756451
 0.05695313 0.04836312 0.05120686 0.04273525 0.05078711 0.04271844
 0.05695508 0.04539873 0.0507871  0.04756152 0.05078707 0.05120688
 0.04273526 0.04274353 0.05120686 0.05120686 0.0453996  0.04839963
 0.04839956 0.05492447]
tr_loss:[0.01859862 0.01980169 0.02146619 0.01676939 0.0186004  0.01980169
 0.02064211 0.01980228 0.01859862 0.0177368  0.01859719 0.02024356
 0.01769729 0.01859862 0.02146621 0.02146618 0.02146621 0.01782483
 0.01980167 0.01859861 0.01676939 0.01859861 0.01859665 0.0214662
 0.01860039 0.02629505 0.0214662  0.01676939 0.0214662  0.01980169
 0.0214662  0.01899073 0.02629539 0.01859861 0.01676938 0.01980174
 0.0198017  0.02024356 0.01859862 0.01978378 0.02037176 0.01676315
 0.01676939 0.01980167 0.02892981 0.01859116 0.01899074 0.02146235
 0.01908704 0.01980168]
tr_loss:[0.01573319 0.01573319 0.01648851 0.01227515 0.00781554 0.01227516
 0.01573317 0.00893941 0.00337943 0.01227516 0.00771028 0.01910002
 0.01227432 0.01227618 0.01227515 0.01805753 0.00894476 0.01693415
 0.01805754 0.00963488 0.00894475 0.01910002 0.00894474 0.0122735
 0.01630129 0.01637197 0.01209241 0.00894475 0.01623835 0.01573318
 0.01227516 0.01573318 0.01623677 0.01693389 0.00780411 0.01573317
 0.01573318 0.01648851 0.02206948 0.01227515 0.00894742 0.01648851
 0.01573317 0.01645998 0.01209241 0.01227516 0.00894475 0.01227474
 0.0180576  0.01227516]
tr_loss:[0.00695929 0.00463748 0.00892537 0.00463003 0.01110681 0.00695929
 0.01100295 0.01484142 0.01382283 0.01100295 0.01484144 0.00463736
 0.01100295 0.01554785 0.0231737  0.00695929 0.0046363  0.01485201
 0.00977454 0.01484145 0.01482491 0.01114607 0.01100295 0.00977455
 0.01110241 0.01563827 0.01484146 0.01100291 0.01484144 0.00977455
 0.01100912 0.00977455 0.0172691  0.00812103 0.00977455 0.01098315
 0.01483954 0.01100294 0.01726934 0.01482548 0.01726932 0.00684171
 0.00892537 0.01484144 0.0155065  0.01099629 0.00892537 0.01070956
 0.01100295 0.00892538]
tr_loss:[0.01638417 0.0162701  0.00947963 0.01132417 0.00947965 0.01627065
 0.00579515 0.00579515 0.0059468  0.01132418 0.00232886 0.00755829
 0.01606912 0.0063814  0.00455101 0.0144798  0.00579458 0.00455117
 0.00947964 0.01125536 0.01132418 0.01281479 0.00947966 0.00332527
 0.0054277  0.0059468  0.01627067 0.00579514 0.0054277  0.0054277
 0.01797336 0.01132418 0.02344533 0.00455115 0.01627037 0.00947964
 0.00579514 0.01627051 0.00579515 0.00947964 0.0063814  0.00579515
 0.00579539 0.018062   0.01117136 0.00579514 0.00455065 0.00579514
 0.00947982 0.00947965]
tr_loss:[0.00323157 0.00627988 0.0182872  0.01828718 0.00323143 0.00781692
 0.00680881 0.012536   0.00627874 0.00323223 0.01253599 0.01253599
 0.02661889 0.00630624 0.01828716 0.01828719 0.01828504 0.0075661
 0.00781692 0.00680881 0.012556   0.01059494 0.00645415 0.01059452
 0.01253598 0.01738414 0.0068075  0.00323158 0.01052371 0.01059495
 0.00645592 0.0032315  0.01828719 0.01059575 0.00323143 0.01261904
 0.02665501 0.01827196 0.01059495 0.02022296 0.00323143 0.008583
 0.00323143 0.01253601 0.01059495 0.00627874 0.00472852 0.00323143
 0.01067916 0.00781692]
tr_loss:[0.005425   0.01071679 0.02031735 0.01117446 0.00997991 0.00405215
 0.00305605 0.01465712 0.00712639 0.02117717 0.01322705 0.01116813
 0.01117446 0.01160162 0.00634185 0.00352717 0.01070107 0.02031727
 0.00459757 0.0065725  0.00305605 0.0146571  0.00305605 0.02031742
 0.00277881 0.00997989 0.01465712 0.01071678 0.01322709 0.02028444
 0.01080362 0.00997989 0.01071678 0.005425   0.01071677 0.00857757
 0.01465711 0.01117446 0.01465712 0.02031742 0.00305612 0.01240608
 0.01071678 0.01465712 0.01465712 0.01465712 0.01324415 0.00305605
 0.00600773 0.01075694]
tr_loss:[0.01079809 0.01057869 0.00520746 0.00285849 0.00611394 0.00285849
 0.00285849 0.00830107 0.01403537 0.00285849 0.01072239 0.01079596
 0.01960032 0.00830107 0.00705058 0.0120904  0.00285848 0.01079809
 0.00285849 0.00285849 0.00665585 0.00737851 0.01084059 0.00615658
 0.00615995 0.00830108 0.01072239 0.01080608 0.00448529 0.01197963
 0.01072668 0.02060874 0.01079642 0.01072239 0.00953403 0.0120904
 0.01406325 0.01406326 0.00734422 0.00606097 0.01406325 0.01209039
 0.01079809 0.00958611 0.01075669 0.00606852 0.00958611 0.01406325
 0.01299755 0.02003217]
tr_loss:[0.00639144 0.0113166  0.00772247 0.01166404 0.00968674 0.0113166
 0.01131642 0.00994288 0.00576601 0.00828908 0.00639144 0.0027835
 0.00639138 0.00940236 0.00589911 0.01775277 0.01131657 0.00828909
 0.00968674 0.00968674 0.00968674 0.0027835  0.01166406 0.00576601
 0.00828909 0.01131657 0.01949639 0.00881683 0.01256564 0.01111958
 0.0027835  0.01166405 0.00968672 0.00690225 0.00828909 0.01131659
 0.0147058  0.01131659 0.00968674 0.00296478 0.0027835  0.0027835
 0.00590047 0.00278342 0.01766199 0.01775325 0.01131659 0.00420477
 0.00994415 0.01131659]
tr_loss:[0.00966778 0.01527092 0.00966926 0.00773632 0.00203196 0.00735614
 0.0096678  0.00849728 0.00513309 0.02172045 0.00513309 0.00478429
 0.01482011 0.00454771 0.00966793 0.00481971 0.00281507 0.00243723
 0.01570916 0.00454771 0.00966778 0.00966779 0.00849728 0.00203196
 0.00851895 0.00454771 0.00282266 0.00454771 0.00851989 0.00966779
 0.00478718 0.00968372 0.00501709 0.00454771 0.00454771 0.00966811
 0.00851988 0.01107078 0.01107079 0.00773633 0.00483635 0.00735614
 0.00851989 0.00386237 0.0110708  0.00513309 0.02294802 0.00966782
 0.00454771 0.00851988]
tr_loss:[0.01039908 0.00667404 0.00686584 0.0211002  0.0087209  0.01125398
 0.00550871 0.01026746 0.01125398 0.00776648 0.01173406 0.01125398
 0.00289628 0.01516404 0.00681842 0.0102667  0.01518988 0.00872128
 0.00686584 0.01020071 0.00561839 0.00550227 0.01518988 0.00469055
 0.00574055 0.00478214 0.01518989 0.00686583 0.01518986 0.00550874
 0.00776647 0.00574055 0.00686583 0.00776647 0.00872135 0.00561544
 0.01038952 0.02203191 0.00686584 0.00550874 0.00872129 0.00872129
 0.01039908 0.00686584 0.00397313 0.01518988 0.0103991  0.00683898
 0.00686583 0.00872129]
tr_loss:[0.00368408 0.00639508 0.00890264 0.014212   0.00567053 0.00890263
 0.00960785 0.00657576 0.00567053 0.00918097 0.0089025  0.01790472
 0.00518023 0.0083105  0.01010449 0.00657575 0.00890264 0.00831052
 0.00918097 0.00656184 0.00943673 0.00918097 0.00604674 0.00918097
 0.00831052 0.00337823 0.0034023  0.00657576 0.00831049 0.00657576
 0.00657575 0.00340184 0.00831052 0.00831052 0.00657575 0.0083105
 0.00960784 0.00657049 0.00831052 0.00657575 0.00168958 0.00976573
 0.00890451 0.00657586 0.00657575 0.014212   0.00900416 0.00918097
 0.00657551 0.01421199]
tr_loss:[0.00571825 0.00571825 0.00693772 0.01325899 0.02413261 0.012524
 0.00439257 0.00899424 0.01068984 0.00671116 0.00159114 0.01068354
 0.00439257 0.00335173 0.00571825 0.00439256 0.00693742 0.01068356
 0.01068356 0.00899423 0.01757144 0.00439257 0.00571825 0.01068356
 0.00439256 0.00619842 0.00571822 0.00439251 0.01325996 0.00439257
 0.01325996 0.01068355 0.00899424 0.00571825 0.00627012 0.00682549
 0.00571824 0.00439257 0.02413275 0.01757601 0.00899424 0.00619842
 0.02523188 0.01325996 0.00899424 0.00602133 0.00671125 0.00580448
 0.00335175 0.00682537]
tr_loss:[0.00928724 0.00473188 0.00296901 0.01823751 0.00113804 0.00473701
 0.00296779 0.02653783 0.00928724 0.00743192 0.00111365 0.01421823
 0.01198746 0.00395283 0.00473701 0.00296779 0.01325769 0.00296779
 0.00715176 0.00113888 0.0062141  0.00296779 0.00404773 0.00262693
 0.00815187 0.00743192 0.00404955 0.01421822 0.00473701 0.00404955
 0.00490451 0.00113888 0.00113888 0.00490451 0.00284658 0.0133049
 0.00267418 0.01325768 0.00490451 0.00473701 0.01421824 0.00296779
 0.01421822 0.00647028 0.01325768 0.00296779 0.00296779 0.004737
 0.01325767 0.00494087]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3800 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3801, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3801 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3802, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3802 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3803, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3803 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3804, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3804 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3805, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3805 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3806, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3806 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3807, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3807 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3808, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3808 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3809, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3809 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3810, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3810 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3811, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3811 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3812, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3812 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3813, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3813 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3814, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3814 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3815, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3815 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3816, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3816 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3817, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3817 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3818, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3818 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3819, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3819 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3820, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3820 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3821, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3821 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3822, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3822 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3823, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3823 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3824, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3824 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3825, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3825 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3826, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3826 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3827, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3827 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3828, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3828 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3829, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3829 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3830, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3830 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3831, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3831 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3832, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3832 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3833, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3833 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3834, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3834 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3835, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3835 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3836, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3836 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3837, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3837 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3838, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3838 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3839, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3839 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3840, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3840 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3841, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3841 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3842, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3842 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3843, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3843 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3844, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3844 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3845, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3845 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3846, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3846 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3847, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3847 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3848, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3848 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3849, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3849 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3850, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3850 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3851, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3851 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3852, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3852 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3853, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3853 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3854, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3854 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3855, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3855 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3856, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3856 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3857, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3857 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3858, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3858 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3859, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3859 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3860, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3860 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3861, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3861 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3862, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3862 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3863, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3863 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3864, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3864 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3865, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3865 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3866, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3866 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3867, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3867 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3868, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3868 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3869, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3869 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3870, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3870 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3871, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3871 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3872, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3872 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3873, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3873 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3874, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3874 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3875, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3875 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3876, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3876 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3877, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3877 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3878, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3878 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3879, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3879 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3880, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3880 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3881, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3881 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3882, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3882 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3883, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3883 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3884, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3884 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3885, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3885 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3886, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3886 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3887, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3887 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3888, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3888 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3889, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3889 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3890, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3890 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3891, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3891 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3892, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3892 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3893, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3893 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3894, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3894 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3895, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3895 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3896, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3896 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3897, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3897 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3898, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3898 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3899, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3899 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3900, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-3800
text_input.shape
(3900, 14400)
learning_input_tmp.shape
(3900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3900, 80)
learning_output.shape
(750, 80)
Model: "sequential_79"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_79 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4899111 1.4670173 1.509331  1.5094749 1.4793565 1.4982154 1.5093307
 1.509331  1.5050374 1.4793596 1.4670173 1.509239  1.4902083 1.5072501
 1.5050398 1.5093309 1.4920244 1.4799216 1.5093307 1.5050373 1.509287
 1.4969329 1.4670173 1.5067843 1.5050371 1.46702   1.5093307 1.5093307
 1.4607555 1.5093307 1.5094225 1.5094733 1.5093307 1.509331  1.5093307
 1.4798414 1.4670173 1.5093307 1.4944243 1.5093151 1.4776485 1.4670173
 1.4670173 1.5093307 1.5050372 1.4670174 1.4670174 1.5086777 1.4902043
 1.4670173]
tr_loss:[0.9357494  0.90579736 0.9486477  0.9505989  0.9536641  0.95060235
 1.013119   1.0131199  0.9057973  0.9238907  0.95059884 0.90775025
 0.96882325 0.9077501  0.92387027 0.9508152  0.9077569  0.9089076
 0.9238275  0.9238907  0.9506214  0.94855565 0.9357519  0.9396936
 1.0131189  0.9416958  0.90579736 0.92389315 0.9239458  0.9303335
 0.94956625 1.013119   1.0080206  0.9077501  1.0131189  0.9535731
 0.94194996 0.95059574 0.9245262  0.9179279  0.9357502  0.9079504
 0.9447649  0.9077501  0.95366395 0.9505989  0.9498948  0.9505989
 0.9486476  0.9238907 ]
tr_loss:[0.490592   0.47210082 0.45668116 0.4718477  0.4805298  0.44439203
 0.45149153 0.45879978 0.46095163 0.4443922  0.5202695  0.45198163
 0.4882737  0.47210082 0.4721009  0.47210082 0.47342739 0.46113786
 0.45149165 0.45149165 0.45149153 0.4721009  0.45460692 0.45879883
 0.46556512 0.45155352 0.47210082 0.47342736 0.45149153 0.47342736
 0.5202706  0.47507277 0.47210082 0.45283365 0.4721016  0.47210088
 0.45276204 0.47210082 0.47492734 0.47166696 0.45149153 0.47344247
 0.47210082 0.4527622  0.4734273  0.48102456 0.4514916  0.450837
 0.48183066 0.4566811 ]
tr_loss:[0.2332995  0.23328337 0.2452029  0.2839305  0.2839305  0.23330903
 0.24492204 0.2452029  0.24515834 0.25479105 0.23447299 0.23638837
 0.24520293 0.23328345 0.2332834  0.2292629  0.2363606  0.28393885
 0.2452462  0.23842315 0.25479102 0.23328337 0.24520294 0.26356846
 0.24557152 0.24520287 0.2328293  0.24520311 0.24521372 0.2452029
 0.23328337 0.24516019 0.25475937 0.2635685  0.24520326 0.2840057
 0.28393054 0.2452029  0.24520293 0.2344728  0.24520293 0.2635755
 0.24516019 0.24520238 0.23842302 0.24638173 0.23316967 0.24520293
 0.2336402  0.25479105]
tr_loss:[0.12082388 0.10796034 0.10796033 0.10386477 0.10761628 0.12082388
 0.10752795 0.11288412 0.10796034 0.10796032 0.10761628 0.11229841
 0.10796034 0.10796098 0.10761628 0.10752799 0.10613681 0.10795212
 0.10796036 0.10796036 0.10381491 0.10796037 0.10761627 0.11229844
 0.10761616 0.10752802 0.10796036 0.10761631 0.11229841 0.11229847
 0.11229844 0.10796034 0.11934283 0.09910549 0.10385853 0.10761627
 0.11228124 0.11349201 0.11934282 0.10761011 0.11939595 0.11749706
 0.12082388 0.11375646 0.11349058 0.11229843 0.11939595 0.11939597
 0.11939595 0.11349197]
tr_loss:[0.0498938  0.04603305 0.04071156 0.04958037 0.04071156 0.04576285
 0.04085792 0.03613951 0.04560979 0.04094632 0.04065062 0.04300322
 0.04071158 0.0498938  0.04053576 0.04989392 0.0408578  0.04071156
 0.04224984 0.04660244 0.04071156 0.04989379 0.04989384 0.04501387
 0.04300321 0.04561286 0.04071156 0.04989384 0.04071156 0.0498938
 0.05199574 0.04071157 0.04508214 0.04576285 0.04086306 0.04660242
 0.0408578  0.04071157 0.04660251 0.04071156 0.04161087 0.04085851
 0.04071168 0.04660136 0.0498938  0.04851152 0.03613952 0.0361395
 0.04910647 0.04071154]
tr_loss:[0.0226152  0.01546389 0.02261518 0.01288218 0.01546394 0.02093679
 0.01546393 0.02714347 0.02949953 0.0233705  0.0226152  0.02144405
 0.00824099 0.02093679 0.01546393 0.0226152  0.01546393 0.01887111
 0.01546393 0.01627482 0.01531937 0.01546391 0.01546303 0.01770051
 0.02144123 0.02141128 0.02714347 0.01546393 0.01546393 0.01655858
 0.02299719 0.02093679 0.01546394 0.00824099 0.0188129  0.01288187
 0.01655769 0.0143712  0.01546393 0.00824099 0.02144486 0.0294995
 0.01655766 0.02269838 0.01546879 0.02143397 0.02337048 0.0143712
 0.0226152  0.01527535]
tr_loss:[0.02002088 0.02777256 0.02002069 0.02774475 0.01788676 0.0116478
 0.01788818 0.0116478  0.02439253 0.01164774 0.01788818 0.02002067
 0.0087825  0.02758874 0.0116478  0.01788818 0.01260898 0.0116478
 0.00368177 0.0116478  0.01622276 0.01788818 0.01788792 0.01591567
 0.0116478  0.0116477  0.01166395 0.02002068 0.02777254 0.0243925
 0.00368177 0.00368177 0.02002066 0.00368178 0.02002069 0.02002068
 0.01051279 0.01050815 0.02337037 0.01642762 0.00368177 0.02777253
 0.02001122 0.02002069 0.01788818 0.01788818 0.02777257 0.01918038
 0.02777261 0.02439253]
tr_loss:[0.00988811 0.01241166 0.01552222 0.01992995 0.01241166 0.01992995
 0.01108039 0.01992996 0.02335412 0.02501512 0.01108004 0.01241223
 0.00244316 0.00244316 0.01972474 0.0194574  0.01220501 0.01225441
 0.01992992 0.01993003 0.02055785 0.00244316 0.01241166 0.01439136
 0.01108039 0.01554286 0.02339938 0.01989983 0.0128829  0.00244316
 0.02501512 0.02378488 0.01241166 0.01554277 0.02459211 0.01295372
 0.01914735 0.01992997 0.02501512 0.0133308  0.01586998 0.0250151
 0.01992983 0.01241166 0.01241166 0.02339938 0.02501513 0.02469927
 0.0124139  0.00797729]
tr_loss:[0.01513891 0.01410102 0.01513894 0.02192434 0.01513893 0.0161635
 0.01513893 0.01427167 0.0220599  0.0220264  0.02205989 0.01331018
 0.01117605 0.01594651 0.01226631 0.01513893 0.02114763 0.02333331
 0.0228361  0.01513888 0.023472   0.01590976 0.01432812 0.02114448
 0.01616342 0.0150256  0.00863216 0.02114915 0.01922392 0.0220599
 0.01432811 0.01513893 0.0220599  0.0133102  0.01513893 0.02147398
 0.00226899 0.02114715 0.01513893 0.01121402 0.01513891 0.01921009
 0.01516152 0.02114713 0.01513908 0.01513893 0.01512172 0.01616489
 0.01259794 0.01513884]
tr_loss:[0.0170518  0.0173107  0.01731068 0.0173107  0.01611073 0.00409317
 0.01705266 0.01112391 0.01594618 0.0170518  0.0173107  0.01731187
 0.00409317 0.02136302 0.0170518  0.00409317 0.01705171 0.01904112
 0.0173107  0.01777803 0.0170518  0.01240523 0.02178646 0.0170518
 0.01240523 0.0220506  0.01731068 0.0170518  0.0170518  0.00409317
 0.01731008 0.01731066 0.01705175 0.01904114 0.01904108 0.0170518
 0.01708072 0.02178714 0.02178622 0.00409317 0.02336217 0.01240523
 0.0170518  0.01731052 0.00409315 0.01705016 0.01904113 0.0170518
 0.0170534  0.02336215]
tr_loss:[0.01688736 0.01863442 0.01688737 0.01674403 0.01688822 0.00934605
 0.01687482 0.01674404 0.01688736 0.01674401 0.01688736 0.01249757
 0.01688737 0.02180691 0.01150996 0.01150856 0.01398528 0.02281669
 0.01674403 0.01144284 0.01870314 0.01249757 0.01688736 0.01688736
 0.01870176 0.01863431 0.01870313 0.01688736 0.01688735 0.02180953
 0.01674401 0.01673553 0.00412718 0.02180954 0.00437454 0.01667431
 0.01674404 0.01144471 0.00437453 0.01688737 0.01398067 0.00437454
 0.01501791 0.01688737 0.01863442 0.01688737 0.01386195 0.01870278
 0.02180954 0.01688737]
tr_loss:[0.01916177 0.01902598 0.01290773 0.01916173 0.01778935 0.0129451
 0.01908447 0.00183337 0.0137336  0.01778933 0.01561129 0.01538362
 0.01457538 0.01201185 0.01916176 0.01294512 0.0129451  0.01072776
 0.00832945 0.01778934 0.0129451  0.01800994 0.01201185 0.00773981
 0.01294568 0.0129451  0.0074154  0.02201125 0.01284213 0.0129451
 0.01917523 0.01266084 0.01778936 0.01201185 0.01290775 0.0129451
 0.00187219 0.01201185 0.0129451  0.00183338 0.02201583 0.01778936
 0.01778935 0.0129451  0.00183338 0.00183338 0.00183332 0.01444476
 0.01294509 0.01201186]
tr_loss:[0.0238795  0.00111171 0.01052703 0.02184207 0.01035295 0.01820781
 0.01375813 0.00111171 0.00111171 0.01052703 0.02183883 0.00890973
 0.01923698 0.02183881 0.00111171 0.01011406 0.00890976 0.01005212
 0.01024213 0.02183881 0.0105123  0.01194738 0.01222438 0.01052703
 0.02183883 0.0124437  0.01194751 0.01052703 0.01024218 0.01369013
 0.01052703 0.01052703 0.01052703 0.02183885 0.02183883 0.01052703
 0.01011406 0.00640237 0.01222439 0.02388134 0.01052703 0.02183885
 0.00111171 0.01040524 0.01563316 0.01823919 0.01913432 0.02183885
 0.00890973 0.00111171]
tr_loss:[0.02295193 0.01676563 0.00223864 0.02550368 0.02470289 0.01043728
 0.01043729 0.02295195 0.02552099 0.0247029  0.0247029  0.01341814
 0.01010734 0.01030808 0.01023971 0.02470289 0.01551022 0.0188458
 0.01043729 0.01043729 0.01043729 0.01043729 0.00223864 0.01043746
 0.01043728 0.01043729 0.01043729 0.0247029  0.01089749 0.01884809
 0.00976765 0.01013663 0.01043729 0.01043729 0.01881542 0.00711463
 0.02470289 0.01043728 0.01058786 0.01167707 0.00892392 0.01884807
 0.02295195 0.01043729 0.01551022 0.00223864 0.0098082  0.00223864
 0.00980054 0.00981698]
tr_loss:[0.02478468 0.0179821  0.00963317 0.00963316 0.02046035 0.01162428
 0.01494519 0.00969137 0.01932028 0.00669675 0.00963318 0.0026547
 0.01820702 0.0092323  0.01283869 0.02416987 0.00265471 0.0026547
 0.00963363 0.0188075  0.02416988 0.00963413 0.00963341 0.018207
 0.00963317 0.02504243 0.0026547  0.02222499 0.00963317 0.00963317
 0.00963317 0.00963317 0.0026547  0.02416988 0.00963317 0.00936807
 0.018207   0.02417009 0.00265471 0.00963318 0.0026547  0.01494519
 0.01494519 0.02501251 0.00963318 0.00963318 0.00963318 0.00963318
 0.01270328 0.01283284]
tr_loss:[0.00748755 0.00658724 0.0157635  0.00748751 0.02229187 0.02145627
 0.00748755 0.02018892 0.00252437 0.00658718 0.01576336 0.00748905
 0.02018895 0.00654577 0.01271858 0.00748755 0.02018894 0.00748808
 0.00960468 0.00658724 0.00748755 0.00987858 0.00806116 0.00658724
 0.02018892 0.01127487 0.0075186  0.00748755 0.02018893 0.01914108
 0.00748753 0.01576253 0.01933658 0.00747644 0.01271854 0.00748607
 0.01576349 0.00748755 0.01305814 0.00814559 0.00693042 0.00748755
 0.00798619 0.00658724 0.00702272 0.00748755 0.00987702 0.01574971
 0.00748755 0.00767806]
tr_loss:[0.00417442 0.00417443 0.01021961 0.00745858 0.00450669 0.00266668
 0.00687823 0.00796567 0.0135646  0.00417442 0.01356461 0.01021962
 0.01356458 0.00687822 0.00417897 0.00450853 0.00448574 0.00450858
 0.0047759  0.01476793 0.01476132 0.01207625 0.01207313 0.0045086
 0.00450859 0.00364254 0.0074587  0.01476793 0.00417442 0.0045086
 0.01356458 0.01356461 0.01207867 0.01356462 0.01201652 0.00450859
 0.00417442 0.00417442 0.0074425  0.00450859 0.01476792 0.01021962
 0.01208346 0.00582627 0.00364258 0.01207867 0.0045086  0.01021924
 0.0045086  0.00745858]
tr_loss:[0.00338193 0.00422358 0.00339017 0.01013716 0.00422594 0.00526242
 0.01074771 0.00808454 0.01057474 0.01684242 0.01112908 0.01013698
 0.00899549 0.01057486 0.00947284 0.00526242 0.00422593 0.00422594
 0.00422593 0.00422593 0.00427581 0.00805621 0.01112906 0.00444313
 0.00526314 0.00422593 0.00430107 0.00418591 0.00422593 0.00422594
 0.01057474 0.00526242 0.00422593 0.00433699 0.01013723 0.01057474
 0.01057473 0.01112955 0.00808453 0.0064457  0.00894082 0.00368639
 0.01182643 0.01684215 0.00422593 0.00338192 0.00422593 0.01683285
 0.00338194 0.00422593]
tr_loss:[0.01278812 0.00742627 0.00706525 0.00742256 0.00742627 0.01278812
 0.00745997 0.00595113 0.00711301 0.02026601 0.00742627 0.0131483
 0.01278812 0.01359885 0.00742628 0.00717896 0.00742627 0.00742627
 0.00742627 0.01401216 0.00663282 0.00742627 0.02026601 0.00742627
 0.00749905 0.00720967 0.01278812 0.00721323 0.00742627 0.00721362
 0.01278813 0.01278812 0.00742627 0.00711301 0.0128527  0.00573079
 0.00573053 0.00742072 0.00742627 0.00742627 0.00644442 0.00742627
 0.00745997 0.02026601 0.01282306 0.00742627 0.00742625 0.0202639
 0.01282306 0.00745998]
tr_loss:[0.00795541 0.0136585  0.00817672 0.01511062 0.00814018 0.00796664
 0.00773599 0.00781613 0.01487461 0.00942378 0.00796664 0.01043321
 0.00817672 0.00796661 0.01346558 0.01487459 0.00814018 0.00817671
 0.01346558 0.00817671 0.00817671 0.00795532 0.01483623 0.02274833
 0.00796627 0.02274809 0.00817667 0.00795532 0.00817672 0.00795779
 0.01330558 0.02274833 0.00817691 0.01330067 0.00817672 0.00796664
 0.01043314 0.00814018 0.01346559 0.00817672 0.01454938 0.01348724
 0.00905779 0.00796663 0.0072676  0.02025961 0.01043325 0.00796664
 0.00578213 0.00817671]
tr_loss:[0.00573397 0.01258011 0.00573397 0.00782462 0.00573397 0.00573398
 0.00573383 0.00612942 0.00791403 0.00662974 0.00592909 0.01160867
 0.00573397 0.00670784 0.00573397 0.01160868 0.0075277  0.00431976
 0.00798187 0.00573397 0.01160868 0.00597162 0.00782463 0.00573396
 0.01160868 0.00573397 0.00573397 0.00573397 0.00782463 0.00573397
 0.01207493 0.01160868 0.00612939 0.01180433 0.00782464 0.01803243
 0.00782457 0.00573488 0.00782462 0.00752928 0.00674147 0.00573397
 0.0116134  0.00782462 0.00573397 0.01207495 0.00573344 0.01207494
 0.00573397 0.01160868]
tr_loss:[0.01115679 0.00667477 0.00901952 0.00343394 0.00789667 0.00343394
 0.00382752 0.00343395 0.0127436  0.00356172 0.00789663 0.0117759
 0.00488898 0.00901952 0.00901951 0.00901952 0.00343394 0.00901951
 0.00536689 0.00901952 0.00493211 0.00343394 0.00343395 0.01019396
 0.00901951 0.00343394 0.00788273 0.00343394 0.0090195  0.00758119
 0.01730271 0.00575783 0.00901948 0.01115679 0.00901951 0.01022233
 0.00343394 0.00343303 0.00488905 0.00667481 0.01022228 0.01022228
 0.00397257 0.01115679 0.01022227 0.00901951 0.01022078 0.0034347
 0.01178849 0.00287097]
tr_loss:[0.0028307  0.00657586 0.00645507 0.00352485 0.00352485 0.00352485
 0.01170757 0.00657586 0.01170764 0.00352373 0.00352485 0.01350629
 0.00352485 0.01000285 0.00352485 0.01099951 0.01170762 0.0035249
 0.00352485 0.00591619 0.00657586 0.01170764 0.01170763 0.00352485
 0.00277902 0.01099951 0.01779819 0.00349128 0.01099951 0.00352485
 0.00657586 0.00352485 0.00352565 0.01170763 0.01170808 0.00591619
 0.01000283 0.01553849 0.00277894 0.01170764 0.00339457 0.01170762
 0.01170763 0.01172575 0.002775   0.00352485 0.01350628 0.00591619
 0.01170762 0.00657586]
tr_loss:[0.00462808 0.00403432 0.00349705 0.01239824 0.00290551 0.00472565
 0.00772413 0.01242232 0.0112744  0.01371695 0.00472565 0.01072726
 0.00472565 0.00472565 0.00472565 0.00472565 0.0058889  0.00349705
 0.00676659 0.00472565 0.01239844 0.01239844 0.00471749 0.012399
 0.00349705 0.00675293 0.0084994  0.01029626 0.0084994  0.01533274
 0.00775639 0.00676056 0.00549646 0.01877118 0.01876637 0.01876104
 0.00472565 0.00349705 0.01229226 0.0047746  0.01372142 0.01533272
 0.00775639 0.00775639 0.00775639 0.01072726 0.00472227 0.00687544
 0.00858376 0.01341532]
tr_loss:[0.00476717 0.00609784 0.0047655  0.00668755 0.00544427 0.00720657
 0.00269116 0.01146936 0.00544427 0.00544427 0.00544433 0.01897495
 0.00544427 0.00476718 0.01305175 0.00476717 0.01305175 0.00544427
 0.01905346 0.00544427 0.00269116 0.00544427 0.01419902 0.01872675
 0.01420793 0.00544686 0.00720297 0.00544427 0.00812667 0.00476718
 0.01147607 0.00544427 0.00720259 0.00544427 0.00269116 0.00545431
 0.00425581 0.00476717 0.01605422 0.00486982 0.01305173 0.01305296
 0.01419902 0.00544427 0.00720628 0.01305175 0.00669285 0.00269116
 0.00544427 0.00547093]
tr_loss:[0.00288802 0.00294229 0.01351991 0.01087503 0.00524328 0.00452682
 0.01228144 0.00768198 0.01351994 0.00721658 0.00524328 0.00768196
 0.00865496 0.00997899 0.01351991 0.00547538 0.00538192 0.01359536
 0.01275168 0.00736228 0.01269691 0.01351991 0.00524328 0.01351991
 0.01351989 0.00723191 0.00865381 0.01351988 0.00287722 0.01351989
 0.00547461 0.00524327 0.01275168 0.01275168 0.00720147 0.00524326
 0.00452682 0.01275173 0.01275168 0.01087505 0.01351991 0.00524305
 0.00391775 0.0135199  0.01275168 0.00524328 0.00517901 0.00524328
 0.00524328 0.00523916]
tr_loss:[0.01135232 0.01135233 0.01163622 0.00423315 0.00420038 0.00367606
 0.00440547 0.00306074 0.00331676 0.0041569  0.0050442  0.01163618
 0.01163622 0.01411545 0.00637327 0.00710773 0.00440547 0.00440547
 0.01135233 0.00440547 0.00502585 0.00440543 0.00896954 0.0071324
 0.0116255  0.00710771 0.00423315 0.0116362  0.00440547 0.01163622
 0.00504229 0.00439737 0.00710771 0.00423315 0.0044051  0.00426958
 0.01411546 0.00715383 0.0081106  0.01163622 0.00423315 0.01135232
 0.00263885 0.00440547 0.01135233 0.01135233 0.00710773 0.00367606
 0.00440548 0.00440547]
tr_loss:[0.00926149 0.00740072 0.01059113 0.00332744 0.00926149 0.00380756
 0.01677216 0.00722599 0.00938774 0.01059285 0.00371419 0.01059044
 0.01058226 0.00722599 0.0033326  0.00281892 0.00722599 0.00722599
 0.00955373 0.00428457 0.00722599 0.00926149 0.01059112 0.00298238
 0.01059112 0.00541686 0.00711723 0.01041379 0.01059113 0.00722599
 0.00961456 0.00281898 0.00541686 0.0092615  0.00926149 0.00922026
 0.00369774 0.00428463 0.01059112 0.00926148 0.01059112 0.0074011
 0.00926149 0.00541686 0.01058859 0.00926127 0.00722599 0.00421289
 0.00711723 0.00926148]
tr_loss:[0.00528862 0.00784266 0.00408267 0.00516647 0.00784264 0.00408255
 0.00408256 0.00876423 0.00349497 0.00407357 0.01095643 0.01095643
 0.00784266 0.01095644 0.00876423 0.01050926 0.00408255 0.00528871
 0.00408255 0.00408255 0.01050926 0.00528871 0.00422888 0.00784266
 0.01050457 0.00629968 0.01095643 0.01020349 0.00408255 0.01095643
 0.00408179 0.00784265 0.00630845 0.00784265 0.00630772 0.00408266
 0.01050917 0.0063077  0.01020349 0.0044979  0.00428772 0.01050926
 0.00408255 0.00784264 0.00434655 0.01622739 0.00867534 0.00408262
 0.01049828 0.00517988]
text_input.shape
(3900, 14400)
learning_input_tmp.shape
(3900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(3900, 80)
learning_output.shape
(750, 80)
Model: "sequential_80"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_80 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1102384 1.1518568 1.1104938 1.1518568 1.1338933 1.1087867 1.1105541
 1.0904297 1.0904721 1.1404248 1.1049889 1.1405684 1.1518568 1.1104931
 1.0904801 1.1799223 1.102048  1.1287935 1.1482626 1.1104937 1.1104937
 1.1420357 1.1518569 1.1518567 1.1104937 1.0891161 1.1104937 1.1404797
 1.0904801 1.1105213 1.09048   1.141073  1.1104937 1.1104939 1.1104971
 1.146649  1.0994382 1.1799259 1.0913922 1.140425  1.1170486 1.0905493
 1.1385876 1.1422322 1.1104939 1.1402682 1.0904801 1.1104937 1.179926
 1.1049933]
tr_loss:[0.8093109  0.7894777  0.78663677 0.7866433  0.79176384 0.78663427
 0.7774444  0.7884255  0.7918593  0.7898606  0.7815503  0.78663695
 0.7894595  0.7899508  0.78922796 0.7898606  0.7774444  0.79204744
 0.7866369  0.78663695 0.7898605  0.7802776  0.7889353  0.77726364
 0.7774444  0.7898606  0.78986067 0.80945575 0.7898599  0.7866369
 0.7866368  0.79260325 0.79185915 0.78986055 0.7899097  0.8093109
 0.7866369  0.7902864  0.7870547  0.7898607  0.78986067 0.77744436
 0.79065573 0.7894785  0.8101303  0.7918585  0.78663695 0.77744436
 0.77744424 0.7774445 ]
tr_loss:[0.43045655 0.42072424 0.42074108 0.41684145 0.4154005  0.43790102
 0.43046165 0.431734   0.43370324 0.4154005  0.45633703 0.4304616
 0.4304616  0.4563366  0.4154005  0.41540056 0.43046218 0.43040878
 0.4304616  0.42172712 0.4207243  0.43046156 0.45633706 0.4379014
 0.4304616  0.43046156 0.4304616  0.45633706 0.42074108 0.42177638
 0.43305817 0.41684538 0.43046165 0.431254   0.4304615  0.41540056
 0.43682903 0.4207243  0.43790132 0.45633706 0.4405244  0.43115288
 0.42174968 0.43046156 0.43591148 0.43046156 0.4154005  0.43390718
 0.43657407 0.4207243 ]
tr_loss:[0.255337   0.25018752 0.26161844 0.26449367 0.26449364 0.26355553
 0.26464763 0.255337   0.27259788 0.26373982 0.26161847 0.25706348
 0.2617131  0.26374084 0.26161847 0.26161847 0.26161847 0.27855137
 0.2587551  0.25002477 0.26161847 0.25204474 0.26790062 0.2526709
 0.2500248  0.2785514  0.27259788 0.2625669  0.255337   0.255337
 0.26622844 0.27860278 0.26256698 0.26161847 0.27855253 0.26161847
 0.2644937  0.26161847 0.26600352 0.26449367 0.25706118 0.27218944
 0.2785514  0.2587322  0.26162177 0.2500248  0.2625051  0.26161847
 0.272595   0.25267118]
tr_loss:[0.14941642 0.14977054 0.15195255 0.14383706 0.14704695 0.14979087
 0.14849451 0.1438369  0.15691257 0.14849181 0.14703484 0.14383706
 0.14383705 0.14942397 0.14942397 0.14978471 0.14472702 0.14620203
 0.14879222 0.143837   0.14849451 0.14942396 0.14383705 0.14620212
 0.15195255 0.14669418 0.15692225 0.14978476 0.14977054 0.14474836
 0.14383706 0.14942399 0.14849499 0.14383703 0.15195253 0.15195271
 0.14383705 0.14476237 0.14384298 0.14552744 0.14664127 0.14669952
 0.14383705 0.14849451 0.14620204 0.15003414 0.14942487 0.14982891
 0.14664128 0.15195253]
tr_loss:[0.0785362  0.08749198 0.08621603 0.09202272 0.07621263 0.08621603
 0.08749187 0.08890612 0.08550961 0.08547817 0.09202273 0.07853621
 0.0785362  0.0785362  0.087492   0.07621261 0.08748829 0.08088644
 0.09202273 0.07621261 0.0785362  0.07621263 0.087492   0.09202273
 0.0785362  0.07720908 0.07621261 0.07621262 0.0867665  0.0785362
 0.087492   0.0791392  0.0785362  0.09202269 0.08676367 0.087492
 0.09202273 0.08621603 0.09202273 0.07621261 0.0785362  0.0785362
 0.0785362  0.08046096 0.07621262 0.07853618 0.09202273 0.09202273
 0.087492   0.09056596]
tr_loss:[0.07342239 0.05802225 0.06351189 0.08133315 0.08133317 0.07178558
 0.06401315 0.07342243 0.07242776 0.06407949 0.07342241 0.07243272
 0.07342242 0.07749838 0.08133316 0.07138844 0.07321477 0.08135916
 0.06527755 0.06407933 0.0640795  0.08133317 0.08133315 0.07721274
 0.06390406 0.0640795  0.07721278 0.08133315 0.08241226 0.08133315
 0.08133357 0.06411441 0.08133318 0.07269972 0.06407958 0.06407501
 0.08241047 0.07749841 0.08133315 0.07721274 0.08133316 0.0640795
 0.07138739 0.06620704 0.0640795  0.08133316 0.08133293 0.07269973
 0.07749841 0.06320515]
tr_loss:[0.0697336  0.06254782 0.0625478  0.07171459 0.0625466  0.06216288
 0.06129429 0.06119763 0.07102202 0.06119857 0.08020421 0.06254781
 0.05626655 0.06254782 0.06229571 0.06254782 0.0625478  0.07173527
 0.06292251 0.05626632 0.07173529 0.07173531 0.06977695 0.06254782
 0.0714684  0.06254782 0.06208422 0.0755849  0.06216303 0.07173531
 0.08056206 0.06254772 0.05667685 0.07173531 0.08056203 0.07102202
 0.06254782 0.07173531 0.06254782 0.06254782 0.06169453 0.06508632
 0.06508633 0.08056206 0.08056208 0.07173531 0.06897773 0.06983511
 0.06216304 0.07146196]
tr_loss:[0.06004873 0.07646228 0.0685342  0.05961451 0.0594479  0.06755316
 0.06897949 0.06004871 0.07588816 0.07588802 0.06004875 0.06004876
 0.06897949 0.06004874 0.06147812 0.06494687 0.06897947 0.06004875
 0.0726819  0.06004875 0.06581517 0.05398957 0.07268204 0.06899299
 0.06004871 0.06004875 0.0624014  0.06594642 0.06004875 0.07588798
 0.06682087 0.06004871 0.07588802 0.05398958 0.06004874 0.05981634
 0.06004375 0.0669025  0.06897949 0.06372396 0.06897921 0.06594643
 0.05398957 0.07268201 0.07268205 0.06004875 0.06005671 0.05961452
 0.05398957 0.06813846]
tr_loss:[0.05452833 0.06567832 0.05704655 0.06746991 0.06565519 0.05861763
 0.06816808 0.06206611 0.05845826 0.05704658 0.06746992 0.06746993
 0.05705885 0.06568305 0.05704658 0.06137042 0.06739386 0.05704658
 0.06746991 0.0584093  0.06830545 0.05704819 0.05641165 0.0657767
 0.05741103 0.05704657 0.06830544 0.06467077 0.064399   0.06746991
 0.05704669 0.06746991 0.06137034 0.07073801 0.06746991 0.06567831
 0.06567832 0.05198    0.05703589 0.05197994 0.0570462  0.05855112
 0.05198776 0.05452486 0.07065501 0.05336995 0.05452817 0.06567527
 0.07074098 0.05704657]
tr_loss:[0.05655696 0.05600528 0.05311742 0.06122621 0.05655695 0.05655695
 0.05552641 0.05655788 0.05910353 0.05655696 0.05355467 0.05655696
 0.05495263 0.05655167 0.06567241 0.05552641 0.05916491 0.05655692
 0.05600394 0.05532178 0.05414265 0.06122319 0.05495263 0.05409696
 0.05655697 0.05916493 0.06060647 0.05655696 0.05655696 0.05655696
 0.05786945 0.05408759 0.05495267 0.05655619 0.05495263 0.06567241
 0.06567241 0.05655696 0.06116195 0.0643485  0.05552641 0.06122621
 0.0556599  0.06435086 0.05552641 0.05495263 0.06435087 0.05655696
 0.06567241 0.05600394]
tr_loss:[0.05658703 0.05688591 0.05714151 0.05619894 0.05714152 0.06355682
 0.05688591 0.05492118 0.05680849 0.05731744 0.05731744 0.0571417
 0.05731744 0.05619894 0.05438565 0.06225691 0.05688593 0.05731728
 0.06225691 0.05731744 0.05731743 0.06355681 0.05688592 0.05731743
 0.05714151 0.05731744 0.06326183 0.0622569  0.05610869 0.05536179
 0.05731744 0.05731314 0.06543822 0.06225692 0.06408034 0.05731743
 0.05727063 0.05731744 0.05688592 0.06749439 0.05619894 0.06358621
 0.05688593 0.05808347 0.06759433 0.06355681 0.05731757 0.05688593
 0.05688632 0.05520108]
tr_loss:[0.06351871 0.06432195 0.06965861 0.05789893 0.06393422 0.05815213
 0.06834441 0.05815214 0.05815215 0.05815213 0.05842835 0.05815213
 0.06043418 0.0643217  0.0635187  0.0696585  0.05813167 0.0592395
 0.05815214 0.06365203 0.05815295 0.06350368 0.06456484 0.05843483
 0.05815214 0.05815213 0.06834441 0.05941442 0.0585239  0.06401215
 0.05816424 0.06966124 0.05941452 0.05815213 0.05923953 0.05819668
 0.05815221 0.05807052 0.06351868 0.05929612 0.05815172 0.06965856
 0.05815213 0.06400086 0.05815606 0.06400083 0.05815215 0.0683444
 0.05941454 0.05813167]
tr_loss:[0.06360281 0.06080381 0.06080185 0.06924708 0.06015138 0.06158929
 0.05565571 0.05565571 0.06080185 0.0585067  0.05926915 0.06066654
 0.0556557  0.05565571 0.05566237 0.05850646 0.05561572 0.05565568
 0.06158929 0.0556557  0.05850646 0.06642029 0.05850651 0.05565571
 0.0664203  0.06085756 0.0624757  0.06080185 0.05565571 0.0556425
 0.0556557  0.06159339 0.05591526 0.05565571 0.06158927 0.06080185
 0.05538661 0.05565571 0.06080184 0.06080185 0.05927465 0.0664203
 0.0608475  0.06158931 0.06158929 0.0556557  0.06080186 0.0664203
 0.06158929 0.05850733]
tr_loss:[0.0617445  0.05255378 0.06160418 0.05308411 0.05306543 0.06141115
 0.0617445  0.05429571 0.05601837 0.06030419 0.05748864 0.0571337
 0.06030432 0.06174449 0.0617445  0.05419459 0.05713487 0.05772502
 0.06174451 0.06031951 0.05306528 0.05306543 0.06141107 0.06780399
 0.06014841 0.06173999 0.06030481 0.05306547 0.06029855 0.05306543
 0.0617445  0.05772502 0.05713391 0.0542957  0.05306543 0.06021752
 0.06174451 0.05255125 0.05255378 0.05316609 0.05306606 0.05816359
 0.05631442 0.06021751 0.05713316 0.0617445  0.06030424 0.05419446
 0.05306543 0.05306543]
tr_loss:[0.06340753 0.05594718 0.05366449 0.05761848 0.06340753 0.05704463
 0.05366893 0.06212931 0.06212404 0.05704463 0.05366449 0.05952942
 0.06340751 0.05366449 0.06138301 0.05366449 0.05366449 0.05346834
 0.05712413 0.05367306 0.05366449 0.05559416 0.05366232 0.06212932
 0.05366449 0.05692311 0.05366449 0.0634106  0.05366449 0.05366449
 0.06397234 0.05366421 0.06227062 0.0559461  0.05366449 0.06340753
 0.05734722 0.05366458 0.06212932 0.05366449 0.05761848 0.06212931
 0.05366448 0.06171129 0.05366449 0.06212932 0.06212932 0.05359235
 0.05419738 0.05366449]
tr_loss:[0.0551089  0.05510889 0.0542716  0.06402712 0.0551089  0.06525622
 0.06525632 0.06616437 0.06393715 0.05891709 0.05522107 0.06215906
 0.05514093 0.05865651 0.06953476 0.05510164 0.0551089  0.05656925
 0.06525622 0.06402711 0.054412   0.0551089  0.06616432 0.06525623
 0.06953473 0.05510889 0.05865656 0.06402714 0.06953447 0.054412
 0.05441206 0.06525622 0.05441201 0.06525622 0.0615022  0.05656733
 0.05510888 0.06402713 0.0551089  0.05865657 0.06402712 0.05644067
 0.0551089  0.05510917 0.05510889 0.05865656 0.054412   0.054412
 0.0540299  0.06402713]
tr_loss:[0.05234135 0.06613038 0.05510204 0.06381943 0.0649887  0.05329927
 0.06498867 0.06498868 0.05329927 0.05441542 0.05511865 0.05441543
 0.05853597 0.0575582  0.06381943 0.05511865 0.06504871 0.06498867
 0.06381887 0.05669907 0.0649887  0.05511865 0.05511865 0.0649887
 0.06381952 0.05441543 0.05511865 0.06505289 0.06381963 0.05511865
 0.0638203  0.05329927 0.05511867 0.05506384 0.05329927 0.05329927
 0.05328342 0.05756309 0.06172007 0.06498869 0.06149746 0.05510581
 0.05511863 0.05447633 0.06381531 0.05511864 0.0590443  0.05447633
 0.06381943 0.05758652]
tr_loss:[0.05425572 0.0623102  0.05754592 0.05425572 0.05425572 0.05425572
 0.05425576 0.06231017 0.05595286 0.05289115 0.05289116 0.06293451
 0.06466662 0.0629345  0.06231965 0.05754592 0.0657205  0.05675033
 0.05418994 0.05289116 0.05289115 0.06277706 0.05656028 0.05595286
 0.0567208  0.05289116 0.05754592 0.05425573 0.06293451 0.06231017
 0.05425572 0.05425415 0.05672083 0.05595284 0.05754592 0.05425573
 0.05986203 0.05425572 0.05425573 0.0567208  0.05818713 0.05425573
 0.05672079 0.06317505 0.06231017 0.0542589  0.05595285 0.06293155
 0.05385659 0.05294787]
tr_loss:[0.06052393 0.05405899 0.06133799 0.06052398 0.06353611 0.05711323
 0.05405901 0.06052398 0.06091917 0.06052396 0.06052398 0.05391826
 0.05418674 0.05775243 0.06133751 0.05706555 0.06052398 0.05306704
 0.0584986  0.05306704 0.05406043 0.05405648 0.05405899 0.05306686
 0.05711322 0.05715616 0.05397039 0.05405884 0.05556635 0.06133749
 0.05397039 0.05912902 0.06052398 0.05306704 0.05405831 0.05405898
 0.06052396 0.05706819 0.05666572 0.05382807 0.06052396 0.05706554
 0.05406457 0.05405899 0.05405912 0.06134215 0.06052398 0.06052398
 0.05912907 0.05397039]
tr_loss:[0.058662   0.05479898 0.05479898 0.05512344 0.05487379 0.05593579
 0.05479898 0.05866202 0.06315026 0.05487379 0.05565058 0.05657636
 0.05866203 0.058662   0.05479898 0.0544432  0.05479892 0.05570629
 0.06140616 0.05806348 0.0556693  0.05479898 0.05487378 0.0547995
 0.05806344 0.06131076 0.05479326 0.05479899 0.0548011  0.05487379
 0.05479898 0.05479898 0.05656896 0.05866253 0.05485415 0.05713291
 0.05806311 0.06737617 0.0613802  0.05713291 0.05421882 0.05709312
 0.05656886 0.05711658 0.06135905 0.05806349 0.05421878 0.05866202
 0.06135848 0.0613591 ]
tr_loss:[0.05544537 0.06034096 0.05754342 0.06172099 0.05711357 0.05754342
 0.05545404 0.06172098 0.05544537 0.06296194 0.06296183 0.0605181
 0.05544537 0.05630125 0.05679966 0.061721   0.05679967 0.06094613
 0.06171549 0.06172099 0.05754342 0.05603983 0.05544537 0.05544537
 0.05544537 0.05458086 0.05754342 0.05754342 0.06172099 0.06172098
 0.05603987 0.06033925 0.06296182 0.05540536 0.06296016 0.05754342
 0.06172099 0.05679972 0.05754343 0.0562974  0.05971707 0.05971707
 0.05530666 0.05971707 0.05754067 0.05971707 0.05544536 0.06053891
 0.05679606 0.06053919]
tr_loss:[0.05547788 0.05547786 0.06064586 0.05547786 0.05635997 0.06099347
 0.06204608 0.05502271 0.05547785 0.05718962 0.0628643  0.05393653
 0.0624213  0.05575351 0.05554701 0.05575352 0.05548163 0.05393561
 0.05522111 0.06286427 0.05718962 0.06204711 0.05547785 0.05545511
 0.06205178 0.05500752 0.0620461  0.05718961 0.05547786 0.05547786
 0.06055109 0.05440875 0.06286429 0.06204609 0.0620461  0.06037952
 0.05575352 0.05547786 0.05393643 0.05393654 0.0620461  0.05544028
 0.06098604 0.05718962 0.05575351 0.05575352 0.06099427 0.05547786
 0.06286429 0.06015394]
tr_loss:[0.0545487  0.0546156  0.05982484 0.06669065 0.05461559 0.05461559
 0.05461558 0.05982484 0.06175457 0.05806502 0.05461558 0.05806499
 0.05806502 0.05981705 0.05424744 0.05461559 0.058065   0.05555093
 0.05461559 0.06115474 0.05806501 0.05806502 0.05479001 0.05461559
 0.06181569 0.05396616 0.06669071 0.058065   0.05384271 0.05478477
 0.05396616 0.05555131 0.05461558 0.05461507 0.05384266 0.05461559
 0.05806512 0.06254311 0.05452561 0.06175454 0.06254466 0.0546156
 0.05982484 0.05461559 0.05461559 0.05982483 0.06175455 0.05555133
 0.05806501 0.05461558]
tr_loss:[0.05969539 0.06680611 0.06124247 0.05815213 0.05358328 0.05358328
 0.05282006 0.0596954  0.05589309 0.05818325 0.05358327 0.06124987
 0.06089965 0.05282004 0.05358328 0.05358328 0.05282004 0.05813304
 0.05556875 0.06124939 0.05908795 0.05822587 0.0547501  0.0596954
 0.06681372 0.05842071 0.05969538 0.05969539 0.05358328 0.05364674
 0.06124987 0.05556868 0.05969537 0.06680274 0.05813304 0.05282004
 0.05969538 0.05691121 0.05358328 0.05691121 0.05813304 0.05589309
 0.05358328 0.05969538 0.05969539 0.05358328 0.06681345 0.06273412
 0.05813304 0.0596954 ]
tr_loss:[0.06064006 0.056689   0.06096703 0.05304636 0.06702728 0.05304636
 0.05304636 0.06095893 0.05304636 0.06096703 0.05304635 0.06128584
 0.05337048 0.05479847 0.05304636 0.05304664 0.06037083 0.06116005
 0.05317374 0.05304597 0.05238662 0.05304636 0.05304636 0.05238666
 0.05664559 0.05304676 0.06096704 0.06128583 0.05664559 0.05304636
 0.0531606  0.05239125 0.05304635 0.06128583 0.05313621 0.05803419
 0.06128583 0.05283991 0.05648316 0.05803422 0.05304635 0.06096705
 0.05668904 0.05669219 0.06129431 0.05304632 0.05304636 0.06060101
 0.06128585 0.05304636]
tr_loss:[0.05305321 0.06053611 0.06252996 0.05305315 0.05565015 0.05759401
 0.05305315 0.06252994 0.05923946 0.06096897 0.05299775 0.06096898
 0.06096898 0.06252995 0.05305315 0.05250313 0.05288021 0.05565015
 0.06096901 0.06801493 0.05281421 0.05305315 0.05305315 0.06096677
 0.05305315 0.05440069 0.06096898 0.06801796 0.05565015 0.05305315
 0.06252987 0.05565015 0.05330295 0.06252962 0.05305315 0.05593713
 0.05305315 0.05316542 0.06312354 0.05625712 0.06377716 0.05565015
 0.05565015 0.05297681 0.06252994 0.05919548 0.05759401 0.05565015
 0.06252995 0.05594702]
tr_loss:[0.05755752 0.05336146 0.0547118  0.05764478 0.06016416 0.0547118
 0.05704353 0.06109001 0.05589908 0.05698613 0.05296966 0.05410099
 0.05329969 0.06079254 0.05764478 0.05330123 0.05329969 0.06240762
 0.06346755 0.06781638 0.06016905 0.05962181 0.05332213 0.06051883
 0.06106427 0.05329778 0.05410099 0.06111046 0.05296966 0.05764479
 0.06111048 0.06346755 0.05329969 0.0547118  0.0532997  0.05329969
 0.05305458 0.05329968 0.0532997  0.05962182 0.05471193 0.05329966
 0.0531258  0.0601706  0.06111049 0.05410099 0.05471179 0.05329969
 0.05764479 0.0624076 ]
tr_loss:[0.05353276 0.05635588 0.05890821 0.05635588 0.05353297 0.05353297
 0.05353298 0.06088439 0.05353297 0.05353296 0.0561576  0.05353297
 0.05669316 0.05981923 0.05665068 0.05353297 0.05636933 0.05353297
 0.05695271 0.05353297 0.05386534 0.05386514 0.06094229 0.05327081
 0.06739552 0.06114874 0.05353297 0.05353297 0.05890818 0.06115346
 0.06115348 0.05684001 0.05353297 0.05353297 0.05353304 0.05655707
 0.05890818 0.06340684 0.05353297 0.06115348 0.05386534 0.05353296
 0.05635714 0.05576741 0.05353297 0.05376589 0.06115348 0.0608435
 0.06733652 0.05353297]
tr_loss:[0.05385013 0.0611751  0.05304615 0.05385011 0.06314747 0.06322689
 0.05722408 0.05385013 0.05914778 0.05914778 0.05359159 0.05914778
 0.06125237 0.05570635 0.05399158 0.05914778 0.06125237 0.05399864
 0.05416908 0.05399154 0.05385013 0.05304614 0.05385013 0.06662315
 0.05385013 0.05385013 0.06125237 0.05399154 0.05914778 0.05570634
 0.05359159 0.05518873 0.05516812 0.06568784 0.05386901 0.05914777
 0.05914779 0.06125226 0.0538502  0.05399154 0.0577754  0.05359019
 0.05385013 0.05914778 0.05786213 0.06669045 0.06125237 0.05382692
 0.05304615 0.06125236]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3900 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3901, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3901 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3902, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3902 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3903, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3903 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3904, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3904 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3905, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3905 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3906, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3906 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3907, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3907 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3908, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3908 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3909, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3909 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3910, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3910 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3911, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3911 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3912, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3912 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3913, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3913 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3914, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3914 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3915, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3915 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3916, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3916 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3917, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3917 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3918, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3918 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3919, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3919 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3920, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3920 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3921, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3921 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3922, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3922 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3923, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3923 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3924, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3924 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3925, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3925 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3926, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3926 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3927, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3927 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3928, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3928 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3929, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3929 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3930, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3930 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3931, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3931 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3932, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3932 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3933, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3933 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3934, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3934 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3935, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3935 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3936, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3936 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3937, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3937 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3938, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3938 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3939, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3939 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3940, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3940 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3941, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3941 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3942, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3942 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3943, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3943 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3944, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3944 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3945, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3945 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3946, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3946 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3947, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3947 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3948, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3948 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3949, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3949 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3950, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3950 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3951, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3951 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3952, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3952 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3953, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3953 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3954, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3954 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3955, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3955 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3956, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3956 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3957, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3957 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3958, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3958 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3959, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3959 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3960, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3960 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3961, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3961 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3962, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3962 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3963, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3963 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3964, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3964 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3965, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3965 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3966, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3966 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3967, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3967 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3968, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3968 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3969, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3969 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3970, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3970 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3971, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3971 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3972, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3972 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3973, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3973 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3974, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3974 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3975, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3975 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3976, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3976 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3977, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3977 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3978, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3978 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3979, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3979 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3980, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3980 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3981, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3981 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3982, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3982 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3983, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3983 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3984, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3984 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3985, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3985 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3986, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3986 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3987, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3987 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3988, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3988 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3989, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3989 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3990, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3990 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3991, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3991 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3992, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3992 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3993, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3993 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3994, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3994 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3995, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3995 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3996, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3996 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3997, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3997 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3998, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3998 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(3999, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 3999 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4000, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-3900
text_input.shape
(4000, 14400)
learning_input_tmp.shape
(4000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4000, 80)
learning_output.shape
(750, 80)
Model: "sequential_81"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_81 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2052246 1.1864411 1.1845057 1.1995611 1.2007812 1.1893344 1.1866089
 1.1830553 1.1997917 1.2007812 1.1774137 1.2007812 1.2007812 1.1845057
 1.2007815 1.193771  1.1866088 1.1830558 1.1845053 1.2007813 1.2052246
 1.2007812 1.1880693 1.2007813 1.2007812 1.1984279 1.2007813 1.2007812
 1.1984257 1.193125  1.1830559 1.1901503 1.1865702 1.2007815 1.186413
 1.2007813 1.2007812 1.1984288 1.2052244 1.2031453 1.198271  1.206845
 1.2007813 1.2052246 1.1829902 1.1984245 1.2007774 1.2007813 1.1830553
 1.1824884]
tr_loss:[0.68315136 0.6830832  0.68635976 0.7185717  0.68315125 0.7160824
 0.71923244 0.68315554 0.7160823  0.717248   0.7189808  0.6876982
 0.68315136 0.7189808  0.68635994 0.67531884 0.68315136 0.69008124
 0.68315333 0.7160822  0.68315136 0.68635976 0.6831034  0.68315136
 0.68315136 0.7160823  0.7160823  0.7142584  0.68315136 0.7137345
 0.68315136 0.68312633 0.6832612  0.68315667 0.68315136 0.6906167
 0.68315136 0.71599704 0.7160822  0.68315136 0.7159053  0.6831565
 0.6831514  0.7142584  0.67485744 0.69070673 0.71971166 0.7189808
 0.7160822  0.71724254]
tr_loss:[0.32557145 0.3267579  0.32557145 0.32798046 0.32557148 0.34270126
 0.32557145 0.34270126 0.33397013 0.32320994 0.32241684 0.34270123
 0.31876317 0.32557145 0.32798076 0.33394793 0.32557145 0.32557148
 0.34270126 0.32675788 0.3252765  0.32557148 0.32425863 0.3427012
 0.3278442  0.34270123 0.32557145 0.32557145 0.32798076 0.32219216
 0.32241693 0.3232099  0.31994995 0.32798117 0.3188441  0.32557145
 0.3255714  0.32557148 0.32557145 0.33394793 0.32798076 0.32557148
 0.32557145 0.32242557 0.32557148 0.32969132 0.32558364 0.32557148
 0.32557145 0.32557148]
tr_loss:[0.12766197 0.1276619  0.12766197 0.12766194 0.12777828 0.12766197
 0.12420752 0.12253328 0.1274372  0.12618403 0.12766197 0.12766197
 0.1330384  0.12749985 0.11878848 0.12746482 0.12766197 0.12530717
 0.13053803 0.11867324 0.12766194 0.13000941 0.13053806 0.12766197
 0.12766194 0.12766197 0.12766197 0.12574336 0.12766197 0.12766197
 0.12261822 0.12420978 0.12743719 0.12766196 0.12247069 0.12766196
 0.12130755 0.12766196 0.12766197 0.12261818 0.13002583 0.12611236
 0.12766197 0.12640253 0.12282419 0.12766197 0.12581582 0.12754218
 0.12420982 0.12766194]
tr_loss:[0.0584322  0.06636773 0.06636776 0.06636778 0.05843221 0.05029205
 0.05843222 0.05492233 0.05321527 0.0584322  0.0584322  0.05843221
 0.05597784 0.05849383 0.05832153 0.0584322  0.05321527 0.05591166
 0.04883711 0.06270294 0.05843221 0.06270282 0.06270283 0.05843221
 0.05320279 0.05843221 0.06636775 0.04883713 0.05834441 0.05843221
 0.05843221 0.0584322  0.06270282 0.0584322  0.04686157 0.06636779
 0.06270281 0.06636777 0.04818643 0.04883359 0.05597784 0.05843221
 0.04883713 0.05843221 0.05485782 0.0584322  0.05779475 0.06636775
 0.05852005 0.05843221]
tr_loss:[0.02936109 0.02974457 0.02974457 0.03161834 0.02974458 0.02974457
 0.02882215 0.02974404 0.02974457 0.02335044 0.02974457 0.02974457
 0.02974457 0.02612242 0.0297446  0.0316425  0.03164252 0.0316425
 0.02974935 0.02974457 0.02974476 0.02335044 0.02335149 0.02883789
 0.02974457 0.02816344 0.02974356 0.02974457 0.02974457 0.03103064
 0.02645827 0.02974457 0.02974457 0.03103049 0.02974457 0.02816346
 0.02974457 0.03164252 0.02348909 0.02974457 0.03058421 0.02974457
 0.02816344 0.02883797 0.02974457 0.02974455 0.03224533 0.02658619
 0.03164248 0.03057605]
tr_loss:[0.01723072 0.02400883 0.02501102 0.02360592 0.0240095  0.02400951
 0.01723072 0.02400956 0.0172307  0.02400951 0.02426397 0.0240095
 0.02400951 0.02499306 0.0253876  0.01978977 0.02387059 0.01723072
 0.02406679 0.02426396 0.02400951 0.02400951 0.0240095  0.02516448
 0.02222411 0.0240095  0.0240095  0.02222347 0.02400974 0.02400951
 0.02562563 0.02502223 0.0240095  0.02400951 0.0240095  0.02400951
 0.02426395 0.0240095  0.02426398 0.01855884 0.0240095  0.02400949
 0.02426397 0.0240095  0.0240095  0.02501102 0.01807711 0.01723072
 0.0240095  0.0240095 ]
tr_loss:[0.01926284 0.01926284 0.01890261 0.02347233 0.02539753 0.02084454
 0.02123228 0.01604539 0.01926284 0.01926284 0.01890261 0.01536952
 0.01969393 0.0153691  0.02123228 0.01926374 0.01534795 0.01926284
 0.01926284 0.02123233 0.02341902 0.02258817 0.01482986 0.01482988
 0.01890261 0.01536953 0.01482988 0.01926284 0.02347232 0.01536953
 0.014668   0.01482988 0.01926284 0.01926284 0.02123205 0.01926284
 0.01926949 0.02123228 0.01926284 0.01926284 0.02153468 0.01926284
 0.01926171 0.01482988 0.01529814 0.02157072 0.01536953 0.02324246
 0.02123228 0.01926284]
tr_loss:[0.00962753 0.01828875 0.0159938  0.0173661  0.01736607 0.01215672
 0.0159938  0.01222258 0.01736608 0.00962753 0.01632165 0.01222259
 0.00962754 0.0108215  0.00962752 0.00962752 0.00962753 0.01046447
 0.01828875 0.01394796 0.00987113 0.0141547  0.00962752 0.01736609
 0.01444868 0.00962752 0.01400003 0.01222259 0.01223276 0.01617908
 0.00962753 0.00962731 0.01394795 0.00962753 0.00893009 0.00962753
 0.01736609 0.01451867 0.01250792 0.01085884 0.00962688 0.01394796
 0.00962753 0.00962753 0.01698905 0.01736609 0.01599381 0.00962752
 0.01415471 0.01216515]
tr_loss:[0.01987333 0.01722234 0.00678844 0.02244169 0.01718873 0.00678844
 0.00678844 0.01847248 0.01434197 0.01003814 0.01987252 0.00678844
 0.01434197 0.02244172 0.01742354 0.01997941 0.01722218 0.02244173
 0.00678844 0.00678844 0.0098722  0.00678814 0.01974964 0.02244171
 0.00678844 0.01502201 0.0125006  0.01047608 0.00678849 0.00621925
 0.00678844 0.00678845 0.00621925 0.00678844 0.00659141 0.02243897
 0.00678844 0.01047501 0.01987318 0.00678844 0.01986545 0.0104747
 0.00678844 0.0067885  0.00678844 0.00678845 0.01047469 0.01997941
 0.01718857 0.01047468]
tr_loss:[0.00923028 0.00923028 0.00923028 0.02520415 0.00923006 0.01912224
 0.00820624 0.00922952 0.00923039 0.00923028 0.01395467 0.0092303
 0.00923834 0.00923028 0.00923028 0.00923028 0.00923028 0.02860764
 0.0286076  0.0092284  0.02860763 0.02183873 0.00923032 0.02570827
 0.02520365 0.01320627 0.02570828 0.00920848 0.00917622 0.01720015
 0.02570827 0.02860765 0.02351111 0.02570827 0.00923028 0.00923028
 0.0209805  0.0177473  0.00923028 0.00923028 0.02351105 0.00923028
 0.02860764 0.00923028 0.02428446 0.01912223 0.00923028 0.02860763
 0.00922931 0.01292999]
tr_loss:[0.02304991 0.00909538 0.02132501 0.02986502 0.0237137  0.00852195
 0.00909164 0.02986501 0.02101711 0.00913076 0.02986613 0.00909163
 0.02986499 0.02101711 0.02986497 0.00909163 0.02132525 0.00909164
 0.02304991 0.01108425 0.00909163 0.02986499 0.00843186 0.02371578
 0.02101714 0.00909163 0.00909163 0.00909163 0.02304991 0.00909163
 0.00909164 0.02172963 0.02304991 0.029865   0.02101711 0.01809588
 0.00909163 0.0230499  0.00843223 0.00909164 0.02371576 0.01964218
 0.02986495 0.02300726 0.02969513 0.0090916  0.02986501 0.02986499
 0.029865   0.01964246]
tr_loss:[0.00957102 0.02412116 0.02412117 0.00957102 0.01147845 0.02184549
 0.01294632 0.02184525 0.02254932 0.00957102 0.03052412 0.02259283
 0.0145344  0.0225927  0.00939234 0.0145344  0.01461139 0.01452812
 0.00957102 0.03052411 0.00939233 0.00957102 0.0145344  0.00957103
 0.00935061 0.01803249 0.02412117 0.00935061 0.00957102 0.00957102
 0.00957102 0.00957102 0.0305241  0.01786207 0.00939258 0.02058968
 0.00935061 0.00957102 0.01850697 0.00966233 0.00957103 0.03052413
 0.01148125 0.00957102 0.02081821 0.03052413 0.03052516 0.03052411
 0.00957102 0.01117506]
tr_loss:[0.00994094 0.01880452 0.01099895 0.01008233 0.02008508 0.01099895
 0.01008353 0.01008234 0.01008235 0.01008233 0.02126982 0.03001055
 0.01880451 0.03020719 0.01099895 0.01008233 0.01008234 0.03020719
 0.02126982 0.01008234 0.00897879 0.01008234 0.03020719 0.02073349
 0.00994796 0.01008234 0.01008233 0.02426082 0.03020719 0.01008233
 0.01008233 0.01099895 0.01008234 0.0228098  0.00993984 0.0242608
 0.03020718 0.01008234 0.0089788  0.01008233 0.01099895 0.01008233
 0.01008233 0.0242608  0.01008234 0.01008234 0.01160624 0.03020719
 0.01008233 0.0152378 ]
tr_loss:[0.01621369 0.01698103 0.00852965 0.00846463 0.00843306 0.01697563
 0.0167214  0.00852966 0.0122481  0.00875865 0.01799126 0.00843287
 0.02625491 0.02625493 0.0172341  0.00773752 0.02077552 0.00843306
 0.02625491 0.02625495 0.00843307 0.01223583 0.00843306 0.0206504
 0.00838984 0.01799126 0.00852965 0.01671268 0.00843301 0.00842902
 0.0084265  0.00843306 0.00852965 0.0122357  0.01697562 0.00820649
 0.01672139 0.02625493 0.00852965 0.01799126 0.00843516 0.0262549
 0.02077533 0.02625512 0.02625495 0.00843306 0.00843306 0.02625714
 0.00843306 0.00843306]
tr_loss:[0.01819009 0.01070373 0.00499127 0.00499127 0.00499127 0.00499127
 0.00499127 0.0123657  0.01548862 0.01247106 0.01819009 0.0060619
 0.00589828 0.00499127 0.00499224 0.00499127 0.01280123 0.00499127
 0.01060849 0.0049886  0.0046848  0.01819009 0.01819009 0.0060619
 0.01279994 0.0060619  0.01819009 0.01280164 0.00499127 0.01819007
 0.01160538 0.01247106 0.00499127 0.00499127 0.00606186 0.00499127
 0.00499127 0.00467618 0.01819009 0.00970827 0.00499127 0.00589829
 0.01160531 0.00446636 0.01160538 0.01347977 0.00499127 0.01819008
 0.00606189 0.00499127]
tr_loss:[0.00739796 0.00387345 0.00584317 0.00739793 0.00387349 0.00739796
 0.00739796 0.00255881 0.00387349 0.00387377 0.01057842 0.00255881
 0.00976613 0.00255875 0.00387348 0.00698539 0.00387349 0.00739796
 0.00255881 0.00976613 0.00975764 0.0038735  0.00537161 0.00584317
 0.00976614 0.00387348 0.00372093 0.00584317 0.00387349 0.00776348
 0.00387349 0.00387349 0.00387349 0.00357433 0.00387348 0.00387349
 0.00387349 0.00739796 0.00465857 0.00465919 0.00387349 0.00387349
 0.00976614 0.00387341 0.00795476 0.00387349 0.00975887 0.00372093
 0.00313514 0.00776712]
tr_loss:[0.00739183 0.00891208 0.00739279 0.00891209 0.00891052 0.00891208
 0.01467352 0.01599947 0.00891208 0.00891208 0.00891208 0.0154361
 0.00740836 0.00891208 0.00891208 0.00410166 0.00908345 0.00739184
 0.00509037 0.00891208 0.00891209 0.00438794 0.00891208 0.00739133
 0.00908312 0.01599935 0.01521711 0.00891208 0.01599946 0.01599752
 0.00635327 0.00739184 0.0088668  0.00739184 0.01521711 0.00438866
 0.0051938  0.00907751 0.0073918  0.00739627 0.00519387 0.00891208
 0.00739184 0.00519072 0.01543643 0.00635327 0.00635336 0.00891208
 0.00891208 0.00891208]
tr_loss:[0.01683998 0.00446281 0.00831919 0.01250268 0.0126832  0.01250188
 0.00804909 0.01250269 0.01850797 0.01250268 0.01251786 0.00804909
 0.01241035 0.00777788 0.00804909 0.0173713  0.01250268 0.01250466
 0.00924571 0.01250369 0.01629594 0.00831919 0.01850798 0.0127289
 0.01250268 0.00924574 0.01250269 0.00804909 0.01253157 0.0125026
 0.00920562 0.00804907 0.01850798 0.02030637 0.00646486 0.0073486
 0.01737132 0.01250268 0.00709586 0.00777787 0.01252626 0.00924571
 0.01250268 0.01850797 0.02030637 0.01250269 0.01250269 0.02083596
 0.01191034 0.01250269]
tr_loss:[0.01002606 0.00710706 0.00710704 0.00809215 0.00710706 0.01005202
 0.01005058 0.00710706 0.01005186 0.01005186 0.0161365  0.00710707
 0.00581692 0.0098691  0.01005185 0.00670388 0.01613651 0.01005186
 0.0067073  0.01005186 0.00710706 0.01005186 0.0100519  0.01005186
 0.01005185 0.0077092  0.01005185 0.01005186 0.00809038 0.01005185
 0.01557728 0.00492337 0.00916011 0.01423691 0.01005186 0.01005186
 0.01625248 0.01005186 0.01005186 0.01573104 0.0049191  0.01005185
 0.01613651 0.00920566 0.01005186 0.01005666 0.00716714 0.0100519
 0.01005186 0.01060386]
tr_loss:[0.00667604 0.0052327  0.00364096 0.0052327  0.00724377 0.01001473
 0.00722693 0.0052327  0.0052327  0.00723165 0.00722694 0.0118796
 0.00274549 0.00722693 0.00486226 0.0052327  0.00523257 0.0052327
 0.01248167 0.00417352 0.0054664  0.00523268 0.0052328  0.0052327
 0.0052327  0.0052327  0.0083777  0.00722694 0.0052327  0.0052327
 0.00523269 0.01120842 0.00559356 0.0052327  0.0052327  0.00523269
 0.0052327  0.0052327  0.00414109 0.0083777  0.0052327  0.00559504
 0.0052327  0.00454466 0.00414161 0.01174828 0.00722694 0.00486226
 0.0124876  0.0052327 ]
tr_loss:[0.01139587 0.00352505 0.00268737 0.00352505 0.00352505 0.00349898
 0.00512774 0.003525   0.00352506 0.0087799  0.0051719  0.00607933
 0.00352505 0.00352505 0.01139572 0.00338264 0.00705126 0.00354285
 0.00350658 0.00359204 0.00352505 0.01052784 0.01139585 0.00512774
 0.01254838 0.00352505 0.00877984 0.00352505 0.00352505 0.00512774
 0.00352505 0.00607937 0.00512774 0.00352506 0.01254837 0.00352505
 0.00352505 0.00338942 0.01139593 0.01139587 0.00674138 0.00705126
 0.00352505 0.00266137 0.00359203 0.00359204 0.00352505 0.00352505
 0.0034347  0.00352505]
tr_loss:[0.01189369 0.00436001 0.01660372 0.01476259 0.00614102 0.00614102
 0.0147636  0.00446956 0.00446956 0.0118678  0.00923156 0.00446956
 0.0104733  0.00614102 0.00446956 0.01263276 0.01660387 0.01660372
 0.01263327 0.01263327 0.00574177 0.00446956 0.01165548 0.00446956
 0.00635721 0.00614176 0.0166037  0.00446956 0.01085404 0.00446956
 0.01095438 0.00439648 0.00436    0.01047321 0.00613501 0.01263325
 0.00446956 0.00446956 0.00446956 0.01095438 0.00446956 0.00446956
 0.00446956 0.00998464 0.00581029 0.00343737 0.0166037  0.00614102
 0.0166037  0.0166037 ]
tr_loss:[0.00778258 0.00778258 0.00494169 0.00778258 0.01275652 0.01275652
 0.01867315 0.00494169 0.00479666 0.00535764 0.0126344  0.01867316
 0.00516509 0.01570554 0.00494028 0.01139842 0.00494174 0.0125735
 0.00536021 0.01139839 0.00494169 0.01139839 0.00479241 0.00778258
 0.00494169 0.01275652 0.00494169 0.00494169 0.00494168 0.01867316
 0.01867277 0.01421812 0.01275652 0.00494169 0.00494169 0.0079314
 0.00494169 0.00494169 0.00494169 0.00673816 0.01867314 0.01867317
 0.01275652 0.00479665 0.00494169 0.00494167 0.00493487 0.00479665
 0.00494169 0.00494168]
tr_loss:[0.00420816 0.01753571 0.00420847 0.00958903 0.00620321 0.00405074
 0.00420816 0.01753571 0.01195935 0.00421776 0.01478839 0.00399482
 0.00399482 0.00420816 0.01195627 0.01753571 0.00430688 0.01478838
 0.00420816 0.00399482 0.00958903 0.00420816 0.01233174 0.01195935
 0.00399482 0.00399482 0.01753571 0.00958903 0.01059792 0.0042081
 0.00958903 0.00620064 0.00958903 0.0175357  0.00421302 0.01154602
 0.00420816 0.01217066 0.00420816 0.00537707 0.00592825 0.01061423
 0.01405824 0.00421156 0.01291512 0.01478838 0.00420816 0.0175357
 0.00420816 0.00958903]
tr_loss:[0.00383383 0.00314788 0.01307206 0.00314787 0.00314788 0.00314788
 0.01056801 0.00314788 0.00314781 0.00314788 0.00581755 0.00315697
 0.0085901  0.00314788 0.01053348 0.00314787 0.00314788 0.00314788
 0.01443757 0.00635236 0.0029256  0.01328087 0.01328096 0.00314788
 0.01045587 0.01056801 0.01443758 0.01307206 0.01026009 0.00309597
 0.01056802 0.00292561 0.01219005 0.01038113 0.01056801 0.01443759
 0.00314788 0.00314788 0.00307826 0.00314788 0.01443758 0.00314788
 0.00314788 0.010742   0.01056802 0.01056801 0.00314788 0.01045587
 0.01045587 0.00851227]
tr_loss:[0.00726885 0.00643408 0.00238632 0.00238632 0.00537537 0.01124889
 0.00238632 0.00249813 0.01032478 0.00239222 0.00238837 0.00238632
 0.00537537 0.00537544 0.00238632 0.00238632 0.00238632 0.00238632
 0.00238632 0.00238632 0.00244592 0.00643479 0.00537539 0.00238632
 0.00958766 0.0024368  0.00748934 0.00238632 0.01124888 0.00950945
 0.00238632 0.01124888 0.00356443 0.01032478 0.00950945 0.00708309
 0.00546994 0.006434   0.00958766 0.00726885 0.00238632 0.00238632
 0.00347577 0.01032477 0.00238632 0.00238632 0.01032477 0.00238632
 0.00356443 0.00644466]
tr_loss:[0.00720091 0.00706062 0.00294698 0.00911927 0.0070606  0.00294697
 0.00744413 0.00294697 0.00294697 0.0081903  0.00294697 0.00294697
 0.0022722  0.00294697 0.00339739 0.00706061 0.00294697 0.00294697
 0.00704542 0.00815916 0.00437149 0.00447082 0.00294697 0.00294697
 0.00376613 0.00294697 0.00294697 0.00339437 0.00706061 0.00706061
 0.00744414 0.00384074 0.00911925 0.00296868 0.0042233  0.00815916
 0.00294697 0.00739169 0.00447082 0.00706061 0.00739955 0.00294697
 0.00294131 0.00294697 0.00294697 0.00815917 0.00387425 0.00294697
 0.00437149 0.00706062]
tr_loss:[0.00477429 0.00548138 0.00477429 0.00548138 0.00548142 0.00548138
 0.00477429 0.0029854  0.00479906 0.00922851 0.00477429 0.00477429
 0.00477429 0.00473233 0.00298553 0.00477429 0.00477429 0.00543595
 0.00477429 0.00548138 0.00477429 0.00477429 0.00477429 0.00477566
 0.00477429 0.00477421 0.00477429 0.00442696 0.00765967 0.00477428
 0.00298553 0.00548139 0.00477429 0.00477429 0.00765967 0.00311272
 0.00885403 0.00780572 0.00922851 0.00477428 0.00477429 0.00922851
 0.00543595 0.00477429 0.00318019 0.00548139 0.00477429 0.00772261
 0.00548138 0.00477429]
tr_loss:[0.00518427 0.01058822 0.00527688 0.00870017 0.00527689 0.00494494
 0.00870017 0.0100343  0.00527688 0.00367516 0.00527687 0.00591675
 0.00367516 0.00367516 0.00367516 0.00138624 0.01057377 0.00527703
 0.00367515 0.00528388 0.00527688 0.00969706 0.01004682 0.00527688
 0.00199267 0.00527688 0.00527688 0.01003429 0.00367516 0.00527671
 0.00527688 0.01058902 0.00138647 0.00870016 0.00518141 0.00367516
 0.00527688 0.00478176 0.00075254 0.00527688 0.00527688 0.01058841
 0.00924387 0.00345623 0.00527688 0.00527688 0.00367515 0.00527688
 0.00870016 0.00527688]
text_input.shape
(4000, 14400)
learning_input_tmp.shape
(4000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4000, 80)
learning_output.shape
(750, 80)
Model: "sequential_82"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_82 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1492139 1.1907301 1.1833539 1.1405159 1.2214588 1.1521163 1.1833533
 1.1515821 1.151582  1.151582  1.1516179 1.1213853 1.1374032 1.1705996
 1.1833538 1.151582  1.1907301 1.1378952 1.1405275 1.1515821 1.151582
 1.1369432 1.2214588 1.151582  1.151582  1.19073   1.1405203 1.1466873
 1.1833539 1.2214588 1.1515821 1.183354  1.1833538 1.1405274 1.1515821
 1.151582  1.1266528 1.2214588 1.1515821 1.1505749 1.1374031 1.2201879
 1.1907301 1.151582  1.1506739 1.183354  1.1515821 1.1907301 1.2214588
 1.1512442]
tr_loss:[0.7632605  0.7699038  0.7702502  0.7699038  0.7571927  0.7699037
 0.7640705  0.76990354 0.7640498  0.7709278  0.7924448  0.77203304
 0.7699038  0.7640529  0.75074685 0.7699038  0.7699028  0.76990634
 0.763664   0.7636641  0.76876545 0.77180636 0.7507452  0.75074494
 0.791525   0.7632604  0.76990384 0.764049   0.76990366 0.7640499
 0.76120937 0.7699038  0.7699038  0.791525   0.76990604 0.7646721
 0.77042955 0.7631372  0.7636641  0.7712922  0.7699038  0.7630808
 0.76598155 0.7699038  0.76471436 0.76990384 0.75067556 0.76366407
 0.7637493  0.7718316 ]
tr_loss:[0.37171203 0.3560874  0.36874795 0.36343297 0.36343294 0.37171206
 0.3567257  0.36343303 0.3788971  0.37889713 0.36856222 0.3717121
 0.35994253 0.37154073 0.35671812 0.36343297 0.35153547 0.36343297
 0.36343297 0.36343297 0.36872745 0.35608897 0.35671967 0.3717112
 0.37171203 0.363433   0.363433   0.36343303 0.3472356  0.36343297
 0.36342198 0.3634321  0.3604363  0.3782309  0.3634399  0.36343297
 0.3789125  0.36343303 0.34684235 0.3468426  0.37171206 0.37171212
 0.35608885 0.3567181  0.36343303 0.37170875 0.35995483 0.36343703
 0.363433   0.36343303]
tr_loss:[0.20838742 0.21209049 0.19940451 0.20843966 0.20838737 0.2121404
 0.2047197  0.20931438 0.20471974 0.20838746 0.20838746 0.2093598
 0.20838745 0.20838745 0.20838745 0.20838742 0.20838742 0.21209049
 0.20838742 0.20838745 0.20838745 0.21209049 0.20931438 0.20931439
 0.20838742 0.20838742 0.19978377 0.20838745 0.20931439 0.20838745
 0.19604196 0.20838742 0.19677505 0.20838745 0.20804298 0.20838745
 0.20472014 0.2065074  0.20838742 0.20838733 0.20838866 0.20931439
 0.20838742 0.2065508  0.20838742 0.21209049 0.20678893 0.20263235
 0.20931439 0.20555773]
tr_loss:[0.11423428 0.11930293 0.11423429 0.11930294 0.11712886 0.11844168
 0.11762647 0.11712885 0.11885454 0.11930291 0.11830684 0.12356701
 0.12356694 0.11547519 0.11712885 0.1184904  0.11423429 0.11886682
 0.12759794 0.123567   0.11930291 0.11844164 0.11881322 0.12759796
 0.11886682 0.11712885 0.11712886 0.12356701 0.1184417  0.11712886
 0.11423428 0.11794187 0.11844168 0.12356675 0.11712885 0.11712887
 0.11844166 0.12038195 0.11712886 0.11642591 0.11423429 0.12149451
 0.11830684 0.11930291 0.12087917 0.11712885 0.11712886 0.11712886
 0.11712889 0.1276015 ]
tr_loss:[0.06712822 0.06576949 0.08499638 0.06712371 0.07509565 0.06576949
 0.07492094 0.08499639 0.08499636 0.06712823 0.07492094 0.0735593
 0.07567537 0.07567537 0.08499638 0.08499638 0.07539526 0.06712823
 0.06712822 0.06989974 0.06712823 0.06712823 0.07539526 0.07483714
 0.06712822 0.07916997 0.06712823 0.06723345 0.06712823 0.0849964
 0.07356654 0.06712823 0.06712823 0.06712822 0.08499637 0.08499638
 0.06712823 0.06712823 0.0657781  0.06989974 0.08464064 0.06989973
 0.08499639 0.08499638 0.07356653 0.06712823 0.08471853 0.06712823
 0.06712823 0.06712821]
tr_loss:[0.05715116 0.05715116 0.05915684 0.0670466  0.05715117 0.05715117
 0.06706121 0.05715117 0.06853462 0.05719855 0.07615215 0.07615255
 0.06853459 0.06706475 0.07615214 0.05919089 0.05715116 0.06687798
 0.05715117 0.06706475 0.05715116 0.07615216 0.07615217 0.05715199
 0.05642095 0.07615217 0.05715116 0.05715117 0.06383427 0.07605501
 0.05715117 0.06383427 0.06125445 0.05715117 0.05715116 0.06274698
 0.07121512 0.06720226 0.06835554 0.06719742 0.06704807 0.07615215
 0.06751081 0.05715114 0.06835555 0.05715117 0.05715116 0.066878
 0.06413355 0.05715116]
tr_loss:[0.05581949 0.06615002 0.06493058 0.07810389 0.05581249 0.05581949
 0.07810389 0.05581949 0.05581949 0.0558194  0.05581949 0.05581949
 0.0649306  0.07461651 0.05581949 0.06292755 0.05581949 0.05581947
 0.05581949 0.05581768 0.0558195  0.06600127 0.06584934 0.07461651
 0.06738678 0.06825112 0.05581949 0.0746165  0.0573758  0.05581949
 0.06709786 0.0558195  0.05581949 0.0781039  0.06601745 0.07461649
 0.05581949 0.07810389 0.07461645 0.07461644 0.06549628 0.07461645
 0.05581949 0.07461573 0.05581949 0.06549628 0.05581949 0.05581949
 0.06798185 0.0558195 ]
tr_loss:[0.0702096  0.07020962 0.08403597 0.05420361 0.07599355 0.06431197
 0.05421584 0.05790759 0.06308737 0.06321097 0.05418753 0.06291694
 0.06321095 0.05420361 0.07599355 0.07020961 0.06291693 0.05420361
 0.07599355 0.0702096  0.07020962 0.05420361 0.06550892 0.06321084
 0.05420362 0.06323471 0.06321096 0.07599355 0.05420353 0.06552015
 0.06391355 0.06117471 0.07020958 0.06117471 0.05692685 0.06117471
 0.06323472 0.0702096  0.07599357 0.07599355 0.06391357 0.05420361
 0.07599356 0.06279121 0.06431231 0.05420361 0.05422792 0.07020963
 0.07020962 0.06607989]
tr_loss:[0.05201529 0.05201415 0.05838271 0.05679179 0.05201655 0.05201499
 0.06120574 0.05201528 0.05534972 0.05933602 0.0574731  0.05201528
 0.05201529 0.05686979 0.05747917 0.05201529 0.05201528 0.06485997
 0.05201529 0.05838271 0.05201529 0.05201528 0.05201529 0.05669454
 0.05201528 0.05201528 0.06120572 0.05648185 0.06120575 0.05933608
 0.05201523 0.05245537 0.05201528 0.05201528 0.05201529 0.06485998
 0.05201521 0.05686977 0.0524314  0.05201528 0.05201576 0.05201529
 0.06485998 0.06120574 0.06120573 0.05499793 0.05510334 0.06120573
 0.05201528 0.05201528]
tr_loss:[0.05453466 0.0552008  0.05256869 0.05453465 0.05961909 0.05453632
 0.05453464 0.05702921 0.05226687 0.05250264 0.05545415 0.05545415
 0.05516589 0.05453461 0.05453466 0.05453466 0.05545414 0.05545414
 0.05961909 0.05453465 0.05909082 0.05453467 0.05545414 0.05453466
 0.05490363 0.05453466 0.05453423 0.05544037 0.05453466 0.05453464
 0.05453466 0.05721812 0.05890547 0.05250264 0.05721813 0.05453466
 0.05721813 0.05453466 0.05453466 0.05545414 0.05453466 0.05909083
 0.05453464 0.05485156 0.05545413 0.05909083 0.05453466 0.05453466
 0.05453466 0.05545415]
tr_loss:[0.05933939 0.05991108 0.05742941 0.05991108 0.05991109 0.05991109
 0.05591185 0.05681412 0.05310031 0.05991108 0.05592339 0.06354505
 0.06194596 0.05991109 0.05753282 0.0632866  0.05753277 0.05991108
 0.05991108 0.05750614 0.05933937 0.05201626 0.05310057 0.05991108
 0.05991108 0.05591185 0.05991108 0.05591184 0.05991108 0.05797281
 0.05991108 0.05991108 0.06355047 0.05581944 0.05991108 0.05991108
 0.05774487 0.06322358 0.06394011 0.05933937 0.05933937 0.0633762
 0.05990834 0.05596476 0.05212104 0.0598316  0.05753284 0.06395565
 0.05591186 0.0632866 ]
tr_loss:[0.06257932 0.06411475 0.0607814  0.06078141 0.05678821 0.06078142
 0.06078141 0.06257931 0.05993901 0.0523052  0.06078141 0.05862765
 0.05993898 0.06078141 0.06078141 0.0607814  0.06388748 0.0607814
 0.06411476 0.06399529 0.0646954  0.06469535 0.05993901 0.05364067
 0.06078142 0.06078159 0.06058545 0.0607814  0.05233576 0.05862757
 0.05678828 0.0567882  0.05859415 0.05233544 0.05993881 0.06257931
 0.05786926 0.0607814  0.0607814  0.06078141 0.06257931 0.06469531
 0.05233578 0.06078142 0.0607007  0.05678845 0.06110568 0.06078141
 0.06257933 0.05993901]
tr_loss:[0.05201093 0.06003745 0.05929823 0.05569836 0.05741232 0.05569835
 0.06057533 0.05569835 0.05569835 0.05569835 0.05569835 0.05568874
 0.05569835 0.05094641 0.05569814 0.06003745 0.05569835 0.05196066
 0.05569834 0.05201093 0.05569835 0.05569867 0.05569835 0.0551408
 0.05569835 0.05569835 0.05741286 0.05569835 0.0600323  0.05569835
 0.05455092 0.05569835 0.05455092 0.05569836 0.06003746 0.0556411
 0.05094719 0.06057531 0.05569835 0.05591141 0.05815655 0.05569835
 0.05521019 0.05569835 0.05569836 0.05929603 0.05569836 0.05815654
 0.05185425 0.0605753 ]
tr_loss:[0.05130218 0.05130222 0.05715734 0.05130222 0.05724862 0.05130479
 0.05281803 0.05130222 0.05130222 0.0528801  0.05500634 0.05509199
 0.05130222 0.05255881 0.05357335 0.05130222 0.05823657 0.05715733
 0.05553501 0.06120058 0.05143171 0.05130222 0.05729947 0.05130222
 0.05288006 0.05406749 0.05827649 0.05729947 0.0528801  0.05281145
 0.05130221 0.05130222 0.0550091  0.05553497 0.05715734 0.05130221
 0.05255783 0.05130222 0.05715732 0.05130221 0.05494883 0.05287361
 0.05448184 0.05715733 0.0513023  0.05130222 0.05130222 0.05130435
 0.06120059 0.05448144]
tr_loss:[0.05154169 0.05154169 0.05154169 0.05154169 0.06143413 0.05154169
 0.05530722 0.05956855 0.06822711 0.05459229 0.05154169 0.05154169
 0.05154173 0.05154169 0.05459228 0.05539715 0.05154169 0.05458527
 0.05833557 0.05820654 0.05154169 0.05833704 0.05459228 0.0682205
 0.05154169 0.05154805 0.05154169 0.05154169 0.05154169 0.05154169
 0.05168086 0.05154162 0.06822051 0.05154169 0.05956855 0.05708379
 0.05689814 0.05154169 0.05613066 0.05530659 0.05820654 0.05154169
 0.05459228 0.05154169 0.06143414 0.05154307 0.05154169 0.06822051
 0.06822108 0.05459192]
tr_loss:[0.05228338 0.05228338 0.05932304 0.05228338 0.05954408 0.06921498
 0.05228338 0.05228338 0.06921665 0.06472615 0.05228338 0.06472614
 0.06130143 0.0522834  0.0522834  0.05932304 0.05228338 0.06921662
 0.05958495 0.05228338 0.05228142 0.06472616 0.06093736 0.05525223
 0.0522835  0.05954272 0.06473769 0.05854725 0.0601908  0.06921662
 0.0647293  0.05954408 0.06120386 0.05228339 0.05228347 0.05929856
 0.05228338 0.05227641 0.05934995 0.05228338 0.05970996 0.05954042
 0.05228339 0.0522834  0.05947708 0.0522834  0.06190937 0.05228338
 0.06472638 0.05562962]
tr_loss:[0.05913135 0.06456266 0.05224966 0.06456266 0.05224966 0.05224966
 0.05224963 0.05224966 0.06456266 0.05224966 0.05224935 0.06456267
 0.06456266 0.05600426 0.06456266 0.06128344 0.0596246  0.05224965
 0.0585728  0.05224966 0.05874347 0.06549892 0.05224966 0.05224966
 0.06549893 0.06456267 0.05224966 0.05600426 0.05234504 0.05224966
 0.06549892 0.05885684 0.05600426 0.06456267 0.05224966 0.06153398
 0.05224966 0.06456265 0.0545176  0.05224969 0.05224966 0.05885711
 0.05910969 0.05224966 0.05225027 0.05857281 0.06547652 0.06153395
 0.05941337 0.06456265]
tr_loss:[0.0564477  0.0622478  0.06069801 0.05212042 0.0522186  0.06224782
 0.05933041 0.0564477  0.05933041 0.05764367 0.0564477  0.06008047
 0.05644534 0.05397484 0.0522186  0.0522186  0.06224779 0.05628086
 0.06114467 0.05818967 0.05779669 0.06018108 0.05221093 0.05628086
 0.06223562 0.06715756 0.0522186  0.05221868 0.0522186  0.05221861
 0.05294939 0.06114467 0.05764366 0.05218774 0.0522186  0.0522186
 0.05221856 0.06114467 0.06224779 0.05631218 0.06126232 0.05397484
 0.05222068 0.0522186  0.0522186  0.0522186  0.05931263 0.0522186
 0.06224779 0.05857462]
tr_loss:[0.05598413 0.05213838 0.05341582 0.05213838 0.05811892 0.05213834
 0.05672284 0.05619253 0.05213838 0.05213837 0.05213838 0.05987155
 0.05806267 0.05213689 0.05619253 0.05607296 0.05865796 0.05857756
 0.05341582 0.05213838 0.05347959 0.05987157 0.05751932 0.05987158
 0.05598532 0.05865795 0.05865794 0.05987159 0.05213838 0.05213838
 0.05213838 0.05825716 0.05213838 0.05806267 0.05213837 0.05213837
 0.05212978 0.05213838 0.05213838 0.05213837 0.05619253 0.05598532
 0.05865796 0.05430511 0.05213838 0.05213838 0.05213838 0.05213837
 0.05202924 0.05213837]
tr_loss:[0.05494771 0.0526019  0.05869799 0.05778035 0.05260189 0.05356449
 0.05594513 0.0526019  0.0526266  0.05260189 0.05489393 0.05582255
 0.0526019  0.0526019  0.05523274 0.05525232 0.05260189 0.05796199
 0.05260189 0.05796181 0.05796199 0.05113676 0.0526019  0.05525232
 0.05086831 0.05088516 0.0549476  0.05594514 0.05582256 0.05582255
 0.05113719 0.05202426 0.05260189 0.05497687 0.05086829 0.0526019
 0.05260189 0.05593012 0.05260189 0.0549476  0.0549766  0.05579184
 0.05260189 0.05800755 0.05798452 0.0526019  0.05796199 0.05796199
 0.05494761 0.05494761]
tr_loss:[0.05891412 0.05041996 0.06026629 0.06026629 0.05447432 0.05447431
 0.05447431 0.06026629 0.05447431 0.05413665 0.05547768 0.06026627
 0.05368674 0.05368676 0.05413669 0.05807541 0.0541367  0.05447432
 0.05552633 0.05447432 0.05413665 0.05447432 0.05890391 0.05889245
 0.05447432 0.06026629 0.05368674 0.05369216 0.05447431 0.0591055
 0.05413669 0.05113857 0.05114474 0.05447431 0.05894361 0.05894361
 0.05368674 0.05528206 0.05910566 0.05447432 0.05447432 0.05368675
 0.0591055  0.05358055 0.05894361 0.05447431 0.05356815 0.05891169
 0.05447432 0.05368674]
tr_loss:[0.05537087 0.05563738 0.05410705 0.05976716 0.05410677 0.05729489
 0.05189549 0.05721104 0.05653359 0.05563738 0.05583132 0.05563738
 0.05976731 0.0556303  0.06071403 0.06250642 0.05564761 0.05563738
 0.06250642 0.0533424  0.06250642 0.05563738 0.05563738 0.06071403
 0.05563738 0.05563542 0.05373751 0.06250642 0.05189551 0.05721119
 0.05976731 0.05563738 0.06250644 0.05373751 0.0537375  0.05563738
 0.05563738 0.05373751 0.0556374  0.05373751 0.05327699 0.05163179
 0.05563738 0.060714   0.05563938 0.05621596 0.05564179 0.0518955
 0.05630436 0.0556374 ]
tr_loss:[0.05566161 0.05422947 0.05181443 0.05408209 0.05422951 0.05422947
 0.05422947 0.05422946 0.05422946 0.05422946 0.05422946 0.05343033
 0.05899407 0.05181443 0.05422947 0.05158685 0.05422946 0.05181443
 0.05408209 0.05422946 0.05422946 0.05422946 0.05422946 0.05408209
 0.05422722 0.05422947 0.05181443 0.05422946 0.05422946 0.05899395
 0.05422946 0.05395916 0.05379515 0.05181444 0.05422946 0.0540821
 0.05422961 0.05422946 0.05650136 0.05422947 0.05151874 0.05395835
 0.05158067 0.05395833 0.05884342 0.05422946 0.05422946 0.0540821
 0.05422946 0.0541222 ]
tr_loss:[0.05211843 0.05211843 0.05824789 0.05514889 0.05198918 0.05514866
 0.05514865 0.05957895 0.05757502 0.05211843 0.05757502 0.05514865
 0.0582479  0.05211843 0.05211005 0.05211843 0.05514865 0.05619026
 0.05514865 0.05514865 0.05619037 0.05211843 0.05211829 0.05211843
 0.05211844 0.05211843 0.05387499 0.05211843 0.05434433 0.05211843
 0.05957895 0.05211843 0.05619039 0.0533203  0.05514865 0.05514865
 0.05190362 0.05192929 0.05434434 0.05824791 0.05187023 0.05198918
 0.05387499 0.05211843 0.0514912  0.05211843 0.05211843 0.05211935
 0.05211843 0.05669697]
tr_loss:[0.05288474 0.05109525 0.05109527 0.05969181 0.05109527 0.05688465
 0.05969181 0.05688467 0.05969181 0.05817246 0.05969181 0.05444508
 0.05969181 0.05109527 0.05536263 0.05531167 0.05688466 0.0510937
 0.05423648 0.05969181 0.05109522 0.05423647 0.05109527 0.05109527
 0.05478749 0.05120038 0.05109528 0.05109528 0.05109528 0.05421395
 0.05109527 0.05288474 0.05109527 0.05688465 0.05362404 0.05817247
 0.05817082 0.05287511 0.05109527 0.05109527 0.05288471 0.05288474
 0.05295338 0.05109527 0.05688467 0.05109527 0.05288474 0.05109527
 0.05109527 0.05109527]
tr_loss:[0.05836563 0.05836562 0.05376025 0.05109213 0.05733977 0.0575649
 0.05109214 0.06021912 0.05384327 0.06016161 0.05836563 0.05367417
 0.05367417 0.05109214 0.05109214 0.05109213 0.05115281 0.05109213
 0.05109214 0.05109213 0.05367417 0.05109213 0.0601616  0.0601616
 0.05109213 0.05109213 0.05836561 0.05836563 0.05836789 0.05836563
 0.05464638 0.05109213 0.05116364 0.05381716 0.05556861 0.05367417
 0.05377588 0.05464399 0.0601616  0.0601616  0.054644   0.05109214
 0.0575649  0.05865237 0.0535413  0.05109214 0.05836563 0.05384391
 0.05109213 0.05109213]
tr_loss:[0.05392627 0.05709527 0.05851319 0.0593282  0.05143275 0.06067268
 0.05143275 0.05851318 0.05851319 0.05850624 0.05411794 0.05143275
 0.05387277 0.05143275 0.05851317 0.05143275 0.05143275 0.05143275
 0.05797721 0.05143275 0.05143273 0.05143264 0.05143275 0.05383652
 0.05851318 0.05883218 0.05383674 0.05709521 0.0514368  0.05789337
 0.05897367 0.05143275 0.05143275 0.05143424 0.05392627 0.05883218
 0.05428667 0.05851318 0.05143275 0.05143275 0.05851319 0.05851319
 0.06067268 0.05143275 0.05143275 0.05358701 0.05143468 0.05143324
 0.05142247 0.05851319]
tr_loss:[0.05138087 0.06117661 0.05291541 0.056995   0.05138088 0.05298349
 0.05412974 0.05138087 0.05138088 0.05573536 0.05138088 0.05573537
 0.05699502 0.05138087 0.0515744  0.05138086 0.05138087 0.06117661
 0.05699502 0.05138087 0.05138087 0.05681575 0.05138087 0.05699502
 0.05298324 0.05699563 0.05765541 0.05699502 0.05138087 0.05292235
 0.05697427 0.06117661 0.06117661 0.05699503 0.05138087 0.05699503
 0.06117661 0.05138088 0.05836763 0.0525452  0.05836799 0.05573536
 0.05699501 0.05697423 0.05138087 0.05138087 0.05573538 0.05406003
 0.05699502 0.05729106]
tr_loss:[0.05126721 0.05126721 0.05496608 0.05126721 0.05126747 0.05126721
 0.05163988 0.06070948 0.05126721 0.05128109 0.05738219 0.05108255
 0.05126718 0.05126721 0.05346704 0.05126721 0.05738218 0.05475822
 0.05126284 0.05164108 0.05543146 0.05126721 0.05126733 0.05737427
 0.06070948 0.05484291 0.05126718 0.05126721 0.05128109 0.05543153
 0.06070948 0.05126721 0.05126721 0.05126721 0.06070948 0.05484338
 0.05126721 0.05126721 0.05346753 0.05126721 0.05484338 0.05466308
 0.05126721 0.05604756 0.05126722 0.05346716 0.05496597 0.05484338
 0.05126723 0.05127788]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4000 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4001, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4001 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4002, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4002 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4003, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4003 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4004, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4004 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4005, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4005 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4006, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4006 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4007, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4007 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4008, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4008 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4009, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4009 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4010, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4010 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4011, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4011 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4012, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4012 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4013, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4013 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4014, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4014 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4015, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4015 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4016, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4016 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4017, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4017 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4018, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4018 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4019, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4019 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4020, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4020 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4021, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4021 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4022, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4022 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4023, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4023 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4024, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4024 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4025, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4025 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4026, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4026 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4027, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4027 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4028, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4028 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4029, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4029 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4030, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4030 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4031, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4031 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4032, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4032 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4033, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4033 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4034, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4034 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4035, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4035 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4036, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4036 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4037, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4037 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4038, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4038 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4039, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4039 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4040, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4040 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4041, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4041 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4042, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4042 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4043, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4043 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4044, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4044 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4045, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4045 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4046, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4046 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4047, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4047 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4048, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4048 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4049, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4049 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4050, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4050 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4051, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4051 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4052, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4052 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4053, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4053 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4054, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4054 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4055, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4055 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4056, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4056 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4057, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4057 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4058, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4058 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4059, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4059 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4060, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4060 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4061, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4061 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4062, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4062 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4063, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4063 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4064, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4064 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4065, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4065 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4066, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4066 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4067, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4067 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4068, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4068 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4069, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4069 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4070, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4070 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4071, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4071 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4072, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4072 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4073, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4073 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4074, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4074 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4075, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4075 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4076, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4076 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4077, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4077 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4078, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4078 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4079, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4079 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4080, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4080 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4081, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4081 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4082, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4082 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4083, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4083 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4084, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4084 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4085, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4085 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4086, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4086 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4087, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4087 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4088, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4088 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4089, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4089 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4090, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4090 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4091, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4091 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4092, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4092 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4093, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4093 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4094, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4094 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4095, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4095 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4096, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4096 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4097, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4097 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4098, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4098 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4099, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4099 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4100, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-4000
text_input.shape
(4100, 14400)
learning_input_tmp.shape
(4100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4100, 80)
learning_output.shape
(750, 80)
Model: "sequential_83"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_83 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4346768 1.4600997 1.4363718 1.4494505 1.4363719 1.4347749 1.4347748
 1.4522278 1.4464995 1.4348037 1.4473435 1.4347749 1.4494587 1.4347749
 1.4465954 1.4429117 1.4347749 1.4363719 1.4361763 1.4347748 1.4472313
 1.4347749 1.4347749 1.4363717 1.4522299 1.4393742 1.3979583 1.4347748
 1.4598291 1.4455115 1.4347749 1.4206539 1.4347749 1.4522277 1.4347749
 1.4026355 1.4494587 1.4347749 1.4494588 1.4347726 1.4347749 1.4347749
 1.4363719 1.4347748 1.4347749 1.4347748 1.4393151 1.4601157 1.4522278
 1.4398501]
tr_loss:[0.8601432  0.86243474 0.84845227 0.8503197  0.83268195 0.8601184
 0.8484522  0.8601351  0.83890086 0.8484522  0.83268183 0.84995687
 0.8601351  0.832682   0.8601351  0.8484522  0.8484522  0.8718308
 0.8484522  0.84392893 0.83268195 0.8503641  0.8484522  0.859828
 0.87183094 0.87183094 0.83495414 0.8484522  0.8359749  0.8601351
 0.83495426 0.8484522  0.8484524  0.843929   0.8481089  0.8484503
 0.84845227 0.8561076  0.8528553  0.8484522  0.83268195 0.83790267
 0.8484522  0.8561079  0.8484521  0.8484522  0.8539464  0.832682
 0.85216665 0.83268195]
tr_loss:[0.48315954 0.4937485  0.49374843 0.48866445 0.49374914 0.4953824
 0.49044093 0.4937485  0.5130512  0.49374884 0.4937485  0.48558465
 0.48504153 0.5065603  0.4777585  0.4937485  0.48480636 0.5130868
 0.4937485  0.5065604  0.49374843 0.5065603  0.4937485  0.48887414
 0.4777587  0.49375066 0.48558465 0.49374866 0.4937485  0.510811
 0.49146995 0.49374852 0.4937485  0.48315954 0.4936576  0.4831853
 0.48632517 0.4937485  0.4777587  0.5065603  0.4937474  0.5065603
 0.4937485  0.49374837 0.4855846  0.5065633  0.4951315  0.5083018
 0.4937485  0.5065603 ]
tr_loss:[0.27469355 0.27469358 0.27469355 0.274692   0.27469358 0.2704977
 0.2929718  0.27049756 0.27854794 0.26755032 0.27469358 0.27469358
 0.27469355 0.27482706 0.2924439  0.27469358 0.26886177 0.27469358
 0.27854913 0.27469355 0.27854744 0.27471012 0.3024536  0.27469411
 0.29243898 0.2757131  0.27469358 0.26755035 0.27469358 0.27469358
 0.27469522 0.29390174 0.27469358 0.27469355 0.27571312 0.27146664
 0.27469355 0.28370777 0.27469608 0.27469358 0.2675504  0.27154693
 0.27571312 0.27469358 0.2715477  0.27469355 0.27096486 0.27469358
 0.28370777 0.27469364]
tr_loss:[0.10223399 0.10442774 0.09518268 0.10203733 0.09530495 0.09518267
 0.1038437  0.10203733 0.10111548 0.10397126 0.09799059 0.10147707
 0.09518267 0.10259204 0.1011311  0.10442762 0.09518268 0.10940132
 0.10937144 0.10384367 0.09972537 0.1025577  0.10442765 0.10937145
 0.10442764 0.10224328 0.10397162 0.10442762 0.10787799 0.09518275
 0.10203733 0.09518268 0.10203731 0.09518268 0.09518267 0.10442762
 0.10940127 0.09506389 0.10203733 0.09517451 0.10442765 0.09518266
 0.10442764 0.1094013  0.10442762 0.10787801 0.09518266 0.09518268
 0.09518266 0.09518269]
tr_loss:[0.03544745 0.03073473 0.03023692 0.02402605 0.03073474 0.03462759
 0.02402596 0.04344376 0.02402476 0.0350905  0.02402605 0.03544744
 0.03716884 0.03462759 0.03023691 0.02402604 0.02402605 0.03023691
 0.03342159 0.02402747 0.02836589 0.03023693 0.03023691 0.02402606
 0.03342126 0.03554603 0.02402607 0.02402605 0.03544744 0.02402606
 0.03073474 0.02402605 0.03389104 0.03023692 0.02402605 0.0392003
 0.03509056 0.03438635 0.03542804 0.02630697 0.03509049 0.03023691
 0.02402605 0.02402605 0.02402605 0.02402605 0.02434105 0.02402606
 0.02402606 0.03317583]
tr_loss:[0.00856739 0.00856794 0.02165    0.01198367 0.01601836 0.01400114
 0.00856735 0.01612417 0.00856739 0.01400739 0.0119837  0.00856737
 0.01601836 0.01978158 0.00856738 0.01666811 0.02636142 0.01506488
 0.01400739 0.01601836 0.0216499  0.01400739 0.00856738 0.01601836
 0.00856738 0.01400739 0.00856738 0.01667989 0.01667991 0.00856739
 0.00856738 0.00856738 0.01668854 0.00853875 0.00856738 0.01856179
 0.00854468 0.01601836 0.02164998 0.0263614  0.02161674 0.01400739
 0.00856738 0.00856738 0.0178187  0.01978158 0.0263614  0.00856738
 0.01856178 0.0185618 ]
tr_loss:[0.02151767 0.02193172 0.009313   0.009313   0.009313   0.009313
 0.01460523 0.00931298 0.01152265 0.009313   0.01722113 0.0219317
 0.00931339 0.00936557 0.02151767 0.0090431  0.01506532 0.009313
 0.01149695 0.009313   0.01305826 0.01309165 0.00931297 0.009313
 0.009313   0.009313   0.009313   0.00930161 0.009313   0.00833977
 0.009313   0.0219317  0.009313   0.01507631 0.01769708 0.01154776
 0.009313   0.02193171 0.02151767 0.00931754 0.01459657 0.01179183
 0.02151767 0.00931275 0.01460522 0.02193171 0.009313   0.01460459
 0.02151767 0.00943121]
tr_loss:[0.01433143 0.00873849 0.00873849 0.00996363 0.01433143 0.01234943
 0.01234943 0.00873849 0.00873849 0.01606107 0.00873849 0.00873849
 0.01262151 0.00873849 0.00873849 0.00950389 0.01476226 0.00828029
 0.00873849 0.01433143 0.01997058 0.00873849 0.00873849 0.00873849
 0.01101252 0.01476227 0.00873849 0.01672439 0.01476229 0.01476227
 0.00873847 0.00873849 0.00873849 0.00873849 0.01082118 0.00873848
 0.00873849 0.01232296 0.00828029 0.00873849 0.01876674 0.01433144
 0.00873849 0.00873849 0.01068072 0.01859406 0.01234875 0.00872465
 0.01438809 0.00873849]
tr_loss:[0.00525019 0.00525019 0.01687642 0.00771378 0.00487583 0.0108971
 0.0074985  0.00525019 0.00818786 0.00659526 0.01687642 0.00525019
 0.00818786 0.00899596 0.00525019 0.00487579 0.0055436  0.00524786
 0.00659526 0.00487579 0.00659526 0.00659526 0.01036402 0.00972344
 0.00524145 0.00525018 0.00525015 0.01035721 0.00525019 0.00525019
 0.00525019 0.00659526 0.01687643 0.01650601 0.00972344 0.01653019
 0.00525019 0.00818786 0.00818786 0.00525019 0.00818786 0.00525019
 0.00742785 0.01035722 0.01378084 0.00659526 0.01378084 0.00516322
 0.00972344 0.01089709]
tr_loss:[0.0125847  0.01177853 0.00782471 0.0084768  0.00511752 0.00353059
 0.01258471 0.00806171 0.00743101 0.00425972 0.0076182  0.00300027
 0.00397718 0.00397515 0.00782471 0.00397807 0.01258472 0.00397515
 0.01425691 0.00397515 0.0035306  0.00397515 0.01258471 0.0060262
 0.008874   0.00397515 0.01425689 0.0035306  0.00397515 0.00397514
 0.00782472 0.00397515 0.00397515 0.01185351 0.00397515 0.01425692
 0.00993717 0.0060262  0.00782472 0.00847681 0.008874   0.0142569
 0.00397524 0.00397915 0.00599523 0.00397515 0.0060262  0.00782472
 0.00993717 0.00805601]
tr_loss:[0.00911991 0.01256832 0.00911991 0.0125683  0.0064201  0.01256834
 0.00642116 0.0064201  0.0064201  0.0064201  0.00815045 0.00553737
 0.01190591 0.00642011 0.0064201  0.00998636 0.00673197 0.00911989
 0.00501725 0.00911991 0.00642011 0.00998635 0.0064201  0.0057729
 0.00815045 0.00852192 0.0064201  0.00647218 0.0064201  0.01190913
 0.00565018 0.0064201  0.00565018 0.00721381 0.00846363 0.01346748
 0.00911991 0.0064201  0.01256832 0.01256832 0.01346755 0.01256832
 0.00942412 0.0064201  0.00911991 0.00911989 0.00852189 0.0064201
 0.00897972 0.00895725]
tr_loss:[0.01098236 0.0091335  0.01029192 0.01816254 0.00932308 0.00695233
 0.00669609 0.0091335  0.00857794 0.00913351 0.00695234 0.01425267
 0.01441166 0.01806927 0.00857795 0.01029192 0.00910683 0.0091335
 0.00913351 0.00913342 0.0091326  0.01441094 0.00913351 0.00913351
 0.0180695  0.00913351 0.0087543  0.0091335  0.01441094 0.0180695
 0.0091335  0.0091335  0.00986802 0.01047694 0.00913351 0.01099202
 0.00914045 0.00913351 0.01441094 0.0091335  0.00913351 0.00914077
 0.010978   0.00913351 0.00913351 0.01029191 0.01436675 0.00857794
 0.00913348 0.0091335 ]
tr_loss:[0.01241753 0.00719506 0.00549331 0.00781791 0.00549328 0.00781794
 0.00781794 0.00806374 0.00781794 0.00781794 0.00781794 0.00797864
 0.00549317 0.00781794 0.00781794 0.00781839 0.00684926 0.00719505
 0.00584645 0.00781794 0.01470063 0.01253177 0.00713983 0.00781794
 0.00781794 0.00797864 0.00549331 0.0054933  0.00781794 0.00781795
 0.00781794 0.00781794 0.00681134 0.01470065 0.0078179  0.00781794
 0.00702657 0.00781809 0.00797864 0.00713983 0.00651593 0.00781115
 0.01470065 0.00797864 0.0054933  0.00781794 0.00781794 0.00781794
 0.00781794 0.00781794]
tr_loss:[0.00968892 0.00408466 0.00485272 0.00507099 0.0040456  0.00485272
 0.00485274 0.00602294 0.00144559 0.01072379 0.00485272 0.00485272
 0.00485272 0.00252624 0.00403041 0.00507099 0.0096892  0.00968921
 0.00485271 0.00602294 0.00485272 0.00725969 0.00485272 0.00458841
 0.01205379 0.00314182 0.00485272 0.00763196 0.00485272 0.01205379
 0.00486205 0.00485272 0.00558863 0.00457951 0.00485272 0.00507099
 0.004038   0.00485272 0.00507096 0.00878864 0.00968914 0.00485272
 0.00485272 0.0040456  0.00484763 0.00485272 0.00763195 0.00270741
 0.00602372 0.004038  ]
tr_loss:[0.00521963 0.00389875 0.00651478 0.00389875 0.00389875 0.00521963
 0.00645456 0.00495279 0.00389875 0.00609667 0.00389875 0.00389875
 0.00389875 0.00376696 0.00389875 0.0039618  0.0033338  0.00389875
 0.00759352 0.00389875 0.00759352 0.00953787 0.00389875 0.00645541
 0.00651478 0.0115448  0.01017262 0.00389875 0.00389875 0.00389875
 0.00389875 0.00495281 0.00938047 0.00389875 0.00389875 0.00673513
 0.00376697 0.00521963 0.00389875 0.00390165 0.00389875 0.00389875
 0.00645541 0.00389875 0.00432809 0.00389875 0.00645541 0.00645541
 0.00389875 0.00389875]
tr_loss:[0.00433191 0.0093377  0.00679146 0.01212806 0.01060628 0.00433185
 0.00433179 0.00433185 0.00728058 0.00728059 0.00679146 0.00679146
 0.01060628 0.01558367 0.01583016 0.00742712 0.00388154 0.00679146
 0.0093377  0.0093377  0.00742402 0.00433208 0.0093377  0.01583013
 0.00433185 0.00679146 0.00960114 0.00433185 0.00933765 0.00721783
 0.00688964 0.00474989 0.00433185 0.00433097 0.00679146 0.01583012
 0.00433185 0.00433185 0.01060628 0.00433185 0.00433185 0.00679146
 0.00955895 0.00955403 0.0047517  0.00433185 0.01210406 0.01583014
 0.00433185 0.01271387]
tr_loss:[0.00474578 0.00474578 0.00828176 0.00474578 0.00474578 0.00474363
 0.00474578 0.00474578 0.00476253 0.00474578 0.00474578 0.01555098
 0.00474579 0.00432719 0.01060868 0.00474578 0.00474592 0.00828176
 0.01658686 0.01759515 0.00474578 0.00474578 0.01088847 0.0068182
 0.00474578 0.0141023  0.00681819 0.01644515 0.01088846 0.00869728
 0.00474563 0.00474578 0.00474578 0.01418823 0.00474578 0.01418837
 0.00474578 0.01190832 0.00681819 0.00474578 0.00681819 0.00474578
 0.00474578 0.00474578 0.00472504 0.00474578 0.00474578 0.01060868
 0.01759515 0.00681819]
tr_loss:[0.00420012 0.01021574 0.012996   0.0117712  0.01021576 0.00785128
 0.01686779 0.00419613 0.01180269 0.00529133 0.01313158 0.01686779
 0.00419613 0.00376482 0.0168678  0.01177121 0.01299598 0.00784832
 0.01036648 0.00419613 0.01686778 0.00419613 0.00784831 0.00419613
 0.00529133 0.01036648 0.00419613 0.00784831 0.00700116 0.00420688
 0.0080621  0.00419613 0.00516171 0.00419613 0.00419613 0.00529133
 0.00419613 0.00700114 0.01177121 0.01340769 0.00419613 0.01036561
 0.00419613 0.00419613 0.00765175 0.00419613 0.00700115 0.00419613
 0.01036648 0.00419613]
tr_loss:[0.01099653 0.00847633 0.00343628 0.01393235 0.01417517 0.00343629
 0.00343628 0.00343628 0.00343628 0.00343628 0.00802893 0.00343628
 0.00343629 0.00343628 0.00880243 0.01417516 0.00441029 0.01393236
 0.00343628 0.00599399 0.01393235 0.00599345 0.00602827 0.00343628
 0.00343628 0.01178456 0.005994   0.01393233 0.0034363  0.00343606
 0.0029445  0.00343628 0.00343628 0.00343628 0.01417518 0.01176916
 0.00343628 0.005994   0.00985098 0.0029445  0.00626326 0.00343628
 0.00800742 0.00802894 0.01099653 0.00985097 0.01393234 0.00343628
 0.00343628 0.00600393]
tr_loss:[0.00325939 0.0073169  0.00993089 0.0060977  0.00261152 0.00351393
 0.00325938 0.00325939 0.00731689 0.00325953 0.00325939 0.00817191
 0.00325939 0.00325939 0.00598779 0.00325939 0.00416027 0.00325939
 0.003518   0.0032592  0.00325939 0.0060977  0.0060977  0.00596251
 0.00817187 0.00817191 0.01227519 0.00325939 0.00817191 0.01227519
 0.00408899 0.0073169  0.00325939 0.00325939 0.00325939 0.00325938
 0.00325939 0.00351833 0.00504196 0.00325939 0.01227519 0.00419232
 0.00325939 0.00504249 0.0060977  0.00325939 0.00261152 0.00807526
 0.00598779 0.00408869]
tr_loss:[0.00711687 0.00481459 0.00481475 0.00400857 0.00481475 0.0106048
 0.00481474 0.00481803 0.00828611 0.00745797 0.00828609 0.00828611
 0.00536516 0.00481475 0.00544438 0.00481554 0.00400858 0.00607189
 0.00400857 0.00400857 0.00481475 0.00745795 0.00469647 0.01198155
 0.00468177 0.00607189 0.00481475 0.00481474 0.00536515 0.00481475
 0.00481474 0.00607189 0.00400857 0.00271824 0.00481473 0.00398372
 0.00398641 0.00482133 0.00481474 0.00745797 0.004816   0.00511413
 0.00481475 0.00481474 0.00711685 0.00481428 0.00745797 0.00490981
 0.00557659 0.0082861 ]
tr_loss:[0.0063467  0.00634417 0.00570672 0.00708982 0.00634416 0.00708982
 0.00634416 0.00595088 0.00457849 0.00544582 0.00919493 0.00634416
 0.01264091 0.00476563 0.00595683 0.00774081 0.00476563 0.00634416
 0.00421224 0.00649738 0.00919493 0.00708982 0.00601494 0.00634417
 0.00632319 0.01037704 0.00774081 0.00649738 0.00634416 0.00919493
 0.00919493 0.00586739 0.00634416 0.00649738 0.00433938 0.00634417
 0.00919493 0.00634416 0.00634417 0.00570672 0.00634416 0.00634419
 0.00708982 0.00296519 0.00634416 0.01264427 0.00441423 0.00634416
 0.00634417 0.00919493]
tr_loss:[0.00685517 0.00487402 0.00603067 0.00422845 0.00603068 0.01276155
 0.00639066 0.00685517 0.00603068 0.00751198 0.00603053 0.00685517
 0.00835365 0.00603068 0.00751198 0.00600195 0.00869082 0.00659235
 0.00633879 0.00486066 0.00603067 0.01276158 0.00317819 0.00603067
 0.00835365 0.00603067 0.00603068 0.00487402 0.00751197 0.00632497
 0.00751198 0.00519791 0.00981296 0.0060192  0.00603068 0.00519762
 0.0066681  0.00603067 0.00487402 0.00603067 0.00603068 0.00751198
 0.00697674 0.00603068 0.00603067 0.00603068 0.00487402 0.00603067
 0.00597738 0.00751197]
tr_loss:[0.00724677 0.00421425 0.00669758 0.0042146  0.00384443 0.00669822
 0.0092396  0.00669915 0.00580168 0.00421461 0.00669596 0.01047699
 0.00649773 0.0042156  0.0042146  0.00636899 0.0042146  0.0042146
 0.00420431 0.00649773 0.0104492  0.00421433 0.0103335  0.0042146
 0.00414755 0.00669758 0.00421665 0.00734587 0.0042146  0.0092396
 0.00414755 0.00494362 0.00486384 0.00659059 0.00636899 0.00414424
 0.00816931 0.01044923 0.00344492 0.00816929 0.00734924 0.00667652
 0.00421831 0.0042146  0.0042146  0.00414755 0.0042146  0.0042146
 0.0042146  0.00354535]
tr_loss:[0.00239896 0.00939636 0.00308221 0.00469378 0.00469378 0.00346602
 0.00402275 0.00321464 0.00936101 0.00243571 0.00627355 0.00308229
 0.00308229 0.00755597 0.00402275 0.00243574 0.00308229 0.00643841
 0.00308228 0.00308229 0.0030823  0.00308229 0.00627355 0.01036921
 0.00643841 0.00936102 0.00402275 0.00308229 0.00243574 0.00816375
 0.0030831  0.00308229 0.00316103 0.00308229 0.00755597 0.00755597
 0.00308229 0.00243574 0.01015963 0.00643841 0.00936103 0.00308229
 0.00610966 0.00835129 0.00308229 0.00835129 0.01200284 0.00308229
 0.00308229 0.01036368]
tr_loss:[0.0107408  0.01074078 0.00759092 0.0044327  0.01275649 0.00312142
 0.00648116 0.00312143 0.00312143 0.00312142 0.01051771 0.00328913
 0.00312143 0.002553   0.00328922 0.00312143 0.005333   0.00885748
 0.00312143 0.00759092 0.01074078 0.00674501 0.00310489 0.00375965
 0.01275702 0.00644186 0.0107408  0.00312142 0.01074079 0.00533299
 0.00644186 0.00312143 0.00648014 0.00759092 0.00759092 0.00648116
 0.01074079 0.00312142 0.00312142 0.00255301 0.00460201 0.00339124
 0.00371629 0.00312143 0.00312143 0.00759096 0.00942967 0.00312143
 0.00312142 0.01275701]
tr_loss:[0.00408645 0.00408645 0.00541942 0.00486993 0.00408646 0.00409531
 0.00408644 0.01170733 0.00408645 0.00350677 0.00541941 0.00429478
 0.01170733 0.00403533 0.00541941 0.0035166  0.00664927 0.00408645
 0.00403533 0.00443347 0.00408645 0.00524942 0.00408675 0.00406079
 0.0055     0.00408645 0.0035166  0.00408645 0.00408645 0.00408645
 0.0035166  0.00408645 0.01170734 0.00541941 0.00408641 0.00363806
 0.00703649 0.00365092 0.00408645 0.00408645 0.01174913 0.00408645
 0.00443378 0.00953126 0.00541941 0.0035166  0.00408644 0.00771815
 0.00771773 0.00550005]
tr_loss:[0.00363798 0.01037314 0.00416016 0.00450734 0.00419301 0.00363799
 0.004146   0.00975845 0.00414968 0.01392139 0.00419302 0.01186906
 0.01186537 0.01186907 0.00671645 0.00563128 0.00492847 0.00419302
 0.01186908 0.01392133 0.00419302 0.00975128 0.00419302 0.00407275
 0.00669284 0.00419302 0.00720975 0.00419302 0.00419306 0.01392139
 0.00690636 0.00407275 0.00419303 0.00231314 0.00419302 0.00419302
 0.00419302 0.00419302 0.00566158 0.00498332 0.00419295 0.00773633
 0.00690675 0.0041931  0.00419302 0.00363798 0.00419302 0.0041929
 0.00419302 0.00671645]
tr_loss:[0.00467844 0.00318957 0.00613725 0.00613725 0.00613725 0.00756402
 0.00613725 0.00318957 0.00350811 0.00318957 0.0088372  0.00318957
 0.00645927 0.00467844 0.00613725 0.00318957 0.00645927 0.01283971
 0.00993797 0.00318955 0.00318957 0.00318957 0.00318957 0.00883721
 0.00318957 0.00318957 0.00756403 0.00613725 0.00756403 0.00318932
 0.00645927 0.00318957 0.01283971 0.01025805 0.0107771  0.00318957
 0.00436482 0.00645927 0.00883692 0.01077708 0.00520396 0.00318957
 0.00318957 0.00318957 0.00261994 0.00318957 0.00613725 0.00318957
 0.00467844 0.00318957]
text_input.shape
(4100, 14400)
learning_input_tmp.shape
(4100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4100, 80)
learning_output.shape
(750, 80)
Model: "sequential_84"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_84 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3615074 1.3615074 1.3615074 1.3582668 1.3615074 1.3615074 1.3615074
 1.3574231 1.3423322 1.3615074 1.3615074 1.3615074 1.3547504 1.3615073
 1.342599  1.3425994 1.3615437 1.3615074 1.3547504 1.3615074 1.3615073
 1.342754  1.3415979 1.3615074 1.3615073 1.3402946 1.3547504 1.3547504
 1.36587   1.3615074 1.3615074 1.3415968 1.3615074 1.3425432 1.3574231
 1.3615077 1.361507  1.3425989 1.3615074 1.3658702 1.3444736 1.3425938
 1.3399365 1.3346325 1.3547504 1.3547504 1.3615091 1.347595  1.3283981
 1.3283981]
tr_loss:[0.8296795  0.81100065 0.8266989  0.8095144  0.8156244  0.8160265
 0.82968247 0.82632625 0.82968205 0.81100047 0.80774766 0.8075043
 0.8268735  0.8266991  0.82670134 0.8203875  0.8125494  0.8110005
 0.82669896 0.81749743 0.8266988  0.80800045 0.8199828  0.80173653
 0.82968205 0.8160264  0.8266989  0.8175138  0.80790406 0.8266989
 0.8213174  0.8266989  0.80173653 0.8266989  0.8188489  0.8095034
 0.82369864 0.81562454 0.81751406 0.8266989  0.82669985 0.8266548
 0.8266989  0.82665634 0.81579334 0.81100047 0.8266991  0.8266989
 0.8266988  0.8266988 ]
tr_loss:[0.40800485 0.38894027 0.38776988 0.3966539  0.3968119  0.40053844
 0.37555265 0.409622   0.3880568  0.40053836 0.40023166 0.40800476
 0.37478873 0.40053836 0.3880568  0.37479192 0.39665383 0.40053836
 0.40045372 0.40052128 0.3888794  0.40053836 0.39710027 0.37472573
 0.39733413 0.38751784 0.4080077  0.40386885 0.40053803 0.40058622
 0.400527   0.37479186 0.40053838 0.40053838 0.39464182 0.39665383
 0.39996538 0.39989382 0.38895875 0.40053838 0.40062723 0.40800625
 0.37479192 0.38776985 0.39665383 0.38776988 0.40053836 0.39691392
 0.40053836 0.40049163]
tr_loss:[0.20665164 0.24256358 0.2390767  0.23712358 0.22454605 0.22122249
 0.20665164 0.2245492  0.23123312 0.22454605 0.22764096 0.22123408
 0.22206864 0.22764102 0.2390767  0.20665161 0.22722235 0.22454607
 0.2245461  0.22454607 0.22454607 0.22454605 0.2245461  0.22454607
 0.23123312 0.23099458 0.23907666 0.22250323 0.22754511 0.2245461
 0.224546   0.20665164 0.22690468 0.22454607 0.227554   0.23717609
 0.2269047  0.2263633  0.2245461  0.23907547 0.23099455 0.23099455
 0.23907673 0.23123312 0.22454605 0.22759442 0.22454877 0.22245936
 0.2245461  0.22454605]
tr_loss:[0.09116695 0.09737419 0.10552766 0.09737419 0.09737419 0.09737419
 0.08451179 0.10336361 0.0973742  0.09753329 0.0973742  0.09986645
 0.1012312  0.08451179 0.1007607  0.11776105 0.10123123 0.09738574
 0.10523162 0.11294504 0.09737422 0.08451179 0.09572037 0.0973742
 0.0973742  0.0973742  0.09737421 0.0973742  0.0973685  0.10470633
 0.10542972 0.10336362 0.0973742  0.09737231 0.09781547 0.10523238
 0.09699907 0.10523129 0.10336362 0.09902622 0.0973742  0.09902622
 0.11294501 0.09737422 0.11116793 0.09737327 0.10542965 0.09737421
 0.11294508 0.09737419]
tr_loss:[0.04918462 0.03722995 0.05441622 0.04492084 0.04499635 0.0455335
 0.02633417 0.05260643 0.03722995 0.04499604 0.04553349 0.04404046
 0.05260645 0.04492084 0.04578494 0.03992564 0.03780862 0.03722993
 0.03706616 0.03457515 0.03722994 0.04404046 0.04304432 0.05435381
 0.03722994 0.03722994 0.04492083 0.02633417 0.03722994 0.03723141
 0.03718877 0.03780862 0.05260644 0.03722995 0.02650973 0.03722995
 0.03722995 0.0365736  0.02633417 0.02633376 0.04131059 0.02633417
 0.04131088 0.05245959 0.03780861 0.03694891 0.05260642 0.03722995
 0.05260645 0.04492082]
tr_loss:[0.02467756 0.02267083 0.02289494 0.01679316 0.02281738 0.01679316
 0.02913121 0.02408687 0.02898963 0.01679316 0.01679312 0.01679059
 0.01679316 0.01679316 0.02122743 0.01679316 0.01701925 0.00842087
 0.02849512 0.01679728 0.02289494 0.01679316 0.02913122 0.01679316
 0.01679316 0.02913123 0.02281739 0.02913121 0.01679316 0.01679316
 0.02122743 0.01679352 0.01679324 0.01679316 0.01679315 0.01679316
 0.02684968 0.02289494 0.01679316 0.02406088 0.02467754 0.02898964
 0.0291312  0.00842088 0.01749249 0.0291312  0.0228101  0.0291312
 0.02281739 0.01679316]
tr_loss:[0.01320364 0.01574584 0.01668587 0.01039072 0.01999463 0.01046047
 0.01946338 0.01046039 0.020563   0.01064321 0.01999464 0.01946338
 0.01046039 0.01046038 0.01599215 0.01055428 0.01674365 0.01668586
 0.01046039 0.0168269  0.02056302 0.01064321 0.01046039 0.01046039
 0.01668586 0.01320364 0.01999466 0.01046039 0.01046039 0.01064434
 0.01668587 0.01668586 0.01668408 0.01599076 0.01320364 0.01162618
 0.01046039 0.01046039 0.01999464 0.01046039 0.01035038 0.01999465
 0.01046039 0.01668567 0.01046039 0.01320364 0.01046039 0.01046039
 0.01046038 0.01027477]
tr_loss:[0.029891   0.03796402 0.01429693 0.0142969  0.02097807 0.02498457
 0.02736517 0.02374903 0.01429691 0.0142969  0.02736517 0.01357016
 0.03796402 0.01429691 0.0253291  0.02498458 0.02106569 0.0142969
 0.0237033  0.01429691 0.03796436 0.01429687 0.01429692 0.02106569
 0.01429691 0.01691533 0.01691533 0.01429691 0.02998841 0.01429691
 0.02998831 0.02736517 0.02061627 0.02736517 0.01357014 0.01429691
 0.02498414 0.02532911 0.01429691 0.03796401 0.0142969  0.0253291
 0.01429691 0.01429691 0.01429393 0.0299884  0.02998181 0.01429691
 0.0142969  0.01429685]
tr_loss:[0.0121603  0.02204759 0.02512999 0.0121603  0.02357597 0.0121603
 0.0121603  0.02795296 0.01216029 0.01216029 0.01648654 0.02777563
 0.01216031 0.0121603  0.0121603  0.01158174 0.02357604 0.0121603
 0.01215663 0.03586469 0.0121603  0.02777561 0.03586469 0.0121603
 0.02661795 0.01954437 0.02512999 0.0121603  0.0251294  0.03586469
 0.02656481 0.01648654 0.0277756  0.01216029 0.0121603  0.01216029
 0.02046003 0.02673874 0.01216029 0.01648654 0.0121603  0.02777562
 0.01968192 0.0121603  0.01158174 0.0115817  0.01954561 0.02061293
 0.01380524 0.02357598]
tr_loss:[0.01909006 0.00754279 0.01799234 0.00754279 0.00754279 0.00754279
 0.0124987  0.00754423 0.00754279 0.01909007 0.00754279 0.00740175
 0.00754279 0.0124987  0.007406   0.00754207 0.01909007 0.02398931
 0.00754279 0.01947771 0.01404121 0.01112599 0.01467181 0.01909007
 0.00754279 0.0239893  0.0124987  0.00754279 0.02398931 0.01997879
 0.01112667 0.02398931 0.00754279 0.01909008 0.01909007 0.0207605
 0.00754279 0.01976095 0.00754279 0.01662765 0.01875565 0.00754279
 0.02076862 0.0239893  0.00754293 0.01997881 0.00740175 0.01947772
 0.00754279 0.00742429]
tr_loss:[0.01101471 0.01535044 0.01813251 0.01055303 0.00932839 0.01940248
 0.01813274 0.01101472 0.01101472 0.0080461  0.0177881  0.01101472
 0.01101471 0.01101472 0.01101472 0.01101472 0.01101471 0.01101472
 0.01101472 0.01879883 0.02251453 0.01108133 0.01535044 0.01940808
 0.01879885 0.01101472 0.01813274 0.00932837 0.02445994 0.01879863
 0.02241898 0.02214786 0.01101473 0.01101472 0.01101471 0.01101472
 0.01101472 0.01535044 0.01101472 0.02445995 0.01101472 0.0110147
 0.01108143 0.01101472 0.02214787 0.01813274 0.01813274 0.01813274
 0.01813274 0.01865706]
tr_loss:[0.01469377 0.01554208 0.01390486 0.02163934 0.01070211 0.02547999
 0.01505562 0.01070402 0.01504705 0.01504708 0.01504706 0.01504705
 0.0150468  0.00709128 0.01504706 0.01504706 0.01487803 0.01504697
 0.02127296 0.01504705 0.02163935 0.015047   0.02164365 0.02473139
 0.01504706 0.00709128 0.01504706 0.019083   0.01400556 0.02473139
 0.0205167  0.00709128 0.0107022  0.01504706 0.01390601 0.019083
 0.00709128 0.01504706 0.01504705 0.01504706 0.01487801 0.019083
 0.01504705 0.01504705 0.02144989 0.0247314  0.01990439 0.01504706
 0.01504706 0.01943933]
tr_loss:[0.01959007 0.01951708 0.02531045 0.02009352 0.01959007 0.01452812
 0.01452797 0.02531045 0.01959007 0.01804037 0.01452812 0.02500081
 0.01452812 0.01937094 0.02500083 0.01405935 0.02500082 0.02138851
 0.0105951  0.0145281  0.01438677 0.01451194 0.02199804 0.02138629
 0.01452812 0.01509089 0.01452145 0.01452813 0.01804099 0.01452812
 0.02051882 0.00674503 0.01452812 0.01804101 0.01452812 0.01438677
 0.01452812 0.01804099 0.01452813 0.02494953 0.0200211  0.02164201
 0.00674502 0.01804101 0.00674503 0.02494953 0.01452812 0.01452812
 0.01452812 0.01438677]
tr_loss:[0.01703897 0.01018385 0.02013461 0.02393155 0.01241651 0.02013462
 0.02630843 0.01197528 0.02442977 0.01237238 0.01704731 0.02013461
 0.0170473  0.01916473 0.01237238 0.02062117 0.02381038 0.01237238
 0.01237238 0.02630844 0.01237238 0.01237238 0.01237239 0.0198695
 0.01237238 0.02075578 0.01237238 0.01237516 0.01237238 0.0073439
 0.01237238 0.0073439  0.01237264 0.01373717 0.01237221 0.02380333
 0.0124138  0.01701615 0.00734391 0.01237245 0.02381004 0.02075579
 0.0073439  0.01237288 0.0073439  0.01237239 0.01237237 0.0073439
 0.01237238 0.01237239]
tr_loss:[0.02550136 0.0193595  0.01381478 0.01859693 0.01260609 0.01859693
 0.01514272 0.01014626 0.01014601 0.01014601 0.01014601 0.01014601
 0.01014601 0.01014601 0.01014601 0.0225319  0.02550133 0.01014229
 0.01032615 0.01514272 0.00975906 0.01859693 0.01014601 0.00924347
 0.02550136 0.0156888  0.00924347 0.01014601 0.01014601 0.00924348
 0.02164485 0.01951311 0.02164453 0.01933951 0.00924347 0.01014601
 0.01261573 0.00924347 0.01859693 0.02164485 0.01014601 0.02550135
 0.01014601 0.01805225 0.01014586 0.01014601 0.01022404 0.01933949
 0.02253194 0.01617065]
tr_loss:[0.01753192 0.00733072 0.01823943 0.01753191 0.00733072 0.01815381
 0.01774098 0.02107904 0.00733072 0.01146327 0.0167576  0.00733073
 0.00733072 0.00733072 0.01815382 0.00733072 0.00732573 0.00721647
 0.0167576  0.01515978 0.0183444  0.01146327 0.00733081 0.00733072
 0.00733073 0.0182488  0.00962104 0.00733072 0.0167576  0.01824879
 0.00733777 0.00936368 0.00733073 0.01774723 0.01824741 0.0182488
 0.00936371 0.00733072 0.00733072 0.01818847 0.00733118 0.00721647
 0.02107903 0.00733072 0.00733072 0.01146327 0.02107901 0.00733072
 0.01511218 0.0181957 ]
tr_loss:[0.01387586 0.02119644 0.00996977 0.02122845 0.01713577 0.02568221
 0.02119642 0.00996965 0.00996973 0.01988064 0.01302116 0.02568221
 0.00996973 0.02063196 0.01303943 0.01303943 0.01387585 0.01871909
 0.02169633 0.00996975 0.01988064 0.00996974 0.02010307 0.01387612
 0.02119642 0.00996975 0.02063196 0.00996973 0.01887924 0.00996973
 0.00996973 0.02169632 0.00996974 0.00927266 0.0211964  0.02568221
 0.00996973 0.00927203 0.0099697  0.02169633 0.00996973 0.01303943
 0.00996973 0.00992789 0.02169633 0.02063194 0.01988064 0.01986427
 0.01887968 0.00927278]
tr_loss:[0.01020491 0.01020473 0.01020612 0.01787165 0.01020479 0.02541222
 0.02153678 0.01310273 0.02541223 0.01020479 0.01020479 0.02153678
 0.01981783 0.01020479 0.01020479 0.01020479 0.01020479 0.02340099
 0.02541222 0.02087928 0.02201418 0.02025277 0.02541224 0.01020479
 0.01020479 0.02087926 0.01020479 0.02153678 0.02153678 0.00947585
 0.01310273 0.01020479 0.02541222 0.02340071 0.02541222 0.01020479
 0.01020479 0.01081279 0.01383398 0.01020479 0.01020479 0.01020479
 0.01025826 0.01020479 0.01021891 0.01029866 0.01020479 0.00947585
 0.02340108 0.02541221]
tr_loss:[0.0113146  0.00737597 0.00733287 0.00737717 0.00744059 0.00737718
 0.00741318 0.02054375 0.01841927 0.00737717 0.02054375 0.01131462
 0.00815286 0.0168901  0.01839139 0.00737717 0.01637641 0.0168901
 0.00737717 0.0180895  0.0153443  0.01689009 0.02054375 0.01841926
 0.02054372 0.01637641 0.01808953 0.00737717 0.01839298 0.01744579
 0.00737717 0.00737717 0.02054374 0.01808953 0.01637641 0.00737717
 0.0161358  0.00737718 0.01637641 0.01131462 0.00737717 0.00737717
 0.01839296 0.01765801 0.00737717 0.01131462 0.01667114 0.0168901
 0.02054374 0.01131462]
tr_loss:[0.02324121 0.01736003 0.00885972 0.00885975 0.00901848 0.01847021
 0.00885975 0.00885975 0.00885976 0.00885975 0.01806973 0.00885975
 0.00885975 0.00885975 0.0173204  0.00885975 0.01733745 0.02052075
 0.02324121 0.01013246 0.01013246 0.01013246 0.00885976 0.01676488
 0.00885975 0.00885975 0.00885975 0.01733745 0.01673865 0.00885976
 0.01346697 0.01835438 0.02052346 0.01013248 0.00885976 0.00885558
 0.00901848 0.00885155 0.01733745 0.02324121 0.01013246 0.00885975
 0.00885975 0.00885976 0.00901849 0.00885977 0.00901849 0.01020494
 0.00885975 0.01835439]
tr_loss:[0.0082762  0.01045083 0.00941289 0.01923985 0.00827627 0.01863481
 0.01800101 0.01800101 0.01045083 0.0175991  0.00940578 0.01045083
 0.01045083 0.01876777 0.01863481 0.00827628 0.01045083 0.02414155
 0.01800101 0.01045084 0.01045083 0.02160872 0.01868077 0.01045083
 0.0149718  0.01678484 0.01045083 0.01045083 0.01045083 0.01759908
 0.02160872 0.0149718  0.01059766 0.02209277 0.01045083 0.01045083
 0.01045083 0.01059904 0.02414156 0.0103989  0.01045083 0.0146198
 0.01045083 0.01868077 0.01045083 0.0149718  0.01045083 0.01045083
 0.01045084 0.01045083]
tr_loss:[0.01466187 0.01726748 0.01240139 0.01094804 0.02228333 0.01096055
 0.00771423 0.01094804 0.01094804 0.01707784 0.01094804 0.01757122
 0.01094804 0.01094804 0.011196   0.01726748 0.01094804 0.01757122
 0.01098527 0.01094804 0.01094804 0.01757122 0.0124764  0.02228332
 0.01098527 0.01094804 0.01093305 0.02228335 0.01398775 0.01094804
 0.01465433 0.01757122 0.01094804 0.02228335 0.01582146 0.0109482
 0.00771478 0.02228334 0.01094804 0.01094806 0.01094804 0.01094804
 0.01094804 0.0214083  0.01844713 0.01757098 0.01757122 0.01094804
 0.010948   0.00771423]
tr_loss:[0.01072367 0.00877267 0.01987328 0.0099085  0.02075773 0.01071981
 0.01072013 0.01060433 0.01995743 0.01072014 0.00888471 0.01072014
 0.01995746 0.01072014 0.01072018 0.01071996 0.01072014 0.01072014
 0.01861414 0.01072016 0.01072019 0.01359889 0.01072013 0.0106107
 0.01359833 0.01995743 0.01113608 0.02075844 0.01063709 0.01072014
 0.01051561 0.01072013 0.01620524 0.01860955 0.01744491 0.01072014
 0.01072014 0.01995745 0.01072014 0.00888471 0.01072013 0.01987327
 0.01987327 0.01987327 0.01072011 0.01548234 0.01072014 0.01072014
 0.01861111 0.01036465]
tr_loss:[0.00850761 0.00850761 0.01769933 0.00850761 0.01871793 0.01577767
 0.01157304 0.00850762 0.01657951 0.01865664 0.01606337 0.00850761
 0.00850761 0.00831393 0.01871793 0.00850761 0.00850761 0.00859041
 0.0153194  0.00859005 0.01563982 0.01775226 0.01871791 0.01552957
 0.01577767 0.01217165 0.01646759 0.01775227 0.00850763 0.01553208
 0.00850761 0.01522209 0.01790193 0.01871793 0.01871793 0.01135092
 0.0164112  0.01522204 0.00850761 0.00851957 0.01790175 0.00863947
 0.01523747 0.01871792 0.00836704 0.01157304 0.01658332 0.01959338
 0.01657948 0.00850761]
tr_loss:[0.00767021 0.01747638 0.00768704 0.00766994 0.01720857 0.00766994
 0.00766994 0.00766994 0.01138576 0.02004948 0.00766993 0.01138576
 0.00766994 0.01450788 0.01138576 0.01722674 0.0200495  0.01747638
 0.00766994 0.01720853 0.01319982 0.00767071 0.00733895 0.01747638
 0.01749818 0.00766994 0.01767599 0.00766993 0.00767052 0.01138576
 0.01828205 0.01138576 0.01767601 0.01794396 0.01871895 0.00766994
 0.0200495  0.00766994 0.00766994 0.01871895 0.02004949 0.01138576
 0.01618799 0.0076699  0.01024936 0.01794396 0.01828204 0.00766994
 0.00731245 0.00766994]
tr_loss:[0.01991852 0.01861067 0.0077917  0.0077917  0.0077917  0.01593207
 0.0074377  0.01736401 0.0077917  0.01477947 0.0077917  0.0077917
 0.0077917  0.02005112 0.020026   0.0077917  0.0077917  0.0077917
 0.0077917  0.0077917  0.01860701 0.01880752 0.01478714 0.01880754
 0.01594684 0.00895276 0.0077917  0.01736772 0.00779636 0.02048532
 0.02004949 0.01619687 0.0077911  0.02197501 0.0077917  0.021975
 0.02048531 0.02048532 0.0077917  0.01618914 0.00779172 0.0077917
 0.01157237 0.01991853 0.01477872 0.0147787  0.01991853 0.01880752
 0.01860898 0.0074377 ]
tr_loss:[0.0073817  0.00738034 0.00738034 0.01689561 0.00738034 0.00738034
 0.01391813 0.00738034 0.00738034 0.01858934 0.00721074 0.00738034
 0.00738034 0.00738034 0.01689561 0.00751942 0.01555001 0.01191282
 0.02198745 0.00738034 0.01595362 0.0185891  0.00738034 0.00737027
 0.01937272 0.01689562 0.00738034 0.01391813 0.00738034 0.00727545
 0.00738034 0.01865297 0.01391813 0.01048887 0.01689561 0.00737865
 0.01689561 0.01191282 0.00738034 0.01048885 0.01865087 0.01557301
 0.00738034 0.00738034 0.02198743 0.01689561 0.00738034 0.00721074
 0.01785765 0.0193727 ]
tr_loss:[0.0124017  0.01839505 0.01791828 0.01862874 0.01202318 0.01146791
 0.01774619 0.011922   0.01774619 0.01586289 0.00768951 0.01202377
 0.011922   0.01862874 0.00764191 0.00805661 0.0076419  0.011922
 0.01654392 0.01586309 0.00764191 0.00764191 0.00764191 0.01202377
 0.01774619 0.0076419  0.01774618 0.00764191 0.00764191 0.00764191
 0.016543   0.01192188 0.00764191 0.00764191 0.00764191 0.00764191
 0.00762061 0.00764191 0.01202377 0.00764191 0.017689   0.01586289
 0.00764097 0.01202377 0.01774619 0.01654392 0.01774619 0.01742078
 0.00764191 0.00764396]
tr_loss:[0.01568659 0.00895211 0.00895211 0.02025293 0.01566699 0.01159272
 0.00839331 0.01256629 0.00895211 0.01941445 0.01834564 0.00927038
 0.00892679 0.01606943 0.00927038 0.00899055 0.00927038 0.0194186
 0.00927038 0.00895164 0.00895211 0.00899055 0.01670161 0.01671008
 0.00895211 0.00936538 0.00895211 0.01159272 0.00895212 0.00895211
 0.00895211 0.00895211 0.00895211 0.00895211 0.01663134 0.00927038
 0.00895211 0.01785132 0.00899055 0.00895211 0.00851267 0.01909037
 0.00895211 0.02025293 0.01667371 0.01606959 0.00842705 0.02025294
 0.00927038 0.0089521 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4100 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4101, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4101 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4102, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4102 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4103, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4103 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4104, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4104 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4105, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4105 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4106, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4106 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4107, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4107 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4108, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4108 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4109, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4109 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4110, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4110 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4111, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4111 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4112, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4112 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4113, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4113 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4114, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4114 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4115, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4115 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4116, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4116 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4117, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4117 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4118, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4118 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4119, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4119 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4120, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4120 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4121, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4121 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4122, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4122 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4123, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4123 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4124, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4124 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4125, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4125 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4126, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4126 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4127, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4127 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4128, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4128 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4129, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4129 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4130, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4130 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4131, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4131 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4132, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4132 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4133, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4133 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4134, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4134 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4135, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4135 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4136, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4136 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4137, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4137 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4138, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4138 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4139, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4139 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4140, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4140 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4141, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4141 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4142, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4142 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4143, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4143 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4144, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4144 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4145, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4145 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4146, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4146 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4147, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4147 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4148, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4148 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4149, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4149 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4150, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4150 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4151, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4151 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4152, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4152 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4153, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4153 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4154, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4154 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4155, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4155 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4156, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4156 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4157, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4157 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4158, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4158 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4159, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4159 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4160, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4160 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4161, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4161 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4162, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4162 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4163, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4163 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4164, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4164 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4165, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4165 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4166, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4166 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4167, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4167 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4168, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4168 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4169, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4169 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4170, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4170 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4171, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4171 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4172, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4172 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4173, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4173 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4174, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4174 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4175, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4175 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4176, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4176 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4177, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4177 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4178, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4178 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4179, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4179 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4180, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4180 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4181, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4181 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4182, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4182 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4183, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4183 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4184, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4184 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4185, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4185 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4186, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4186 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4187, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4187 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4188, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4188 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4189, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4189 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4190, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4190 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4191, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4191 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4192, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4192 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4193, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4193 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4194, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4194 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4195, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4195 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4196, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4196 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4197, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4197 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4198, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4198 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4199, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4199 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4200, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-4100
text_input.shape
(4200, 14400)
learning_input_tmp.shape
(4200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4200, 80)
learning_output.shape
(750, 80)
Model: "sequential_85"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_85 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.8067974 1.8083178 1.8067791 1.7667475 1.8067791 1.8074086 1.8067791
 1.8083061 1.7668984 1.8067791 1.8067791 1.7667475 1.8097885 1.8076837
 1.7663883 1.7769935 1.807834  1.7664598 1.8067791 1.807834  1.7669111
 1.8067791 1.7663753 1.8194157 1.807834  1.7673485 1.8067791 1.8067774
 1.821846  1.8067791 1.8067791 1.8078343 1.8067791 1.8067789 1.8067799
 1.8067791 1.8078343 1.8078343 1.7961388 1.8067791 1.8067791 1.7770052
 1.8067791 1.8078343 1.8078343 1.8097748 1.8067791 1.8067791 1.8067791
 1.8067789]
tr_loss:[0.8681434  0.86814326 0.86836374 0.87261784 0.86814326 0.872618
 0.87595904 0.8669464  0.9034885  0.86814326 0.9034878  0.86814326
 0.9001914  0.86814326 0.8681434  0.8770851  0.86813784 0.86814487
 0.86814326 0.8682475  0.86814326 0.86814326 0.86814326 0.8771679
 0.86814326 0.8683934  0.86816454 0.8850354  0.86814326 0.86786425
 0.87685096 0.86814326 0.86814326 0.86814326 0.9117346  0.8684597
 0.8726177  0.86811876 0.86814326 0.86814326 0.86814326 0.8681434
 0.86814326 0.86813927 0.88061297 0.86814326 0.87685096 0.8681429
 0.8726179  0.86838627]
tr_loss:[0.49237758 0.4923776  0.47548723 0.4923776  0.49237758 0.49237758
 0.48683682 0.47541815 0.4923776  0.46714407 0.5047261  0.4909443
 0.49237767 0.46714932 0.5009225  0.49237737 0.49237758 0.49237758
 0.4925053  0.4923776  0.4923776  0.5009225  0.48669043 0.49237758
 0.49282604 0.4923776  0.50470906 0.49237758 0.4923776  0.4923776
 0.50981635 0.49468365 0.49234313 0.5085689  0.49237758 0.49237767
 0.49237794 0.50466543 0.47245994 0.48349604 0.49237758 0.49687976
 0.4923776  0.4923776  0.4848899  0.49237767 0.5047046  0.4923776
 0.4923776  0.48502025]
tr_loss:[0.30068943 0.30068946 0.29957885 0.29957888 0.30068943 0.30068946
 0.3006895  0.3006895  0.3006895  0.29370117 0.3029579  0.29778275
 0.3068125  0.29778275 0.3006895  0.30295593 0.30109468 0.30068952
 0.29778275 0.30068946 0.30068946 0.30068946 0.29778272 0.30068952
 0.30068952 0.30068558 0.30068946 0.2963292  0.30069086 0.30038255
 0.3006895  0.29370123 0.30060163 0.30068946 0.29778275 0.30661803
 0.2933324  0.30681252 0.3006894  0.30068946 0.30068946 0.29778278
 0.3006894  0.29778278 0.30632597 0.3092362  0.29957885 0.3006894
 0.30068946 0.30923668]
tr_loss:[0.1580647  0.15414488 0.15845206 0.15414488 0.15414488 0.15863088
 0.15845764 0.1580647  0.15414491 0.15414487 0.15845764 0.15053637
 0.1580233  0.14298478 0.15845762 0.15414491 0.15806472 0.15414487
 0.15414488 0.15845762 0.15432888 0.1541449  0.15414488 0.15414488
 0.15414488 0.15414488 0.15414491 0.15414485 0.14734662 0.15898779
 0.1541449  0.15414488 0.14298478 0.1541449  0.15414493 0.15908495
 0.15806465 0.15863088 0.15881222 0.14298478 0.1580647  0.14734656
 0.15863156 0.15863092 0.15863086 0.1580647  0.15518266 0.1619389
 0.15414488 0.15414488]
tr_loss:[0.05268891 0.0525289  0.0526889  0.05768999 0.05268889 0.04653389
 0.05268889 0.05268889 0.05268891 0.05261021 0.0526946  0.05268889
 0.0526889  0.05159966 0.05268889 0.04116921 0.05268891 0.05718675
 0.05268888 0.05269034 0.05268889 0.05268889 0.05268889 0.0526889
 0.05268889 0.05768998 0.0526889  0.0526889  0.0526889  0.05789109
 0.0526889  0.05160207 0.04654896 0.0526889  0.0526889  0.05268892
 0.05268891 0.0526889  0.05768998 0.0526889  0.05514843 0.0526889
 0.0526889  0.05159966 0.05268891 0.05268853 0.04116775 0.05728417
 0.0526889  0.05279626]
tr_loss:[0.02017111 0.02577681 0.01357902 0.02022142 0.02022141 0.0195166
 0.0195166  0.02022142 0.02338366 0.02022139 0.02022142 0.02586859
 0.01357903 0.0195166  0.01954749 0.02755837 0.02022141 0.02022142
 0.02022143 0.02587179 0.02351574 0.01357902 0.02577686 0.01816131
 0.02591255 0.01817313 0.02644726 0.02022142 0.02022141 0.0195166
 0.01816364 0.0202214  0.02022142 0.02348932 0.02022142 0.01954749
 0.01357902 0.02022126 0.02022142 0.02022141 0.02022142 0.02351574
 0.02577686 0.02022142 0.02577686 0.02075231 0.01357903 0.02022141
 0.01357902 0.02022142]
tr_loss:[0.00865578 0.00954363 0.00954363 0.00954363 0.01370222 0.00954363
 0.01828266 0.00917116 0.01699245 0.00954363 0.00954363 0.01005164
 0.00865577 0.00968304 0.00954363 0.01699245 0.00954363 0.01090739
 0.00954167 0.01755526 0.01699245 0.01370222 0.00953768 0.00954363
 0.01370222 0.01753876 0.01831839 0.01699245 0.00954363 0.00954364
 0.00954361 0.01704957 0.00865576 0.01699245 0.00954789 0.01198267
 0.00954363 0.01090739 0.00917116 0.01090797 0.01370222 0.01648349
 0.01370222 0.00954363 0.01090739 0.01699245 0.01090739 0.00865576
 0.01702167 0.00954362]
tr_loss:[0.01845169 0.01738294 0.01919539 0.02014435 0.00741713 0.01632464
 0.00741712 0.00741713 0.01930821 0.02364828 0.02014435 0.00741714
 0.00741793 0.02014436 0.01197145 0.00741677 0.00741713 0.01738296
 0.00743803 0.01845168 0.0191954  0.01232014 0.01197145 0.00741709
 0.00741713 0.00741713 0.00851119 0.01845168 0.01991058 0.00741713
 0.01946535 0.00741713 0.00627829 0.00741713 0.02370294 0.00741713
 0.02017321 0.01776172 0.00722989 0.01919539 0.00742882 0.00741713
 0.00741713 0.00741713 0.01640667 0.00741713 0.01197145 0.012321
 0.00741713 0.00634662]
tr_loss:[0.02001501 0.00792724 0.00792539 0.00792725 0.00792723 0.01461537
 0.01998883 0.00792724 0.02176468 0.02734459 0.00792723 0.00792724
 0.02083871 0.01659978 0.00806392 0.00801802 0.00792726 0.01659976
 0.0080219  0.02067515 0.00792724 0.01400745 0.00792724 0.00792724
 0.00792723 0.00801803 0.00801803 0.00792723 0.02734459 0.02734459
 0.00792723 0.02120852 0.02116366 0.00792723 0.00892333 0.01582667
 0.02734459 0.00792723 0.00792723 0.00792723 0.01807754 0.00792724
 0.00801802 0.00792724 0.00792723 0.00792723 0.01807827 0.0079268
 0.00792724 0.02734459]
tr_loss:[0.00532661 0.00532595 0.00891281 0.00532661 0.00891281 0.00532661
 0.01482039 0.0053249  0.00532662 0.01482036 0.0053265  0.01410889
 0.00891281 0.00532662 0.00532661 0.00532662 0.01233674 0.00891281
 0.00532662 0.00532662 0.00532236 0.01560327 0.00534032 0.0141089
 0.01120483 0.00532662 0.0189706  0.00532662 0.01409715 0.00532689
 0.00532662 0.00532661 0.00532662 0.01482068 0.00532662 0.00787551
 0.01560327 0.00532662 0.01560328 0.00532662 0.0189706  0.00532662
 0.00532662 0.00532661 0.00831972 0.00532662 0.01120532 0.01602941
 0.00531844 0.00532662]
tr_loss:[0.00805261 0.00203424 0.00866835 0.00405295 0.01067608 0.00820694
 0.00781352 0.00405295 0.00405295 0.00405295 0.00405295 0.0035178
 0.00781352 0.00834839 0.00405295 0.00405295 0.00405295 0.00820694
 0.00584247 0.00405652 0.00820694 0.00360396 0.00405387 0.00405295
 0.00405295 0.01074808 0.00405298 0.00360396 0.00405295 0.0040533
 0.0058201  0.00405295 0.00405295 0.00405295 0.00405295 0.00694342
 0.00405295 0.00781348 0.00405295 0.00360426 0.00405295 0.00405813
 0.00405295 0.00751033 0.00866829 0.00820694 0.00805353 0.00820694
 0.00805049 0.00466508]
tr_loss:[0.00786002 0.00786002 0.0079093  0.00618104 0.01116846 0.00786003
 0.0061452  0.00670117 0.00719308 0.00656141 0.00786002 0.00719308
 0.01116974 0.00786001 0.00786001 0.00786002 0.00786002 0.0061452
 0.00549298 0.00786002 0.00785983 0.0079093  0.00446327 0.00693838
 0.00347757 0.00417154 0.00786002 0.00786001 0.00670117 0.00786001
 0.00786002 0.00693839 0.00786002 0.00786001 0.00786002 0.00786002
 0.00786002 0.00670117 0.00549804 0.00670117 0.0078622  0.00786002
 0.00786002 0.00786002 0.00786001 0.01523921 0.00786003 0.00786001
 0.0061452  0.00431362]
tr_loss:[0.0091627  0.00933058 0.01034121 0.01034121 0.00969684 0.0091627
 0.00744636 0.01034119 0.00795657 0.00655604 0.00969685 0.01034014
 0.00513315 0.01034121 0.01034121 0.0091627  0.00795657 0.00479777
 0.01034117 0.01034121 0.01034121 0.00480321 0.01034122 0.01034121
 0.00933058 0.00916271 0.00590547 0.00740686 0.01034121 0.0103412
 0.0103412  0.01034121 0.01034121 0.00503437 0.01034121 0.01034121
 0.01034122 0.01034121 0.01034122 0.01034121 0.01034121 0.00960123
 0.0103412  0.01034122 0.0048032  0.01034121 0.01034127 0.01033725
 0.00655604 0.0103412 ]
tr_loss:[0.00584428 0.00622669 0.00622669 0.00537023 0.00584427 0.00622665
 0.00622669 0.00725322 0.0063133  0.00545375 0.00622669 0.00237318
 0.00622669 0.00484003 0.00622669 0.0102267  0.00484003 0.00622683
 0.00622669 0.00425777 0.0064813  0.00622669 0.0062267  0.00484003
 0.00631329 0.0062265  0.00624888 0.00622101 0.00725322 0.00622669
 0.00622669 0.00484003 0.01378343 0.0064813  0.00622669 0.00622697
 0.00622669 0.00622669 0.00622669 0.00622669 0.00484003 0.0063133
 0.0063133  0.00622669 0.00622669 0.00402068 0.00484075 0.00622669
 0.01294157 0.0063133 ]
tr_loss:[0.00736125 0.00679357 0.00340136 0.00523563 0.01055294 0.00340137
 0.00282021 0.00340137 0.00340137 0.00706273 0.00299495 0.00523563
 0.00653611 0.00340137 0.00340137 0.00736126 0.00736141 0.00340137
 0.00924848 0.00299495 0.00340137 0.00114481 0.00340137 0.00678965
 0.00340137 0.00298741 0.00340137 0.00706273 0.00340402 0.00340137
 0.00691388 0.00579053 0.00340137 0.00114406 0.0034223  0.00340137
 0.00299489 0.00304322 0.00340137 0.00709296 0.00340137 0.00691388
 0.00302228 0.00297564 0.00520685 0.01041799 0.00410375 0.00935865
 0.00523563 0.00340137]
tr_loss:[0.00343837 0.00854663 0.00343306 0.00612785 0.00612785 0.01339546
 0.01339546 0.01106133 0.00343837 0.01022618 0.00343837 0.01022251
 0.00343837 0.00612785 0.00854664 0.00459833 0.00343837 0.01036807
 0.00343836 0.01339546 0.01020941 0.00343836 0.00729732 0.00343837
 0.00726482 0.00343837 0.00977665 0.01041794 0.00343818 0.00563201
 0.01106133 0.01339546 0.00343837 0.00879087 0.01106133 0.00343837
 0.00343837 0.00264094 0.00343836 0.00343837 0.00977665 0.00977656
 0.00343836 0.00730131 0.00343837 0.00343836 0.00343838 0.00343837
 0.00343837 0.0034254 ]
tr_loss:[0.00389534 0.00393267 0.0024885  0.01690354 0.00387405 0.01227678
 0.00389534 0.00389534 0.00389534 0.00389534 0.01147646 0.00389534
 0.00389534 0.00389534 0.00651375 0.00389534 0.00389534 0.00651374
 0.00389534 0.00389534 0.00389534 0.00389534 0.00389534 0.01004006
 0.00925666 0.00389534 0.00389534 0.01114492 0.00389534 0.00389574
 0.00389535 0.01159912 0.00389534 0.00389526 0.01227678 0.00989947
 0.00389534 0.00237393 0.00717735 0.00389534 0.0106978  0.01227678
 0.00389534 0.01690354 0.00389534 0.00389534 0.0122762  0.00389534
 0.00389534 0.01361553]
tr_loss:[0.0155896  0.00344598 0.01027316 0.00342819 0.00342819 0.00842494
 0.0155896  0.00342819 0.00933881 0.00342819 0.00343537 0.00342819
 0.00802789 0.00553118 0.00553117 0.00342819 0.0093388  0.00342819
 0.00343537 0.00342819 0.00342819 0.01065491 0.01558959 0.00342819
 0.0061678  0.00749368 0.00342736 0.00342819 0.0062631  0.003475
 0.00342819 0.00342819 0.00846346 0.00342819 0.0034282  0.00797
 0.00342819 0.00342819 0.00342819 0.00342819 0.00842494 0.0155896
 0.0155896  0.00342819 0.00553117 0.00342819 0.00933881 0.00342819
 0.00626418 0.01065491]
tr_loss:[0.00265528 0.00265528 0.00265528 0.00673844 0.01023393 0.01023393
 0.00265527 0.00265528 0.0070854  0.00265528 0.00265528 0.00265153
 0.00265528 0.00271992 0.0061154  0.00654305 0.00930097 0.00265528
 0.00513445 0.00443113 0.00265153 0.00265528 0.00265528 0.00265528
 0.00265795 0.00076955 0.0061154  0.00621499 0.00265528 0.00394389
 0.00265528 0.00394389 0.00265528 0.00265528 0.0035149  0.0070854
 0.01023394 0.01023394 0.01023393 0.00265153 0.00265528 0.00265153
 0.00265528 0.0070854  0.00265528 0.00581637 0.00265528 0.00361919
 0.00265528 0.0039439 ]
tr_loss:[0.00349598 0.00410165 0.00349598 0.00349616 0.00360848 0.00349598
 0.00276221 0.00349598 0.00349598 0.00347978 0.00810776 0.00349598
 0.00349608 0.00631776 0.00810778 0.00425921 0.00631776 0.00349598
 0.00296082 0.00349598 0.00349598 0.00349598 0.00410165 0.00349598
 0.00410165 0.00349598 0.00472777 0.01068935 0.00631776 0.00349598
 0.003497   0.00349598 0.00349598 0.00393401 0.00349597 0.00349597
 0.00349597 0.00410165 0.00349598 0.00276172 0.004736   0.00349598
 0.00360285 0.00349598 0.010695   0.00349598 0.00296084 0.00349598
 0.00631782 0.00349598]
tr_loss:[0.00223648 0.00509417 0.00365429 0.00468758 0.00509418 0.00421079
 0.00573768 0.00408384 0.00579341 0.00365429 0.00509418 0.00505697
 0.00509418 0.01209616 0.00509419 0.00421822 0.00509418 0.00509418
 0.00579341 0.00408384 0.00509418 0.00509418 0.00509417 0.00509418
 0.00509418 0.003735   0.00509418 0.00261438 0.01166033 0.00509418
 0.00408384 0.00509418 0.00573767 0.00509418 0.00408385 0.00509418
 0.00509418 0.003735   0.003735   0.003735   0.00509418 0.00369017
 0.00509424 0.00579341 0.00579341 0.00509417 0.00421754 0.00468758
 0.00517199 0.0022094 ]
tr_loss:[0.00469249 0.0046925  0.00671943 0.00235888 0.00469251 0.0046925
 0.00671944 0.0046925  0.00387723 0.0046925  0.00235889 0.00468978
 0.00665003 0.0046925  0.00671944 0.0046925  0.0046925  0.00469232
 0.00671943 0.00236017 0.00572427 0.0046925  0.00440447 0.00665005
 0.00469244 0.00387723 0.0046925  0.00234327 0.0046925  0.0046925
 0.00469249 0.01159126 0.00120175 0.0046925  0.0046925  0.00643001
 0.00665004 0.00671943 0.00201399 0.00232259 0.00383627 0.00665003
 0.00572427 0.00120171 0.00678079 0.0046925  0.0046925  0.0046925
 0.00124746 0.00470102]
tr_loss:[0.00951496 0.00320535 0.00951509 0.00320535 0.00320535 0.00320535
 0.00320535 0.00320535 0.00320535 0.00320535 0.00603695 0.00951509
 0.00694047 0.00249557 0.00320535 0.00951509 0.00328537 0.00470018
 0.00320535 0.00390031 0.00951509 0.00320535 0.00610345 0.00320535
 0.00320535 0.00320535 0.00320531 0.00320534 0.00320535 0.00312733
 0.00320667 0.00320534 0.00320535 0.00102653 0.00320534 0.00097712
 0.00320535 0.00320535 0.00320535 0.00610345 0.00090253 0.00320535
 0.00320535 0.00951509 0.00090258 0.00320535 0.00320535 0.00320535
 0.0009766  0.0095151 ]
tr_loss:[0.00163299 0.00163299 0.00418019 0.00163299 0.00163543 0.00163299
 0.00163299 0.00418047 0.00163287 0.00539913 0.00221999 0.00163299
 0.00163276 0.00163299 0.00163299 0.00163299 0.00163299 0.00221999
 0.00164288 0.00163299 0.00163299 0.00603156 0.00163299 0.01120601
 0.00689999 0.00750943 0.00163299 0.00163299 0.00163299 0.00224601
 0.00163299 0.00469578 0.00689999 0.00604191 0.00211274 0.00163299
 0.00539946 0.00163299 0.00211274 0.00163299 0.00163299 0.00163299
 0.00173131 0.00211083 0.00604193 0.00211274 0.00163309 0.00163299
 0.00184164 0.00163299]
tr_loss:[0.00124207 0.00478062 0.00489433 0.0012406  0.00550542 0.00124207
 0.00124207 0.00124207 0.005794   0.00124207 0.00124207 0.00729705
 0.00550541 0.00547313 0.00124075 0.0012421  0.0143598  0.00798421
 0.01435981 0.005794   0.00547342 0.00124207 0.00124207 0.00124207
 0.00124206 0.00124207 0.00124207 0.00124207 0.00124207 0.01435979
 0.01886303 0.01435981 0.00124208 0.00124207 0.00124207 0.00490054
 0.0143598  0.00124207 0.00547361 0.00124207 0.00124207 0.00124528
 0.00513643 0.00124207 0.00554113 0.00124207 0.00124207 0.00124207
 0.00278726 0.01435981]
tr_loss:[0.00859665 0.00162883 0.01600545 0.00706249 0.00162878 0.00162881
 0.01601929 0.00162878 0.00162878 0.00720719 0.00650548 0.00585729
 0.00162878 0.00162911 0.00650549 0.00162878 0.00162878 0.00162878
 0.00162878 0.00162878 0.00162879 0.00162878 0.00706249 0.00643125
 0.00336135 0.00601182 0.00162879 0.00706249 0.00251121 0.00162878
 0.00162878 0.00162878 0.01601932 0.00162878 0.00620765 0.00387836
 0.00162878 0.00162891 0.00162878 0.00162878 0.00162878 0.0070625
 0.00336168 0.00162879 0.00162881 0.00336168 0.01601942 0.00183862
 0.00336168 0.01601931]
tr_loss:[0.00128975 0.00128975 0.00456107 0.00239726 0.00128975 0.00128975
 0.00128975 0.00692285 0.00349963 0.00128975 0.00128964 0.00239731
 0.00128974 0.00128975 0.00128975 0.00128975 0.00239731 0.00128975
 0.01408758 0.00523675 0.00128975 0.01408758 0.00128975 0.00128975
 0.00128975 0.00128975 0.00128974 0.00480258 0.00239731 0.00128975
 0.00764253 0.00128973 0.00128975 0.00129047 0.00239731 0.00128975
 0.00350017 0.00239731 0.00128975 0.00692289 0.00523674 0.00523675
 0.00128975 0.00128975 0.00129594 0.00128975 0.00523674 0.00128975
 0.00523675 0.01408758]
tr_loss:[0.00134579 0.00124941 0.00134579 0.0020079  0.00142344 0.00392902
 0.00392904 0.00134579 0.00536347 0.00134693 0.0020079  0.00134636
 0.00134579 0.00229559 0.00132832 0.01130026 0.00183622 0.00134579
 0.0020079  0.0051771  0.00239534 0.00134579 0.00134579 0.00134579
 0.00134579 0.00239492 0.00134579 0.00134579 0.00134579 0.00134579
 0.00164472 0.0051771  0.00134579 0.00229559 0.00134934 0.00737288
 0.0022956  0.00200788 0.00134579 0.00134579 0.00132832 0.01136317
 0.00134582 0.00134579 0.00134579 0.00132002 0.0013458  0.00134579
 0.00210807 0.00134579]
tr_loss:[0.0040267  0.01000278 0.0024048  0.0024048  0.00073886 0.0024048
 0.00544394 0.00066348 0.00073886 0.0024048  0.01000278 0.0024048
 0.0024048  0.00445773 0.0024048  0.00073886 0.00074547 0.00073886
 0.0024048  0.0024048  0.00544394 0.0024048  0.00240475 0.00239991
 0.0005348  0.0024048  0.00066348 0.0014277  0.0024048  0.0024048
 0.00073886 0.003209   0.00074547 0.00240526 0.0024048  0.00240414
 0.01000278 0.0024048  0.0014277  0.0024048  0.00240479 0.00073821
 0.0024048  0.00240479 0.0024048  0.00236812 0.00445772 0.00073886
 0.0024048  0.0024048 ]
text_input.shape
(4200, 14400)
learning_input_tmp.shape
(4200, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4200, 80)
learning_output.shape
(750, 80)
Model: "sequential_86"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_86 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3909423 1.3909423 1.4147434 1.3909423 1.3831825 1.4001211 1.3940014
 1.3909422 1.3939438 1.3909423 1.3909419 1.4021788 1.3909423 1.3940012
 1.3909423 1.402223  1.3909423 1.3956585 1.3965266 1.3941386 1.3909423
 1.3895481 1.3956531 1.3909357 1.4147437 1.3909423 1.3909423 1.400121
 1.3909425 1.4147081 1.3911618 1.3909422 1.3940014 1.3909413 1.3937399
 1.3909451 1.3895481 1.3909559 1.3909423 1.3940014 1.3909423 1.4147437
 1.4001211 1.4134691 1.3909423 1.400121  1.3909423 1.3909423 1.400121
 1.3909422]
tr_loss:[0.8294188  0.8294188  0.8294188  0.82941866 0.81346244 0.86886805
 0.84139097 0.8612617  0.8294188  0.8474518  0.84139097 0.84138525
 0.8294188  0.8294188  0.82725686 0.8294188  0.8294188  0.86909217
 0.82941866 0.8474515  0.8294188  0.81366634 0.8294188  0.8294188
 0.84745157 0.82941866 0.81369525 0.8294188  0.8294188  0.8294188
 0.87112266 0.8291128  0.8294188  0.8294188  0.826454   0.81366557
 0.82677764 0.86909807 0.85650367 0.8294188  0.86907756 0.8612636
 0.84153014 0.8294188  0.8292009  0.8690923  0.86887753 0.8253797
 0.8294188  0.8691324 ]
tr_loss:[0.43506566 0.43288955 0.41301927 0.4003953  0.4276085  0.424846
 0.42760882 0.42471036 0.42479196 0.42544183 0.42479196 0.43288976
 0.43484467 0.424792   0.42479196 0.43506527 0.4158225  0.40039477
 0.4276085  0.4247663  0.424792   0.43457264 0.41582632 0.40039462
 0.424792   0.424792   0.42545137 0.40039474 0.424792   0.424792
 0.4328896  0.424792   0.40121183 0.43288964 0.4254523  0.424792
 0.4247486  0.44420034 0.40039486 0.424792   0.424792   0.424792
 0.43288955 0.424792   0.43487412 0.4328896  0.41184545 0.424792
 0.41950282 0.4276085 ]
tr_loss:[0.17758627 0.2029398  0.20293978 0.20293978 0.20293978 0.2029398
 0.20293975 0.19350202 0.20883803 0.20293978 0.19350202 0.2029398
 0.19934016 0.20293975 0.2029398  0.20293975 0.19350202 0.20293978
 0.20293978 0.20577109 0.1993402  0.22215696 0.19864652 0.20293978
 0.1993402  0.20311335 0.18616568 0.19934018 0.19350201 0.2029398
 0.1948413  0.20883806 0.17768462 0.20293975 0.2029398  0.20293978
 0.18329439 0.20293978 0.19938107 0.2029398  0.18329439 0.20293978
 0.20293975 0.18329498 0.2029398  0.1986454  0.17768463 0.19350202
 0.19934016 0.20293978]
tr_loss:[0.12160666 0.12790331 0.12791018 0.11500671 0.12791015 0.12791017
 0.10826027 0.11500671 0.12791017 0.10504858 0.12649485 0.12791017
 0.12791017 0.12125573 0.1293073  0.12791017 0.11492107 0.11030965
 0.12158911 0.10387337 0.12791033 0.12791017 0.12791014 0.1293073
 0.12815729 0.12791017 0.12791017 0.1419858  0.12791017 0.12329006
 0.12791017 0.10850825 0.12791017 0.12158911 0.12791017 0.12791017
 0.12791017 0.11102749 0.12649491 0.12649491 0.12821373 0.1279084
 0.12298515 0.11500671 0.12649491 0.10851357 0.12791017 0.12629828
 0.12791014 0.1293073 ]
tr_loss:[0.06529931 0.07070576 0.07070845 0.0652993  0.06419273 0.06529931
 0.06529912 0.06419273 0.0652993  0.0652993  0.06529931 0.06529932
 0.06529931 0.06529932 0.06192139 0.06529932 0.06474908 0.06474906
 0.06529931 0.0652993  0.06529932 0.04495978 0.0652993  0.05774732
 0.06529931 0.06530999 0.06529932 0.06474906 0.07069917 0.06529931
 0.0619214  0.06529931 0.06529973 0.05200288 0.06529931 0.06419273
 0.06529932 0.06474906 0.06474876 0.0652993  0.06529932 0.06529931
 0.06529931 0.06529932 0.06529932 0.06529931 0.06192139 0.04564975
 0.0619214  0.06529929]
tr_loss:[0.04816414 0.04816394 0.04816394 0.04816394 0.04404499 0.06566802
 0.05991096 0.06547979 0.05475936 0.04816394 0.05476554 0.04403234
 0.04403235 0.04816394 0.04403234 0.04858343 0.04403235 0.04816394
 0.04392432 0.06618451 0.04816394 0.04816394 0.04816394 0.04816394
 0.04820095 0.04816394 0.04816394 0.06618502 0.04614804 0.04816394
 0.04816394 0.04403236 0.06618501 0.04816394 0.03814945 0.05991042
 0.04816394 0.04816394 0.04816394 0.04403235 0.04817363 0.04403235
 0.04403235 0.04816394 0.04816394 0.04403234 0.04816427 0.03888952
 0.06566806 0.04816394]
tr_loss:[0.05175006 0.05100491 0.07198359 0.05098473 0.05175006 0.05098473
 0.05098473 0.05098473 0.05098489 0.06719567 0.05098461 0.05098473
 0.05098473 0.0483299  0.04774585 0.06719567 0.0451351  0.05098473
 0.07230926 0.04968625 0.05098261 0.04669413 0.05098385 0.05098473
 0.04513511 0.04669415 0.05098473 0.07230838 0.05098473 0.05098474
 0.05098473 0.07229421 0.071983   0.05098472 0.05020121 0.04513501
 0.05100761 0.05098473 0.05098473 0.05098473 0.05098473 0.05098473
 0.05098469 0.05098473 0.05098473 0.06012528 0.05921654 0.03792581
 0.05098474 0.05098473]
tr_loss:[0.04875796 0.05228782 0.05229146 0.05228781 0.05356374 0.05228782
 0.05228782 0.07644558 0.05356374 0.05228757 0.05228782 0.04562206
 0.04750644 0.07644559 0.07644559 0.05044845 0.05228782 0.06964982
 0.0522877  0.05365162 0.07644559 0.05228783 0.05228782 0.05228782
 0.07435097 0.05228783 0.05228782 0.04006519 0.05228782 0.05228782
 0.06553487 0.06205337 0.05228782 0.06964982 0.04231969 0.07435095
 0.05228781 0.04750644 0.05228782 0.04562528 0.05228794 0.05228782
 0.07434709 0.05229501 0.05228782 0.05232585 0.05228782 0.06205337
 0.05228782 0.06205337]
tr_loss:[0.05222837 0.05222838 0.04702703 0.05222837 0.05222145 0.0760803
 0.05222837 0.05222837 0.05222837 0.0757558  0.05222832 0.04790684
 0.05221484 0.04702702 0.0618019  0.06924048 0.04790734 0.06499465
 0.04549579 0.04702702 0.07616248 0.05222837 0.07311332 0.05222837
 0.05222836 0.04702713 0.05222836 0.05222836 0.05222837 0.0523725
 0.04702702 0.05222837 0.05222837 0.05222837 0.0618019  0.05222837
 0.05222836 0.06494901 0.05222837 0.05222832 0.06180187 0.05424895
 0.04074914 0.07473072 0.05222837 0.04751139 0.04702702 0.06180189
 0.05222836 0.05222836]
tr_loss:[0.05198876 0.05111789 0.05198876 0.04096057 0.04621453 0.07444865
 0.05198876 0.05198876 0.05198876 0.04621454 0.05113062 0.04658601
 0.05198876 0.07444864 0.05198877 0.06065043 0.06736944 0.05198876
 0.04640892 0.07051109 0.05198555 0.05155175 0.07444859 0.05198876
 0.04621453 0.04818386 0.04640892 0.05198876 0.05198876 0.07057109
 0.07197125 0.07444863 0.05198876 0.05198876 0.05178471 0.051989
 0.07053251 0.05198876 0.05198876 0.05198877 0.07383113 0.05198876
 0.0519871  0.05111947 0.05198885 0.0527116  0.06736944 0.04462823
 0.07444864 0.05198877]
tr_loss:[0.05337522 0.05337521 0.04172824 0.05337591 0.05337616 0.05336851
 0.05337719 0.04443235 0.06617612 0.05337521 0.04026088 0.05337521
 0.05337521 0.05337526 0.05337521 0.05327735 0.06056944 0.05337522
 0.05337521 0.0533752  0.05337521 0.04568459 0.06056944 0.07344063
 0.05337472 0.06855461 0.05001825 0.04754082 0.06544395 0.05337521
 0.06842243 0.06056945 0.05337521 0.04568075 0.04754082 0.05337521
 0.04754082 0.05337522 0.06056945 0.07002023 0.05336209 0.05337521
 0.05337521 0.0727272  0.06617612 0.05337521 0.04172821 0.05337521
 0.07344063 0.0533752 ]
tr_loss:[0.05447526 0.06102394 0.06994338 0.05447526 0.06107789 0.06728566
 0.05447526 0.05447526 0.05447526 0.04687648 0.0544754  0.05447526
 0.05447524 0.05447526 0.05447526 0.05447526 0.04859823 0.05447525
 0.04859823 0.05452764 0.04687648 0.05447526 0.05447526 0.05447526
 0.07265384 0.05447525 0.07356898 0.05447526 0.05447525 0.04264056
 0.0664492  0.04859823 0.06832735 0.0592217  0.07356898 0.04708109
 0.0662358  0.05447526 0.05447652 0.04687648 0.0417892  0.05447524
 0.0735689  0.04859823 0.07356898 0.05698716 0.04859823 0.06610937
 0.05447526 0.05447526]
tr_loss:[0.06837036 0.05306878 0.05306855 0.05306878 0.05306878 0.05306878
 0.06594528 0.05306878 0.05306878 0.05306881 0.05306878 0.06031523
 0.06594528 0.05306878 0.05298878 0.05301608 0.05306878 0.05306878
 0.05294362 0.06591691 0.06594528 0.05278813 0.05306878 0.06031523
 0.04740346 0.05306878 0.05306878 0.07235287 0.05306877 0.05306923
 0.04637029 0.05306876 0.04296332 0.05306878 0.05306878 0.04563311
 0.0530769  0.04741269 0.05306878 0.04636988 0.04740346 0.07316846
 0.05306878 0.05306878 0.05306872 0.06031523 0.04740346 0.05266045
 0.04563309 0.05306878]
tr_loss:[0.05159947 0.05999883 0.03937216 0.05159946 0.05160803 0.05159947
 0.04597472 0.04451703 0.0463675  0.05109094 0.05159945 0.0463675
 0.05159946 0.05159947 0.05254904 0.05159946 0.04088025 0.05159947
 0.05159946 0.05159946 0.05159947 0.0463675  0.0460132  0.0463675
 0.05159947 0.07348515 0.05159947 0.06412392 0.05159947 0.04451703
 0.05159946 0.05159946 0.05159845 0.05159946 0.04618882 0.05169241
 0.07348516 0.05999883 0.05159946 0.05159947 0.05159947 0.04451703
 0.06595032 0.05159946 0.06394093 0.05159942 0.06158015 0.07287
 0.05159947 0.05159947]
tr_loss:[0.07091912 0.05110464 0.05110464 0.04654222 0.07400645 0.06021567
 0.05113994 0.06021567 0.04590288 0.05110464 0.05110464 0.05110464
 0.05110464 0.04120559 0.05110464 0.05110464 0.0672086  0.07091455
 0.07400645 0.06021566 0.06021567 0.05110464 0.05110464 0.04601907
 0.05110464 0.04654221 0.05110464 0.05110464 0.05110464 0.07094429
 0.05110461 0.06021555 0.06021567 0.04654221 0.05110464 0.05110464
 0.07089061 0.06417428 0.04456225 0.05110464 0.05110464 0.05110464
 0.04120499 0.04601903 0.07400642 0.0672086  0.04121616 0.04456224
 0.04458158 0.04654222]
tr_loss:[0.04955273 0.05853856 0.04955301 0.05053414 0.04233232 0.04955301
 0.07159664 0.04955301 0.05782448 0.04955301 0.04390014 0.07159663
 0.04952862 0.04955301 0.04955301 0.04955301 0.06961749 0.04390014
 0.07188552 0.05853856 0.04603227 0.04955301 0.049553   0.04955301
 0.05853857 0.0639021  0.05853856 0.04954667 0.04955301 0.04955301
 0.05853856 0.04603214 0.04390014 0.04955301 0.04955301 0.04955301
 0.05026063 0.06999277 0.04955301 0.04955301 0.04955302 0.06538417
 0.04955301 0.04603214 0.06538417 0.04390014 0.04955302 0.04955298
 0.0585308  0.04423007]
tr_loss:[0.04188371 0.0610807  0.04960937 0.06108068 0.04188376 0.04188377
 0.04188377 0.04188376 0.0405414  0.06107833 0.04188377 0.04188421
 0.04960937 0.06108068 0.04088187 0.04188376 0.04188377 0.04188376
 0.0404038  0.04188376 0.06108068 0.04188382 0.04188376 0.04236966
 0.04188377 0.04188377 0.04188377 0.05916563 0.05491183 0.04188377
 0.0405414  0.06108068 0.04188377 0.04188513 0.04188377 0.05537478
 0.04960939 0.04188377 0.06108071 0.03810018 0.0556232  0.04188377
 0.03167876 0.04073934 0.04178787 0.04188377 0.0405414  0.04188376
 0.04088188 0.04188377]
tr_loss:[0.02133059 0.0195451  0.02133058 0.02133058 0.033279   0.02133058
 0.02030374 0.02112876 0.02133058 0.02133059 0.02030374 0.02133058
 0.02133058 0.01995614 0.01912569 0.02133059 0.02133059 0.0275783
 0.0220983  0.02133276 0.02133058 0.02133059 0.02030374 0.02133059
 0.02133059 0.02030374 0.03261105 0.02133058 0.02133058 0.03028237
 0.02030374 0.02133059 0.033175   0.03358855 0.02031063 0.02133059
 0.02133058 0.02363043 0.02030369 0.0220983  0.02133059 0.02999418
 0.03028105 0.02128968 0.02757831 0.03028231 0.02133058 0.03317466
 0.02133058 0.02133058]
tr_loss:[0.01443315 0.01443323 0.01443315 0.0198257  0.00923152 0.01443315
 0.01352231 0.01982569 0.01443365 0.02028705 0.01893491 0.01443315
 0.01443288 0.01446239 0.01808745 0.01443316 0.01443315 0.01443315
 0.01443315 0.01443315 0.01443315 0.01443315 0.01953751 0.01443315
 0.01974948 0.02368736 0.02028738 0.0193362  0.01443315 0.00998181
 0.01993096 0.02028738 0.02028738 0.01993096 0.01443313 0.02038475
 0.01808749 0.00923153 0.01904513 0.00923152 0.00923152 0.01443315
 0.00923152 0.01443315 0.01443315 0.01443315 0.01443315 0.0202569
 0.01443313 0.01443315]
tr_loss:[0.01570815 0.01570815 0.01570815 0.00917706 0.01570815 0.01946293
 0.01567456 0.01979657 0.01890528 0.01570815 0.01946293 0.01570809
 0.01570815 0.02212303 0.01892404 0.01892404 0.01979657 0.01570236
 0.01775841 0.01570923 0.01570815 0.01570815 0.01570817 0.01314608
 0.01892404 0.01629172 0.01570815 0.01570815 0.01862045 0.01892404
 0.00917707 0.01570815 0.01570815 0.01570815 0.01570815 0.01571028
 0.01570815 0.01570815 0.01570818 0.01543842 0.01570814 0.01979657
 0.01940879 0.01570815 0.01570815 0.01776133 0.01800562 0.01946292
 0.01800707 0.01579861]
tr_loss:[0.01750383 0.017504   0.01750293 0.01750383 0.02004192 0.02013213
 0.01750383 0.01742313 0.01988214 0.01750383 0.01750383 0.02004192
 0.01749079 0.01858319 0.0185831  0.02086433 0.01873536 0.01988124
 0.01750383 0.02266748 0.01750383 0.01019413 0.01749716 0.01019413
 0.0175603  0.01750383 0.01750383 0.01750478 0.01873536 0.01750383
 0.02013214 0.02013212 0.01750383 0.02004192 0.01988214 0.01996705
 0.01019413 0.02086433 0.02086433 0.01750379 0.01750383 0.01019413
 0.01750383 0.01750383 0.01750383 0.02266747 0.01988213 0.02267279
 0.01750383 0.01750382]
tr_loss:[0.02425337 0.01640024 0.0199868  0.01956854 0.01640023 0.01601655
 0.00907918 0.01998506 0.00907918 0.01640024 0.01640025 0.0204469
 0.01640025 0.01640025 0.01640053 0.02224755 0.01987287 0.02070244
 0.01640033 0.01640025 0.01640025 0.01776044 0.01640025 0.02224749
 0.01640024 0.01640025 0.01640025 0.02224752 0.01640025 0.01640081
 0.01640455 0.02069532 0.01640023 0.01640025 0.01640024 0.02070244
 0.01640024 0.01640025 0.01576463 0.0204469  0.01640025 0.01640871
 0.01801014 0.02070244 0.01738387 0.0090784  0.01640024 0.01652561
 0.00907918 0.01640025]
tr_loss:[0.01902078 0.0140175  0.01401653 0.00734974 0.0140175  0.0140175
 0.0140175  0.0140175  0.01946981 0.02010836 0.00734974 0.02010836
 0.01351516 0.01405741 0.01452563 0.01401748 0.0140175  0.0140175
 0.01401751 0.0140175  0.00734974 0.0140175  0.0140175  0.0140175
 0.01526371 0.01916893 0.0140175  0.0140175  0.01916895 0.01958589
 0.0140175  0.01649764 0.01916895 0.0140175  0.02267377 0.0218075
 0.01706641 0.0134108  0.0140175  0.0140175  0.0140175  0.01766746
 0.01649798 0.0140175  0.01371445 0.0140175  0.0140175  0.0140175
 0.0140175  0.01401751]
tr_loss:[0.01223797 0.0072659  0.01223781 0.01223781 0.0119871  0.01223781
 0.01223781 0.01786412 0.01720529 0.01223781 0.01223781 0.01935514
 0.01223852 0.0072659  0.0072659  0.01223781 0.01223781 0.01720713
 0.01935514 0.01223781 0.01409204 0.01939349 0.01223781 0.01223781
 0.01761995 0.01223781 0.01720526 0.01223512 0.01980488 0.01409204
 0.01223781 0.01063408 0.01786513 0.01223781 0.01409203 0.01223781
 0.01223781 0.0072659  0.01409203 0.01295784 0.01409204 0.0122377
 0.0072659  0.01223781 0.01935514 0.01784736 0.01223781 0.01223781
 0.0122378  0.01223781]
tr_loss:[0.01624877 0.00898994 0.00898994 0.00898994 0.01169956 0.00884514
 0.00898994 0.00898994 0.00898995 0.01806578 0.01700188 0.01715473
 0.00898994 0.01493128 0.01169956 0.00898989 0.00898994 0.01624877
 0.00898994 0.00898994 0.00898994 0.01556549 0.01023555 0.00588246
 0.00899002 0.01493127 0.00898994 0.01700188 0.01148616 0.01564306
 0.00898994 0.00898994 0.00898997 0.00904683 0.00898994 0.01800779
 0.00898994 0.00898994 0.01626291 0.00898994 0.00858821 0.00898994
 0.00898994 0.00898802 0.00898994 0.00899379 0.00858821 0.00898994
 0.00898994 0.01493128]
tr_loss:[0.0173538  0.00482256 0.013845   0.00482257 0.01317856 0.01524395
 0.00482257 0.00482257 0.01149427 0.00482257 0.0094675  0.0173538
 0.00482256 0.01427043 0.01344215 0.01524396 0.01735382 0.01384759
 0.00946691 0.00482397 0.00471042 0.00545411 0.01524395 0.00482256
 0.01384745 0.00482257 0.0138476  0.01468383 0.00482257 0.0094675
 0.00482257 0.00848414 0.0142687  0.00482256 0.00482257 0.01480455
 0.00760744 0.00482257 0.00482266 0.00482256 0.00482253 0.0138476
 0.01152107 0.00760877 0.00482257 0.00482257 0.00482257 0.00482257
 0.0094675  0.01524395]
tr_loss:[0.00544223 0.00544223 0.00544223 0.01222444 0.00544223 0.00544223
 0.00544223 0.00747882 0.00544223 0.00544223 0.00793427 0.00544227
 0.00544224 0.00544223 0.01222444 0.00544223 0.00544225 0.02536039
 0.00544223 0.00544326 0.01373063 0.00544211 0.00544223 0.01372937
 0.0253604  0.00544223 0.01222444 0.00793451 0.01292665 0.01456736
 0.01622822 0.00544223 0.00544223 0.01344357 0.00544223 0.00544223
 0.00544223 0.01292665 0.00544223 0.00544223 0.02536039 0.00544223
 0.01375543 0.01372642 0.00544224 0.00544223 0.00544223 0.01377307
 0.00544224 0.01754085]
tr_loss:[0.00392096 0.00683107 0.0039211  0.00392096 0.00392096 0.00392096
 0.00393193 0.00725611 0.00392096 0.00392096 0.0060792  0.00392096
 0.00760634 0.01822972 0.00668305 0.00392096 0.00392097 0.00723253
 0.00392097 0.00382697 0.00757039 0.00639665 0.00391808 0.00392096
 0.00392096 0.00342607 0.00639665 0.00890572 0.00723915 0.00392097
 0.00401223 0.00392096 0.01822972 0.00392096 0.01822972 0.00557421
 0.00392096 0.00392096 0.00392096 0.01822971 0.00756792 0.00392096
 0.00342607 0.00639665 0.01822972 0.00878296 0.00723897 0.00392096
 0.00639665 0.00392096]
tr_loss:[0.00576599 0.005766   0.005766   0.00874674 0.005766   0.00580028
 0.00874676 0.00576342 0.00247207 0.005766   0.005766   0.005766
 0.005766   0.00197174 0.00576546 0.00603738 0.005766   0.00576601
 0.00874676 0.00861202 0.005766   0.00267688 0.00655744 0.005766
 0.00378741 0.00874675 0.00631813 0.00861195 0.00861195 0.005766
 0.00267688 0.005766   0.00564246 0.00267688 0.005766   0.005766
 0.005766   0.005766   0.00575886 0.00242213 0.01080168 0.005766
 0.00553565 0.00257017 0.00652761 0.00555893 0.005766   0.00762022
 0.00363334 0.00267688]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4200 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4201, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4201 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4202, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4202 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4203, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4203 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4204, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4204 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4205, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4205 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4206, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4206 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4207, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4207 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4208, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4208 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4209, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4209 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4210, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4210 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4211, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4211 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4212, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4212 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4213, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4213 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4214, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4214 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4215, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4215 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4216, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4216 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4217, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4217 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4218, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4218 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4219, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4219 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4220, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4220 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4221, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4221 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4222, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4222 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4223, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4223 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4224, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4224 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4225, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4225 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4226, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4226 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4227, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4227 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4228, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4228 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4229, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4229 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4230, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4230 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4231, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4231 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4232, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4232 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4233, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4233 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4234, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4234 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4235, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4235 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4236, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4236 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4237, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4237 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4238, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4238 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4239, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4239 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4240, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4240 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4241, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4241 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4242, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4242 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4243, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4243 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4244, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4244 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4245, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4245 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4246, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4246 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4247, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4247 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4248, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4248 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4249, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4249 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4250, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4250 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4251, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4251 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4252, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4252 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4253, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4253 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4254, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4254 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4255, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4255 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4256, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4256 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4257, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4257 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4258, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4258 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4259, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4259 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4260, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4260 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4261, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4261 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4262, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4262 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4263, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4263 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4264, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4264 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4265, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4265 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4266, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4266 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4267, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4267 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4268, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4268 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4269, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4269 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4270, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4270 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4271, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4271 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4272, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4272 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4273, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4273 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4274, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4274 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4275, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4275 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4276, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4276 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4277, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4277 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4278, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4278 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4279, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4279 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4280, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4280 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4281, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4281 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4282, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4282 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4283, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4283 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4284, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4284 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4285, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4285 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4286, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4286 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4287, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4287 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4288, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4288 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4289, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4289 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4290, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4290 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4291, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4291 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4292, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4292 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4293, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4293 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4294, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4294 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4295, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4295 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4296, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4296 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4297, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4297 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4298, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4298 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4299, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4299 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4300, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-4200
text_input.shape
(4300, 14400)
learning_input_tmp.shape
(4300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4300, 80)
learning_output.shape
(750, 80)
Model: "sequential_87"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_87 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2293967 1.2900918 1.2900918 1.2129104 1.2293875 1.229397  1.2293968
 1.2304943 1.3147962 1.2403842 1.3147961 1.2294086 1.2294137 1.2900918
 1.2293966 1.2293967 1.2439463 1.2400366 1.2293967 1.2293966 1.2357659
 1.2333816 1.2557019 1.2293966 1.2293966 1.2293968 1.2293967 1.3148009
 1.2436364 1.2293967 1.2293968 1.2598112 1.2294053 1.2891126 1.2403841
 1.3147962 1.2900915 1.243567  1.2900908 1.2559879 1.2334045 1.2900915
 1.2293968 1.2293968 1.2335781 1.2435695 1.229397  1.2293959 1.2293968
 1.2293968]
tr_loss:[0.6620194  0.6581313  0.6577595  0.65625453 0.64511704 0.65806246
 0.65806246 0.6580626  0.6540517  0.65806246 0.65806246 0.6580696
 0.65156925 0.6580625  0.65793276 0.68752575 0.65806246 0.6620602
 0.65806246 0.65806246 0.65806246 0.64420235 0.6533453  0.66206026
 0.64369667 0.67930514 0.66206014 0.67895925 0.6436966  0.6580625
 0.6580626  0.6580556  0.66206014 0.6436967  0.6620602  0.68752575
 0.6580652  0.6580626  0.65806246 0.65806246 0.6436967  0.66206026
 0.65616333 0.65807825 0.66206026 0.6465012  0.66206014 0.6580626
 0.6530625  0.6772778 ]
tr_loss:[0.30558106 0.33027878 0.31149426 0.3114942  0.31149426 0.33027878
 0.33913827 0.3068301  0.30739555 0.33027878 0.3055797  0.31800777
 0.31149417 0.32285133 0.31123042 0.30683008 0.30683008 0.31317902
 0.33027878 0.32286993 0.33027878 0.31149426 0.33027878 0.30557966
 0.31149426 0.31800777 0.30683097 0.30874187 0.32285136 0.30969942
 0.31800783 0.33027878 0.32264748 0.31149423 0.30793434 0.32285133
 0.30683017 0.32284778 0.31055078 0.31149426 0.32285136 0.32457376
 0.32285133 0.3370317  0.3228514  0.31800777 0.31414467 0.32285133
 0.3228514  0.32285136]
tr_loss:[0.19116446 0.19116446 0.1911645  0.19112083 0.19116446 0.18447533
 0.18149358 0.17631705 0.19075754 0.19268616 0.19116446 0.19116446
 0.176317   0.19119777 0.18023732 0.19116446 0.19116446 0.1907576
 0.1911645  0.18446603 0.19116445 0.19116445 0.19116445 0.19116445
 0.17631702 0.18023726 0.19116448 0.19116509 0.19075754 0.19116446
 0.19075759 0.19116446 0.176317   0.19045664 0.1911644  0.19116446
 0.176317   0.19116445 0.1911645  0.19116446 0.19116445 0.19075759
 0.1907576  0.18023737 0.176317   0.19116446 0.18160775 0.18446869
 0.19075783 0.19116451]
tr_loss:[0.07910801 0.07754393 0.07672867 0.07935005 0.08595787 0.07672866
 0.07912239 0.07912239 0.0791224  0.07672868 0.07912238 0.08337117
 0.0837004  0.07912239 0.07912238 0.07914861 0.07912257 0.07862182
 0.07672866 0.07912239 0.07912239 0.07912238 0.07916176 0.07912239
 0.07912238 0.07912239 0.08370042 0.07912274 0.07912239 0.08370043
 0.07912238 0.0791224  0.07912238 0.07912238 0.07672868 0.07912239
 0.07912238 0.07912238 0.07912239 0.0837004  0.08202313 0.07799475
 0.08370043 0.08370043 0.07912239 0.06764241 0.06764241 0.07672866
 0.07912239 0.06764241]
tr_loss:[0.02621461 0.02621459 0.02517025 0.02537333 0.02537333 0.02537603
 0.02537333 0.03237768 0.02537334 0.02537334 0.03446289 0.02667934
 0.03081004 0.02537331 0.02537333 0.02621459 0.03237768 0.02537339
 0.02537334 0.02545148 0.02537333 0.01407855 0.02621461 0.02537333
 0.02537334 0.02537333 0.01407854 0.01407855 0.02621461 0.02537333
 0.03081002 0.03415548 0.03415548 0.0262146  0.02537333 0.03237768
 0.02537334 0.03415548 0.02537335 0.02621459 0.02537334 0.01407855
 0.02516898 0.03354172 0.03439439 0.02537333 0.01407855 0.02537333
 0.01407854 0.02621461]
tr_loss:[0.01451232 0.0145127  0.02256916 0.01471459 0.02256916 0.01451233
 0.02275904 0.01451233 0.01451232 0.0147147  0.01451232 0.0145123
 0.01451232 0.00383569 0.01455421 0.0145121  0.02275905 0.01451191
 0.02063801 0.01451232 0.01451232 0.01891265 0.01451232 0.01451232
 0.00383569 0.02273001 0.01471469 0.01891268 0.01448899 0.01451232
 0.01451232 0.01490513 0.01471468 0.01451228 0.01451232 0.0147147
 0.01451361 0.01480752 0.01451232 0.01451242 0.02159169 0.01451232
 0.01451232 0.02256916 0.01471468 0.01451232 0.0145123  0.01451232
 0.01471467 0.01451729]
tr_loss:[0.01004301 0.01255214 0.01255214 0.01255215 0.01255265 0.01823163
 0.01481132 0.01255214 0.01112953 0.0120029  0.01695647 0.0120029
 0.01255214 0.01255214 0.01255215 0.01255214 0.01255214 0.01200271
 0.01255219 0.01255215 0.01004302 0.01257377 0.01255214 0.01255214
 0.01004301 0.01724254 0.01255215 0.01255214 0.01808614 0.01255214
 0.01255773 0.00154142 0.01255214 0.0199278  0.01255214 0.01255214
 0.01255214 0.01255214 0.0165803  0.01255214 0.0120029  0.01987996
 0.01255215 0.00154142 0.01255214 0.01255214 0.01255214 0.01255215
 0.01255214 0.01255214]
tr_loss:[0.01163663 0.00575419 0.01490753 0.01254306 0.01437705 0.01163663
 0.01254306 0.01254306 0.01254316 0.01163663 0.01163663 0.00833004
 0.01488189 0.01254306 0.01254306 0.0057547  0.00100728 0.0057547
 0.01437723 0.01490753 0.01380184 0.01163663 0.01254306 0.00575469
 0.01254306 0.01490753 0.01254306 0.01254306 0.01254306 0.01253985
 0.01102686 0.00100727 0.01437723 0.0057547  0.01488189 0.0057547
 0.01254306 0.01163663 0.01254306 0.01446385 0.00576684 0.01490753
 0.01254306 0.01254306 0.01254306 0.01254306 0.01212823 0.01254306
 0.01254306 0.0057547 ]
tr_loss:[0.01076354 0.01444956 0.01444957 0.01444956 0.01214733 0.0142567
 0.01444956 0.01444956 0.01444956 0.01965493 0.01444956 0.01214733
 0.01444956 0.0027518  0.01080992 0.01444956 0.01444956 0.01444957
 0.01444956 0.01444956 0.01444956 0.01444956 0.01444956 0.01444957
 0.0123239  0.01444956 0.01214733 0.01444986 0.01347447 0.01408291
 0.01302964 0.01250426 0.01444956 0.01444899 0.0027518  0.01214733
 0.01444956 0.01456636 0.01135147 0.01444956 0.00302318 0.01444956
 0.01444956 0.00302318 0.0142567  0.00302318 0.01444956 0.01444956
 0.01214733 0.01444956]
tr_loss:[0.00315018 0.01460983 0.00307423 0.01442101 0.01460983 0.01052771
 0.01054509 0.01460983 0.01230046 0.01460981 0.01345782 0.01460983
 0.01460983 0.01460983 0.01460979 0.0134578  0.00315018 0.01460983
 0.0146098  0.01460983 0.01442545 0.01460897 0.00315018 0.01460983
 0.00307423 0.01052695 0.01460983 0.01078922 0.01442545 0.01460983
 0.01460983 0.01460983 0.01460983 0.01460983 0.01442545 0.00307423
 0.01460983 0.01479069 0.01145991 0.01460983 0.00315018 0.01345301
 0.01211804 0.01460983 0.01460969 0.01460983 0.01460904 0.01460983
 0.01460983 0.01460982]
tr_loss:[0.01230185 0.01230186 0.01437151 0.00463914 0.01230186 0.01230185
 0.01326133 0.01183945 0.01230185 0.01230185 0.01230185 0.00463915
 0.01230075 0.01230185 0.00116459 0.01230186 0.00116459 0.01230185
 0.01437151 0.00463915 0.01437151 0.01230186 0.01326134 0.00479284
 0.00463914 0.01150887 0.00116459 0.01230186 0.01326134 0.01230186
 0.01230182 0.01326132 0.01223567 0.01437151 0.01230186 0.01408353
 0.01231059 0.01230185 0.01230186 0.00463914 0.01230185 0.00116459
 0.01151455 0.01230185 0.01305894 0.01337317 0.00463915 0.00463914
 0.01230186 0.00463915]
tr_loss:[0.0143291  0.00737424 0.01161262 0.01161262 0.01161949 0.01161262
 0.01161262 0.00737424 0.01161262 0.00066256 0.01105668 0.00737425
 0.00737425 0.01142291 0.00910956 0.00066256 0.00737425 0.01161262
 0.01161262 0.01564612 0.00737425 0.01417427 0.01161262 0.01154427
 0.01161262 0.00737425 0.01186855 0.00911473 0.01161262 0.00737575
 0.01161262 0.01161262 0.01105668 0.01161262 0.0158289  0.01161262
 0.01161262 0.01161262 0.01161262 0.01105668 0.00737426 0.01161262
 0.01161262 0.01161262 0.01161262 0.01161262 0.01161262 0.01161324
 0.01161262 0.01564612]
tr_loss:[0.01175419 0.01175419 0.0146887  0.01175419 0.00884668 0.01682807
 0.01583505 0.00086145 0.0169549  0.01175485 0.01175419 0.00884667
 0.0117173  0.01908876 0.01175419 0.0117542  0.01175419 0.01583641
 0.01175673 0.01172507 0.01175419 0.01127127 0.01175419 0.01175419
 0.01175419 0.01175419 0.01468872 0.01175419 0.01175419 0.00884669
 0.00884667 0.01175419 0.01175419 0.01722021 0.0117542  0.01175426
 0.01175419 0.01175419 0.00884668 0.01175419 0.01175419 0.01175419
 0.01578726 0.01175419 0.01175419 0.01127122 0.01641676 0.01583503
 0.00884668 0.01721692]
tr_loss:[0.01157107 0.00052925 0.01157107 0.01157107 0.01157107 0.01157107
 0.01157107 0.01157107 0.00764676 0.01157107 0.01157107 0.01157107
 0.01157107 0.01622623 0.01157013 0.01158087 0.01157107 0.00052925
 0.01157107 0.00052925 0.00052925 0.01157114 0.01157107 0.01090934
 0.01157107 0.01622773 0.00764675 0.01503003 0.01157105 0.01143175
 0.01157107 0.01567095 0.00764676 0.01586852 0.01157107 0.00764675
 0.01157107 0.01588619 0.01151815 0.01157107 0.00052925 0.01157107
 0.00764674 0.01567095 0.00764674 0.0114647  0.00052925 0.01157107
 0.01157107 0.01157107]
tr_loss:[0.01163188 0.01163191 0.00522507 0.01163188 0.00037511 0.01164263
 0.01210264 0.00522507 0.01163188 0.01433449 0.0116465  0.01163188
 0.01079994 0.01379389 0.01163187 0.01163187 0.01163188 0.01163188
 0.01205935 0.00522507 0.01163187 0.00037511 0.01163188 0.01163188
 0.01433449 0.01163187 0.01416915 0.01079994 0.01163287 0.01163187
 0.00522508 0.00522507 0.01163187 0.01163188 0.01163187 0.01162526
 0.01082237 0.01163188 0.01163186 0.01163188 0.01163188 0.01163187
 0.01079994 0.01163188 0.01302656 0.00522507 0.01379389 0.01163188
 0.01163188 0.00522507]
tr_loss:[0.0124763  0.00357579 0.00357578 0.0124763  0.01204112 0.0124763
 0.0124763  0.01172796 0.0124763  0.00357579 0.0124763  0.01247637
 0.0124763  0.01246311 0.00114873 0.01245205 0.00357552 0.00114873
 0.0112666  0.0124763  0.0124763  0.0124763  0.01371046 0.01247877
 0.00357579 0.0124763  0.00357579 0.0124763  0.01204113 0.01365171
 0.01245205 0.0124763  0.00357579 0.00357579 0.01278211 0.01145276
 0.0124763  0.01204086 0.01247623 0.01247629 0.00357579 0.00114873
 0.00357579 0.00114873 0.00357579 0.0124763  0.00357579 0.01336963
 0.0124763  0.00357579]
tr_loss:[0.01345394 0.01345393 0.0021841  0.00311245 0.01241802 0.01345394
 0.00218409 0.01120997 0.01377426 0.01199973 0.01241801 0.01034007
 0.01241804 0.01345393 0.01099258 0.01345393 0.0121154  0.01345393
 0.01345394 0.01345393 0.01377426 0.01345394 0.013454   0.01345393
 0.01209731 0.01345394 0.00311388 0.00311388 0.01342656 0.01345392
 0.01345393 0.01377426 0.0021841  0.01345394 0.00311388 0.00311387
 0.01216089 0.01345393 0.01345394 0.01348813 0.01100494 0.01345393
 0.01345393 0.01345373 0.0021841  0.01345393 0.01216091 0.01345455
 0.00311388 0.01211542]
tr_loss:[0.01256282 0.01355031 0.01256282 0.01256282 0.01256282 0.01114404
 0.01256279 0.01117173 0.01256282 0.00352599 0.00352599 0.00352599
 0.01256282 0.00144919 0.01271519 0.01256282 0.00352599 0.00352599
 0.00144919 0.01202745 0.01256179 0.0124706  0.01269878 0.01256282
 0.00352599 0.00352599 0.00988097 0.01256282 0.01256282 0.01117173
 0.01257984 0.01256282 0.00144919 0.01256282 0.01256281 0.01256282
 0.0124706  0.01256282 0.01150883 0.00352598 0.01276318 0.01256282
 0.01256282 0.01256285 0.01256282 0.0125138  0.01256282 0.00352599
 0.01256282 0.01256282]
tr_loss:[0.01117375 0.01117375 0.01117375 0.01117375 0.01117375 0.01205392
 0.01375061 0.01117375 0.01105746 0.01375061 0.00506112 0.01117375
 0.01117385 0.01373605 0.01117469 0.01117375 0.01117375 0.01372959
 0.01117375 0.01117375 0.01117363 0.00024998 0.01117373 0.01117375
 0.01373549 0.00506113 0.01373604 0.01107691 0.01113499 0.01117375
 0.01117394 0.01117375 0.01117375 0.01117375 0.01117375 0.01373605
 0.01124883 0.01117375 0.00024998 0.01117375 0.01117528 0.01117375
 0.00506112 0.01375061 0.0098509  0.01373605 0.01402525 0.01117375
 0.0098509  0.00024998]
tr_loss:[0.01608706 0.01508648 0.01080826 0.01669769 0.01080826 0.00012596
 0.01484029 0.00764009 0.01080136 0.01497652 0.01080829 0.01080826
 0.01488478 0.01080826 0.01080826 0.00944408 0.0094441  0.01080826
 0.01080826 0.01080826 0.01080826 0.01484039 0.01080829 0.01080826
 0.00976353 0.01080826 0.01080826 0.00012596 0.00763992 0.00012596
 0.01080826 0.01146064 0.01488476 0.01080826 0.01080826 0.0108108
 0.01083567 0.01488475 0.00763992 0.01080826 0.01080826 0.01080826
 0.01080826 0.01637162 0.01080826 0.01080826 0.01564148 0.00012596
 0.01088192 0.01637162]
tr_loss:[0.01096635 0.00045621 0.00882059 0.01553106 0.01096637 0.00907779
 0.01619579 0.01634831 0.01372864 0.01156983 0.01773253 0.00045621
 0.00045621 0.01746359 0.01096637 0.00907777 0.01746539 0.01096638
 0.01096635 0.01096637 0.01049749 0.01096637 0.01096637 0.00892824
 0.0163483  0.01096637 0.01169085 0.01096637 0.0109644  0.00907778
 0.01096637 0.01096638 0.01634832 0.01096637 0.01096637 0.00045621
 0.01096637 0.01096637 0.01096637 0.01619591 0.01096637 0.01096637
 0.01096637 0.01096637 0.01096637 0.00907778 0.01096637 0.01096704
 0.01096637 0.01096637]
tr_loss:[0.01084437 0.01084437 0.00801224 0.01084437 0.01084437 0.01084437
 0.00801223 0.00801224 0.01648749 0.01084437 0.01084437 0.01537732
 0.01677654 0.01084436 0.00929727 0.01521495 0.01084436 0.00930173
 0.00801217 0.00801224 0.00801223 0.01084436 0.01084437 0.01069694
 0.01648749 0.01677639 0.01084436 0.01084437 0.01084436 0.01084436
 0.01128322 0.0164875  0.01084437 0.01084437 0.00024122 0.01537665
 0.01084437 0.01083982 0.0144283  0.01537587 0.00801224 0.01084436
 0.01084437 0.01497302 0.01084436 0.01497302 0.01084437 0.01538038
 0.01084437 0.01084437]
tr_loss:[0.01102355 0.01102355 0.00955228 0.01380779 0.01102355 0.00955228
 0.01047191 0.01441165 0.01102354 0.00540853 0.01294809 0.01102355
 0.00556218 0.01294656 0.01102355 0.01102355 0.01102355 0.0094464
 0.01102355 0.01102634 0.01102355 0.00019722 0.01102352 0.0141096
 0.01102355 0.01294231 0.0110233  0.01102355 0.01102355 0.01550364
 0.01103112 0.01102355 0.01410959 0.01102355 0.01102355 0.01102355
 0.01102355 0.01102355 0.0141096  0.01076822 0.00019722 0.00540852
 0.01410959 0.01410959 0.01106384 0.01102355 0.00540852 0.00540853
 0.01102355 0.01102355]
tr_loss:[0.01346563 0.01346563 0.01210893 0.01210893 0.01210892 0.01210893
 0.01210893 0.01210893 0.01267186 0.01210893 0.01210893 0.01210892
 0.01210893 0.01346563 0.01210893 0.00373982 0.01139996 0.01210893
 0.01210843 0.00973331 0.01064335 0.01210893 0.01197403 0.00373982
 0.0011341  0.01210893 0.01659695 0.0011341  0.01201338 0.01210891
 0.01210895 0.01641491 0.01210893 0.01210893 0.01346563 0.01663836
 0.01210889 0.01294377 0.01267186 0.01210893 0.01210893 0.01224634
 0.01210893 0.00373981 0.0011341  0.01214795 0.01032232 0.01149384
 0.01294375 0.01210893]
tr_loss:[0.01111932 0.0125752  0.00152017 0.0125752  0.01735844 0.00336021
 0.0125752  0.00336021 0.01354678 0.01257516 0.01235013 0.00336082
 0.01118816 0.0125752  0.0125752  0.0125752  0.0125752  0.01110342
 0.01235013 0.0125752  0.0125752  0.01153336 0.01118815 0.00336021
 0.00336021 0.01235013 0.01354678 0.0125752  0.01262925 0.0125752
 0.01354678 0.0125752  0.01254611 0.00152017 0.0125752  0.0109933
 0.01257518 0.0125752  0.0125752  0.01118815 0.01354677 0.0125752
 0.0125752  0.01258009 0.0125752  0.01257357 0.0125752  0.0125752
 0.01257521 0.01235013]
tr_loss:[0.00372305 0.00372304 0.01193882 0.01193882 0.01193882 0.00372305
 0.00084522 0.01193936 0.01258026 0.01360817 0.00372304 0.01193882
 0.01193882 0.01258025 0.01679409 0.00084522 0.00372304 0.01193882
 0.00084522 0.00372305 0.01193882 0.01075331 0.01193866 0.00084522
 0.01193882 0.01192904 0.01258026 0.00372304 0.01258026 0.01193882
 0.01193882 0.01258025 0.01258017 0.01075422 0.01152897 0.01193882
 0.01075329 0.01193882 0.00084522 0.01193919 0.01193879 0.01193882
 0.01193882 0.01193882 0.00372304 0.0116171  0.00084522 0.01248426
 0.01193882 0.0119388 ]
tr_loss:[0.01405097 0.01135463 0.01135471 0.00026637 0.01135463 0.01514719
 0.01135463 0.01144875 0.01135463 0.01135463 0.01135463 0.00026637
 0.01405097 0.01135463 0.01135463 0.01135463 0.00475407 0.00026637
 0.01135374 0.01135657 0.01135463 0.01340826 0.01135462 0.01135463
 0.01135463 0.01719726 0.01381735 0.01340826 0.01135463 0.01135463
 0.01135463 0.01135463 0.01135463 0.00475099 0.01135463 0.01135497
 0.00026637 0.01135463 0.00475407 0.01135488 0.01247817 0.01135463
 0.01135463 0.00475408 0.00475407 0.01060273 0.01135463 0.00475407
 0.00475408 0.01405098]
tr_loss:[0.00989511 0.01325987 0.01441634 0.01116391 0.01468007 0.00013699
 0.01032777 0.00592967 0.00592966 0.00592965 0.01116391 0.01032797
 0.01116376 0.00905017 0.01116391 0.01349978 0.01116391 0.00592967
 0.01116391 0.01032802 0.01116391 0.01116391 0.01355595 0.01468007
 0.00013699 0.00013699 0.00013699 0.01032797 0.00592965 0.00592966
 0.00908899 0.01113042 0.01116391 0.01116391 0.00592966 0.01116347
 0.01116391 0.0111516  0.01468007 0.01116391 0.01116391 0.01116391
 0.01116391 0.01116382 0.01116391 0.01468007 0.01468007 0.00013699
 0.00592967 0.00592967]
tr_loss:[0.00011191 0.01445959 0.01121523 0.01108273 0.01108273 0.01108273
 0.01108928 0.01108273 0.00597361 0.01108273 0.01108273 0.00597361
 0.00597361 0.00011191 0.01108273 0.014445   0.01346862 0.01108279
 0.00531473 0.00597362 0.01108273 0.01108273 0.01108273 0.01466156
 0.01108273 0.00597361 0.00597362 0.01108273 0.01020908 0.00597361
 0.01108273 0.00598724 0.01108272 0.01594994 0.01108273 0.01108273
 0.01466155 0.01108273 0.01108273 0.00597361 0.0110517  0.01108273
 0.01108273 0.01108273 0.01462083 0.00597362 0.00011191 0.01063405
 0.01108273 0.01480829]
text_input.shape
(4300, 14400)
learning_input_tmp.shape
(4300, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4300, 80)
learning_output.shape
(750, 80)
Model: "sequential_88"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_88 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.7676313 1.7676312 1.7676315 1.7676281 1.7672634 1.7676312 1.7605984
 1.7676312 1.7507519 1.7676312 1.7507521 1.7676313 1.7606928 1.7543266
 1.7676313 1.7696941 1.7603861 1.7676313 1.7676313 1.7676327 1.7676312
 1.7676313 1.7523091 1.7507519 1.7606926 1.7430756 1.7544922 1.7616383
 1.7676313 1.7675337 1.7676313 1.7676313 1.757151  1.7676313 1.7550507
 1.7507521 1.7570473 1.7572134 1.760026  1.7556374 1.7671067 1.760026
 1.7703661 1.7507521 1.7507579 1.7676313 1.7676313 1.7676315 1.7676313
 1.7676313]
tr_loss:[1.3400463 1.3403552 1.3403552 1.3403552 1.3574215 1.3403552 1.3403553
 1.3574216 1.3574216 1.3339313 1.3403839 1.3402836 1.3414465 1.3473127
 1.3403552 1.3403552 1.3403553 1.3559144 1.3389461 1.3574216 1.3403552
 1.3403552 1.3422238 1.3574226 1.3403552 1.3403552 1.3405203 1.3657209
 1.3403553 1.3442059 1.3457198 1.365721  1.3415025 1.3403553 1.3574215
 1.3403552 1.3657205 1.3403553 1.3403553 1.3442078 1.3657209 1.3389807
 1.3574216 1.3404232 1.3657209 1.3403553 1.3384539 1.3403552 1.3348888
 1.3441837]
tr_loss:[0.7604419  0.776803   0.75742143 0.7605485  0.7574215  0.7574214
 0.76044166 0.7574214  0.7574214  0.76044166 0.7574215  0.76044166
 0.75729036 0.7574214  0.75398713 0.7502748  0.75742143 0.7574214
 0.7574214  0.75742143 0.7539872  0.76044166 0.76044166 0.7574185
 0.75741285 0.77680314 0.7616452  0.7574214  0.75742143 0.7573261
 0.7561256  0.7574214  0.7574214  0.7768029  0.7574214  0.7604417
 0.75742143 0.7539872  0.7586884  0.75581336 0.7581811  0.77680296
 0.7574214  0.76044166 0.776803   0.76044166 0.75742143 0.7574214
 0.7574214  0.7574214 ]
tr_loss:[0.40862203 0.4137028  0.40862203 0.40867144 0.40862197 0.40916044
 0.40916047 0.40862197 0.40862197 0.42164612 0.42164618 0.40862203
 0.40862197 0.40862197 0.41371956 0.40916038 0.41248503 0.42972344
 0.40862203 0.4146077  0.40862197 0.40916047 0.40862203 0.40862197
 0.40862197 0.4143668  0.40862212 0.40862203 0.40862197 0.40862203
 0.40862212 0.40862197 0.42164612 0.414606   0.41473716 0.40916044
 0.41249427 0.40916044 0.40862197 0.41452402 0.42164612 0.40862197
 0.40862203 0.42972344 0.40862197 0.40862197 0.41967422 0.40862197
 0.40862197 0.4086094 ]
tr_loss:[0.26173815 0.27295485 0.26173815 0.26173818 0.26173815 0.26173818
 0.2715498  0.26282912 0.27295485 0.27154955 0.26173815 0.26282912
 0.2617175  0.26173815 0.26173812 0.27362686 0.26173815 0.26639122
 0.26173815 0.27295485 0.26639122 0.26285687 0.26173815 0.27295485
 0.2704939  0.27295485 0.27154976 0.27323464 0.26173815 0.26173815
 0.26173815 0.27295446 0.26173818 0.26407647 0.26173815 0.2620657
 0.2695374  0.26173818 0.26173815 0.26965755 0.26173815 0.26173815
 0.26173815 0.27295482 0.26173815 0.26244178 0.26173815 0.26173815
 0.26173815 0.26965755]
tr_loss:[0.21090321 0.21058555 0.21217766 0.2105855  0.21014038 0.21217766
 0.21058552 0.21058555 0.21058555 0.21014038 0.21014039 0.21014039
 0.21058555 0.21176401 0.21058555 0.20826776 0.21135092 0.21058555
 0.21128759 0.21058555 0.21058555 0.21058555 0.2173647  0.21135099
 0.21014038 0.2173647  0.21058555 0.21058555 0.21058555 0.21058555
 0.21058552 0.2100834  0.21058555 0.21217763 0.21014038 0.21057466
 0.21058555 0.21008125 0.21217766 0.21008334 0.21008337 0.21217766
 0.21061802 0.21217766 0.211309   0.21058555 0.21058555 0.20669541
 0.21058555 0.21014039]
tr_loss:[0.18321925 0.18041071 0.1852705  0.18303101 0.183031   0.18492387
 0.18041071 0.17898822 0.18041073 0.18780252 0.18492715 0.18492717
 0.18780759 0.18492715 0.18492715 0.18492715 0.18492715 0.18492715
 0.18492717 0.18470874 0.18698366 0.18493089 0.18492775 0.17898822
 0.18492717 0.183031   0.18303101 0.18492715 0.18492214 0.18492715
 0.1842654  0.18492715 0.18492717 0.18780266 0.18492961 0.18492717
 0.18492718 0.18492715 0.18492717 0.18780267 0.18780266 0.17898867
 0.18492715 0.17898822 0.17898823 0.18492715 0.18492715 0.18492715
 0.18492717 0.18426539]
tr_loss:[0.13809343 0.1367187  0.13672207 0.1331031  0.13809171 0.13809171
 0.13809171 0.13809171 0.13808362 0.13809171 0.13693616 0.1391182
 0.13823366 0.13831297 0.13814685 0.13708548 0.13809171 0.13809171
 0.13951686 0.13809171 0.13809174 0.13809171 0.13809171 0.1318007
 0.13672204 0.13180068 0.13812247 0.13809171 0.13809171 0.13180068
 0.13809171 0.13809171 0.13809173 0.13480899 0.13492131 0.13809171
 0.13809271 0.13180068 0.13180067 0.13809171 0.13809171 0.13809168
 0.13180065 0.13180068 0.13185558 0.13180067 0.1318007  0.1331031
 0.13809171 0.13180067]
tr_loss:[0.1072401  0.10724008 0.10791379 0.10919271 0.10489474 0.11032176
 0.10791372 0.10791373 0.10992781 0.10791371 0.10791646 0.10489477
 0.10791372 0.10791373 0.1072401  0.10791373 0.1099278  0.10489474
 0.10919279 0.10791372 0.10791371 0.10791373 0.10791373 0.11080687
 0.10489476 0.10646641 0.10791372 0.10791372 0.10791373 0.11032133
 0.11044461 0.1064664  0.10261543 0.10791373 0.10791371 0.10791373
 0.10791372 0.10791371 0.10791372 0.10489474 0.10791372 0.10489476
 0.10791372 0.10919274 0.10791371 0.10791373 0.10489476 0.10791372
 0.10791372 0.11080392]
tr_loss:[0.08440453 0.08362546 0.08017571 0.0801757  0.0801757  0.08440453
 0.08362547 0.08440435 0.0783873  0.08017569 0.08017378 0.08430946
 0.0801757  0.08803296 0.08817756 0.07999416 0.07645153 0.08017568
 0.08017571 0.0875937  0.08362545 0.08362545 0.08798896 0.07839532
 0.08538736 0.07839644 0.08017569 0.08017581 0.08239338 0.08017569
 0.08200772 0.08438583 0.08017569 0.08017568 0.08017571 0.08440452
 0.08800331 0.08017569 0.08016433 0.0801757  0.08817752 0.08017571
 0.0801757  0.08362546 0.08017569 0.08059058 0.08017569 0.08017568
 0.08017472 0.07645155]
tr_loss:[0.06812896 0.06113451 0.06113451 0.06113448 0.05345704 0.0681416
 0.05345704 0.06015006 0.0611344  0.06812894 0.06106367 0.06812894
 0.06113449 0.06103115 0.0611345  0.06448038 0.06113448 0.06113449
 0.06113448 0.06113451 0.06113449 0.06213012 0.05345704 0.0681416
 0.06212107 0.06113449 0.06113264 0.06406675 0.06113451 0.06533646
 0.05993812 0.06113449 0.06113511 0.06113451 0.06812896 0.06212109
 0.06212108 0.05345704 0.06113451 0.06113449 0.06212108 0.06113451
 0.06113449 0.06113449 0.06533646 0.06113638 0.06113819 0.0611371
 0.06113448 0.06113448]
tr_loss:[0.06176763 0.05337319 0.06176763 0.06283993 0.06176763 0.06176763
 0.06260635 0.0680964  0.06061025 0.06230529 0.06176273 0.06176763
 0.06176763 0.06176763 0.0617677  0.06260635 0.06260635 0.06176763
 0.06176763 0.0617676  0.06910285 0.06260635 0.06209893 0.06636722
 0.06176762 0.05337318 0.06736311 0.06260635 0.05337318 0.06176735
 0.06176762 0.06176899 0.06176762 0.06260637 0.06910285 0.06910285
 0.06176763 0.06176763 0.06636723 0.06176763 0.06910286 0.06176763
 0.06061025 0.06260637 0.06866332 0.06049063 0.06176762 0.06176763
 0.06636722 0.06176762]
tr_loss:[0.05411733 0.06709979 0.06249103 0.06160884 0.06249103 0.06249103
 0.06934251 0.06249103 0.06291521 0.06934251 0.06249103 0.06464433
 0.06709979 0.06934251 0.05411733 0.05411733 0.0658263  0.06249103
 0.06709979 0.05411733 0.06249103 0.06160885 0.06248363 0.06291523
 0.06249103 0.06249103 0.06249103 0.06249103 0.06235573 0.06249103
 0.06249103 0.06249107 0.05411733 0.06249005 0.06249102 0.0693308
 0.06249242 0.06709979 0.0624911  0.06873431 0.06249095 0.06291517
 0.06249103 0.06291483 0.06873763 0.06291523 0.06249103 0.06934251
 0.06249104 0.06821004]
tr_loss:[0.06177191 0.06084681 0.06169533 0.06261978 0.06169533 0.06626175
 0.06261981 0.06261981 0.06169532 0.06169533 0.06631617 0.06261981
 0.06169532 0.06169533 0.0626198  0.06261981 0.06169532 0.0616953
 0.06169532 0.06169533 0.06169533 0.06169499 0.06169531 0.06169532
 0.05441127 0.06169533 0.06169533 0.06165688 0.05441127 0.06778191
 0.06169533 0.05441127 0.06143477 0.06169533 0.06169529 0.06840788
 0.06169529 0.06169629 0.06840788 0.06169533 0.05441127 0.06169534
 0.06169533 0.06169531 0.06169532 0.06169533 0.06180521 0.06169532
 0.06169533 0.06631617]
tr_loss:[0.05921629 0.05469392 0.0665397  0.06198433 0.05921629 0.05921628
 0.06347556 0.05921628 0.06625439 0.05999807 0.05921628 0.05921628
 0.06232436 0.0623196  0.05921629 0.06198433 0.05925737 0.05921628
 0.0662544  0.06198435 0.06198431 0.05921628 0.05469393 0.05921629
 0.05921629 0.05921629 0.05921628 0.05921629 0.05999806 0.05921628
 0.06198432 0.05935926 0.05944581 0.05921628 0.05921628 0.05921628
 0.06625441 0.05921279 0.06625441 0.05469393 0.06625441 0.05921629
 0.05921628 0.06386539 0.06347783 0.05921628 0.05921673 0.05469392
 0.06198431 0.05999808]
tr_loss:[0.05730377 0.05499033 0.0602961  0.0589445  0.06162221 0.05499033
 0.05499032 0.05499032 0.05499032 0.06029603 0.05499033 0.05499033
 0.06162222 0.05498998 0.05499033 0.05499033 0.05611333 0.0605615
 0.05499033 0.05499033 0.05499032 0.05611333 0.05499032 0.0602961
 0.05499033 0.05611331 0.0602961  0.05499032 0.05499033 0.06162223
 0.06162222 0.06162222 0.05499033 0.06114259 0.05499032 0.05499033
 0.05499031 0.05499033 0.0589445  0.05741588 0.05894451 0.05499033
 0.05499033 0.05499033 0.06029274 0.05849928 0.05611331 0.05499033
 0.05611333 0.06029609]
tr_loss:[0.05140143 0.06010104 0.05140137 0.05140143 0.05140143 0.0514014
 0.05140143 0.06370503 0.05140143 0.05140114 0.05140143 0.0559928
 0.05140143 0.05563561 0.06010104 0.06010103 0.05140163 0.05140143
 0.05140143 0.05140143 0.06010103 0.05140143 0.05140143 0.05140143
 0.05140143 0.05140143 0.05277559 0.06010103 0.05140143 0.06010103
 0.06370503 0.0513993  0.05140143 0.05563562 0.05508922 0.05140143
 0.06370503 0.05140143 0.06010103 0.05140103 0.0527754  0.05140143
 0.06370503 0.05140143 0.06010102 0.06010104 0.05520274 0.05140143
 0.05140143 0.06010105]
tr_loss:[0.05241925 0.05241924 0.06130745 0.05241924 0.05241924 0.07103394
 0.05327765 0.06130744 0.05241925 0.05241925 0.05444086 0.05241925
 0.05241924 0.05241924 0.05241925 0.05138959 0.05241924 0.05297809
 0.05241925 0.05241925 0.05241883 0.05241925 0.07103394 0.07103394
 0.05747367 0.05241925 0.05241925 0.05239477 0.05323567 0.07103394
 0.05241924 0.05809699 0.06130745 0.06130745 0.05342161 0.05241804
 0.05241924 0.05241925 0.05241923 0.05105125 0.05241924 0.07103394
 0.05412052 0.05241846 0.05693779 0.058097   0.05241924 0.05242812
 0.05240605 0.05444086]
tr_loss:[0.05334489 0.05324971 0.05799727 0.05799727 0.05324971 0.05324935
 0.05259759 0.05324971 0.05134851 0.05324971 0.05324971 0.05784302
 0.0532498  0.05325039 0.05324971 0.05404405 0.05404405 0.06686016
 0.05799728 0.05324971 0.05324971 0.05324971 0.05324971 0.05583172
 0.05324971 0.0532497  0.0513485  0.05332123 0.05311715 0.0532497
 0.05799279 0.05324971 0.05324916 0.05324971 0.05324971 0.05324971
 0.05404404 0.06686016 0.05328915 0.06686016 0.0532497  0.05839209
 0.05326975 0.0532495  0.05404406 0.05324971 0.0532497  0.05324971
 0.05324971 0.05324971]
tr_loss:[0.05544543 0.05550187 0.05550188 0.05675817 0.05544401 0.05544541
 0.05584815 0.0554461  0.05550187 0.05544542 0.05544553 0.05544543
 0.05503135 0.05579792 0.05544543 0.05544543 0.06197097 0.05550187
 0.05550187 0.05544543 0.05544543 0.05544543 0.05544543 0.05584807
 0.05544355 0.05503135 0.05550187 0.05550187 0.05544542 0.05544543
 0.05550187 0.06003563 0.05544542 0.05544543 0.06197097 0.05684312
 0.05544542 0.05544542 0.05550187 0.05544542 0.06197097 0.06197097
 0.05550187 0.05544543 0.06197097 0.05676435 0.06197097 0.05544541
 0.05544541 0.05544541]
tr_loss:[0.05511956 0.05602845 0.05654158 0.05602782 0.05602783 0.05602784
 0.056923   0.05602783 0.05602784 0.056923   0.05602419 0.05602783
 0.05602782 0.05602783 0.05647395 0.05614455 0.05602783 0.05500827
 0.05501021 0.05602682 0.05515314 0.05501021 0.05597974 0.05602784
 0.05602784 0.05602784 0.05291129 0.05515314 0.05602781 0.05602784
 0.05539472 0.05291181 0.0565417  0.05602783 0.05487615 0.05602782
 0.05602782 0.05291181 0.06069396 0.05501019 0.05515318 0.05291181
 0.05654158 0.056923   0.05692299 0.05602783 0.05291181 0.05602783
 0.05539491 0.05692299]
tr_loss:[0.05665168 0.05175465 0.05489817 0.05489878 0.05479356 0.05479356
 0.05479356 0.05484797 0.05493939 0.05484797 0.05479356 0.05484797
 0.0549394  0.05504681 0.05479356 0.05484799 0.05479356 0.05479356
 0.05355598 0.05413709 0.05504681 0.05479322 0.05479356 0.05484797
 0.05478072 0.05479357 0.05479351 0.05175465 0.05479356 0.05479356
 0.053556   0.05479354 0.05350636 0.05479356 0.05389483 0.05978629
 0.05930489 0.05175465 0.05175465 0.053556   0.05479356 0.05479356
 0.05479356 0.05479357 0.05479356 0.053556   0.05350733 0.05484767
 0.05479356 0.05175466]
tr_loss:[0.05513785 0.05656893 0.05469735 0.0537894  0.05364967 0.06056803
 0.0537894  0.05364968 0.0537894  0.05364966 0.05667566 0.05472065
 0.05364968 0.05378941 0.05656893 0.0537894  0.05378941 0.05378715
 0.0537894  0.05378943 0.05378941 0.05378941 0.0537894  0.05498261
 0.05617657 0.0537894  0.05342557 0.0537894  0.05364968 0.05534407
 0.05379259 0.0537894  0.05364967 0.05534408 0.05378941 0.05329638
 0.05534407 0.05400751 0.05378941 0.0537891  0.0537894  0.0537894
 0.05378081 0.05364968 0.0537894  0.0537894  0.05364967 0.05378941
 0.05364966 0.05378956]
tr_loss:[0.05281129 0.05281129 0.05537572 0.05281129 0.05281129 0.0528113
 0.0529533  0.05769695 0.05281129 0.05836732 0.0528113  0.0528113
 0.05691013 0.0528113  0.05723335 0.05281129 0.05281218 0.0528113
 0.05258413 0.05295331 0.05536179 0.05267248 0.05281131 0.05281129
 0.05536178 0.0583673  0.0528113  0.05281129 0.05658403 0.05281128
 0.05273011 0.05537573 0.05281129 0.0528113  0.05281129 0.0528113
 0.05618649 0.05691013 0.0583673  0.05281129 0.05281128 0.05536179
 0.05690457 0.05691014 0.05769706 0.05295331 0.05769706 0.05281129
 0.05301144 0.0528113 ]
tr_loss:[0.05169534 0.05169534 0.05963079 0.0546772  0.05870871 0.0546772
 0.05963305 0.05169534 0.05169541 0.05169534 0.06047263 0.05467721
 0.06047265 0.06047264 0.06047263 0.05169534 0.0546772  0.06047264
 0.0546772  0.05963305 0.05169533 0.05169534 0.05169534 0.05169534
 0.05169533 0.05169533 0.05169533 0.05169534 0.05169545 0.05172714
 0.05171307 0.05169535 0.05218768 0.06047264 0.05169534 0.05169534
 0.05761234 0.05169534 0.05761005 0.05169534 0.05169534 0.05169534
 0.05169534 0.06047263 0.05169534 0.05169534 0.05963305 0.05169534
 0.05169534 0.05752695]
tr_loss:[0.05113138 0.05113136 0.06343876 0.05372934 0.05113139 0.05821527
 0.06343876 0.05113138 0.05983936 0.05822574 0.06307839 0.05113139
 0.06307839 0.05763083 0.06307837 0.05821527 0.05111818 0.05983936
 0.05831493 0.05552727 0.0511314  0.05113138 0.05371669 0.05113138
 0.06307838 0.05113138 0.06343877 0.05107933 0.0511314  0.05136933
 0.06307837 0.05113138 0.05113138 0.05546972 0.0630784  0.05983941
 0.06307839 0.05113139 0.05113138 0.05113138 0.05113139 0.05113138
 0.0511271  0.05113138 0.05224915 0.05983936 0.06343876 0.06307839
 0.05372933 0.05113139]
tr_loss:[0.05047283 0.05047299 0.05047283 0.05047281 0.05047281 0.0516026
 0.05047282 0.05436314 0.05047282 0.06159266 0.06159266 0.05619607
 0.05047281 0.05747506 0.05215753 0.05051053 0.05589473 0.05047809
 0.05398766 0.05589468 0.05385312 0.05215753 0.05047283 0.05747508
 0.05047281 0.05602571 0.05434824 0.05676979 0.05270947 0.05674248
 0.05662508 0.05047283 0.05047281 0.05047283 0.05042429 0.05047283
 0.05215753 0.05047282 0.05047282 0.06159266 0.05047282 0.05047281
 0.05047282 0.05270947 0.05215754 0.05558206 0.06159265 0.06159267
 0.05047282 0.05231884]
tr_loss:[0.05035377 0.05035379 0.05376335 0.0503538  0.05035379 0.05035379
 0.05359738 0.0553149  0.06217197 0.05358781 0.05430129 0.05783332
 0.05359105 0.05068955 0.05783332 0.05035381 0.0503538  0.0503538
 0.05068955 0.0503538  0.0552579  0.05035379 0.0503538  0.05035379
 0.05359104 0.05783375 0.05278468 0.05783333 0.05783332 0.05783332
 0.0503538  0.05068955 0.0503538  0.0503538  0.0503538  0.05359174
 0.0503538  0.05783332 0.05281464 0.05035218 0.05783357 0.05030582
 0.0503538  0.05783332 0.05783332 0.05020792 0.0503538  0.0503538
 0.05035375 0.06217198]
tr_loss:[0.05183079 0.05183079 0.05183078 0.05183078 0.05183079 0.05183079
 0.0527452  0.05183079 0.05610694 0.05183078 0.0536828  0.0518308
 0.05196231 0.05104292 0.0536828  0.05183078 0.05195021 0.05399494
 0.0589703  0.05193548 0.0536828  0.05183079 0.05541378 0.0519475
 0.05183078 0.05897031 0.05190359 0.05897031 0.05183079 0.05183078
 0.05183078 0.05183079 0.0536828  0.05183079 0.05183079 0.05183079
 0.05187234 0.05183078 0.05183078 0.0536828  0.0536828  0.05170791
 0.05183079 0.05194749 0.05183078 0.05183078 0.0519475  0.05183078
 0.0560311  0.05183078]
tr_loss:[0.05409472 0.05690221 0.05409472 0.05166208 0.05219278 0.05409472
 0.05409471 0.05409472 0.05409471 0.05409472 0.05280913 0.05280913
 0.05690221 0.05233647 0.05409472 0.05409472 0.05409473 0.05166208
 0.05409471 0.05690221 0.05219277 0.05409472 0.05690221 0.05409538
 0.05280914 0.05166208 0.05233648 0.05409472 0.05409472 0.05166207
 0.0569668  0.05690221 0.05409472 0.05409472 0.05409472 0.05205296
 0.05409472 0.05166208 0.05409471 0.05409471 0.05409472 0.05409472
 0.05409472 0.05409472 0.05690221 0.0569658  0.05409472 0.05409472
 0.05407637 0.05172043]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4300 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4301, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4301 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4302, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4302 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4303, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4303 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4304, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4304 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4305, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4305 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4306, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4306 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4307, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4307 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4308, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4308 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4309, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4309 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4310, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4310 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4311, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4311 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4312, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4312 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4313, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4313 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4314, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4314 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4315, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4315 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4316, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4316 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4317, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4317 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4318, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4318 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4319, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4319 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4320, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4320 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4321, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4321 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4322, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4322 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4323, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4323 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4324, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4324 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4325, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4325 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4326, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4326 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4327, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4327 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4328, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4328 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4329, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4329 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4330, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4330 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4331, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4331 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4332, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4332 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4333, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4333 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4334, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4334 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4335, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4335 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4336, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4336 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4337, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4337 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4338, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4338 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4339, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4339 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4340, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4340 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4341, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4341 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4342, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4342 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4343, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4343 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4344, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4344 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4345, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4345 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4346, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4346 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4347, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4347 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4348, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4348 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4349, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4349 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4350, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4350 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4351, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4351 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4352, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4352 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4353, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4353 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4354, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4354 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4355, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4355 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4356, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4356 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4357, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4357 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4358, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4358 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4359, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4359 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4360, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4360 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4361, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4361 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4362, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4362 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4363, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4363 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4364, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4364 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4365, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4365 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4366, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4366 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4367, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4367 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4368, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4368 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4369, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4369 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4370, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4370 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4371, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4371 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4372, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4372 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4373, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4373 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4374, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4374 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4375, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4375 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4376, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4376 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4377, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4377 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4378, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4378 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4379, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4379 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4380, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4380 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4381, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4381 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4382, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4382 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4383, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4383 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4384, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4384 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4385, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4385 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4386, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4386 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4387, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4387 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4388, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4388 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4389, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4389 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4390, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4390 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4391, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4391 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4392, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4392 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4393, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4393 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4394, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4394 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4395, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4395 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4396, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4396 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4397, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4397 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4398, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4398 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4399, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4399 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4400, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn1-4300
text_input.shape
(4400, 14400)
learning_input_tmp.shape
(4400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4400, 80)
learning_output.shape
(750, 80)
Model: "sequential_89"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_89 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3816149 1.4622288 1.3612036 1.3612037 1.3612036 1.393866  1.4622284
 1.3612034 1.3612036 1.3822241 1.4622284 1.3612034 1.393866  1.4622282
 1.3606323 1.3635192 1.3612036 1.3612034 1.3612026 1.3460081 1.3822947
 1.3612036 1.3136091 1.3822947 1.3612034 1.3612036 1.3612037 1.3827975
 1.3938661 1.346008  1.3636554 1.3559116 1.4622283 1.4622282 1.3612036
 1.3612036 1.3867862 1.3612038 1.386566  1.393866  1.393866  1.3612036
 1.4593563 1.3612034 1.3938658 1.3612328 1.4622284 1.3612036 1.3914214
 1.4622275]
tr_loss:[0.888646   0.8798941  0.9048523  0.86189765 0.86189765 0.8798941
 0.8673825  0.8798939  0.87498015 0.8798941  0.86189777 0.8758186
 0.88160783 0.86189765 0.86738265 0.86738265 0.9048523  0.86189777
 0.8618978  0.86189777 0.86189765 0.8618978  0.86189777 0.9048523
 0.86189777 0.8618991  0.88712996 0.8759373  0.875027   0.86189765
 0.86189777 0.86189765 0.9048523  0.9048523  0.86186564 0.8750526
 0.8750534  0.8798935  0.8798941  0.8618978  0.86620694 0.8798941
 0.8618978  0.8618988  0.8798941  0.86189777 0.88727504 0.87989414
 0.9048523  0.8618978 ]
tr_loss:[0.48169938 0.4383232  0.44284344 0.48169938 0.45914    0.4519163
 0.43828326 0.45961705 0.48169932 0.43832296 0.43827304 0.44812912
 0.43832293 0.45914087 0.48169932 0.43832293 0.45914012 0.48169938
 0.48169932 0.4350732  0.43832287 0.42153835 0.48171172 0.4350732
 0.4589677  0.44993502 0.4383231  0.43832296 0.48169932 0.43832293
 0.45242053 0.43832296 0.44519216 0.44135723 0.43832302 0.43832302
 0.43832293 0.43507195 0.4413467  0.43832293 0.43832296 0.43832296
 0.45166588 0.43832293 0.43832296 0.4413465  0.43832293 0.42151958
 0.44130078 0.43832296]
tr_loss:[0.2689465  0.25108248 0.26894647 0.24694836 0.2458827  0.24499622
 0.24657468 0.25997046 0.24500468 0.24500437 0.24500468 0.24694833
 0.24694833 0.2632645  0.24500461 0.26894647 0.24694908 0.24694833
 0.24694833 0.25812176 0.2469424  0.2581218  0.2689465  0.24694833
 0.29663545 0.2631047  0.24500859 0.24694833 0.24694829 0.29663545
 0.24500465 0.24694833 0.24694833 0.24694833 0.2689465  0.24694829
 0.29663542 0.25414097 0.2689465  0.24694829 0.2450047  0.24587901
 0.24694836 0.24694836 0.29663542 0.24694836 0.2689465  0.24694833
 0.24694972 0.24694999]
tr_loss:[0.11818603 0.12455776 0.12455775 0.12455776 0.1201181  0.10469379
 0.09902084 0.10461529 0.10469379 0.10469381 0.10102244 0.10469376
 0.10469377 0.10586046 0.10469377 0.12093499 0.10469375 0.10105499
 0.10469373 0.10469379 0.10469377 0.11924167 0.10102244 0.12455776
 0.10469376 0.10469377 0.10527847 0.17703892 0.11924167 0.10469376
 0.10469379 0.10469376 0.10469375 0.10469379 0.10469377 0.118176
 0.10102244 0.11924167 0.10469375 0.10468538 0.10469379 0.17703891
 0.12455773 0.11818786 0.10469379 0.12455773 0.10102247 0.10469375
 0.12455773 0.10469375]
tr_loss:[0.02261947 0.02261947 0.02264502 0.02261947 0.02261947 0.09334729
 0.02261947 0.03430969 0.02261947 0.02261947 0.0260588  0.03472597
 0.03472596 0.02261947 0.03472596 0.02261947 0.09334705 0.03472594
 0.02578859 0.02261947 0.03414083 0.02261947 0.02262181 0.09334705
 0.02275391 0.03472645 0.02261947 0.02789702 0.03414081 0.02261947
 0.02261947 0.02261946 0.02261947 0.027897   0.03472596 0.02708945
 0.02261947 0.09334704 0.02247797 0.02261947 0.02261947 0.02242565
 0.03472596 0.02261946 0.02708806 0.03430968 0.03430968 0.02215531
 0.02595676 0.02261946]
tr_loss:[0.02033997 0.07627403 0.07627403 0.0129369  0.01293655 0.01293624
 0.02033995 0.01300319 0.01293655 0.02033995 0.0144368  0.07627403
 0.02033995 0.01293655 0.02221745 0.02033997 0.02033997 0.02267287
 0.0129621  0.02034029 0.01293655 0.02267287 0.07627403 0.07627404
 0.01293655 0.01293655 0.01293655 0.07627402 0.01293656 0.07627402
 0.01293653 0.0234149  0.01914121 0.01293655 0.01293655 0.02033997
 0.01293655 0.07627402 0.01293655 0.0191412  0.01293655 0.01293655
 0.01293655 0.02033997 0.02033995 0.01293655 0.02033995 0.01840894
 0.01293654 0.01294253]
tr_loss:[0.01517527 0.01894487 0.07145401 0.01196273 0.01597138 0.01196273
 0.01918969 0.07145401 0.01559735 0.07145401 0.01196273 0.01597137
 0.0150901  0.0143304  0.01894487 0.01705312 0.07145404 0.01597136
 0.01196273 0.01196273 0.01196273 0.01894487 0.01190711 0.01195532
 0.01196273 0.01196273 0.01944202 0.01597138 0.01196273 0.01200318
 0.01196273 0.01196273 0.01894446 0.01373466 0.01597136 0.01196273
 0.01196273 0.01196273 0.01373466 0.01597136 0.01944202 0.01313529
 0.01196273 0.01196276 0.01196273 0.01196272 0.01196273 0.01894487
 0.01196273 0.01705313]
tr_loss:[0.01151063 0.01151063 0.01092718 0.01151063 0.01151063 0.0644872
 0.01151074 0.01479854 0.01092718 0.0644872  0.01151009 0.01151063
 0.01151063 0.06448529 0.01151063 0.00417593 0.01151063 0.01203261
 0.01092718 0.01151063 0.01151063 0.01151063 0.0644872  0.01151222
 0.01151063 0.01381664 0.01132614 0.0644872  0.01092718 0.01381664
 0.01617063 0.0644872  0.01397089 0.01518795 0.01092718 0.01151063
 0.0644872  0.01151063 0.01092718 0.01397089 0.01151063 0.01092718
 0.01151119 0.06450031 0.01382712 0.01151063 0.01151063 0.0644872
 0.01151063 0.06448723]
tr_loss:[0.00966197 0.01225013 0.00779538 0.01225013 0.05644662 0.01225013
 0.00553091 0.00779391 0.01225013 0.01224744 0.05644662 0.01224987
 0.01225013 0.00318219 0.00730132 0.01225013 0.01225012 0.01224643
 0.01225013 0.01224943 0.00318219 0.01225013 0.01225013 0.01215829
 0.01225013 0.00318219 0.01225014 0.05644662 0.00919905 0.05644662
 0.05644662 0.01225013 0.01225013 0.00919905 0.01225013 0.01528604
 0.05644662 0.01225013 0.05644662 0.01225013 0.00553092 0.00553091
 0.05644662 0.00318219 0.00919905 0.00318219 0.01528606 0.00919905
 0.00318218 0.00318219]
tr_loss:[0.02479284 0.02479285 0.02479285 0.00781203 0.02479285 0.02479293
 0.02479285 0.00767286 0.01559271 0.05658443 0.00689506 0.05658446
 0.01559271 0.02479285 0.02479285 0.02479285 0.05658443 0.02479284
 0.0283221  0.02479284 0.01559272 0.02479284 0.02479285 0.02479282
 0.00547873 0.05658443 0.02479284 0.02077262 0.02479269 0.02479285
 0.02479284 0.02479284 0.02479285 0.00774359 0.0247928  0.0283221
 0.02479285 0.02479285 0.02479285 0.0283221  0.02479285 0.00767287
 0.02479284 0.0283221  0.05658443 0.02479285 0.00547872 0.00836497
 0.05658442 0.02479284]
tr_loss:[0.00499853 0.00969784 0.00269896 0.00504021 0.01149166 0.00501799
 0.01289949 0.05878436 0.05878435 0.00269896 0.01149166 0.01149166
 0.01149166 0.01149166 0.00269896 0.00504086 0.00140854 0.01149166
 0.0160314  0.01149118 0.01149167 0.01149166 0.00504086 0.00504086
 0.05870234 0.05878435 0.01149166 0.01604433 0.01149166 0.00504086
 0.00132582 0.01149166 0.00504086 0.01149166 0.01518815 0.00504086
 0.0114865  0.0019242  0.00970197 0.00499854 0.01518815 0.00504086
 0.01149166 0.00269896 0.00499853 0.01149166 0.01149166 0.01149166
 0.00499853 0.01149166]
tr_loss:[0.01425896 0.00152901 0.00501072 0.00152901 0.00252428 0.00655126
 0.01425896 0.00741062 0.00152901 0.00152901 0.00367096 0.06963269
 0.01425896 0.00144754 0.00715153 0.01425819 0.00152885 0.06963269
 0.00152901 0.00152901 0.06963269 0.06963269 0.06963269 0.00152901
 0.00152901 0.00152901 0.00252401 0.01425896 0.06963269 0.00252428
 0.06963269 0.06963269 0.00152901 0.00655277 0.00655275 0.00580632
 0.0696327  0.06963269 0.06963269 0.00152901 0.00715272 0.00501075
 0.00152901 0.00152901 0.00152901 0.00152549 0.00152901 0.00152901
 0.00152901 0.00252428]
tr_loss:[0.07324575 0.00302046 0.00302046 0.01934715 0.07324575 0.0112596
 0.00302046 0.00302046 0.00302046 0.00302046 0.00302046 0.00302097
 0.00302046 0.01934716 0.00302052 0.00302046 0.00304691 0.00302046
 0.01257956 0.01258224 0.00302046 0.00302046 0.00302046 0.00302046
 0.00639908 0.01066389 0.07324573 0.00660005 0.01258135 0.00302046
 0.01258135 0.07375085 0.00302047 0.00302046 0.01934717 0.00302046
 0.00302046 0.00299245 0.00302046 0.00302046 0.01934715 0.00329917
 0.01934715 0.00302046 0.00302046 0.00660005 0.01934715 0.00302046
 0.07324575 0.01934717]
tr_loss:[0.01249961 0.00358491 0.01719299 0.01719298 0.00358491 0.00358491
 0.07164429 0.01249961 0.01719299 0.01110156 0.00358491 0.00689684
 0.00586008 0.01719299 0.01637963 0.07164427 0.00358492 0.00358491
 0.01313699 0.00357827 0.07164428 0.07164425 0.01249961 0.01719287
 0.00772362 0.00688131 0.00358491 0.00358491 0.00359428 0.01719297
 0.00358491 0.01719299 0.00358503 0.00688131 0.07164427 0.00358491
 0.00358491 0.00358491 0.01249961 0.00358491 0.00358485 0.00358491
 0.00358492 0.01120076 0.00358491 0.00571063 0.07164426 0.00570853
 0.01172851 0.00358491]
tr_loss:[0.00428281 0.00575364 0.06751521 0.06751523 0.0122198  0.00791235
 0.00428281 0.01101    0.00791235 0.0042828  0.00428233 0.01320006
 0.00791234 0.01101    0.00428285 0.00428281 0.00791233 0.06751521
 0.00428281 0.00717105 0.00428281 0.01320005 0.01320006 0.00428282
 0.00428281 0.00442973 0.01320005 0.00957337 0.00428281 0.00428281
 0.00428281 0.00428281 0.01320005 0.01101    0.00376547 0.00428281
 0.06406474 0.00428281 0.00428282 0.00428281 0.01320006 0.00428281
 0.00428281 0.06751521 0.00428281 0.01092334 0.00790702 0.00744058
 0.06751522 0.00428281]
tr_loss:[0.00989819 0.00560902 0.00983404 0.00994788 0.06200882 0.00560902
 0.00998685 0.06200882 0.0056099  0.00560902 0.00560902 0.00560902
 0.00602545 0.00560902 0.00793025 0.06200882 0.00768086 0.00560902
 0.00560902 0.00560902 0.00560902 0.00560902 0.06200882 0.00945717
 0.0084755  0.00998685 0.06200882 0.06200881 0.06200882 0.00560902
 0.06200882 0.00768086 0.00560902 0.00998685 0.00560902 0.01006052
 0.00989806 0.00560902 0.00560902 0.00994951 0.00560902 0.00768086
 0.06200882 0.00561127 0.00945692 0.00560902 0.00560902 0.00560902
 0.00768086 0.00768086]
tr_loss:[0.00797531 0.01018373 0.00677412 0.00677419 0.00677419 0.00677419
 0.00796152 0.01018187 0.0067742  0.0067742  0.00798102 0.00792152
 0.05746069 0.00677419 0.00796152 0.00677419 0.00859807 0.00677419
 0.00859807 0.0067742  0.00853151 0.00677418 0.00842322 0.00796152
 0.00677417 0.00859806 0.00677419 0.00677419 0.00683884 0.00677408
 0.05746068 0.00677419 0.00842295 0.00677419 0.0067742  0.00677419
 0.00795541 0.00796152 0.00677419 0.00677419 0.00677419 0.00799508
 0.00677419 0.00677419 0.00677436 0.00677419 0.05746068 0.00683884
 0.00677419 0.00684735]
tr_loss:[0.0049263  0.0042447  0.00327708 0.00467244 0.0054034  0.0049263
 0.00540341 0.00492631 0.00540341 0.0049263  0.00601215 0.00540341
 0.00540341 0.00702923 0.00702923 0.00540341 0.00540341 0.00492631
 0.00540341 0.00540323 0.05513452 0.00943967 0.00540293 0.0049263
 0.0054071  0.00540341 0.00540341 0.00702925 0.05513452 0.00540341
 0.00540341 0.05513451 0.00492631 0.00492631 0.0049263  0.00425786
 0.00540341 0.00425973 0.00698459 0.00540341 0.05513452 0.05513452
 0.00540341 0.00528913 0.00540341 0.00540341 0.0054034  0.00425973
 0.00492631 0.00425972]
tr_loss:[0.00791759 0.00419155 0.05507448 0.00738382 0.00791758 0.05507449
 0.00312239 0.05507449 0.00791759 0.00419155 0.00683444 0.00791758
 0.00791759 0.00239569 0.00133787 0.00978327 0.00419155 0.00419154
 0.00419155 0.00419155 0.01307635 0.05521908 0.00977977 0.00791759
 0.05507449 0.00791756 0.00312239 0.00419155 0.00791758 0.05507449
 0.00791758 0.05507449 0.0079176  0.00419155 0.00977977 0.00791758
 0.05507449 0.00977977 0.00791758 0.00977977 0.0079174  0.01306936
 0.00791759 0.00791239 0.00791758 0.00331013 0.05507449 0.00419155
 0.00791759 0.00215542]
tr_loss:[0.05758999 0.00706731 0.00693369 0.05717548 0.05758998 0.01330549
 0.00706733 0.0021189  0.00706755 0.05758998 0.05758998 0.00326293
 0.00706735 0.00444989 0.00326293 0.00706732 0.05758878 0.00706732
 0.00952309 0.00706732 0.00706732 0.00711514 0.00444989 0.00326293
 0.00138689 0.05758998 0.00706732 0.00706732 0.00096233 0.05758999
 0.00771073 0.00706732 0.05758997 0.00444989 0.00444989 0.00138689
 0.00703247 0.00444989 0.00706278 0.00871046 0.00326293 0.0014056
 0.00293238 0.00706732 0.00706732 0.00706732 0.0013458  0.00706732
 0.05758998 0.00706732]
tr_loss:[0.00175618 0.00284274 0.00092917 0.06024094 0.00413154 0.00175618
 0.06024094 0.00284274 0.06024094 0.00163345 0.0028428  0.00163345
 0.00651251 0.00284274 0.00284274 0.00284275 0.00163345 0.00284274
 0.00651251 0.00413154 0.00284274 0.00284274 0.00122954 0.00284274
 0.00284274 0.00092926 0.00310843 0.00284273 0.0602409  0.00284274
 0.00284274 0.00284275 0.00284274 0.0090004  0.0028426  0.00284274
 0.0023311  0.00284274 0.00175618 0.00413154 0.00284274 0.00175618
 0.00284274 0.0012356  0.00284274 0.00245968 0.00284275 0.00284275
 0.00284274 0.00472557]
tr_loss:[0.06419452 0.00229826 0.00366588 0.00229826 0.00798114 0.00229826
 0.00798114 0.00389126 0.00798114 0.00229826 0.00229826 0.00229826
 0.00229826 0.00798116 0.06419466 0.00229826 0.00366588 0.00229826
 0.00798115 0.00229826 0.00465943 0.00229826 0.00229824 0.00229826
 0.00229826 0.00496517 0.00530965 0.00229826 0.06419454 0.00229826
 0.06419455 0.00229826 0.00229826 0.00229826 0.00229826 0.00229826
 0.00229826 0.00229847 0.00798116 0.00229826 0.00798114 0.00450207
 0.00229826 0.06419454 0.00366588 0.00475486 0.00496518 0.00229927
 0.00366588 0.00798113]
tr_loss:[0.00220885 0.00220885 0.00634912 0.06398092 0.00894865 0.06398093
 0.00568237 0.00220885 0.00439346 0.06398093 0.06398094 0.00220885
 0.00220885 0.00222215 0.00220885 0.0056823  0.00623003 0.00220886
 0.00220885 0.00685254 0.00894864 0.00606704 0.00220884 0.00430304
 0.00220885 0.00220886 0.00606704 0.00220885 0.00220885 0.00622097
 0.00439347 0.00215934 0.00894865 0.00220885 0.00894865 0.00220886
 0.00221383 0.00220885 0.00220884 0.00220885 0.00220885 0.00894864
 0.00622092 0.06398094 0.00607224 0.06398093 0.00607224 0.00220884
 0.00568208 0.00428331]
tr_loss:[0.00212257 0.0021283  0.00156485 0.00337428 0.00811706 0.0613548
 0.0055308  0.00610287 0.00156485 0.00156485 0.00156485 0.00156485
 0.00156485 0.00599959 0.00156485 0.00156147 0.00156485 0.00811707
 0.00156505 0.0613548  0.00669084 0.00811705 0.00610287 0.00156532
 0.0613548  0.00156485 0.0613548  0.00811705 0.00156485 0.0613548
 0.06135481 0.00156485 0.00156485 0.00610287 0.00599958 0.00156492
 0.00156525 0.00155062 0.00400196 0.00156485 0.0613548  0.00156485
 0.00811899 0.0613548  0.00337428 0.00156485 0.00156485 0.00156485
 0.00156485 0.00156485]
tr_loss:[0.00192166 0.00686413 0.00192013 0.00691065 0.00195331 0.00333243
 0.00529207 0.00529207 0.00192166 0.00337943 0.0068989  0.00550319
 0.00192166 0.05791091 0.00691065 0.00192166 0.00192166 0.00192166
 0.00691064 0.00489726 0.00192166 0.00217292 0.00192166 0.00192166
 0.00191619 0.00795548 0.00191953 0.00192166 0.00529146 0.00691065
 0.00192166 0.00192166 0.00333537 0.00192158 0.00192166 0.00529208
 0.00529207 0.05791092 0.00192166 0.00192166 0.00192166 0.00192166
 0.00691065 0.00192166 0.00192166 0.00794832 0.00192166 0.05791091
 0.00192166 0.00489631]
tr_loss:[0.05513775 0.00353072 0.00539315 0.00190465 0.00757121 0.00353072
 0.05513775 0.05513775 0.00359064 0.00539315 0.00265398 0.00353072
 0.00539315 0.05513776 0.00353071 0.00353072 0.00353072 0.00190466
 0.00353072 0.00353007 0.00539315 0.00539315 0.00353071 0.00353072
 0.00353072 0.00353072 0.05513775 0.00353072 0.05513775 0.00921088
 0.00539315 0.00353072 0.00424712 0.00747921 0.00353071 0.00393486
 0.00539318 0.00309792 0.00539315 0.00159821 0.00353072 0.00424712
 0.05513773 0.05513775 0.00398788 0.00353072 0.00461084 0.00259299
 0.00539258 0.00461076]
tr_loss:[0.05306817 0.00578494 0.00578494 0.00578494 0.00578487 0.00578494
 0.0032186  0.00670946 0.00578494 0.00707935 0.05306825 0.0032186
 0.00258053 0.05306817 0.0032186  0.00578495 0.00316309 0.00570885
 0.00266096 0.00578494 0.00257882 0.00578494 0.00273247 0.00574492
 0.0032186  0.00578494 0.00578494 0.00578494 0.00578494 0.0032186
 0.00578494 0.00578494 0.00273247 0.00578494 0.05306818 0.00273247
 0.0032186  0.00707936 0.00577112 0.0032186  0.05306818 0.00265973
 0.00783682 0.00316309 0.00578494 0.00578494 0.00578494 0.00578494
 0.00578493 0.00579281]
tr_loss:[0.05315117 0.00164751 0.00535279 0.05315118 0.0053528  0.05315117
 0.01058968 0.0053528  0.00535279 0.00164751 0.053153   0.00164751
 0.00164748 0.00535279 0.05315117 0.05315117 0.00229805 0.00119056
 0.05315117 0.0053528  0.00228315 0.05315117 0.00282646 0.0053528
 0.00535279 0.00165443 0.00535279 0.00535269 0.05315117 0.00535279
 0.00228315 0.05315117 0.00328312 0.00535279 0.00164751 0.00535279
 0.00535279 0.00639695 0.00717443 0.00164751 0.05315118 0.00535386
 0.05315118 0.00535279 0.00164751 0.00282647 0.00164751 0.00535278
 0.0053528  0.00228315]
tr_loss:[0.0042571  0.0042571  0.00197126 0.00127003 0.00937897 0.0042571
 0.0042571  0.0042571  0.05410079 0.00683535 0.0042571  0.0042571
 0.0042571  0.0042571  0.0042571  0.05402824 0.0042571  0.0042571
 0.0042571  0.00127003 0.0042571  0.00280843 0.00127002 0.0042571
 0.00425709 0.05410079 0.05410718 0.05410079 0.0042571  0.00190095
 0.00190095 0.00425711 0.00425709 0.00190096 0.0042571  0.00190096
 0.00127002 0.00683222 0.0027986  0.0042571  0.0042571  0.0042571
 0.05410079 0.05410079 0.00127002 0.00127013 0.0042571  0.00195461
 0.00127002 0.00127003]
text_input.shape
(4400, 14400)
learning_input_tmp.shape
(4400, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4400, 80)
learning_output.shape
(750, 80)
Model: "sequential_90"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_90 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4576008 1.4954847 1.4699026 1.4699026 1.4699026 1.4954846 1.4635994
 1.4669926 1.4892267 1.4699026 1.4699026 1.4635881 1.4954846 1.4699026
 1.4669926 1.488206  1.4679753 1.4891884 1.4651923 1.4892267 1.4699026
 1.4892269 1.4699032 1.4699026 1.5103487 1.4699026 1.4654615 1.4630413
 1.4635864 1.4699025 1.4954846 1.4576024 1.4743235 1.4954846 1.4699026
 1.4699026 1.4669925 1.4699026 1.4954846 1.4954847 1.4576008 1.4576008
 1.4892268 1.4645253 1.4699026 1.4699026 1.4954848 1.4699026 1.4699026
 1.4954847]
tr_loss:[0.8149656  0.8078656  0.81496584 0.81496584 0.8149659  0.8149659
 0.84465295 0.81496584 0.80227315 0.8149659  0.8149657  0.81496584
 0.78504795 0.84187603 0.81544554 0.8149077  0.83215654 0.78421503
 0.8149657  0.84465265 0.78368616 0.81496584 0.8021965  0.81496584
 0.81496584 0.8079451  0.81496716 0.81496584 0.8149659  0.8079332
 0.81496584 0.81496584 0.8079332  0.8446525  0.78140014 0.83215654
 0.8079332  0.84465253 0.79832494 0.81148434 0.8149651  0.81496584
 0.8021966  0.81496584 0.81496584 0.81496584 0.81496584 0.81496584
 0.84465265 0.81496584]
tr_loss:[0.52781755 0.5194706  0.51947063 0.5295131  0.51947063 0.5295132
 0.5194706  0.5194706  0.5295121  0.5349321  0.52781755 0.5194707
 0.5349402  0.5194706  0.5349402  0.5194713  0.5194706  0.5292648
 0.5320361  0.5194872  0.58612764 0.5194707  0.5194706  0.5295132
 0.5295131  0.5349401  0.5194706  0.53494024 0.5861273  0.58612764
 0.58612776 0.5295132  0.5349402  0.5194706  0.5194706  0.52951324
 0.5194706  0.58612776 0.53494024 0.53494024 0.53494024 0.53494024
 0.5349401  0.58612776 0.5194706  0.51820934 0.5349403  0.5295132
 0.58612776 0.58612764]
tr_loss:[0.26812175 0.36591285 0.26812792 0.26812178 0.35588455 0.26812178
 0.26812178 0.26769003 0.27265054 0.28284493 0.28284493 0.26812175
 0.26815358 0.2681218  0.2760221  0.26812178 0.26812178 0.35588455
 0.26812178 0.26812172 0.26812178 0.29581243 0.26812178 0.2681218
 0.26812178 0.2827732  0.26812178 0.2681219  0.26812178 0.2681218
 0.27265057 0.28390926 0.29581243 0.2760221  0.3558845  0.2681218
 0.29581246 0.2861375  0.26812178 0.26812178 0.29581246 0.27265063
 0.27934495 0.26812178 0.35588458 0.26812178 0.26812178 0.26812178
 0.27997833 0.27602214]
tr_loss:[0.1246921  0.12469214 0.11116681 0.11116681 0.1111668  0.11281379
 0.20465891 0.11116651 0.1111668  0.1111668  0.11116681 0.1111668
 0.11575379 0.11116688 0.11116679 0.1169287  0.2046589  0.12469213
 0.12128124 0.11281375 0.11116679 0.1246921  0.11116793 0.1111668
 0.20465891 0.20465887 0.2046589  0.1111668  0.1111668  0.11116679
 0.11116679 0.11116673 0.11116681 0.11116681 0.2046583  0.20465882
 0.2046589  0.11116679 0.1111668  0.11116679 0.20465891 0.11824719
 0.11116679 0.11116679 0.12469213 0.11715846 0.20465894 0.1246921
 0.11116678 0.11224278]
tr_loss:[0.1253492  0.06877746 0.07013814 0.06801849 0.06877748 0.07013816
 0.07596582 0.06877746 0.06877748 0.06877746 0.07596581 0.06877746
 0.07596581 0.12534916 0.06877746 0.1253492  0.06943049 0.06877746
 0.07013816 0.07602863 0.07013816 0.07241192 0.07013816 0.06978036
 0.06879181 0.07596581 0.07015827 0.06877746 0.12575443 0.07168492
 0.06978036 0.06877747 0.06877748 0.07371958 0.06877729 0.06877746
 0.06877746 0.06877746 0.06877747 0.06877746 0.06877746 0.07371984
 0.06882353 0.06877901 0.06937882 0.12534918 0.06986706 0.07014008
 0.06937508 0.06877746]
tr_loss:[0.06390147 0.0652326  0.0669352  0.06498892 0.06158952 0.06158952
 0.0669352  0.06731386 0.06158951 0.06158951 0.06192074 0.06158951
 0.06158951 0.06158951 0.06158951 0.06461791 0.06390146 0.06390148
 0.06158951 0.06158951 0.06158951 0.06158951 0.06498892 0.06521723
 0.06498892 0.06158952 0.11391222 0.06496999 0.06390147 0.06316465
 0.0669352  0.06158951 0.06158951 0.06158951 0.06158916 0.06390148
 0.06731291 0.06332304 0.06158951 0.06081108 0.06262262 0.06158952
 0.06158952 0.06859652 0.0615895  0.06158951 0.0669352  0.06498892
 0.11391222 0.11391221]
tr_loss:[0.11761387 0.11761389 0.06122656 0.07079899 0.06122656 0.06672117
 0.06285337 0.06122656 0.06122658 0.06661204 0.06122656 0.06119672
 0.06672116 0.06280451 0.06672116 0.07040747 0.11761387 0.06122656
 0.06285272 0.06672116 0.11761387 0.11761387 0.06122656 0.06672116
 0.11762957 0.06122656 0.06122656 0.06672117 0.06672117 0.0614849
 0.07045953 0.06128712 0.07051247 0.11761387 0.07050233 0.06122656
 0.11761389 0.0628527  0.06122656 0.06122656 0.06661205 0.06672116
 0.06122656 0.06122951 0.06672116 0.07040132 0.07050984 0.06122656
 0.06660147 0.06122657]
tr_loss:[0.06079599 0.11683986 0.11683986 0.06079599 0.06615008 0.06650473
 0.06181643 0.06650473 0.06673099 0.07027362 0.060796   0.11683986
 0.06181643 0.06650473 0.06650475 0.07037865 0.06135765 0.07027362
 0.11610398 0.06615874 0.06650475 0.06079599 0.06079598 0.11683984
 0.11683816 0.06181645 0.06541727 0.06181643 0.06079599 0.06901008
 0.06079598 0.06079599 0.06079599 0.07027967 0.06079599 0.06078819
 0.06111332 0.11683985 0.06650473 0.06079599 0.06181643 0.06079625
 0.06053327 0.06079599 0.06650475 0.06083858 0.06650475 0.06650475
 0.06071263 0.06650475]
tr_loss:[0.05967301 0.0649844  0.0636107  0.06729276 0.059673   0.06408748
 0.06635906 0.06408749 0.06498437 0.06078309 0.05967299 0.1125152
 0.06729253 0.06408749 0.059673   0.1125152  0.05967414 0.06408749
 0.11251519 0.06815241 0.06408748 0.05967301 0.11238669 0.06635903
 0.05967301 0.059673   0.06408747 0.06729278 0.05904219 0.1125152
 0.06361072 0.059673   0.059673   0.05967301 0.05967301 0.06093137
 0.06408747 0.06734053 0.05983735 0.1125152  0.06734043 0.06734044
 0.05967301 0.059673   0.06729277 0.05967301 0.05967301 0.0663885
 0.059673   0.06361072]
tr_loss:[0.0601172  0.06011632 0.06508631 0.11094882 0.06417442 0.06011613
 0.06011613 0.06819436 0.06185598 0.06011613 0.06567738 0.06017682
 0.06011613 0.06011613 0.06417442 0.0621725  0.06011613 0.06011613
 0.06011613 0.06011613 0.06011613 0.06769686 0.11094882 0.06011613
 0.06417354 0.06185598 0.06011639 0.06217249 0.06011613 0.06011613
 0.06011613 0.11094882 0.06011614 0.06011613 0.11094882 0.06011615
 0.06011613 0.06011538 0.0651018  0.11094882 0.05903552 0.06417442
 0.06417441 0.06508616 0.06011613 0.06567188 0.06185598 0.06417442
 0.06516796 0.06011613]
tr_loss:[0.05956902 0.05956902 0.05956901 0.0613346  0.0683672  0.06710222
 0.0613346  0.05956902 0.05956902 0.11639979 0.05956902 0.05956903
 0.05956902 0.0680011  0.0680011  0.06539551 0.05956902 0.05956902
 0.1163998  0.1163998  0.0680011  0.05969206 0.05956902 0.05830805
 0.06800111 0.05956902 0.05956902 0.06141918 0.05957197 0.05956903
 0.1163998  0.06800109 0.05956902 0.05956902 0.06133416 0.06579069
 0.05956902 0.05956902 0.06644183 0.11639979 0.05956902 0.05956902
 0.06800109 0.05956902 0.0680011  0.06067853 0.05956902 0.1163998
 0.05956902 0.05956904]
tr_loss:[0.05791618 0.0676503  0.06073602 0.06701496 0.06999448 0.12030645
 0.06760155 0.12030645 0.06557697 0.06073602 0.06999448 0.05791617
 0.05791625 0.05791618 0.06999482 0.053283   0.06073602 0.05791068
 0.05791617 0.05791617 0.06760155 0.05791617 0.12030645 0.05791618
 0.06760155 0.05791634 0.06073602 0.06999438 0.12030645 0.05791618
 0.12030645 0.05791618 0.06992547 0.05791616 0.12030645 0.06999447
 0.05791617 0.06073592 0.0579162  0.05791617 0.05791617 0.06999449
 0.06999448 0.05791618 0.12030645 0.05791617 0.06701495 0.0579166
 0.06836203 0.06836326]
tr_loss:[0.06729703 0.06789666 0.05657638 0.11827777 0.05657638 0.05657638
 0.05657638 0.05657638 0.11827777 0.0604471  0.05657638 0.05840995
 0.05657638 0.11827777 0.06789668 0.05657638 0.05657639 0.05657638
 0.06715778 0.06715777 0.05651243 0.11827777 0.06603321 0.06789666
 0.05657748 0.11827771 0.11827777 0.1182797  0.05657638 0.05657638
 0.05657638 0.11827777 0.05657638 0.11827777 0.05566045 0.05657638
 0.05657638 0.06715777 0.05657639 0.05657638 0.05657638 0.0649671
 0.05657638 0.05657638 0.05657638 0.05657638 0.05656816 0.05658803
 0.06789665 0.05662175]
tr_loss:[0.05723495 0.05723494 0.05723494 0.11444309 0.05723493 0.0579493
 0.05723494 0.06163761 0.05723494 0.05723494 0.05723494 0.11444309
 0.11444309 0.05723494 0.11444309 0.05723563 0.05723494 0.06545111
 0.06530817 0.05723494 0.05723493 0.06497528 0.05723494 0.05723494
 0.05723494 0.05723495 0.05711323 0.06545113 0.05723493 0.06705467
 0.05705589 0.06545111 0.11444309 0.06705467 0.05723493 0.0572352
 0.11444309 0.05723494 0.06705467 0.06545111 0.05723494 0.05723793
 0.05723492 0.05723494 0.05723493 0.05723483 0.11444309 0.06705465
 0.05794932 0.06163762]
tr_loss:[0.06765892 0.06465627 0.0585277  0.0585277  0.06768179 0.05950196
 0.06283986 0.0585277  0.0585277  0.05950987 0.0585277  0.0604452
 0.06703059 0.06699553 0.06283986 0.06699554 0.06703061 0.06403884
 0.06767857 0.11164562 0.05852775 0.11164562 0.0585277  0.05853401
 0.11204352 0.0585277  0.11164562 0.0601118  0.06695203 0.0585277
 0.06403886 0.0585277  0.1116456  0.06283987 0.06403884 0.0669411
 0.06454236 0.05833604 0.06403886 0.06403885 0.0585277  0.0585277
 0.05852886 0.0585277  0.0585277  0.11164562 0.06403885 0.05950196
 0.0585277  0.06283987]
tr_loss:[0.10910525 0.10910524 0.05920193 0.05920193 0.05920193 0.05920193
 0.05920193 0.05920193 0.06761677 0.10910525 0.10911234 0.10910524
 0.06272796 0.06289361 0.0592034  0.05963327 0.05920193 0.06606898
 0.05920193 0.06272797 0.05920192 0.10910524 0.05920193 0.06606898
 0.05920193 0.06606674 0.05920193 0.06289428 0.05920193 0.05920193
 0.10910525 0.06631021 0.10910524 0.10910524 0.10952216 0.05920193
 0.06555814 0.10910525 0.05920193 0.05920193 0.05920193 0.05920193
 0.06272797 0.05920193 0.06606898 0.10910517 0.05920193 0.05920269
 0.05920181 0.05920194]
tr_loss:[0.05892701 0.05826951 0.05855074 0.06157077 0.05855074 0.0643033
 0.06430329 0.06637985 0.06148791 0.10738709 0.05854839 0.06157077
 0.05855074 0.05855074 0.05855074 0.05855074 0.05855404 0.06148791
 0.06425318 0.10738709 0.05855074 0.05855074 0.06051041 0.06430329
 0.06157077 0.10738709 0.06469532 0.05907678 0.06148791 0.10738709
 0.05855074 0.06148791 0.05855076 0.10738709 0.06148791 0.05827916
 0.05855013 0.10738709 0.10738709 0.06051041 0.06148791 0.05855074
 0.0626687  0.05855074 0.05855074 0.06148791 0.05867276 0.05963701
 0.05855074 0.0614879 ]
tr_loss:[0.05982249 0.10614049 0.05982249 0.05574762 0.05811671 0.0561986
 0.1060525  0.10614049 0.0533816  0.10614048 0.0533816  0.10613968
 0.05574762 0.0561986  0.05859744 0.05574762 0.05982226 0.0533816
 0.0533816  0.05619859 0.05561028 0.0533816  0.05619859 0.05859744
 0.0533816  0.0533816  0.05859744 0.0533816  0.05379551 0.05574762
 0.05859744 0.05573452 0.10614049 0.05982249 0.05980589 0.05574762
 0.05574762 0.0533816  0.0533816  0.0533816  0.0533816  0.0533816
 0.05338191 0.05982249 0.05338233 0.0533816  0.05338159 0.05859744
 0.05968131 0.0533816 ]
tr_loss:[0.04623718 0.04718436 0.09989973 0.03855618 0.04113265 0.03559982
 0.0355995  0.0355995  0.04476407 0.0355995  0.0362922  0.0375806
 0.03559951 0.09990293 0.04623717 0.09989973 0.03561866 0.04623718
 0.04476406 0.0355995  0.04623718 0.0355995  0.0355995  0.04623718
 0.03559951 0.03855607 0.09989973 0.09989973 0.09989975 0.0382688
 0.03855617 0.03559263 0.0355995  0.03559951 0.03559951 0.03559951
 0.03566517 0.044317   0.03559952 0.04623718 0.09989969 0.03559951
 0.03539463 0.03559946 0.0355995  0.0355995  0.04623718 0.09989973
 0.03559949 0.03559951]
tr_loss:[0.0146177  0.01250247 0.02127245 0.0146177  0.01123607 0.0146177
 0.01123784 0.01123607 0.0751344  0.01123607 0.01123607 0.01123607
 0.02127245 0.02127246 0.02127245 0.02127245 0.02047987 0.02127245
 0.01123609 0.01123201 0.02127246 0.01341775 0.01123607 0.01938427
 0.01123607 0.01123607 0.01123609 0.0751344  0.01123607 0.02127246
 0.01123607 0.01461769 0.02132662 0.01123607 0.01123607 0.01123607
 0.01123607 0.01400242 0.01123607 0.01123607 0.01341892 0.02009097
 0.01123607 0.01123607 0.02127245 0.0751344  0.01123607 0.01123607
 0.01123606 0.02167612]
tr_loss:[0.00635081 0.01591023 0.00992728 0.0159109  0.00635229 0.01591098
 0.00992727 0.01508398 0.00643804 0.00635229 0.01508399 0.01500014
 0.0063523  0.00647198 0.00635229 0.00736261 0.00635229 0.00635229
 0.06257497 0.01508398 0.06257496 0.01500015 0.00635229 0.01508399
 0.00633674 0.01382432 0.00635229 0.00635229 0.00635229 0.00635229
 0.01590381 0.0147794  0.00635443 0.00635229 0.01508403 0.00992728
 0.01508398 0.00635229 0.00635229 0.00635228 0.01508398 0.0063523
 0.06257496 0.00635229 0.00635229 0.06257496 0.0063523  0.01500015
 0.00635229 0.00635229]
tr_loss:[0.0058446  0.0058446  0.0058446  0.01518193 0.06255443 0.01131585
 0.0058446  0.00585132 0.0058446  0.00584461 0.0058446  0.06255443
 0.0058446  0.01390735 0.00584461 0.00597682 0.01518193 0.00584462
 0.00908136 0.0058446  0.01518194 0.0086164  0.0058446  0.06255443
 0.00584466 0.00858764 0.0058446  0.06255443 0.01269445 0.01518193
 0.01411746 0.06255443 0.0058446  0.01525697 0.01518194 0.0058446
 0.00566347 0.01411746 0.00908134 0.06255443 0.00738451 0.06255443
 0.06255443 0.00587099 0.0139031  0.06255443 0.0058446  0.0058446
 0.06255443 0.0058446 ]
tr_loss:[0.0097699  0.00587363 0.00587364 0.00587364 0.00587363 0.00587364
 0.01465403 0.01283405 0.00587363 0.06228522 0.00587363 0.00587364
 0.00587364 0.00587363 0.01245115 0.01277629 0.00587364 0.06228523
 0.01458093 0.00587363 0.0127763  0.00587364 0.00587363 0.00587363
 0.01458106 0.0097699  0.01277575 0.00850867 0.00587363 0.01465402
 0.0123714  0.00587363 0.00587364 0.01211203 0.06228523 0.01465403
 0.00587363 0.00587363 0.06228523 0.00587363 0.00587363 0.00587363
 0.00587365 0.00587364 0.00587364 0.00587363 0.01465402 0.00587375
 0.0127763  0.00587364]
tr_loss:[0.0120875  0.01127076 0.01433886 0.0060343  0.00603429 0.00603429
 0.06286268 0.01433884 0.01438365 0.00603435 0.01190921 0.01435254
 0.00603429 0.01109895 0.00603429 0.01127076 0.06286266 0.06286267
 0.00603429 0.01207393 0.01433886 0.01111141 0.01207457 0.00603431
 0.00603429 0.00603491 0.00603429 0.00603429 0.00603429 0.00603429
 0.00603429 0.00603429 0.01427699 0.06286267 0.00603429 0.06286267
 0.00603429 0.01433886 0.01180043 0.00603429 0.06286268 0.00603431
 0.00830307 0.00603429 0.00603429 0.00603429 0.01180042 0.01433886
 0.01433886 0.00603431]
tr_loss:[0.00642339 0.00642339 0.00642565 0.0064234  0.00635542 0.00862275
 0.0064234  0.01386318 0.01125627 0.00862275 0.00642346 0.00642339
 0.00642341 0.0064234  0.00642339 0.0064234  0.0064234  0.01125627
 0.01386318 0.01386527 0.01261396 0.00862275 0.01384387 0.0064234
 0.00862275 0.0064234  0.01375948 0.00862275 0.01125627 0.00644111
 0.01019788 0.00824806 0.0630193  0.01386318 0.01386318 0.06301929
 0.00642339 0.00641233 0.00642339 0.01385656 0.01035841 0.01386318
 0.06301929 0.0064234  0.01386318 0.01209879 0.0064234  0.00642341
 0.01035842 0.06301929]
tr_loss:[0.0135665  0.0135665  0.00654809 0.00654809 0.00654809 0.00654809
 0.00654809 0.0089853  0.01169453 0.00654809 0.06266882 0.01356649
 0.01230825 0.06166837 0.00654802 0.01136815 0.01083776 0.01171912
 0.06266882 0.01018467 0.00654756 0.0065481  0.00654809 0.00654812
 0.00654809 0.00654809 0.00654809 0.00691357 0.00898949 0.06266882
 0.00654811 0.00655372 0.01171912 0.00654809 0.0135665  0.0135665
 0.00654809 0.00654811 0.0135665  0.01136815 0.00654809 0.00654809
 0.01136816 0.01205425 0.0135665  0.00654809 0.013922   0.01081889
 0.01281261 0.00653908]
tr_loss:[0.00622695 0.01348308 0.00622695 0.00618462 0.01200185 0.06172587
 0.01200185 0.06172578 0.06172578 0.00622695 0.0091068  0.01348335
 0.00622695 0.00418108 0.00622695 0.01183803 0.00622695 0.00622695
 0.00622695 0.06172578 0.00623843 0.00910679 0.00622695 0.00622879
 0.01200185 0.01348307 0.06172578 0.00622695 0.00622695 0.06172578
 0.00622695 0.00622695 0.06172578 0.00622695 0.01225104 0.01060587
 0.00622695 0.06172578 0.01161391 0.00622695 0.0116139  0.01224619
 0.00645889 0.00622695 0.00622695 0.01348308 0.01161391 0.00622695
 0.0116139  0.06172578]
tr_loss:[0.01353272 0.0060018  0.01353272 0.0060018  0.0060018  0.0060018
 0.0060018  0.0060018  0.0060018  0.06037467 0.01353273 0.01273978
 0.0060018  0.06037467 0.01286274 0.01455149 0.00600185 0.00844172
 0.01353272 0.0060018  0.0060018  0.0125546  0.00604821 0.01352653
 0.0060018  0.0060018  0.01353272 0.0060018  0.0060018  0.06037467
 0.06037467 0.01149657 0.06037467 0.00600157 0.01149658 0.01248826
 0.01353273 0.0060018  0.0060018  0.06037467 0.01204231 0.01353272
 0.00600194 0.0060018  0.06037467 0.0060018  0.01353273 0.00600189
 0.0060018  0.0060018 ]
tr_loss:[0.05943865 0.01283242 0.00610847 0.01364993 0.00610847 0.00610847
 0.05943863 0.00610847 0.00927045 0.00934352 0.0136492  0.0061087
 0.01365003 0.00610847 0.00610847 0.00610845 0.00610847 0.00610847
 0.01342845 0.05943863 0.01365002 0.00934352 0.00934353 0.01365002
 0.00610847 0.00610847 0.00610847 0.01342845 0.05943863 0.00610847
 0.01365002 0.05943863 0.01365003 0.01302523 0.05943863 0.01227781
 0.00610847 0.05943863 0.00610847 0.05943864 0.00926931 0.00610847
 0.00610847 0.05943863 0.00610847 0.05943863 0.01365002 0.00610847
 0.01342845 0.01365002]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4400 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4401, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4401 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4402, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4402 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4403, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4403 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4404, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4404 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4405, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4405 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4406, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4406 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4407, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4407 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4408, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4408 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4409, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4409 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4410, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4410 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4411, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4411 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4412, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4412 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4413, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4413 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4414, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4414 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4415, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4415 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4416, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4416 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4417, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4417 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4418, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4418 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4419, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4419 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4420, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4420 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4421, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4421 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4422, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4422 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4423, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4423 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4424, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4424 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4425, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4425 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4426, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4426 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4427, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4427 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4428, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4428 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4429, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4429 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4430, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4430 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4431, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4431 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4432, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4432 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4433, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4433 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4434, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4434 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4435, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4435 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4436, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4436 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4437, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4437 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4438, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4438 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4439, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4439 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4440, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4440 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4441, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4441 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4442, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4442 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4443, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4443 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4444, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4444 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4445, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4445 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4446, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4446 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4447, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4447 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4448, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4448 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4449, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4449 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4450, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4450 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4451, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4451 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4452, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4452 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4453, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4453 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4454, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4454 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4455, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4455 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4456, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4456 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4457, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4457 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4458, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4458 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4459, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4459 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4460, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4460 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4461, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4461 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4462, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4462 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4463, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4463 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4464, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4464 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4465, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4465 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4466, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4466 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4467, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4467 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4468, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4468 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4469, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4469 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4470, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4470 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4471, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4471 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4472, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4472 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4473, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4473 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4474, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4474 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4475, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4475 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4476, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4476 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4477, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4477 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4478, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4478 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4479, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4479 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4480, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4480 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4481, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4481 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4482, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4482 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4483, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4483 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4484, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4484 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4485, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4485 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4486, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4486 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4487, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4487 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4488, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4488 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4489, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4489 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4490, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4490 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4491, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4491 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4492, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4492 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4493, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4493 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4494, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4494 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4495, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4495 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4496, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4496 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4497, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4497 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4498, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4498 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4499, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4499 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4500, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-4400
text_input.shape
(4500, 14400)
learning_input_tmp.shape
(4500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4500, 80)
learning_output.shape
(750, 80)
Model: "sequential_91"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_91 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.5271509 1.5137001 1.509754  1.5137818 1.5940568 1.5137814 1.5137819
 1.5033025 1.5939974 1.5137818 1.5939972 1.5137818 1.5137817 1.5939958
 1.5939972 1.5137819 1.5939974 1.5136093 1.5095571 1.5137819 1.5939974
 1.5286397 1.5092627 1.5177758 1.5137819 1.5938671 1.5097668 1.5124862
 1.5137818 1.51372   1.5064377 1.5277556 1.5137818 1.513821  1.5137794
 1.5137819 1.5137818 1.5939972 1.5137818 1.52864   1.5137818 1.5137818
 1.5137818 1.5038421 1.5137358 1.5052259 1.5137818 1.5137818 1.5939972
 1.5261691]
tr_loss:[0.9625408  0.9741596  0.96031773 0.96252996 0.9603178  0.97413385
 0.97413385 0.9625406  0.956581   0.9594709  0.97413385 0.98098165
 0.97413385 0.9741335  0.97413385 0.959058   0.960484   0.97413385
 0.97402513 0.97414684 0.9741786  0.969731   0.97413385 0.981207
 0.9695903  0.96261024 0.95806485 0.9577448  0.96959037 0.97413385
 0.96506816 0.97413385 0.97413385 0.96254045 0.97413766 0.97413385
 0.9625405  0.97413385 0.96959037 0.97413397 0.96254045 0.96959037
 0.9812296  0.97413385 0.96959037 0.9625405  0.97413385 0.9590579
 0.96254045 0.97413385]
tr_loss:[0.52700883 0.55597186 0.5270088  0.55597186 0.52700883 0.5195662
 0.55597186 0.5334207  0.52700883 0.5169669  0.52700883 0.52700883
 0.5270089  0.5169669  0.52700883 0.52700883 0.52700883 0.51757365
 0.52700883 0.5169669  0.5182338  0.52700883 0.52592254 0.5175737
 0.5270103  0.5559718  0.5167365  0.5175737  0.51942784 0.516966
 0.52700883 0.5270052  0.5175737  0.55596626 0.52700883 0.52701503
 0.51818025 0.5270089  0.52700883 0.52700883 0.51544935 0.5559718
 0.5181816  0.51696694 0.5253904  0.51696694 0.5559718  0.5169668
 0.5559718  0.51696694]
tr_loss:[0.3101766  0.3288855  0.3288855  0.3112226  0.31613943 0.31613937
 0.32888556 0.3101764  0.3112226  0.31613946 0.31122264 0.31613943
 0.31122264 0.30575615 0.31613943 0.30815554 0.30824748 0.3264148
 0.3112226  0.31613946 0.30576587 0.31613946 0.31061584 0.3161394
 0.31613946 0.31096533 0.31613946 0.31613946 0.31613946 0.31613946
 0.31613946 0.3288855  0.31606156 0.31613144 0.31613946 0.31613946
 0.3161394  0.3288855  0.3161394  0.31613943 0.3161407  0.3109654
 0.31122267 0.3288855  0.31613943 0.32888597 0.3163131  0.31614012
 0.31613943 0.3222755 ]
tr_loss:[0.1584969  0.17825289 0.16154003 0.17172775 0.17172775 0.20667315
 0.16154002 0.2066731  0.16806233 0.17172778 0.20667315 0.16783862
 0.2066731  0.17172778 0.16153046 0.17172782 0.17172775 0.17825289
 0.17172778 0.20667315 0.1584969  0.17172778 0.17172779 0.16143285
 0.17172778 0.17172778 0.17172778 0.17172776 0.17172778 0.17172778
 0.16143288 0.17172778 0.16806236 0.17172775 0.20667312 0.1678387
 0.17172782 0.16143286 0.17172775 0.17172778 0.17172775 0.1717278
 0.17172779 0.1678387  0.17098773 0.20667315 0.16783866 0.17172778
 0.1678386  0.17172778]
tr_loss:[0.08063055 0.05161221 0.08062613 0.08062613 0.07169974 0.05161221
 0.08062613 0.08062611 0.08062613 0.10071614 0.0608627  0.10087647
 0.08062612 0.08062612 0.07169974 0.10071615 0.05161219 0.10071616
 0.08062612 0.07169977 0.10071613 0.08062612 0.08119693 0.08062625
 0.08062613 0.0624065  0.08062612 0.05156917 0.10071615 0.07169975
 0.08062555 0.08062613 0.08062613 0.08062612 0.08062612 0.05161222
 0.08062612 0.08062612 0.08062613 0.08062612 0.08062612 0.10071615
 0.10071614 0.06086271 0.08062612 0.05161218 0.05161218 0.08062612
 0.0608627  0.05161222]
tr_loss:[0.06979763 0.03514741 0.05580384 0.06979764 0.05580384 0.05580384
 0.05566429 0.02427613 0.04593965 0.03514737 0.06979764 0.03514738
 0.04593965 0.04593965 0.05580382 0.05580383 0.05580384 0.06979764
 0.03640387 0.02427611 0.04995724 0.05580384 0.06979764 0.05580384
 0.06979765 0.05580381 0.05580384 0.04593965 0.02427614 0.05584275
 0.06979764 0.05580384 0.05580383 0.04439912 0.05580384 0.05580384
 0.05580383 0.05580384 0.02427611 0.06979764 0.0737995  0.05580384
 0.05580384 0.05580384 0.05580384 0.05580384 0.05580384 0.05580384
 0.02427614 0.05580383]
tr_loss:[0.01679697 0.02703598 0.0457718  0.03643027 0.04678947 0.0460564
 0.06266077 0.02558994 0.02703604 0.04073425 0.01679694 0.0457718
 0.04577179 0.02784136 0.06165073 0.06165073 0.01679694 0.04157824
 0.04563099 0.0457718  0.04578999 0.06165073 0.0457718  0.06165073
 0.06165073 0.0457718  0.01679697 0.03285803 0.03643027 0.04184578
 0.04577212 0.0457718  0.0457718  0.06165073 0.0457718  0.06165073
 0.01679697 0.027036   0.0457718  0.04639044 0.0457718  0.04577177
 0.0457718  0.01679697 0.03643026 0.04577179 0.04577179 0.01679697
 0.04577179 0.02597323]
tr_loss:[0.02324581 0.03662377 0.01420133 0.04155105 0.03662376 0.03662376
 0.02896269 0.03662377 0.01420133 0.01420133 0.03245181 0.01420133
 0.01420136 0.03662377 0.03662377 0.03660796 0.04155104 0.03662377
 0.03662377 0.03662376 0.03662376 0.03660894 0.01420133 0.01420135
 0.03662377 0.02896269 0.03662375 0.02097631 0.03662377 0.05770583
 0.03662377 0.03662376 0.03662377 0.02317788 0.05770583 0.01420135
 0.03662377 0.04184661 0.04155105 0.02491478 0.05770583 0.03662375
 0.03662377 0.03662375 0.03662377 0.03662376 0.03662376 0.01420135
 0.01420136 0.03662377]
tr_loss:[0.02900537 0.01830027 0.03413029 0.03413029 0.03413029 0.01830027
 0.01830026 0.04003792 0.01830026 0.03413029 0.03413029 0.03413029
 0.02893219 0.03413029 0.01830026 0.03622239 0.05978309 0.02894353
 0.01830027 0.04016756 0.05962663 0.03413029 0.01830027 0.02893219
 0.03413029 0.0341303  0.03413029 0.04019013 0.02893219 0.02636697
 0.05962663 0.03413029 0.03413029 0.03664742 0.03413029 0.03411103
 0.03409159 0.03413029 0.02129958 0.03413029 0.03413029 0.03413029
 0.0341683  0.03413029 0.03413029 0.0341303  0.03412612 0.05962663
 0.01830027 0.03412769]
tr_loss:[0.02053679 0.02053678 0.0347025  0.0347025  0.0311517  0.02053678
 0.0347025  0.0347025  0.0347025  0.02515103 0.03589993 0.0347025
 0.0347025  0.0347025  0.06065087 0.02616122 0.0347025  0.0347025
 0.0347025  0.0347025  0.0347025  0.0347025  0.0347025  0.0347025
 0.0347025  0.02053674 0.02534295 0.02053677 0.02053678 0.02053169
 0.02536272 0.02053677 0.02053679 0.0347025  0.02053679 0.0347025
 0.0347025  0.0347025  0.03457058 0.0347025  0.0347025  0.0311517
 0.02536272 0.02749922 0.06065066 0.0347025  0.0347025  0.0347025
 0.02053679 0.0347025 ]
tr_loss:[0.03573587 0.03573588 0.03826212 0.06114965 0.03573588 0.03573588
 0.0611526  0.0357348  0.06114965 0.03573693 0.06114965 0.03657965
 0.06114965 0.03573587 0.03294721 0.03573588 0.03573588 0.03573588
 0.03573587 0.03826195 0.0611494  0.02191836 0.02191683 0.06114964
 0.02191681 0.03573588 0.03573587 0.06114965 0.06114966 0.02849501
 0.03573587 0.03573587 0.03573588 0.02808964 0.03573583 0.02191681
 0.06114964 0.03573588 0.03573588 0.02849507 0.03294721 0.02191683
 0.03573587 0.03573588 0.02849499 0.03573585 0.03574026 0.0356868
 0.03639098 0.0357348 ]
tr_loss:[0.02266566 0.02946704 0.03160018 0.03636064 0.03390068 0.03636064
 0.03636064 0.03636064 0.06134898 0.03636064 0.02946704 0.03636064
 0.06134897 0.03636064 0.03636061 0.02946704 0.06134898 0.03636064
 0.02946682 0.03636064 0.02266568 0.03636064 0.03636064 0.03636064
 0.03636064 0.03820019 0.03636064 0.02266568 0.03636065 0.02266568
 0.02893673 0.03390068 0.03636064 0.02266566 0.06134897 0.03390068
 0.02946703 0.02946704 0.03820343 0.02266566 0.03636064 0.03636064
 0.06134897 0.02946703 0.03636064 0.03636064 0.06134897 0.02266568
 0.03636064 0.03636065]
tr_loss:[0.03652349 0.03652349 0.06134159 0.03651397 0.03652344 0.03652349
 0.02287021 0.03199042 0.03652319 0.03415786 0.03652351 0.03652272
 0.03652349 0.02287013 0.03652349 0.03652351 0.03652349 0.06134159
 0.06134159 0.02986195 0.03652349 0.06134159 0.03652349 0.03652349
 0.03652349 0.03652346 0.0381516  0.03652349 0.03652333 0.02286955
 0.0228702  0.03652349 0.03652349 0.03652349 0.03415787 0.03652349
 0.03652349 0.03652349 0.02986195 0.06134159 0.03652349 0.02996289
 0.03815164 0.0333987  0.02287023 0.03652349 0.06134159 0.03652349
 0.02986195 0.03339868]
tr_loss:[0.03634019 0.03317344 0.03392688 0.03173713 0.03634023 0.02966585
 0.03634022 0.03634023 0.03801783 0.03634022 0.03634022 0.02960761
 0.02960761 0.03801783 0.06118081 0.02960761 0.03801783 0.03801783
 0.03634022 0.03634022 0.03634023 0.06118081 0.03634023 0.03634022
 0.02960761 0.01971227 0.02267743 0.03634022 0.02267743 0.03634022
 0.02267743 0.03634022 0.02960761 0.03634022 0.03634022 0.0331693
 0.03634017 0.03634023 0.03801783 0.02267745 0.03634022 0.03634023
 0.03690412 0.03634022 0.02267745 0.06117024 0.02960761 0.03631721
 0.03801783 0.03634022]
tr_loss:[0.03579462 0.06083199 0.03318045 0.03579462 0.02867274 0.02867274
 0.03579463 0.03579461 0.03579462 0.03579461 0.03579461 0.03579462
 0.02205259 0.03080832 0.03318045 0.03589455 0.03579461 0.03579461
 0.03080809 0.03579461 0.02205262 0.0358008  0.03579461 0.03629368
 0.03579462 0.03579462 0.06083199 0.02867274 0.03579461 0.03778089
 0.03579461 0.06083199 0.03778089 0.03579458 0.03579462 0.03579461
 0.02867274 0.03778073 0.03579493 0.03579462 0.02205261 0.03778089
 0.03579462 0.0126889  0.03579462 0.06083199 0.06082124 0.02867274
 0.02205261 0.03318045]
tr_loss:[0.0332068  0.02686297 0.0348409  0.0348409  0.02686297 0.03179852
 0.03078143 0.0348409  0.02088765 0.03179852 0.03485837 0.0348409
 0.0348409  0.02088767 0.0348409  0.0348409  0.02088767 0.03550693
 0.02686073 0.0348409  0.0348409  0.0348409  0.0348409  0.0348409
 0.03179852 0.02088767 0.0348409  0.02901081 0.03484092 0.02088769
 0.0348409  0.0348409  0.03484092 0.06021776 0.06021776 0.0348409
 0.03484079 0.02686297 0.0348409  0.02088767 0.02088769 0.02684334
 0.0348409  0.02088767 0.0348409  0.0348409  0.02088767 0.02009065
 0.0348409  0.0348409 ]
tr_loss:[0.0335731  0.0335731  0.0335731  0.01902086 0.05922007 0.05922008
 0.0335731  0.03356768 0.03357311 0.0335731  0.03357276 0.0335731
 0.0335731  0.05922008 0.0335731  0.01902084 0.0335731  0.02387574
 0.03357311 0.01902086 0.0335731  0.0335731  0.02604366 0.02387574
 0.03426549 0.03357311 0.02387574 0.03741752 0.05922008 0.05922007
 0.03741751 0.03356242 0.0335731  0.0335731  0.02968236 0.03741751
 0.03013018 0.0335731  0.03358395 0.01902084 0.01902086 0.0335731
 0.01902085 0.03421844 0.03352404 0.0335731  0.03741751 0.02822064
 0.02427654 0.03357311]
tr_loss:[0.03269841 0.03269841 0.03269838 0.02263317 0.03269841 0.03255903
 0.03269841 0.0326984  0.05768021 0.02263317 0.01947342 0.05768018
 0.01634986 0.03269841 0.03269841 0.05768018 0.02752576 0.03269841
 0.02752577 0.03269841 0.05768018 0.03269841 0.03739604 0.03269841
 0.03269841 0.03739604 0.0326984  0.03269841 0.0326984  0.03269841
 0.03269841 0.02052201 0.02522169 0.03269841 0.03739604 0.02263316
 0.03269841 0.03269841 0.01634987 0.05768018 0.05768018 0.03269834
 0.03269841 0.0326984  0.05768018 0.03273333 0.05768018 0.0326984
 0.03739604 0.0326984 ]
tr_loss:[0.03335692 0.03335692 0.05605673 0.01858516 0.03335699 0.05605721
 0.03335692 0.03746138 0.03335692 0.01351713 0.03335692 0.02266734
 0.03335692 0.0560518  0.05605673 0.03335692 0.03335692 0.03335692
 0.03335692 0.03335692 0.05605673 0.03335677 0.05605673 0.03335692
 0.02054543 0.03336319 0.02263794 0.02102963 0.03335692 0.03335692
 0.02102998 0.03335692 0.05605673 0.05605673 0.03335692 0.01351711
 0.03335692 0.03335692 0.03335692 0.02098605 0.01858516 0.0333548
 0.03335692 0.02054833 0.01351713 0.05605675 0.03335692 0.01858512
 0.0374312  0.05605673]
tr_loss:[0.02829017 0.03579031 0.0349809  0.01289869 0.03579031 0.03579031
 0.03579031 0.03579031 0.019346   0.03579031 0.03579031 0.03579031
 0.03578838 0.03579031 0.03579031 0.01279477 0.03579031 0.01289869
 0.02265351 0.05605265 0.0357903  0.03862405 0.05605265 0.03579035
 0.03579031 0.03579032 0.0227416  0.01289867 0.01289869 0.0357908
 0.01289867 0.02829017 0.01289867 0.05605265 0.03579031 0.03579031
 0.03579029 0.03579031 0.05605265 0.05605267 0.02829017 0.03579031
 0.03579031 0.03579031 0.03579031 0.05605265 0.03577658 0.05605265
 0.05605265 0.02115847]
tr_loss:[0.05639056 0.02358783 0.01347307 0.02238254 0.05697883 0.05639056
 0.02345283 0.02914304 0.05639056 0.0366773  0.03667731 0.03850042
 0.0384976  0.0366773  0.03648529 0.03664858 0.05639056 0.01347305
 0.0366773  0.01347307 0.0366773  0.03667731 0.03667729 0.0366773
 0.0366773  0.01347305 0.01347305 0.01347305 0.0366773  0.05639056
 0.02914304 0.02914304 0.0366773  0.05639056 0.03667731 0.01347307
 0.01346375 0.02065283 0.03657072 0.03667729 0.02065283 0.03715918
 0.02358778 0.0366773  0.0223894  0.0366773  0.05639056 0.0384976
 0.05639056 0.01347305]
tr_loss:[0.0224879  0.03523665 0.05597154 0.03523665 0.03523666 0.0136858
 0.03523666 0.03523666 0.02832356 0.02832353 0.01368578 0.02252419
 0.03523688 0.05597153 0.03523501 0.03576962 0.02082117 0.03523665
 0.03523664 0.03523665 0.05597154 0.03523665 0.03523665 0.05597154
 0.0352364  0.03523665 0.03523666 0.05597154 0.05597153 0.03523666
 0.02247936 0.03523666 0.02832353 0.02832353 0.02090268 0.03523665
 0.03523666 0.03523099 0.02082117 0.01599414 0.0136858  0.03523665
 0.0136858  0.0136858  0.02831742 0.03523665 0.03523665 0.05597154
 0.03523665 0.0136858 ]
tr_loss:[0.03291661 0.03291661 0.03291662 0.02697828 0.03291661 0.03291662
 0.0141512  0.03291653 0.05572985 0.03291661 0.03291661 0.05572986
 0.01415186 0.05572985 0.03291661 0.01415184 0.03295583 0.03291661
 0.03291661 0.03291662 0.02370923 0.03291662 0.03291661 0.03291662
 0.03481451 0.05572986 0.03291662 0.01415186 0.05572985 0.05572985
 0.03291626 0.02697828 0.01415186 0.03291661 0.01415186 0.02697828
 0.02697827 0.03291661 0.03264426 0.01415184 0.02697828 0.03291662
 0.03291661 0.05572985 0.03291661 0.03291661 0.01415184 0.01415186
 0.03291661 0.03291662]
tr_loss:[0.02130051 0.03208112 0.03208112 0.03208112 0.02705536 0.02708067
 0.03208112 0.01563871 0.03208112 0.03208112 0.03208112 0.03208904
 0.03208112 0.03208112 0.03208113 0.03208112 0.03248374 0.03208112
 0.05655792 0.03208112 0.02130051 0.03208112 0.03208112 0.03208113
 0.01563871 0.03208112 0.03208112 0.03471165 0.03471165 0.03208112
 0.03208112 0.03208112 0.03208112 0.03208112 0.01563871 0.03208112
 0.02130051 0.05655792 0.05659838 0.03208078 0.03115211 0.03208112
 0.03208112 0.05655792 0.03471165 0.03208112 0.03208112 0.05655792
 0.03159871 0.03208112]
tr_loss:[0.01743362 0.03244615 0.03244617 0.01743361 0.03244617 0.0225793
 0.01743359 0.03244612 0.02806769 0.03244617 0.03244617 0.03244617
 0.02459391 0.0324461  0.03244599 0.01743359 0.02795461 0.03053406
 0.03244617 0.05770924 0.03244617 0.02459476 0.01743361 0.05770924
 0.01743359 0.03244617 0.03244616 0.03244456 0.03244617 0.02806769
 0.01743362 0.03244617 0.02213487 0.02213487 0.05770924 0.03244617
 0.05770923 0.03244302 0.02257929 0.02806769 0.01743359 0.03244617
 0.02500905 0.02257929 0.03244615 0.01743362 0.03244594 0.03244617
 0.03254253 0.03244617]
tr_loss:[0.0286271  0.03284576 0.05828778 0.03284576 0.03284576 0.03284576
 0.02293837 0.03284576 0.01817751 0.01817657 0.02862995 0.05828778
 0.03284576 0.02505034 0.0181766  0.03284576 0.03284576 0.02726041
 0.05828778 0.03284576 0.02293836 0.0181766  0.0227391  0.0181766
 0.02293837 0.03284576 0.03284254 0.03284576 0.03284576 0.02724633
 0.03379704 0.03284576 0.0226796  0.02293837 0.02862995 0.03346937
 0.03284576 0.03284576 0.02862995 0.03284576 0.03284576 0.02228025
 0.03282126 0.02293837 0.05828778 0.03284576 0.02293836 0.01817657
 0.01817659 0.03284577]
tr_loss:[0.01784792 0.03286991 0.01784794 0.03286991 0.02846485 0.03286991
 0.03692589 0.03268658 0.01785041 0.05822752 0.03286991 0.01784794
 0.03286946 0.01784794 0.02682248 0.03286991 0.03286991 0.01784794
 0.0225481  0.03286991 0.0328699  0.03286991 0.03286991 0.05822752
 0.03286991 0.0328699  0.02236409 0.01784792 0.01784794 0.03286991
 0.02846514 0.03286991 0.03286991 0.02236409 0.05822752 0.05822752
 0.01784794 0.01784794 0.02846486 0.02682324 0.05822728 0.0328699
 0.03285746 0.02846486 0.03286991 0.05822752 0.0328699  0.0328699
 0.03287034 0.0328699 ]
tr_loss:[0.03253311 0.02334404 0.05743886 0.01636747 0.02128593 0.0325331
 0.02773753 0.01636777 0.02548691 0.0325331  0.01636779 0.01636777
 0.05743885 0.03253508 0.02213405 0.05743885 0.03253311 0.01636779
 0.05743885 0.03253311 0.03253307 0.0325341  0.01636779 0.03253311
 0.05743885 0.03253311 0.03253311 0.03253311 0.05743885 0.03253311
 0.03253311 0.03619875 0.03633066 0.01636779 0.06441139 0.0325058
 0.03253309 0.03253311 0.03253311 0.0325331  0.03253311 0.03253311
 0.01636779 0.0574393  0.03365071 0.03253311 0.03253311 0.03649431
 0.0325331  0.0325331 ]
tr_loss:[0.0324508  0.05627618 0.05627618 0.05627618 0.01429261 0.03540476
 0.0324508  0.03245079 0.0324508  0.02023787 0.0324508  0.03245079
 0.01429261 0.01429259 0.03539966 0.03212047 0.05627618 0.0324508
 0.03540483 0.03224931 0.02708172 0.03244847 0.0324508  0.05627618
 0.03245079 0.0324508  0.0324508  0.05627618 0.05627618 0.0324508
 0.05627618 0.01429263 0.03245079 0.0324508  0.05627619 0.05627618
 0.02023787 0.05627618 0.01429261 0.01429259 0.02200224 0.02212293
 0.05627618 0.0324508  0.0324508  0.03245079 0.0324508  0.0324508
 0.01429259 0.0324508 ]
text_input.shape
(4500, 14400)
learning_input_tmp.shape
(4500, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4500, 80)
learning_output.shape
(750, 80)
Model: "sequential_92"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_92 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4166698 1.4183056 1.4058342 1.4058349 1.4165146 1.4165183 1.4025035
 1.4058349 1.4165182 1.4165182 1.4165182 1.4165183 1.4117198 1.3827457
 1.4165182 1.4165184 1.3827463 1.3827456 1.4165182 1.4117199 1.3827457
 1.4144342 1.4058349 1.3821522 1.405835  1.4165182 1.3827456 1.4253461
 1.4165182 1.4165182 1.4026375 1.4123069 1.3827456 1.416518  1.4165182
 1.4252288 1.4165182 1.4165182 1.4058349 1.4117197 1.3827455 1.4165183
 1.4165183 1.3894975 1.4165156 1.4096907 1.4165182 1.4165182 1.4165183
 1.4098711]
tr_loss:[0.8446083  0.86641026 0.8446951  0.8664118  0.8575593  0.8446082
 0.87033576 0.8494865  0.86641014 0.8446083  0.86641026 0.86641026
 0.8446083  0.85547036 0.86641026 0.8446083  0.86641026 0.84627306
 0.85547066 0.86641026 0.86641014 0.85547066 0.86641026 0.86641014
 0.8446083  0.86641026 0.86641294 0.8446083  0.8446083  0.8664104
 0.8491443  0.86641026 0.8702639  0.8702639  0.8446083  0.86641026
 0.85547084 0.8454355  0.86025393 0.86641026 0.86641026 0.85547054
 0.85755885 0.86641026 0.86641204 0.84460956 0.8446082  0.86641014
 0.86641026 0.86639977]
tr_loss:[0.3985111  0.39429113 0.3737172  0.37371725 0.39851123 0.39851123
 0.36988312 0.38665462 0.37058845 0.3698831  0.3698831  0.36988312
 0.36988306 0.36988294 0.43887392 0.39851123 0.36842838 0.398753
 0.36988306 0.36987868 0.36834377 0.39851117 0.38979053 0.4387208
 0.36988312 0.36988372 0.36840537 0.36988312 0.36988312 0.4387208
 0.39851123 0.36988312 0.36988312 0.36988312 0.39851108 0.36840522
 0.36988312 0.3698831  0.43872076 0.39849788 0.3683448  0.36988312
 0.36988312 0.38610572 0.3684051  0.4387208  0.4387208  0.36988306
 0.36988312 0.38979056]
tr_loss:[0.1915929  0.20842831 0.21453886 0.19159286 0.19159289 0.23967922
 0.1915929  0.19672194 0.19159287 0.19159292 0.21635136 0.2145389
 0.19715007 0.1915929  0.19159289 0.21453884 0.21453886 0.19159289
 0.1915929  0.19159289 0.21453884 0.19159289 0.1915929  0.1915929
 0.20005223 0.19159245 0.19159292 0.19444165 0.23980257 0.19715008
 0.19159293 0.1915929  0.19159292 0.1915929  0.19146433 0.19159296
 0.19444165 0.19159286 0.23967922 0.19158423 0.19408838 0.19366078
 0.21453884 0.21453881 0.23967922 0.19444168 0.1915929  0.2145389
 0.19159289 0.19159289]
tr_loss:[0.09237465 0.09538706 0.09262802 0.09538062 0.09237464 0.14576654
 0.09237462 0.14576653 0.09579933 0.14576653 0.09237465 0.09449746
 0.14576651 0.0951926  0.09262804 0.09237466 0.09237467 0.09237464
 0.09518036 0.09246288 0.14576651 0.09237465 0.09237467 0.09262801
 0.09579932 0.09387621 0.14576653 0.09237466 0.09237465 0.14576653
 0.09449749 0.09263469 0.09262804 0.09237462 0.09237465 0.09237464
 0.09449748 0.09306984 0.09262804 0.09237466 0.09262799 0.09237467
 0.09237465 0.09579931 0.1457665  0.09237465 0.1454095  0.09306981
 0.09237465 0.09262802]
tr_loss:[0.04018287 0.04168635 0.04168635 0.03067938 0.04168635 0.04168634
 0.03957089 0.04168634 0.03957088 0.04168635 0.04168634 0.03067939
 0.03957089 0.07345118 0.04168635 0.04168634 0.04018605 0.04168634
 0.07345115 0.03946245 0.03957086 0.03957099 0.03790696 0.04018289
 0.04061009 0.04018606 0.07345118 0.04168635 0.03067938 0.07345118
 0.03067939 0.04168634 0.0395709  0.03067938 0.04018288 0.04168635
 0.04168635 0.04168634 0.04186824 0.03067937 0.0394512  0.03957091
 0.04168634 0.03990467 0.04168634 0.0306794  0.04168634 0.07345115
 0.04168634 0.04018288]
tr_loss:[0.02286008 0.01183815 0.01183815 0.02790164 0.02790164 0.05540878
 0.02571674 0.05540878 0.02286009 0.02790393 0.02790164 0.05540878
 0.02273358 0.02790164 0.05540878 0.02790164 0.02286007 0.02790165
 0.02790165 0.02790164 0.02790105 0.02790164 0.02571674 0.02507393
 0.05540878 0.02790164 0.02790291 0.02790164 0.0227973  0.02521782
 0.02790164 0.02790165 0.01183815 0.05511756 0.02790164 0.02790165
 0.05540878 0.02090435 0.01183815 0.02568796 0.02521782 0.02790164
 0.02570006 0.02790164 0.02790164 0.02790165 0.02790161 0.02790163
 0.02790165 0.02790166]
tr_loss:[0.01921072 0.01931765 0.01653101 0.01921073 0.01928827 0.01921073
 0.01983072 0.01921072 0.02087268 0.01542362 0.05994809 0.01049979
 0.01921073 0.01921073 0.02087268 0.01049979 0.01921073 0.01921073
 0.01921073 0.01922871 0.01921073 0.01049979 0.01921072 0.01921077
 0.02087267 0.01983071 0.01921073 0.01921073 0.01921073 0.02050453
 0.05994809 0.05994808 0.01653101 0.01921072 0.01921073 0.01921073
 0.01921073 0.01921073 0.01921073 0.01921073 0.01921073 0.01921073
 0.01933511 0.05994809 0.01049977 0.01921073 0.01921101 0.01922956
 0.01921073 0.01983071]
tr_loss:[0.01309918 0.05646935 0.01671798 0.01279439 0.01309919 0.01310956
 0.05646934 0.01309918 0.01309919 0.01311223 0.05646935 0.01309918
 0.0131058  0.00830249 0.01670901 0.01309918 0.01309918 0.01309918
 0.05646936 0.05646934 0.00830249 0.05646935 0.05646935 0.05646935
 0.01309919 0.01309919 0.01309919 0.00830249 0.00830249 0.05646934
 0.0083025  0.01310121 0.00830251 0.05646934 0.01309918 0.01671798
 0.01309919 0.01309918 0.01309918 0.01299511 0.01309919 0.01309918
 0.01309893 0.01309918 0.05646934 0.01309919 0.01669873 0.01309919
 0.01309918 0.01038227]
tr_loss:[0.01365807 0.04748762 0.04748763 0.01365808 0.01233822 0.01000092
 0.01000092 0.01365809 0.01000091 0.01345729 0.01365807 0.01761771
 0.01730097 0.01365808 0.0180766  0.01365808 0.01365808 0.01365807
 0.01386611 0.01730097 0.04748762 0.0180766  0.01000091 0.01000092
 0.01365808 0.01247715 0.01365808 0.01730097 0.04748763 0.04748762
 0.01365808 0.01365808 0.01000043 0.01365808 0.01521118 0.01365807
 0.01365808 0.01365808 0.01365808 0.01365807 0.01365808 0.01000092
 0.01365808 0.01365808 0.01730097 0.04748763 0.01365808 0.04748762
 0.01365807 0.04748759]
tr_loss:[0.01712865 0.01710168 0.01710168 0.01710169 0.021577   0.01710168
 0.01710259 0.01710513 0.04120763 0.01319885 0.01710168 0.01721772
 0.01710168 0.01319885 0.02051026 0.01710168 0.01710168 0.01752139
 0.01319885 0.01710168 0.04120762 0.01319885 0.02102885 0.01710168
 0.01710168 0.02051026 0.01761483 0.01710168 0.01710168 0.01710168
 0.01710168 0.01710168 0.01710168 0.01710178 0.04120762 0.01710168
 0.01710168 0.01319885 0.01319885 0.01710168 0.01710169 0.01319909
 0.01710168 0.01567227 0.01710168 0.01710168 0.04120762 0.01710168
 0.01710168 0.04120762]
tr_loss:[0.01128024 0.01761222 0.01761245 0.01760863 0.04135966 0.01761222
 0.01441884 0.01761222 0.01771094 0.02217838 0.04135966 0.02188837
 0.01761222 0.01441884 0.01441884 0.01441884 0.02135039 0.01761408
 0.01441885 0.01761222 0.01761222 0.02135039 0.022176   0.01761222
 0.04135965 0.01846336 0.01761222 0.01842628 0.01441884 0.02217836
 0.01761222 0.01771094 0.04135967 0.04135964 0.0213504  0.01771093
 0.01441884 0.01761222 0.01771018 0.04135965 0.01761222 0.02210769
 0.01441884 0.04135977 0.02171505 0.01761222 0.02188836 0.01761222
 0.01761222 0.01441884]
tr_loss:[0.04346806 0.04346805 0.01707592 0.02203997 0.01702952 0.02282187
 0.01702956 0.01466937 0.0172238  0.01702952 0.01702952 0.04346806
 0.0170295  0.01466937 0.01702952 0.01703001 0.0211817  0.01466937
 0.01702952 0.01707577 0.01707592 0.0211817  0.04346805 0.02219151
 0.04346807 0.01702952 0.01702952 0.01466938 0.01702952 0.02203998
 0.04346805 0.01839124 0.01708724 0.04346806 0.01719312 0.04346805
 0.01839124 0.01702952 0.01570118 0.01702952 0.01702952 0.01702952
 0.0211817  0.04346806 0.01702952 0.01702952 0.01722076 0.01702952
 0.02282188 0.01702952]
tr_loss:[0.04460172 0.01665047 0.01526189 0.02242094 0.02241031 0.01665115
 0.01665047 0.01665047 0.04339236 0.01665047 0.01665047 0.01665047
 0.01514387 0.01665046 0.01514386 0.01664838 0.01665046 0.01665047
 0.01665071 0.01665047 0.01665047 0.01514387 0.01665047 0.01665047
 0.01514386 0.02242376 0.01665046 0.01665047 0.01665047 0.02242374
 0.01665047 0.01665046 0.01665047 0.01665047 0.01665047 0.04339235
 0.01665047 0.01665047 0.01665048 0.04339236 0.01665047 0.01665047
 0.01665047 0.01665047 0.02242376 0.02125619 0.01665046 0.04340137
 0.01665047 0.04339236]
tr_loss:[0.0160353  0.01603319 0.02353203 0.01603319 0.02103873 0.01603319
 0.01603319 0.01603319 0.01603319 0.01603319 0.02102954 0.02307755
 0.01524737 0.02103873 0.01603319 0.01817454 0.01603477 0.02103871
 0.02245882 0.04468741 0.01524737 0.01600706 0.01602719 0.01603319
 0.02225773 0.02245882 0.02103873 0.01603316 0.01603756 0.04468741
 0.01603318 0.01603318 0.04468741 0.02103795 0.01603319 0.02103873
 0.04468739 0.01524738 0.01603319 0.0446874  0.01603319 0.01603319
 0.01524949 0.0160332  0.01603318 0.01603319 0.0446874  0.02307737
 0.01603319 0.01524739]
tr_loss:[0.01549713 0.01549713 0.01549706 0.0143003  0.0143003  0.01549714
 0.01430029 0.01549713 0.01555799 0.04482188 0.01546605 0.01549714
 0.01549726 0.04482182 0.01759609 0.01549713 0.01549713 0.01759607
 0.01549713 0.04482188 0.0143003  0.01543479 0.02156202 0.01549713
 0.01571462 0.04482187 0.01549714 0.01556638 0.0143003  0.0143003
 0.01549713 0.04523179 0.04482186 0.01549713 0.0143003  0.01549713
 0.01549713 0.01549713 0.01546606 0.01549713 0.01546589 0.04471007
 0.04482188 0.0143003  0.01565495 0.04482187 0.02032979 0.02156202
 0.01549713 0.01549713]
tr_loss:[0.01543962 0.03946168 0.03946169 0.01269038 0.01543964 0.01269038
 0.01543964 0.02010264 0.01543963 0.01358613 0.01269039 0.01543962
 0.01549211 0.01378175 0.03946168 0.02010182 0.01950243 0.01554539
 0.01543962 0.01543963 0.01543962 0.01543962 0.03946168 0.01543962
 0.01951081 0.01549214 0.01543962 0.0154396  0.02010349 0.03946168
 0.01543963 0.01543962 0.03946167 0.01543963 0.01543962 0.01269038
 0.01543962 0.01544026 0.03946168 0.02010348 0.01269038 0.01543963
 0.01543963 0.01543962 0.01543963 0.04094943 0.02010345 0.01549308
 0.01951081 0.01543962]
tr_loss:[0.01515063 0.01515063 0.01515063 0.01532906 0.01515063 0.01046231
 0.01515064 0.01515063 0.01829866 0.0104623  0.01515063 0.01810562
 0.01515063 0.01515064 0.01515061 0.01379776 0.01810561 0.03189032
 0.0318943  0.01515063 0.01515063 0.01515063 0.03189033 0.01515063
 0.01810562 0.01515063 0.0104623  0.03189031 0.01515063 0.01515063
 0.01515063 0.03189032 0.0104623  0.01515063 0.01515063 0.01829866
 0.0171046  0.03189033 0.01515064 0.0104623  0.01515063 0.03189031
 0.01515063 0.01515063 0.03189032 0.01877563 0.01515063 0.01515063
 0.01527348 0.03189031]
tr_loss:[0.01707445 0.01466711 0.01362093 0.0081085  0.01466711 0.01451773
 0.01507996 0.0081085  0.01466712 0.02516474 0.02516473 0.01466712
 0.01466711 0.01466714 0.01466711 0.02516474 0.01468679 0.0166654
 0.01451746 0.01549044 0.01546912 0.01466712 0.01458661 0.00811332
 0.01466711 0.0081085  0.00810851 0.02516474 0.01418346 0.01466712
 0.01430946 0.02516474 0.01466711 0.01707439 0.01466712 0.01629383
 0.01466714 0.00810847 0.01466187 0.0081085  0.0081085  0.01629383
 0.01466711 0.01666512 0.01449425 0.01466712 0.0081085  0.01466711
 0.01466711 0.0081085 ]
tr_loss:[0.01543143 0.01543139 0.0346241  0.01543139 0.01543139 0.00689629
 0.01543139 0.0068963  0.01543139 0.01543139 0.01372154 0.01543139
 0.01543139 0.01709606 0.0346241  0.0161613  0.01543139 0.01543139
 0.0346241  0.01543138 0.01543139 0.01543139 0.01543139 0.01236772
 0.01543139 0.01525341 0.01387714 0.01715175 0.03462409 0.03462409
 0.00689629 0.01236337 0.03462409 0.01372154 0.03462408 0.01616369
 0.01543138 0.01543139 0.01543139 0.01616369 0.01543138 0.01232618
 0.00689629 0.01715175 0.01543139 0.01547709 0.01543139 0.01543139
 0.01543139 0.01371759]
tr_loss:[0.01603921 0.0398383  0.00570976 0.01402417 0.00570976 0.01603922
 0.01603921 0.01666975 0.01603922 0.01617821 0.01603922 0.01603922
 0.01603922 0.01604009 0.00570976 0.01603922 0.01604553 0.0154023
 0.01603922 0.01540229 0.01666976 0.01603922 0.01603922 0.01603922
 0.01603921 0.00570949 0.03983857 0.01603922 0.03983829 0.00570975
 0.01258574 0.01666976 0.00570976 0.00570975 0.00570976 0.01603922
 0.0154023  0.0398383  0.01603922 0.03983829 0.01603922 0.00570975
 0.01603922 0.01604092 0.03983829 0.0398383  0.01307397 0.03983829
 0.01603922 0.00571105]
tr_loss:[0.01553822 0.01553822 0.01553822 0.00423078 0.01553822 0.01284773
 0.00423078 0.01553822 0.0137087  0.00423078 0.01370869 0.01553822
 0.00723186 0.01390043 0.01553822 0.01553823 0.01553822 0.0137087
 0.00423078 0.01553822 0.01553814 0.01553822 0.00423078 0.00423078
 0.00423078 0.01553822 0.01553862 0.01553822 0.01553822 0.01390041
 0.01514388 0.01390031 0.01553822 0.0371823  0.01514388 0.01370869
 0.01553822 0.01553822 0.03718231 0.00423078 0.01553822 0.01553822
 0.01553822 0.01554585 0.00423078 0.00423078 0.01553822 0.01553772
 0.01514389 0.01553822]
tr_loss:[0.03839083 0.01404898 0.03839082 0.01404898 0.01404933 0.01404898
 0.01396822 0.00446759 0.01404898 0.01404898 0.01440375 0.01404898
 0.03839082 0.01377795 0.01328524 0.03839083 0.00446759 0.00446759
 0.01404965 0.0044676  0.0132858  0.01404898 0.01404898 0.01404898
 0.03839082 0.01404898 0.0132858  0.01404898 0.01333083 0.03839082
 0.0044676  0.01404898 0.01404898 0.01404898 0.01404898 0.01404898
 0.01331371 0.03838942 0.01282972 0.01440341 0.01404898 0.01269186
 0.01404898 0.03885028 0.01440375 0.01377795 0.01440375 0.01209716
 0.01331371 0.014049  ]
tr_loss:[0.01179771 0.01179771 0.0058244  0.01179805 0.01179771 0.01179771
 0.01458239 0.01180323 0.01179771 0.01428941 0.0112628  0.01187163
 0.03835074 0.01179771 0.01179771 0.01179771 0.01428941 0.01179733
 0.01428941 0.01179771 0.01179771 0.01179771 0.01179771 0.01409089
 0.0058244  0.01179771 0.01428941 0.03835074 0.01258423 0.03835074
 0.00580305 0.01179771 0.03835074 0.01179771 0.01409089 0.01125767
 0.01179768 0.01179771 0.01126278 0.01110796 0.01397394 0.01179771
 0.03835074 0.01409088 0.01179771 0.03835074 0.03835072 0.01179782
 0.01179952 0.01179771]
tr_loss:[0.01173993 0.01173994 0.01173993 0.03594379 0.01173993 0.01173993
 0.01683849 0.03594378 0.01173993 0.01173993 0.03594379 0.01173994
 0.01173606 0.01711023 0.01173993 0.01173993 0.03594222 0.01173993
 0.01173993 0.01173994 0.01173994 0.01683847 0.01173994 0.01716608
 0.03594379 0.01556932 0.00893481 0.01220417 0.01606377 0.01173994
 0.01173994 0.01256707 0.01093136 0.01606378 0.03594379 0.01683849
 0.01267119 0.03594379 0.008935   0.01173993 0.01093136 0.008935
 0.01173994 0.01606378 0.01580388 0.01173994 0.03594379 0.008935
 0.01173993 0.01716598]
tr_loss:[0.01334773 0.01334773 0.02629279 0.0182672  0.01952649 0.01334773
 0.01196912 0.01334772 0.01334773 0.01196912 0.01334785 0.02629278
 0.01196913 0.01334773 0.01150691 0.01196912 0.01196913 0.01334773
 0.01334773 0.01334773 0.01334773 0.01334773 0.01334805 0.01334773
 0.0262928  0.01334772 0.01334773 0.01334773 0.01196912 0.01334773
 0.01196913 0.01334772 0.01152731 0.01255836 0.01977153 0.01830962
 0.02629278 0.01334773 0.01196913 0.01334773 0.01830975 0.01196913
 0.01334773 0.01334772 0.01334773 0.0121288  0.01334773 0.01334773
 0.01334772 0.0183098 ]
tr_loss:[0.02320546 0.01319095 0.01865662 0.012326   0.02320546 0.01320555
 0.01098983 0.01319095 0.01316134 0.01319095 0.01893253 0.01320085
 0.01319095 0.01319095 0.01319095 0.01098985 0.01319095 0.01098985
 0.0132066  0.02320546 0.02320547 0.01319095 0.01766118 0.01333196
 0.01766118 0.01319095 0.01319095 0.01098984 0.01408063 0.01319095
 0.01865663 0.01319095 0.01319095 0.01319095 0.01319095 0.02320546
 0.02320546 0.01098984 0.01319095 0.01319095 0.01319095 0.01865662
 0.01319095 0.01319095 0.02320546 0.01319118 0.01319095 0.02320546
 0.01319086 0.01319095]
tr_loss:[0.01165431 0.01256881 0.01652828 0.01625852 0.02173733 0.0125688
 0.02173733 0.01586734 0.01256881 0.01256881 0.01256881 0.01561992
 0.01256881 0.01586734 0.01256881 0.02173732 0.01256881 0.01218458
 0.00782943 0.01256881 0.01561992 0.01256881 0.01165431 0.01256881
 0.01256881 0.01256881 0.01165431 0.01256881 0.00782943 0.01256881
 0.01256881 0.01256881 0.02173732 0.01227188 0.01256881 0.01256962
 0.02173732 0.02173733 0.01256881 0.01256881 0.01586734 0.01256881
 0.01561992 0.01256881 0.01227076 0.01205679 0.01256881 0.00782943
 0.01257174 0.01256881]
tr_loss:[0.01222201 0.01327603 0.01328404 0.01318157 0.0144287  0.01315136
 0.02464117 0.01328403 0.01315136 0.01315274 0.00550163 0.01315523
 0.00550163 0.00550163 0.01399836 0.01222199 0.01315136 0.01315136
 0.00550163 0.01315136 0.01450801 0.014508   0.01315136 0.00559064
 0.01324675 0.00550163 0.0123552  0.01450801 0.01315136 0.01315136
 0.00550163 0.01315136 0.01315136 0.01315136 0.01315136 0.01399831
 0.01315136 0.01315136 0.01315149 0.01315136 0.0144287  0.02464118
 0.01315136 0.01315136 0.02464117 0.01315082 0.01315136 0.00550163
 0.01298269 0.01315137]
tr_loss:[0.00407544 0.01342896 0.00407544 0.0130684  0.03138449 0.01342896
 0.00407544 0.01237017 0.03138449 0.01342896 0.01342896 0.01342915
 0.00407544 0.01342896 0.03138449 0.01342271 0.03138449 0.01342896
 0.01406978 0.01342896 0.00407544 0.00407544 0.03138449 0.03138449
 0.01342896 0.0140698  0.00407544 0.00407544 0.00407548 0.01237017
 0.01342896 0.01342896 0.01342896 0.01342887 0.01342896 0.01342896
 0.01342896 0.03138449 0.01335734 0.03138449 0.00407544 0.01342896
 0.01342895 0.01342896 0.01342896 0.01342895 0.01202363 0.01342896
 0.01342896 0.01237017]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4500 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4501, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4501 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4502, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4502 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4503, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4503 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4504, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4504 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4505, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4505 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4506, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4506 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4507, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4507 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4508, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4508 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4509, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4509 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4510, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4510 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4511, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4511 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4512, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4512 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4513, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4513 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4514, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4514 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4515, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4515 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4516, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4516 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4517, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4517 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4518, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4518 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4519, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4519 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4520, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4520 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4521, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4521 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4522, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4522 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4523, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4523 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4524, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4524 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4525, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4525 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4526, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4526 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4527, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4527 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4528, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4528 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4529, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4529 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4530, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4530 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4531, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4531 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4532, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4532 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4533, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4533 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4534, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4534 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4535, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4535 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4536, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4536 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4537, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4537 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4538, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4538 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4539, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4539 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4540, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4540 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4541, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4541 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4542, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4542 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4543, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4543 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4544, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4544 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4545, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4545 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4546, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4546 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4547, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4547 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4548, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4548 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4549, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4549 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4550, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4550 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4551, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4551 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4552, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4552 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4553, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4553 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4554, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4554 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4555, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4555 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4556, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4556 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4557, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4557 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4558, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4558 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4559, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4559 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4560, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4560 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4561, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4561 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4562, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4562 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4563, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4563 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4564, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4564 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4565, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4565 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4566, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4566 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4567, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4567 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4568, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4568 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4569, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4569 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4570, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4570 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4571, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4571 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4572, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4572 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4573, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4573 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4574, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4574 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4575, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4575 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4576, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4576 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4577, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4577 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4578, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4578 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4579, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4579 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4580, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4580 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4581, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4581 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4582, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4582 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4583, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4583 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4584, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4584 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4585, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4585 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4586, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4586 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4587, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4587 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4588, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4588 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4589, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4589 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4590, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4590 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4591, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4591 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4592, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4592 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4593, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4593 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4594, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4594 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4595, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4595 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4596, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4596 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4597, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4597 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4598, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4598 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4599, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4599 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4600, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-4500
text_input.shape
(4600, 14400)
learning_input_tmp.shape
(4600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4600, 80)
learning_output.shape
(750, 80)
Model: "sequential_93"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_93 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.5875547 1.5928308 1.5661459 1.5658429 1.5658405 1.5875252 1.5879403
 1.5864784 1.5658429 1.553881  1.5875547 1.5661458 1.565843  1.5661457
 1.5875547 1.5717449 1.5661457 1.5661459 1.5661457 1.5661458 1.5661457
 1.5928309 1.5566761 1.566146  1.5928309 1.5661457 1.5661459 1.5661457
 1.5661457 1.5875547 1.5661458 1.5661459 1.5928309 1.5661459 1.5875547
 1.565843  1.5661459 1.5875547 1.5875561 1.5875547 1.5661458 1.5566708
 1.557613  1.5569103 1.5836229 1.566151  1.5875547 1.5928309 1.5661461
 1.5661777]
tr_loss:[0.91404283 0.89189434 0.89189434 0.89189416 0.9546644  0.9945679
 0.91404283 0.89189446 0.95466435 0.8918942  0.99456775 0.89189416
 0.89189434 0.89189434 0.88930476 0.95466363 0.89189446 0.89228994
 0.9945677  0.89189434 0.8956164  0.89189434 0.9945677  0.89189434
 0.89189434 0.89189434 0.8918942  0.89189434 0.91404283 0.95466423
 0.9945647  0.9945677  0.9945677  0.89189434 0.95466435 0.91404283
 0.89189434 0.95466423 0.89189434 0.8918942  0.88039935 0.89189434
 0.9945677  0.99456775 0.91404283 0.91404283 0.89189434 0.91404283
 0.89189434 0.9546644 ]
tr_loss:[0.42105645 0.42105642 0.42105645 0.48798713 0.4306674  0.42105645
 0.42105645 0.4879872  0.4687296  0.4879872  0.42105645 0.42105642
 0.45342177 0.48763403 0.4306674  0.42919582 0.4306674  0.41560465
 0.45334512 0.48798713 0.42105636 0.42105642 0.42105642 0.4298525
 0.4879872  0.42105645 0.42884913 0.42105642 0.42465883 0.42105645
 0.4686696  0.46866965 0.42105642 0.45334506 0.48798722 0.48798713
 0.42105636 0.42105561 0.42105642 0.45334512 0.4879872  0.42105645
 0.42105645 0.4306674  0.42105642 0.4306674  0.48798713 0.42105636
 0.45334512 0.45334512]
tr_loss:[0.16112146 0.16252823 0.2222209  0.17231022 0.16252823 0.17231026
 0.20114937 0.1625283  0.22222087 0.2222209  0.16252828 0.22222087
 0.1723102  0.20189822 0.2017591  0.16252841 0.17231026 0.22222094
 0.16271085 0.17231026 0.20523754 0.20189819 0.20189819 0.16252822
 0.16252828 0.16252823 0.16112146 0.16252823 0.16252825 0.16252825
 0.20156774 0.1625283  0.16252825 0.20189805 0.22222087 0.16252828
 0.20189822 0.2222209  0.1625283  0.15997621 0.1723102  0.1625283
 0.1625282  0.16255507 0.22222087 0.1723102  0.16112149 0.16252822
 0.16252825 0.16252829]
tr_loss:[0.10567994 0.05582682 0.0558268  0.05991988 0.05582682 0.05582681
 0.05582682 0.05582683 0.13203089 0.05991989 0.06002252 0.05991986
 0.0599199  0.05582682 0.06002256 0.13203266 0.05582681 0.10567994
 0.13203089 0.10567994 0.05582681 0.06186872 0.05582681 0.13203089
 0.05582681 0.05582758 0.10567993 0.06002255 0.13203089 0.05991986
 0.0599199  0.05582669 0.05582681 0.0599199  0.06002257 0.10567993
 0.06059904 0.10567994 0.10567993 0.13203087 0.05582681 0.1320309
 0.05991988 0.05582682 0.10567997 0.05582682 0.06186871 0.0558268
 0.13203092 0.06059826]
tr_loss:[0.02858981 0.0518811  0.02713971 0.02858981 0.03273198 0.03324407
 0.02858981 0.05188749 0.02858982 0.02858982 0.02713972 0.02858982
 0.02713971 0.02713972 0.02858991 0.02858981 0.02858982 0.02858981
 0.02858981 0.02713971 0.02713973 0.0518875  0.02858982 0.02713973
 0.02558156 0.0333515  0.02858981 0.0333515  0.02854316 0.02858982
 0.02858983 0.02859214 0.02713973 0.02858982 0.02858982 0.02858982
 0.03324412 0.02713971 0.02858982 0.08944489 0.02858981 0.02858982
 0.05188749 0.02859285 0.02858982 0.02713973 0.05188749 0.02858981
 0.02858981 0.02858982]
tr_loss:[0.01805149 0.01791172 0.01805149 0.01805149 0.06190816 0.01791173
 0.01805149 0.01805149 0.01791173 0.06190817 0.06190817 0.01791173
 0.01791173 0.01805149 0.01791171 0.01791172 0.0193516  0.0141978
 0.01805149 0.0141978  0.01805149 0.01805149 0.06190817 0.0194772
 0.01419777 0.01791172 0.01805149 0.01805149 0.01805149 0.01805149
 0.01805149 0.01791173 0.01930051 0.01419779 0.01930051 0.01949387
 0.01805149 0.01930051 0.01805149 0.06190816 0.01930052 0.01805149
 0.02040278 0.01930049 0.01419782 0.01791173 0.01791172 0.01930052
 0.06190816 0.01930051]
tr_loss:[0.01033818 0.02121788 0.05602651 0.02232175 0.02232175 0.01033818
 0.01033818 0.02232175 0.01637052 0.02232176 0.02232175 0.02232175
 0.02232175 0.02232175 0.02232175 0.02232175 0.01033818 0.02232176
 0.02232175 0.02232175 0.056027   0.02232175 0.056027   0.01637053
 0.02170254 0.02232175 0.056027   0.02232175 0.01033818 0.02232175
 0.02232175 0.02232176 0.00947138 0.02232175 0.05602699 0.02121784
 0.056027   0.02164137 0.01638375 0.01637053 0.056027   0.01033818
 0.02121788 0.01033818 0.02232175 0.01636979 0.05602699 0.02232175
 0.01637054 0.02232175]
tr_loss:[0.02074477 0.02074477 0.01541341 0.02074477 0.01094065 0.01618908
 0.01618906 0.01094064 0.01618934 0.02074486 0.02074477 0.01094065
 0.02074477 0.02074477 0.02074477 0.02074478 0.05567024 0.01094065
 0.05567024 0.0202498  0.02074476 0.01618907 0.05567024 0.02074477
 0.01618906 0.02074477 0.01618906 0.02074477 0.05567024 0.06017815
 0.02074477 0.02116228 0.02074478 0.02074477 0.0202498  0.01618907
 0.02159194 0.01618908 0.01094065 0.02074477 0.05567024 0.02042978
 0.02074477 0.02159141 0.02042977 0.05567024 0.01932812 0.0202498
 0.02074477 0.05567024]
tr_loss:[0.05611508 0.0165006  0.01346097 0.01346097 0.01346097 0.01330818
 0.01603759 0.01330817 0.01330817 0.00171034 0.05611508 0.01330817
 0.0165006  0.01603759 0.05611508 0.01346324 0.01346097 0.01346097
 0.01346097 0.01330818 0.01462428 0.01346097 0.01346098 0.01462428
 0.0165006  0.01346097 0.01346097 0.01346097 0.01462428 0.01330818
 0.01330817 0.01330817 0.01603759 0.05611508 0.01346097 0.01346097
 0.05611508 0.01330817 0.0160376  0.01346097 0.01603759 0.01346097
 0.01603759 0.05611508 0.01408133 0.0160376  0.01330817 0.01603759
 0.01346096 0.05611508]
tr_loss:[0.00778785 0.06046219 0.00778785 0.00780582 0.01129081 0.00778785
 0.01129081 0.00785516 0.06046219 0.01262819 0.00782355 0.02687613
 0.00778784 0.00778784 0.02687613 0.01129081 0.00778785 0.00778785
 0.01262819 0.00778785 0.00778785 0.00778784 0.00778779 0.00778785
 0.00778784 0.00778785 0.01486488 0.00778785 0.06046218 0.01262819
 0.00778785 0.01262819 0.00778785 0.00778784 0.02687612 0.02687612
 0.00778785 0.01262819 0.00778785 0.01487977 0.00778785 0.00778825
 0.01262819 0.01262819 0.00778785 0.00790877 0.01129081 0.00778785
 0.01126401 0.0077866 ]
tr_loss:[0.01026704 0.06416584 0.01512805 0.01548095 0.00571281 0.00571281
 0.0057128  0.00571282 0.06469084 0.01026704 0.03770874 0.0057128
 0.01512806 0.01488419 0.06469085 0.00571281 0.03770875 0.00571281
 0.06469085 0.00571281 0.01512805 0.06469423 0.06469084 0.0148944
 0.00571281 0.00571281 0.0153045  0.06469086 0.00571282 0.0150357
 0.0057128  0.03770876 0.03770874 0.06469086 0.00571281 0.01512806
 0.01548112 0.0057154  0.01512805 0.00571281 0.00571281 0.01120331
 0.00571315 0.00571281 0.00571281 0.01548112 0.03770876 0.01512805
 0.00571293 0.00571281]
tr_loss:[0.06167783 0.00405275 0.01320994 0.00405275 0.00405252 0.00405275
 0.01321004 0.00405274 0.01245124 0.00405274 0.03612209 0.0361221
 0.01167251 0.06167782 0.00405274 0.01245122 0.00405274 0.00547436
 0.00405274 0.00405274 0.00405275 0.06167784 0.01245123 0.00405275
 0.00405274 0.01315943 0.03612209 0.00405274 0.00206864 0.00405275
 0.00405275 0.00405274 0.00379293 0.00405274 0.01321004 0.00405274
 0.00740349 0.03612209 0.0361221  0.03612209 0.00405274 0.00405274
 0.06167783 0.00405357 0.00405275 0.00405273 0.03612209 0.00405274
 0.00405274 0.00405274]
tr_loss:[0.003632   0.02483918 0.00683647 0.003632   0.003632   0.00683647
 0.00643829 0.003632   0.003632   0.003632   0.003632   0.02483919
 0.003632   0.003632   0.02483919 0.00363115 0.003632   0.00643618
 0.00390086 0.00390082 0.05430662 0.003632   0.003632   0.02483926
 0.02418106 0.00608499 0.003632   0.003632   0.00363206 0.003632
 0.003632   0.02483919 0.02483919 0.003632   0.00683647 0.003632
 0.003632   0.00643829 0.003632   0.003632   0.00643829 0.00075407
 0.003632   0.05430662 0.02483919 0.00364443 0.003632   0.003632
 0.05430666 0.003632  ]
tr_loss:[0.00430582 0.01749487 0.05237923 0.00748795 0.00697717 0.00430583
 0.01010493 0.05237923 0.01749408 0.05237923 0.01010491 0.01010493
 0.05238995 0.00748795 0.01749408 0.00748795 0.01749408 0.01010053
 0.01010493 0.00697717 0.01010493 0.01010492 0.01749408 0.00672315
 0.00697717 0.01009416 0.01010492 0.01010493 0.00430582 0.01010493
 0.01010492 0.01010493 0.00612523 0.00430583 0.01010493 0.01010493
 0.00697717 0.00748795 0.00430583 0.01010493 0.01010494 0.01749408
 0.01010493 0.01010493 0.01749408 0.01010493 0.01010494 0.00612084
 0.00748795 0.00697721]
tr_loss:[0.00381919 0.00874177 0.0128329  0.0128329  0.00874177 0.05111683
 0.0128329  0.0128329  0.00939828 0.00381918 0.05141761 0.0128329
 0.01437795 0.01438439 0.01281922 0.01282596 0.00944417 0.05088938
 0.00874176 0.05111683 0.0128329  0.00381918 0.0128329  0.00874176
 0.00939828 0.01437795 0.0128329  0.0128329  0.00381918 0.0128329
 0.05112449 0.00381683 0.00381919 0.05111683 0.0128329  0.0128329
 0.01283117 0.01283292 0.0128329  0.01437796 0.0128329  0.05111683
 0.05111682 0.00381919 0.0128329  0.0128329  0.0128329  0.05111683
 0.00879385 0.0128329 ]
tr_loss:[0.00906086 0.01282964 0.01282963 0.00905927 0.00906086 0.00906086
 0.04665193 0.002053   0.01282964 0.00906087 0.00906086 0.00906086
 0.00906087 0.00906086 0.00906086 0.01282964 0.00775889 0.04665194
 0.01282963 0.00906086 0.04665194 0.04665193 0.04665192 0.0020546
 0.01282963 0.01282963 0.00906086 0.04665194 0.00558114 0.002053
 0.00906086 0.00906086 0.04665193 0.00906086 0.00906086 0.04665193
 0.00906079 0.00906087 0.04665193 0.00906086 0.00906085 0.00906086
 0.04665193 0.00906091 0.01282964 0.00908016 0.01282964 0.01282963
 0.00906086 0.00906086]
tr_loss:[0.00352189 0.04041443 0.00664033 0.01431056 0.00664034 0.01431072
 0.00784225 0.04041443 0.00352189 0.00664033 0.0083328  0.01431056
 0.00664033 0.00446143 0.00664034 0.00784225 0.00664033 0.04041444
 0.00666854 0.00664033 0.01431056 0.04041443 0.00664242 0.00664034
 0.04041443 0.01431056 0.01431056 0.00664032 0.00784225 0.00352189
 0.00352189 0.01431056 0.00352189 0.00352189 0.00352189 0.00664038
 0.00664033 0.00664033 0.01431056 0.00352189 0.00664033 0.00664034
 0.01431056 0.00664033 0.00664033 0.00784225 0.01431059 0.00664033
 0.01431056 0.04041443]
tr_loss:[0.01683443 0.00772635 0.00726377 0.00726377 0.00772635 0.00982999
 0.00772636 0.01683444 0.01128284 0.00772635 0.01683444 0.00772636
 0.00772635 0.02965649 0.00983    0.00772638 0.02965649 0.00726377
 0.00772635 0.00774883 0.00772635 0.01683444 0.02965648 0.00772635
 0.00772635 0.01128284 0.01146014 0.01683444 0.0296565  0.00772635
 0.00726377 0.00780998 0.00737522 0.00726377 0.00772635 0.00772635
 0.01683443 0.011686   0.00772636 0.02965649 0.01128284 0.0296565
 0.00883493 0.00726377 0.00664347 0.00772635 0.00586273 0.0112728
 0.00772636 0.00726377]
tr_loss:[0.01238848 0.01834393 0.0103128  0.01031279 0.0103128  0.01186555
 0.0103128  0.01186554 0.0103128  0.01186555 0.02106782 0.00803478
 0.01031279 0.02106782 0.01834394 0.01031279 0.01031279 0.01502592
 0.01834393 0.0103128  0.01031279 0.01031279 0.0103128  0.01508241
 0.01186555 0.02106781 0.01508143 0.01186558 0.01031279 0.0104912
 0.0103128  0.01031279 0.01508241 0.01031279 0.02106783 0.02107374
 0.01834393 0.01508241 0.00836823 0.0103128  0.01031279 0.00788164
 0.01508241 0.01031279 0.01031341 0.0103128  0.01031279 0.01031279
 0.01186554 0.02106781]
tr_loss:[0.00780412 0.02433883 0.00780412 0.00780412 0.01266202 0.02433882
 0.00780427 0.00780411 0.00780411 0.01121665 0.02433883 0.02433827
 0.00940649 0.00780412 0.00780412 0.00780412 0.00780412 0.00780411
 0.02433885 0.00780412 0.00780412 0.00942714 0.00780412 0.00780411
 0.00780412 0.01121666 0.00780411 0.02433882 0.00780412 0.01959953
 0.0195708  0.01121666 0.00780412 0.01121666 0.01929167 0.01254968
 0.01121666 0.00590975 0.01121666 0.01266202 0.01959953 0.00780412
 0.00780411 0.02433873 0.00942714 0.00780412 0.01121665 0.00780412
 0.00942714 0.00780407]
tr_loss:[0.00563669 0.01946004 0.00563669 0.00997713 0.00997713 0.00997713
 0.01946004 0.03187564 0.03187563 0.00997713 0.01007309 0.00563669
 0.0056367  0.00563669 0.00563669 0.00997713 0.00704512 0.00563669
 0.00563669 0.00704512 0.03187562 0.00997713 0.01946003 0.00997713
 0.00563669 0.00599196 0.00704512 0.00563669 0.00563669 0.03187562
 0.00563669 0.00563669 0.01038525 0.01946004 0.00997713 0.00564567
 0.00563669 0.00563669 0.01946004 0.00563669 0.00563669 0.00563669
 0.01955351 0.01018455 0.00997713 0.00563669 0.00563669 0.00997713
 0.00563669 0.00997713]
tr_loss:[0.00394121 0.0376313  0.0039412  0.0039412  0.0039412  0.01691433
 0.00650021 0.01823709 0.0039412  0.0039412  0.0039412  0.03763131
 0.00782636 0.00782636 0.01823708 0.03763133 0.03763131 0.03763131
 0.0039412  0.0039412  0.01823706 0.0039412  0.0039412  0.00394119
 0.03763132 0.00782636 0.00782637 0.03763132 0.0039412  0.01823709
 0.0039412  0.0039412  0.0039412  0.0039412  0.03763132 0.03763132
 0.01823708 0.0039412  0.0039412  0.0039412  0.0039412  0.00757472
 0.00757476 0.00650022 0.01823709 0.00650022 0.00532532 0.03763133
 0.00782636 0.0039412 ]
tr_loss:[0.00443925 0.00443925 0.00443925 0.00642265 0.00443925 0.01625823
 0.00335321 0.00443925 0.00443911 0.00339473 0.00443925 0.00166266
 0.00599916 0.03646043 0.00443925 0.00443925 0.03646043 0.03646042
 0.00339473 0.03646042 0.00443925 0.01625823 0.01625823 0.00443925
 0.00443925 0.03646042 0.00443925 0.00443925 0.03646043 0.01625822
 0.00339352 0.01625822 0.00642265 0.00599617 0.00339473 0.00443925
 0.00642263 0.01625823 0.00443925 0.00496894 0.00443924 0.00443925
 0.00443925 0.01625823 0.00443925 0.00496894 0.00443925 0.03646044
 0.00443925 0.00642265]
tr_loss:[0.00696554 0.00280935 0.00631917 0.00631918 0.00718778 0.03315792
 0.03315792 0.00696554 0.00696554 0.0331579  0.01575738 0.00718778
 0.00696554 0.00651608 0.00696554 0.03315793 0.00696554 0.01575738
 0.00696554 0.00696554 0.03315791 0.03315793 0.00280921 0.00696554
 0.00631917 0.00696554 0.00696554 0.00280921 0.03315791 0.00631917
 0.00718778 0.00696554 0.00280921 0.00696554 0.01342266 0.0065161
 0.03315791 0.03315792 0.00696554 0.01575738 0.00696554 0.01575796
 0.00696554 0.03315793 0.03315791 0.00651608 0.0331579  0.03315791
 0.01575738 0.00280921]
tr_loss:[0.00978159 0.00978159 0.00978159 0.00978159 0.00978158 0.00469137
 0.01725961 0.00978158 0.00945632 0.00978159 0.01725961 0.01725961
 0.00978159 0.0046913  0.00978159 0.00469129 0.00860535 0.00978159
 0.00945632 0.0172596  0.00469129 0.00978159 0.00978159 0.00860535
 0.00978159 0.00978159 0.00978159 0.0097816  0.02203409 0.0220341
 0.0220342  0.00469129 0.00978159 0.00978159 0.00978158 0.0172596
 0.00978158 0.00945632 0.00860535 0.00978159 0.00978159 0.00978159
 0.00978159 0.00469129 0.00469129 0.00860535 0.00978159 0.00673895
 0.00860535 0.02203406]
tr_loss:[0.00819532 0.00819532 0.00922171 0.00819532 0.00819532 0.00516038
 0.00516038 0.00819524 0.00819531 0.00516038 0.00819532 0.00819532
 0.01783979 0.00922171 0.00819532 0.00819532 0.00819532 0.00792275
 0.01783979 0.00860071 0.00819532 0.00819532 0.00792276 0.01783979
 0.01783979 0.00819532 0.00819532 0.00922172 0.00819532 0.00516038
 0.01783979 0.01783979 0.00516038 0.00792276 0.00819532 0.00819532
 0.00516038 0.0047238  0.01783979 0.00819532 0.01783979 0.01783979
 0.00819532 0.01784228 0.00819532 0.00819528 0.00819531 0.01783979
 0.01782295 0.01783978]
tr_loss:[0.00463857 0.01509546 0.00463857 0.01509547 0.00475315 0.00475315
 0.00475327 0.00463871 0.00732906 0.00475314 0.00475315 0.00475318
 0.00463858 0.00475315 0.01509547 0.0048298  0.02453155 0.00463858
 0.00463857 0.00475315 0.00475315 0.00475315 0.01509547 0.00475315
 0.00463857 0.00475315 0.01509548 0.00475315 0.00475314 0.00475315
 0.00475315 0.00475317 0.00475303 0.00475315 0.00565995 0.00475315
 0.00475315 0.02453154 0.00475315 0.00475315 0.00475315 0.01509546
 0.02453144 0.00475315 0.00565749 0.00475315 0.00475315 0.00475315
 0.00475315 0.00475315]
tr_loss:[0.01639806 0.00652983 0.0038136  0.00381359 0.01639806 0.01639806
 0.00825845 0.00381359 0.00652983 0.00381359 0.00652983 0.03453848
 0.00652983 0.03453847 0.00586482 0.00586481 0.00381359 0.00652983
 0.00652983 0.03453848 0.00381363 0.00394727 0.00381359 0.0038136
 0.00815098 0.03453847 0.00381359 0.00652983 0.00825845 0.00815097
 0.00381359 0.00381359 0.00586482 0.03453847 0.00652983 0.01639806
 0.00652983 0.00652983 0.00381359 0.01639807 0.00586481 0.00652983
 0.00381359 0.00652983 0.00381359 0.00381359 0.00381462 0.00652983
 0.01639806 0.00381359]
tr_loss:[0.00405853 0.00733176 0.00405852 0.00405851 0.03945231 0.03996469
 0.00405851 0.01613629 0.00733177 0.00405851 0.01613628 0.01613628
 0.00405851 0.00405851 0.00405852 0.03945304 0.00405851 0.0064516
 0.01613628 0.00405851 0.03945231 0.00405851 0.00733176 0.00405851
 0.00405852 0.00216341 0.00899719 0.03945232 0.00405852 0.03945232
 0.00405851 0.00405851 0.00405851 0.00902032 0.01613628 0.01613628
 0.00405851 0.00405851 0.00405851 0.03945232 0.00405842 0.03945232
 0.00405852 0.03945231 0.00899503 0.00899514 0.00902032 0.00405851
 0.03945231 0.00733177]
text_input.shape
(4600, 14400)
learning_input_tmp.shape
(4600, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4600, 80)
learning_output.shape
(750, 80)
Model: "sequential_94"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_94 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3381636 1.1897006 1.1812936 1.2439328 1.1964066 1.1812935 1.1812934
 1.1896982 1.1812936 1.1910689 1.1813676 1.3381637 1.1897004 1.2444284
 1.1812936 1.3021246 1.2439624 1.3381636 1.1897002 1.1812935 1.196409
 1.1812936 1.2439327 1.1897004 1.1812936 1.1812936 1.3381636 1.1897004
 1.1812935 1.1897004 1.1897004 1.1963367 1.1812936 1.1812935 1.3236189
 1.3377715 1.1812994 1.1964066 1.3381637 1.1882927 1.1812936 1.1812936
 1.1812936 1.1812936 1.1876954 1.1812961 1.2439326 1.1812935 1.1812937
 1.243933 ]
tr_loss:[0.7424756  0.7393233  0.7424756  0.7424822  0.7452667  0.74527156
 0.7393233  0.7433988  0.74247557 0.76675713 0.7433957  0.8135336
 0.7433957  0.7433958  0.74526674 0.7424756  0.7424756  0.74339575
 0.74247557 0.81353366 0.7424756  0.7424756  0.7424756  0.7424755
 0.7424756  0.8135338  0.7424755  0.7406578  0.7424756  0.7424756
 0.7424756  0.74245846 0.8135338  0.74526674 0.7424756  0.7474543
 0.7433957  0.7424756  0.7393278  0.74526674 0.7424756  0.7424756
 0.7421535  0.7424761  0.74112    0.74247557 0.74247557 0.74247557
 0.74339575 0.7424756 ]
tr_loss:[0.5422266  0.49922505 0.5424925  0.542493   0.5076191  0.49922508
 0.5117251  0.50403374 0.5424925  0.5424925  0.49922514 0.5210701
 0.5210702  0.49922514 0.49922508 0.49922505 0.49922514 0.5424925
 0.5424925  0.5040337  0.5424924  0.50761914 0.49922508 0.49922505
 0.50403374 0.50761914 0.5424924  0.49922514 0.5210702  0.50403374
 0.49922505 0.54249245 0.5097646  0.5422267  0.49922508 0.49922505
 0.5424925  0.50761914 0.5210702  0.5424925  0.49922505 0.49922475
 0.5119689  0.5210702  0.49922505 0.49922505 0.49922508 0.49605894
 0.5210701  0.52107024]
tr_loss:[0.37940103 0.3663774  0.3178069  0.32723597 0.31780702 0.3282038
 0.3663774  0.3178069  0.3178069  0.3234676  0.3178069  0.33532143
 0.31560796 0.3178183  0.37940103 0.32723588 0.32723597 0.37940097
 0.3178069  0.36637744 0.3178069  0.3178069  0.3178069  0.33532137
 0.32723594 0.3178069  0.3663774  0.37940097 0.3663774  0.33532137
 0.379401   0.3178069  0.31780687 0.3178069  0.3663774  0.3178069
 0.37940097 0.37940097 0.31559446 0.36637738 0.3178069  0.32723588
 0.379401   0.32723594 0.3178069  0.36637735 0.37940097 0.3178069
 0.37940097 0.37940103]
tr_loss:[0.22302918 0.21192363 0.22302918 0.24959266 0.21192363 0.22302918
 0.21192364 0.26719084 0.2671908  0.24959269 0.21192363 0.21680132
 0.21192364 0.21192363 0.21755195 0.21192363 0.21192363 0.21755195
 0.2119236  0.21192364 0.21192363 0.21676393 0.21192363 0.211912
 0.21192364 0.21192363 0.21192363 0.21192364 0.21274304 0.21192364
 0.21274295 0.21679874 0.22302918 0.21192363 0.21192363 0.21192363
 0.24959269 0.2495927  0.21192363 0.26719084 0.2673654  0.21192363
 0.22302914 0.24959269 0.24959274 0.24959263 0.21870479 0.22302918
 0.24959269 0.21192363]
tr_loss:[0.15105966 0.1525642  0.15105966 0.1526443  0.16739765 0.16726355
 0.14914759 0.14932981 0.15105964 0.1525642  0.14938958 0.14914764
 0.14914764 0.1525642  0.18377742 0.15256418 0.16726358 0.15105963
 0.1525279  0.15256418 0.1525642  0.1525642  0.15105964 0.15211122
 0.15212509 0.15105966 0.14899485 0.16726346 0.1525642  0.16726358
 0.14914764 0.15254326 0.15105961 0.16726355 0.16726355 0.1525642
 0.15256421 0.15211122 0.1525642  0.1525642  0.1525642  0.15105963
 0.15105966 0.1525642  0.1525642  0.1525642  0.15105963 0.18377745
 0.18377802 0.15256378]
tr_loss:[0.08762822 0.1168313  0.09352534 0.11683132 0.07909898 0.08896901
 0.09352534 0.11683132 0.09352534 0.09352534 0.09352534 0.09352534
 0.08896901 0.07909901 0.088969   0.09352534 0.09352534 0.11683134
 0.079099   0.09352534 0.09352534 0.08775405 0.09352533 0.09352534
 0.0935248  0.079099   0.1168313  0.08896902 0.1168313  0.08896905
 0.08896903 0.09352534 0.09352536 0.09352534 0.11683132 0.09104191
 0.11682387 0.09352534 0.09352534 0.08896901 0.09352533 0.09103873
 0.09352535 0.09352534 0.09352534 0.08896901 0.0910419  0.08896901
 0.07909898 0.08761196]
tr_loss:[0.07127675 0.07127675 0.06869444 0.06605415 0.06605418 0.05695319
 0.07127424 0.05695318 0.07127675 0.07127676 0.07127675 0.06607559
 0.07127672 0.07127673 0.06561985 0.05906428 0.05695319 0.07127674
 0.06869444 0.05695229 0.06869444 0.05695318 0.09713249 0.09713249
 0.06869445 0.09713251 0.06561985 0.05906428 0.05907056 0.06769244
 0.05906429 0.06618927 0.09713235 0.07127674 0.05695318 0.07127669
 0.0569532  0.05906429 0.05695318 0.07127675 0.06561984 0.05695318
 0.07127675 0.07127674 0.05906429 0.06561986 0.07127674 0.09713249
 0.0971325  0.07127673]
tr_loss:[0.05796415 0.05796416 0.06786377 0.06786377 0.06786376 0.06786376
 0.06786376 0.06786376 0.06786376 0.09420558 0.06786376 0.09420558
 0.06786376 0.06786376 0.06625078 0.09420558 0.06786595 0.06786377
 0.06684698 0.06786378 0.06786376 0.06786376 0.09420558 0.06786377
 0.0540357  0.09420558 0.09420558 0.05403571 0.06786376 0.06786376
 0.0540357  0.06786376 0.06786377 0.06786376 0.05403571 0.06786377
 0.05796417 0.06786377 0.05796416 0.06786376 0.05403571 0.0540357
 0.06786377 0.06786377 0.05403571 0.06684698 0.06786376 0.06684698
 0.06786376 0.05403571]
tr_loss:[0.06089862 0.06617425 0.09439177 0.06089862 0.06084653 0.06411753
 0.06617425 0.06617425 0.06617426 0.05680105 0.06617425 0.09439177
 0.06617425 0.06617425 0.06089862 0.06617425 0.09439177 0.05638411
 0.05680106 0.06617425 0.06617521 0.06617425 0.06617425 0.06617425
 0.05680105 0.06089863 0.09439177 0.06617425 0.05680104 0.06617425
 0.05680105 0.06617425 0.06089862 0.06089862 0.09439178 0.06617424
 0.06617426 0.05680106 0.06617425 0.06617425 0.06617325 0.09439178
 0.06617425 0.06089863 0.06617425 0.06731704 0.06089862 0.06617428
 0.06617425 0.06089862]
tr_loss:[0.06144484 0.0627881  0.06144486 0.09348843 0.0627881  0.0627881
 0.0627881  0.06278823 0.06144484 0.06803266 0.0627881  0.0630502
 0.0627881  0.0627881  0.0627881  0.06278811 0.06868238 0.06144484
 0.0627881  0.06144484 0.06144486 0.06144484 0.0627881  0.0627881
 0.0627881  0.09348555 0.06868237 0.06278811 0.0627881  0.06278767
 0.06484984 0.06305599 0.09334369 0.06144484 0.0627881  0.06144486
 0.0627881  0.09348556 0.0627881  0.06618537 0.06278811 0.0627881
 0.0627881  0.06618537 0.06278831 0.06144484 0.09348556 0.06305021
 0.09348556 0.06144485]
tr_loss:[0.0727952  0.06122994 0.06122994 0.06344981 0.06122994 0.06122993
 0.06122995 0.06662271 0.06122993 0.09238882 0.07279082 0.06122994
 0.06122994 0.07279521 0.09238882 0.09238882 0.0634498  0.06122993
 0.06662271 0.06122994 0.09238881 0.06122994 0.06344981 0.06122994
 0.06122994 0.06171543 0.07279521 0.06122994 0.09238882 0.09238882
 0.09238882 0.09238882 0.06122994 0.0727952  0.06122995 0.06122994
 0.0614571  0.06125964 0.09238882 0.0727952  0.09238882 0.06122988
 0.06973567 0.06141143 0.06122994 0.06344981 0.09238882 0.06122994
 0.06344981 0.06123307]
tr_loss:[0.06337343 0.06686854 0.07758215 0.06337343 0.07721146 0.07721146
 0.07310814 0.06337342 0.07326365 0.06337342 0.07758216 0.06337343
 0.06686856 0.06337343 0.06686854 0.07758216 0.06337343 0.07758214
 0.06686855 0.07758217 0.06337342 0.07721146 0.06337343 0.06337343
 0.06337312 0.07758215 0.07721145 0.06686856 0.06686855 0.07721148
 0.06337343 0.07326965 0.06337343 0.06337343 0.07721148 0.06337343
 0.07758215 0.06909022 0.06338093 0.0633734  0.06686856 0.07326365
 0.07758216 0.06337343 0.06337343 0.06337344 0.06337343 0.07721148
 0.07758217 0.06686856]
tr_loss:[0.06922234 0.07459156 0.07459158 0.06486224 0.06843059 0.06486131
 0.07459158 0.06486131 0.06486131 0.07756947 0.06486131 0.06486131
 0.06486131 0.06486131 0.06486131 0.0684306  0.06486131 0.06486131
 0.07459158 0.06486131 0.06486131 0.06843059 0.06843059 0.06486131
 0.06966355 0.07459158 0.06486131 0.07756713 0.06843067 0.06486131
 0.07756741 0.06486131 0.06830435 0.0696649  0.0775663  0.0745453
 0.06486131 0.0696102  0.07756715 0.06922232 0.07756712 0.06486131
 0.06922232 0.06486131 0.06922267 0.06345341 0.06486131 0.06486131
 0.07756715 0.07454528]
tr_loss:[0.06257945 0.05876793 0.05876793 0.07258652 0.05876793 0.05876793
 0.07258652 0.05876793 0.06543383 0.07258651 0.06187106 0.05876793
 0.05876793 0.05876793 0.07258651 0.05876793 0.07258409 0.07258651
 0.05876793 0.06757165 0.05876793 0.05876793 0.06831007 0.07598249
 0.05876793 0.06543458 0.0759825  0.07258651 0.05876793 0.05876793
 0.05876793 0.05876794 0.07258651 0.0759825  0.06831007 0.07258652
 0.06543453 0.06831007 0.06543453 0.05876793 0.05876793 0.05876793
 0.05876788 0.05876793 0.05876793 0.06543454 0.06129825 0.06831006
 0.05876793 0.05876793]
tr_loss:[0.05525333 0.05525333 0.06840917 0.05929182 0.05525333 0.06304238
 0.05525327 0.05525334 0.05525333 0.05525334 0.05525334 0.05525334
 0.05525334 0.09005736 0.05525334 0.06840916 0.05525334 0.05525333
 0.05525334 0.05789389 0.09041093 0.09041093 0.06304238 0.06351545
 0.06840915 0.06840917 0.05525333 0.05525333 0.06304236 0.05525334
 0.056325   0.06840917 0.05525334 0.06304238 0.05525334 0.05525334
 0.06840916 0.06840916 0.05789389 0.06840916 0.05525333 0.05304309
 0.05525334 0.06304239 0.06304238 0.05525333 0.05525334 0.05525334
 0.09041094 0.06840916]
tr_loss:[0.05484045 0.09728095 0.05484045 0.05484045 0.06104637 0.05484014
 0.09728094 0.09728095 0.05601134 0.05484045 0.09728095 0.05484045
 0.06129183 0.05484045 0.06129282 0.05484045 0.09728096 0.09727049
 0.05484045 0.05484045 0.05484045 0.05484045 0.06135238 0.05484045
 0.06431898 0.05484043 0.09728807 0.06431898 0.05484045 0.0612928
 0.05484045 0.05601134 0.05484045 0.06139217 0.06129281 0.05484045
 0.05484045 0.06135238 0.05484045 0.09728096 0.06135238 0.09728094
 0.06129282 0.06135238 0.05601134 0.05484045 0.06431897 0.05484045
 0.05601134 0.05484045]
tr_loss:[0.06091433 0.0542313  0.05755713 0.05987025 0.0542313  0.09833872
 0.06091433 0.05413329 0.06091433 0.0542313  0.05413329 0.0542313
 0.05755713 0.05755713 0.06091433 0.0542313  0.0542313  0.05755713
 0.0542313  0.06091433 0.05389904 0.05786345 0.0542313  0.09833872
 0.05755714 0.0542313  0.05423077 0.09833872 0.06091433 0.058301
 0.0542313  0.05423131 0.05746056 0.0542313  0.09833872 0.05299488
 0.09833872 0.09833872 0.05755713 0.05755713 0.06091433 0.0542313
 0.05755714 0.09833872 0.09833872 0.0542313  0.05830099 0.05786356
 0.0542313  0.09833872]
tr_loss:[0.0983568  0.0532608  0.0983568  0.05499914 0.05499915 0.05499915
 0.05499914 0.05568982 0.09835681 0.05401666 0.05497617 0.05401666
 0.0532608  0.05499914 0.05499915 0.05325634 0.05499914 0.09835681
 0.05920333 0.05499914 0.05499914 0.05621449 0.05497042 0.05920335
 0.0538232  0.0983568  0.05499915 0.0532608  0.09835681 0.05499914
 0.05499911 0.0532608  0.0532608  0.05499915 0.05499914 0.05401666
 0.05920335 0.05499914 0.05499915 0.05499914 0.0532608  0.05499914
 0.09835681 0.05920335 0.05499914 0.05401666 0.05499914 0.09835681
 0.0532608  0.05499915]
tr_loss:[0.05605222 0.05633013 0.05605222 0.05633013 0.05522606 0.05121506
 0.05121507 0.05121507 0.05633012 0.05633013 0.05633012 0.05633013
 0.09984959 0.06089599 0.05633012 0.05633011 0.05544413 0.05633011
 0.05121507 0.05633018 0.05633013 0.05635533 0.09984959 0.05633013
 0.05633013 0.05633013 0.09984957 0.05121506 0.05633013 0.05522607
 0.05522607 0.05121507 0.05633012 0.05522607 0.05605221 0.05633013
 0.09984959 0.06089598 0.05633013 0.05605223 0.05633013 0.05633013
 0.05347449 0.06089599 0.05633013 0.06089598 0.05605222 0.06089599
 0.05121506 0.05121506]
tr_loss:[0.0533843  0.0533843  0.04796762 0.05338432 0.05352768 0.0533843
 0.05338431 0.05955264 0.0533843  0.04796762 0.05338431 0.04796762
 0.05338431 0.05338432 0.05338431 0.0533843  0.09834936 0.05955263
 0.04796762 0.04796762 0.05955263 0.09834936 0.09834936 0.05338432
 0.05338432 0.04796762 0.05338431 0.09834936 0.05338395 0.09834936
 0.05338432 0.09834936 0.05349933 0.05338432 0.05352768 0.05969457
 0.05276068 0.0533843  0.05955263 0.05956288 0.04796762 0.05338432
 0.04796762 0.05338432 0.04796762 0.05338432 0.05338431 0.09834936
 0.05338432 0.04796762]
tr_loss:[0.03768024 0.03768024 0.04275655 0.03818635 0.03768024 0.03768025
 0.03768024 0.0341425  0.03944252 0.03414252 0.03768024 0.0341425
 0.04275656 0.03768023 0.03628365 0.03768025 0.03628365 0.04275656
 0.03628364 0.04275656 0.0341425  0.04275655 0.03944252 0.03768025
 0.03768025 0.03768024 0.03628364 0.03768024 0.08397897 0.03767996
 0.03768025 0.03768024 0.03817656 0.0341425  0.03772887 0.03768025
 0.04275656 0.03414249 0.03414251 0.04275656 0.0341425  0.08397898
 0.03768025 0.04275656 0.08397897 0.03768023 0.03945579 0.03623112
 0.03768024 0.08397963]
tr_loss:[0.05819209 0.01119012 0.01053101 0.01053098 0.01669703 0.01053101
 0.00964652 0.05819209 0.01053101 0.01053087 0.01669704 0.01053101
 0.01053102 0.01669703 0.01053101 0.01669703 0.01053101 0.01400299
 0.01053101 0.01053102 0.01119011 0.01119012 0.01287832 0.05819209
 0.01669704 0.01400299 0.01119011 0.01052931 0.01053101 0.01053102
 0.01053102 0.01053101 0.05819209 0.01053102 0.05819209 0.00965001
 0.01669704 0.01053101 0.00965038 0.01119012 0.01053102 0.01053102
 0.01119011 0.01119012 0.01053101 0.01053102 0.01053102 0.0581921
 0.01053102 0.01053102]
tr_loss:[0.00438085 0.05267363 0.05267363 0.00438085 0.01139387 0.01139387
 0.00841699 0.01139387 0.00455046 0.00890752 0.00438086 0.00438086
 0.05267363 0.00438085 0.05267364 0.01139387 0.00890752 0.00438086
 0.05267363 0.0045504  0.00438086 0.05267363 0.00438086 0.01139387
 0.05267363 0.00848787 0.05267363 0.00438085 0.01139387 0.05267363
 0.00438086 0.00438086 0.00890753 0.00438086 0.00443    0.01139387
 0.00438086 0.0086138  0.00455046 0.00243856 0.00438086 0.01139387
 0.00438086 0.00438085 0.05267363 0.00438086 0.00455046 0.00438086
 0.00438085 0.00866117]
tr_loss:[0.00510278 0.00510278 0.00988943 0.01032184 0.01032184 0.00510278
 0.00510278 0.00510278 0.00510278 0.01032184 0.05294876 0.00510278
 0.00510278 0.01032184 0.00988943 0.05294876 0.00510278 0.01074578
 0.01013599 0.01013422 0.00510278 0.0051027  0.05294876 0.01023459
 0.00510293 0.00510278 0.05306538 0.00510278 0.05294875 0.01032184
 0.01051183 0.00510278 0.05294876 0.05294876 0.00510278 0.00510278
 0.01032184 0.00400507 0.05294875 0.00510278 0.01032184 0.00988942
 0.01032184 0.00510278 0.00510278 0.00988943 0.01051182 0.00510278
 0.00510505 0.05294876]
tr_loss:[0.005097   0.008965   0.008965   0.005097   0.00414323 0.00651121
 0.005097   0.005097   0.005097   0.00900181 0.005097   0.005097
 0.00875934 0.05240949 0.00651121 0.005097   0.05240949 0.005097
 0.005097   0.008965   0.005097   0.05240915 0.005097   0.005097
 0.00896503 0.008965   0.005097   0.008965   0.00509728 0.05240949
 0.005097   0.00900181 0.005097   0.005097   0.00640012 0.008965
 0.005097   0.005097   0.00891622 0.05240799 0.005097   0.005097
 0.00509795 0.00900182 0.00511363 0.005097   0.008965   0.00616342
 0.05240948 0.05240949]
tr_loss:[0.00734298 0.00440539 0.00440505 0.05428613 0.01123399 0.00685651
 0.00685651 0.00956861 0.00956756 0.00345715 0.00440505 0.00685651
 0.00956756 0.00734298 0.05205695 0.00734298 0.00440509 0.00956756
 0.00440505 0.05205693 0.00440505 0.05205695 0.00440505 0.05205695
 0.00440505 0.05205695 0.00440505 0.00440505 0.0068565  0.05205695
 0.05205695 0.00956756 0.00440505 0.00440505 0.00440505 0.00440505
 0.00734298 0.05205695 0.00440505 0.00956756 0.05205695 0.00734298
 0.01123398 0.00956756 0.00440505 0.00734298 0.00440505 0.00440505
 0.00440501 0.00440505]
tr_loss:[0.00405959 0.01065563 0.01065562 0.05188541 0.05188541 0.01065563
 0.01086068 0.00405959 0.00588545 0.00405959 0.05188541 0.05188541
 0.00588545 0.00310424 0.01081063 0.00405959 0.00405959 0.00588545
 0.00405959 0.05188541 0.01065563 0.01065563 0.01065563 0.05188541
 0.00588742 0.0108607  0.00405959 0.00409915 0.00405959 0.01065508
 0.0108607  0.00405959 0.00405959 0.00405959 0.00405959 0.05188541
 0.00405959 0.00405959 0.00405959 0.00588571 0.00405959 0.00588545
 0.00405959 0.00405959 0.05188541 0.00405959 0.05188542 0.00405959
 0.01065562 0.00701421]
tr_loss:[0.01067738 0.00389295 0.00389295 0.00389295 0.00420812 0.00389295
 0.01067738 0.01067738 0.00389295 0.00389295 0.00420858 0.009812
 0.00389295 0.00389295 0.00420813 0.00389295 0.00389295 0.00395527
 0.00389295 0.01067738 0.01067738 0.05132193 0.00942566 0.00389295
 0.01067738 0.00420812 0.00942566 0.00981201 0.00981201 0.00389295
 0.00942571 0.00939621 0.00389296 0.05132201 0.00389295 0.00420812
 0.00389295 0.01067738 0.00389295 0.00389295 0.00389294 0.01067738
 0.00389295 0.00420812 0.00420812 0.00389295 0.00655284 0.00981201
 0.01069253 0.00655283]
tr_loss:[0.00855969 0.00414984 0.0085597  0.00414984 0.01004805 0.00587539
 0.00414984 0.00414984 0.00414984 0.00414981 0.00855969 0.00414984
 0.00414984 0.00285158 0.00414984 0.00414984 0.00285158 0.00414983
 0.00285158 0.00414983 0.00414984 0.00414983 0.01004824 0.00414984
 0.00414984 0.01004805 0.0041546  0.00414983 0.00414984 0.01004805
 0.0085597  0.05087387 0.00414984 0.01004806 0.00295796 0.00414983
 0.00414984 0.00414983 0.00285158 0.00285158 0.00414984 0.00855969
 0.00414983 0.01004805 0.00414984 0.0085598  0.05087388 0.00414984
 0.00414984 0.0058754 ]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4600 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4601, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4601 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4602, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4602 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4603, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4603 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4604, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4604 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4605, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4605 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4606, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4606 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4607, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4607 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4608, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4608 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4609, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4609 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4610, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4610 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4611, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4611 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4612, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4612 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4613, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4613 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4614, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4614 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4615, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4615 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4616, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4616 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4617, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4617 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4618, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4618 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4619, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4619 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4620, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4620 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4621, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4621 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4622, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4622 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4623, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4623 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4624, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4624 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4625, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4625 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4626, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4626 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4627, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4627 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4628, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4628 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4629, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4629 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4630, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4630 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4631, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4631 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4632, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4632 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4633, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4633 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4634, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4634 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4635, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4635 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4636, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4636 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4637, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4637 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4638, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4638 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4639, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4639 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4640, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4640 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4641, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4641 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4642, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4642 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4643, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4643 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4644, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4644 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4645, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4645 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4646, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4646 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4647, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4647 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4648, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4648 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4649, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4649 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4650, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4650 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4651, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4651 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4652, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4652 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4653, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4653 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4654, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4654 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4655, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4655 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4656, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4656 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4657, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4657 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4658, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4658 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4659, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4659 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4660, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4660 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4661, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4661 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4662, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4662 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4663, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4663 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4664, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4664 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4665, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4665 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4666, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4666 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4667, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4667 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4668, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4668 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4669, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4669 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4670, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4670 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4671, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4671 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4672, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4672 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4673, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4673 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4674, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4674 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4675, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4675 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4676, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4676 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4677, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4677 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4678, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4678 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4679, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4679 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4680, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4680 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4681, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4681 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4682, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4682 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4683, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4683 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4684, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4684 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4685, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4685 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4686, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4686 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4687, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4687 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4688, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4688 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4689, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4689 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4690, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4690 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4691, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4691 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4692, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4692 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4693, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4693 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4694, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4694 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4695, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4695 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4696, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4696 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4697, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4697 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4698, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4698 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4699, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4699 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4700, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-4600
text_input.shape
(4700, 14400)
learning_input_tmp.shape
(4700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4700, 80)
learning_output.shape
(750, 80)
Model: "sequential_95"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_95 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.292568  1.2653574 1.2779331 1.2756485 1.292568  1.275668  1.292568
 1.2925681 1.3002733 1.300337  1.292568  1.2653575 1.3248682 1.3248682
 1.3248682 1.2791984 1.3248676 1.2652868 1.2779329 1.2948796 1.2694141
 1.3179234 1.2779329 1.292568  1.3002734 1.3248681 1.292568  1.3248682
 1.3248682 1.292568  1.2779329 1.279425  1.2779329 1.2791984 1.292568
 1.2779329 1.3002722 1.3002738 1.292568  1.292568  1.2759122 1.2925661
 1.2741247 1.292568  1.2925619 1.292568  1.292568  1.3248682 1.292568
 1.292568 ]
tr_loss:[0.68823135 0.67955303 0.67382526 0.66509086 0.67382646 0.6651646
 0.68823135 0.68823147 0.67955303 0.68823105 0.66513526 0.6809615
 0.6738265  0.6558091  0.673789   0.6650909  0.69325256 0.6795522
 0.68096143 0.6650909  0.68823135 0.68823135 0.66509086 0.6738265
 0.68826467 0.6795531  0.68096143 0.6882284  0.68823147 0.68366796
 0.68308055 0.6650909  0.68308055 0.68823135 0.67955303 0.6932623
 0.6882313  0.6650909  0.68096155 0.68823135 0.68823147 0.69325256
 0.6882314  0.6738266  0.68823135 0.6809628  0.6882313  0.6830798
 0.6830806  0.6786533 ]
tr_loss:[0.3501761  0.32698298 0.3461701  0.36672175 0.3368976  0.35018063
 0.35018057 0.34616622 0.34316716 0.32698303 0.32698303 0.33803883
 0.33803895 0.3461701  0.32698292 0.33803892 0.32698292 0.33803895
 0.36672172 0.32698306 0.32698292 0.3380389  0.36672178 0.3461701
 0.34588903 0.3461788  0.345889   0.35018057 0.32698295 0.34617013
 0.32698292 0.33803886 0.35018063 0.36672172 0.33803892 0.3454621
 0.35018057 0.3501806  0.35018057 0.34617013 0.33803898 0.3461701
 0.34617007 0.35018057 0.33803895 0.34617013 0.35018057 0.34492126
 0.32698292 0.34614038]
tr_loss:[0.10072543 0.11137593 0.11351652 0.10106388 0.11306461 0.11280511
 0.14869662 0.10106389 0.11306461 0.11502238 0.10106388 0.11137595
 0.10072541 0.14869529 0.1130646  0.11306462 0.1007254  0.10072549
 0.10072546 0.1130646  0.10106391 0.11306462 0.10106387 0.1130646
 0.10072543 0.10106387 0.10106388 0.11306462 0.10072546 0.1121522
 0.11351653 0.11306462 0.11137595 0.09873738 0.14869532 0.11306461
 0.1121522  0.14868674 0.11306462 0.11306462 0.1486953  0.11306462
 0.11306462 0.10072549 0.10106377 0.11306462 0.10571498 0.1121522
 0.11215223 0.10106387]
tr_loss:[0.03438206 0.03730983 0.03063636 0.03555862 0.0485815  0.0331713
 0.03033057 0.03555862 0.07791911 0.07791913 0.04883258 0.07791912
 0.03438204 0.03555863 0.03033055 0.07791911 0.03555862 0.04883257
 0.03033058 0.07779111 0.03555862 0.04883257 0.03438204 0.03702586
 0.03555863 0.04883251 0.04883259 0.03730984 0.04883257 0.03438201
 0.03033056 0.03438202 0.04883254 0.03438205 0.07791912 0.03555863
 0.03555862 0.07791913 0.03555863 0.03555862 0.03690724 0.03555861
 0.03438204 0.03730984 0.03702588 0.04883257 0.03555861 0.04883257
 0.03730983 0.03033057]
tr_loss:[0.01791981 0.01637627 0.01637627 0.01798776 0.00929132 0.06075587
 0.03130074 0.01637627 0.01637626 0.03130075 0.01513375 0.00929131
 0.06075587 0.01798777 0.01559712 0.06075587 0.01740702 0.01740702
 0.01637627 0.00929121 0.02933767 0.05621304 0.03130073 0.01554302
 0.01637627 0.06075587 0.01513375 0.03130073 0.01798777 0.01637627
 0.01798778 0.01637627 0.01557004 0.01557003 0.03130073 0.01637627
 0.0163778  0.0092913  0.03130074 0.01637627 0.01637626 0.01637627
 0.06075587 0.0092913  0.01798775 0.0163836  0.01513329 0.01637627
 0.00929131 0.01637627]
tr_loss:[0.05304737 0.00644098 0.00204461 0.00204462 0.00906831 0.05304744
 0.00666867 0.00906831 0.00797311 0.00906831 0.00906832 0.00897575
 0.00204462 0.00666865 0.00906832 0.00988901 0.00791105 0.00906842
 0.00204462 0.0137371  0.05304738 0.00797311 0.00906832 0.05304737
 0.00906832 0.05304737 0.00666866 0.00791105 0.0137371  0.00204461
 0.00988897 0.00906832 0.0089708  0.00666867 0.00906832 0.05304738
 0.00906832 0.05304738 0.00204461 0.00666912 0.01373711 0.00204461
 0.00791105 0.00204462 0.01373711 0.00906831 0.00204461 0.00975426
 0.05304737 0.05304737]
tr_loss:[0.01379799 0.00509616 0.00368279 0.05218481 0.00627267 0.01379799
 0.05218481 0.01418694 0.00627264 0.00625554 0.01379799 0.01379799
 0.01413166 0.00509615 0.01379799 0.0036828  0.00627264 0.00509615
 0.01379799 0.01379799 0.00627267 0.01379799 0.00368279 0.00509616
 0.01379798 0.00627264 0.00627265 0.05218481 0.01379799 0.00627267
 0.01379797 0.01379799 0.00509615 0.00509615 0.0036828  0.01379799
 0.01379798 0.00509616 0.01379799 0.05218481 0.01260874 0.05218481
 0.01379799 0.01380767 0.01379799 0.00509615 0.00938623 0.00938623
 0.01026115 0.00509616]
tr_loss:[0.00749265 0.01351855 0.05441053 0.01351854 0.01655425 0.01534975
 0.05441298 0.01655424 0.01655424 0.05441052 0.00404239 0.01655424
 0.05441052 0.00749265 0.00888761 0.01655425 0.0124047  0.01655425
 0.00404239 0.00749265 0.05441053 0.05441053 0.01534967 0.05441053
 0.01674173 0.01655424 0.01655425 0.00749265 0.00404238 0.05441053
 0.01655425 0.00400287 0.01655418 0.01645072 0.00404239 0.01655424
 0.00888761 0.00404239 0.01352831 0.01655424 0.01655424 0.01655289
 0.01655424 0.01655424 0.00888761 0.01534975 0.05441053 0.00404239
 0.00749404 0.05441052]
tr_loss:[0.00844093 0.00543117 0.01291503 0.01291503 0.00844092 0.00543117
 0.01245856 0.01070745 0.01245855 0.00844093 0.0129152  0.01291498
 0.00543122 0.05461496 0.00551511 0.00551513 0.01245855 0.00543116
 0.00543117 0.00543117 0.01291503 0.00844109 0.05461497 0.05461497
 0.05461497 0.01070745 0.01291503 0.01245856 0.01291503 0.01070744
 0.01291503 0.01291503 0.01291503 0.00844093 0.05461496 0.01245855
 0.01070745 0.05461497 0.00551513 0.01291503 0.05461496 0.00551512
 0.01291503 0.05461497 0.05461497 0.05461497 0.00551511 0.00844092
 0.00844093 0.01291503]
tr_loss:[0.00638565 0.00708091 0.05521397 0.00552837 0.00552837 0.00552837
 0.00552837 0.00552837 0.00552837 0.00188247 0.00552836 0.00552837
 0.00188247 0.00949857 0.00552837 0.00552837 0.05521397 0.00552837
 0.00949857 0.00949856 0.00552837 0.00188247 0.00552837 0.00188247
 0.00552836 0.00188247 0.00552837 0.00552837 0.00552837 0.00949857
 0.05521397 0.00638566 0.00188247 0.00188247 0.00949857 0.00686632
 0.00686633 0.00188247 0.00633373 0.05521398 0.00633373 0.00686633
 0.00553087 0.00552837 0.00949857 0.05521397 0.00552837 0.00552838
 0.00949857 0.00638566]
tr_loss:[0.00165161 0.00165158 0.0200978  0.00165159 0.0200978  0.06108607
 0.00345083 0.00203868 0.0200978  0.00849493 0.00165158 0.00849493
 0.00849493 0.00666859 0.02009456 0.00849493 0.00165199 0.00165158
 0.00165158 0.06108616 0.00165158 0.00165158 0.00849493 0.00165158
 0.00165158 0.00346179 0.00849493 0.06108608 0.01963535 0.00165158
 0.06108608 0.00165158 0.00165158 0.00203869 0.00203866 0.00346179
 0.00849493 0.00165158 0.00849493 0.0200978  0.06108608 0.00666858
 0.00165158 0.00165158 0.00849493 0.00346179 0.00666858 0.00165158
 0.00165158 0.06108608]
tr_loss:[0.00109251 0.00382386 0.00109251 0.02195919 0.06176911 0.00109251
 0.00109251 0.02196559 0.02195919 0.00686571 0.0617691  0.0617691
 0.00382386 0.02195919 0.00109251 0.00109251 0.02195919 0.00109251
 0.00109251 0.02195917 0.00109251 0.00382387 0.00226834 0.0617691
 0.06176821 0.00382387 0.00109251 0.00382386 0.00109251 0.06176909
 0.00109251 0.00382387 0.06176911 0.00109251 0.00109251 0.0047041
 0.02195919 0.00109251 0.00230826 0.0219592  0.00382387 0.00109251
 0.00686606 0.00109251 0.00382386 0.00109251 0.0219592  0.0617691
 0.00686606 0.02195921]
tr_loss:[0.00355319 0.05508004 0.00358093 0.00161965 0.05508003 0.00358093
 0.01436452 0.00161965 0.00181648 0.00313173 0.00352237 0.00358093
 0.01436452 0.00291457 0.00630586 0.00161965 0.00358093 0.00161965
 0.00358093 0.01436452 0.00630585 0.00358093 0.00358093 0.00291456
 0.00358093 0.00181648 0.01436452 0.01436452 0.00358094 0.00181648
 0.00630585 0.00156375 0.00630585 0.01436452 0.01436451 0.00161965
 0.00358093 0.00161965 0.00161965 0.05508003 0.00358094 0.00161965
 0.05508003 0.01436452 0.00630585 0.0035807  0.05506536 0.01436452
 0.00161965 0.01436453]
tr_loss:[0.00908758 0.01005331 0.00081318 0.00918717 0.05184435 0.01005332
 0.00081318 0.00918716 0.00918716 0.01005331 0.00918706 0.00081318
 0.00916017 0.05184435 0.00918716 0.05184435 0.00918716 0.00081318
 0.00663199 0.00081452 0.00663199 0.0029801  0.00081318 0.00918717
 0.00298011 0.00663199 0.00909233 0.00908757 0.00918717 0.006632
 0.0100533  0.00305071 0.00085659 0.00918716 0.00918716 0.00908757
 0.00918717 0.006632   0.0030507  0.05184435 0.00081318 0.0100533
 0.00081318 0.01005331 0.00082121 0.00081318 0.00305048 0.01005331
 0.00918716 0.00918716]
tr_loss:[0.00371457 0.05099443 0.00378651 0.00621928 0.00832219 0.0083222
 0.00943128 0.00943129 0.05099443 0.0083222  0.00088887 0.00943129
 0.00943129 0.0083222  0.00943129 0.00943129 0.0010464  0.00943129
 0.00943128 0.0083222  0.00943127 0.00621928 0.00943129 0.00621928
 0.05099443 0.00942986 0.00621928 0.00681606 0.05099443 0.0083222
 0.00943128 0.00943129 0.00088887 0.0083222  0.00943129 0.00681607
 0.00943129 0.00943129 0.00681606 0.00943125 0.00943129 0.05099443
 0.00371456 0.00088985 0.00832221 0.00937886 0.00943128 0.00943128
 0.05099443 0.00088887]
tr_loss:[0.00483997 0.05214354 0.00483997 0.00483389 0.00610141 0.00610141
 0.00357398 0.05214355 0.00174468 0.00386985 0.00610141 0.00483998
 0.00483995 0.00374322 0.00483997 0.00483998 0.00483997 0.00386986
 0.05214351 0.00483683 0.00483998 0.00483996 0.00483998 0.00174468
 0.05214354 0.00483997 0.00374323 0.00610141 0.00264346 0.00483997
 0.00386985 0.00483997 0.00264397 0.00374323 0.00374323 0.00433734
 0.00483998 0.0035928  0.00483997 0.00483998 0.00264362 0.00483998
 0.00483998 0.00264361 0.05214355 0.05214354 0.00264362 0.00374323
 0.00483983 0.00483997]
tr_loss:[0.00287861 0.05647561 0.00072363 0.00628926 0.00625572 0.01136219
 0.00287861 0.00287861 0.0564756  0.05647561 0.05647649 0.00287861
 0.0564756  0.00625571 0.01136213 0.01136213 0.01136212 0.0564756
 0.00287861 0.00287861 0.01136213 0.00072362 0.00625572 0.01136213
 0.00072363 0.00287861 0.01136213 0.0564756  0.00625572 0.0564756
 0.00625572 0.0028803  0.00072363 0.00287861 0.01136213 0.00287861
 0.00287861 0.01136213 0.01136213 0.0028786  0.00287861 0.00072364
 0.00303686 0.00072363 0.00625572 0.05647561 0.00353548 0.01136213
 0.00287861 0.00625571]
tr_loss:[0.00071412 0.00071412 0.00768446 0.01276151 0.00768446 0.01276148
 0.01276151 0.00449511 0.05720164 0.00294127 0.00768445 0.01276151
 0.00762611 0.00449511 0.00264552 0.00294127 0.05720162 0.00071412
 0.01276151 0.05720163 0.01276151 0.00729356 0.05720163 0.00729434
 0.0076859  0.00768446 0.00762611 0.00071412 0.05720164 0.00449511
 0.05720164 0.00294127 0.01276151 0.01276151 0.05720164 0.00449511
 0.00768445 0.01276151 0.05720163 0.007619   0.00768445 0.00768446
 0.00449511 0.00294127 0.05720165 0.00071412 0.00294127 0.05720164
 0.00768445 0.05720163]
tr_loss:[0.00347082 0.05488416 0.00923214 0.00570846 0.00098688 0.05488417
 0.00663569 0.00347081 0.00570846 0.00098688 0.00923214 0.00923214
 0.00509263 0.00923214 0.00923214 0.00347082 0.00347082 0.05488416
 0.00509262 0.00570846 0.00179337 0.00509263 0.00923214 0.00098688
 0.00570846 0.00570846 0.00347082 0.00570846 0.00570846 0.00346907
 0.00174811 0.00509263 0.00347082 0.00347082 0.00570846 0.00570846
 0.00923214 0.00923195 0.00347082 0.00347082 0.00922951 0.00347082
 0.05488417 0.00098689 0.00347082 0.00347082 0.00570846 0.00098688
 0.00098688 0.05488417]
tr_loss:[0.0054703  0.00607012 0.00598053 0.00521786 0.00607012 0.00521786
 0.00746101 0.00618322 0.05358287 0.00607012 0.00521787 0.00521786
 0.00440336 0.0054703  0.00440337 0.00607012 0.00618322 0.00521786
 0.05358287 0.00521786 0.00440336 0.00279099 0.00521786 0.05358288
 0.00521786 0.00769053 0.00607012 0.00521786 0.05358287 0.00440337
 0.00521792 0.00440337 0.0054703  0.00598053 0.05358287 0.00521786
 0.00521786 0.00279099 0.00607012 0.00769392 0.00617534 0.00521787
 0.0015024  0.00627862 0.0535464  0.00531464 0.05358287 0.00521786
 0.00521786 0.00618321]
tr_loss:[0.00642948 0.00501533 0.00458162 0.00617616 0.0061762  0.00458163
 0.00435398 0.00424577 0.05267398 0.00306982 0.0526742  0.00307005
 0.00458163 0.00617617 0.00458162 0.00307005 0.00617616 0.00617616
 0.00458162 0.00617616 0.00617616 0.00424577 0.00617616 0.00617617
 0.00617616 0.00435416 0.0526742  0.0090407  0.05283991 0.00617616
 0.00424577 0.00642946 0.00458162 0.00435416 0.00555556 0.00424577
 0.0526742  0.00501705 0.00617616 0.00307005 0.00617616 0.00617616
 0.00617616 0.00425298 0.00617616 0.00617616 0.00617616 0.00458163
 0.00617616 0.00458163]
tr_loss:[0.00559023 0.00415655 0.05132166 0.05132166 0.00553125 0.00415656
 0.00415655 0.00550923 0.00461999 0.00095523 0.05132166 0.00553133
 0.00553125 0.00553126 0.00553125 0.00095523 0.00095523 0.00415655
 0.00349578 0.05132166 0.00415656 0.00095523 0.00463932 0.00553125
 0.00553125 0.00559037 0.00553125 0.05132168 0.00349578 0.00553125
 0.00095523 0.00415655 0.00553126 0.00463932 0.00553125 0.05132166
 0.00553125 0.00553125 0.00553427 0.05132166 0.00553125 0.00553126
 0.00095522 0.0055904  0.00553125 0.00553125 0.00349578 0.00463932
 0.00415655 0.00553125]
tr_loss:[0.00471435 0.00435378 0.00016205 0.00471436 0.003944   0.003944
 0.00394399 0.003944   0.00016205 0.00683648 0.00357566 0.0035381
 0.00435378 0.00435378 0.0039098  0.00683649 0.05112617 0.00016205
 0.003944   0.003944   0.00471435 0.00435388 0.00435378 0.00471435
 0.00683648 0.00394219 0.00394399 0.003944   0.003944   0.05108831
 0.003944   0.00683649 0.00471435 0.00435312 0.00016205 0.00394399
 0.05108831 0.00683648 0.00394399 0.00016205 0.05108831 0.003944
 0.00683648 0.003944   0.003944   0.00016205 0.05108831 0.00435378
 0.00435378 0.00471435]
tr_loss:[0.00305071 0.00092719 0.0009272  0.00278047 0.00304298 0.00278047
 0.05201494 0.00929665 0.00278047 0.00929666 0.05201494 0.00394765
 0.00304298 0.00278047 0.0009272  0.00278047 0.0009272  0.00278047
 0.00278047 0.00929665 0.00092725 0.00304298 0.00304298 0.0009272
 0.00304298 0.00929666 0.00304299 0.0009272  0.00278047 0.00929666
 0.00731574 0.0009272  0.05201494 0.00278047 0.05201494 0.0009272
 0.0009272  0.0034397  0.00278047 0.00278275 0.00304298 0.00092721
 0.00929666 0.00278047 0.00278047 0.00280819 0.05201567 0.00278047
 0.00138505 0.0009272 ]
tr_loss:[0.0014744  0.00207439 0.01082382 0.00242514 0.00265365 0.0043557
 0.01082382 0.0043557  0.00207439 0.00242513 0.00207439 0.00207439
 0.00207439 0.05352479 0.00265364 0.00265364 0.00265365 0.00369616
 0.05352478 0.00207439 0.00207439 0.00265364 0.00207439 0.00265364
 0.05352479 0.00242513 0.00207439 0.05352479 0.05352479 0.0036811
 0.00242513 0.00207439 0.00207439 0.00242513 0.00207439 0.00207439
 0.00207439 0.01082382 0.05352478 0.00242513 0.00207439 0.0043557
 0.01082382 0.00207439 0.00207439 0.00242513 0.0043557  0.00730167
 0.0535248  0.05352478]
tr_loss:[0.05411436 0.00217887 0.01032935 0.01032934 0.00217887 0.00217887
 0.00047799 0.00219578 0.00217888 0.00371957 0.00371957 0.00219578
 0.05376077 0.01032935 0.05411436 0.00371957 0.00217888 0.00217888
 0.01032934 0.00439146 0.00217887 0.00217887 0.00217855 0.00217816
 0.05411436 0.01032935 0.01032935 0.00217887 0.00439146 0.00371061
 0.05411436 0.00217888 0.00371957 0.00219355 0.00217815 0.01034136
 0.05411436 0.0103297  0.00217815 0.00217888 0.00217816 0.00371957
 0.00439146 0.00430773 0.05411436 0.01032934 0.00217888 0.00217888
 0.01032935 0.00217887]
tr_loss:[0.00245389 0.00245389 0.00245389 0.05254481 0.00245386 0.0069728
 0.00193606 0.00245389 0.05254481 0.0069728  0.00245389 0.00245389
 0.0069728  0.00697168 0.00245383 0.00255595 0.00203038 0.05254482
 0.00245389 0.00203038 0.00245389 0.00245389 0.00697281 0.00203038
 0.00203037 0.00245389 0.0069728  0.00203038 0.00203038 0.00245389
 0.00203038 0.00245389 0.05254481 0.05254481 0.00245389 0.00270418
 0.00316283 0.00316283 0.00316283 0.00255596 0.00245389 0.00245389
 0.0069728  0.00255596 0.00316283 0.05254481 0.00245214 0.00245389
 0.00255595 0.00193606]
tr_loss:[0.00166317 0.00321675 0.05148244 0.00321675 0.00321675 0.00166317
 0.00278887 0.00278887 0.00321675 0.00437033 0.0021854  0.00437032
 0.00321675 0.00278887 0.0021854  0.00321675 0.05148244 0.0021854
 0.00321675 0.00321675 0.00437033 0.00321675 0.00321675 0.00437033
 0.00278887 0.00321675 0.00321675 0.00158888 0.05148245 0.00321675
 0.05148244 0.00166317 0.00166317 0.00321675 0.00218534 0.00166317
 0.00166317 0.00278887 0.05148244 0.00321675 0.00460096 0.00321675
 0.00279946 0.00166337 0.00437033 0.00166317 0.00437033 0.00278887
 0.0021854  0.05148244]
tr_loss:[0.00353823 0.00409068 0.00409068 0.00353823 0.05154925 0.00186968
 0.00186968 0.00409068 0.00409068 0.00186968 0.00217565 0.00186967
 0.00409068 0.00186968 0.05154924 0.00353823 0.00186968 0.00409068
 0.05154925 0.00186002 0.00402025 0.0040906  0.00343823 0.00415643
 0.00409068 0.00217565 0.00415643 0.00409067 0.00394595 0.05154925
 0.00217565 0.05154925 0.00409068 0.00415644 0.00415644 0.00343823
 0.00649404 0.00353823 0.00186968 0.00415643 0.00409068 0.00409068
 0.00183716 0.05154925 0.00186967 0.00409068 0.00415643 0.00186967
 0.05154925 0.00409068]
text_input.shape
(4700, 14400)
learning_input_tmp.shape
(4700, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4700, 80)
learning_output.shape
(750, 80)
Model: "sequential_96"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_96 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4036473 1.4036474 1.4638444 1.4727767 1.4727768 1.4044977 1.4737757
 1.4638444 1.4638441 1.4499996 1.449519  1.4287007 1.4116617 1.4638441
 1.4727768 1.4287007 1.4610738 1.4069712 1.451207  1.4727768 1.4069712
 1.4724686 1.4287007 1.4495169 1.4727719 1.4727767 1.4610738 1.4069711
 1.4036474 1.4287007 1.4036474 1.4727767 1.4504026 1.4287007 1.4287007
 1.4036472 1.4638441 1.4731385 1.4287007 1.4727768 1.4036521 1.4036472
 1.4495167 1.4727749 1.4287007 1.4036472 1.4069245 1.4727767 1.4495168
 1.4287007]
tr_loss:[0.8656767  0.8362061  0.8656767  0.8361905  0.8859067  0.8763501
 0.8845402  0.8361906  0.8361907  0.86078537 0.9464296  0.8607855
 0.8655877  0.86078537 0.8607853  0.86078537 0.8607855  0.8859067
 0.8361905  0.8361906  0.94642985 0.8656767  0.8834772  0.8607855
 0.8859068  0.8656765  0.8656769  0.8845089  0.8763501  0.86078644
 0.8656767  0.8607855  0.8845402  0.86078537 0.9464296  0.8361905
 0.8860962  0.8607855  0.8361905  0.95351124 0.86084634 0.86078537
 0.8656767  0.86078537 0.86078537 0.83685195 0.8749582  0.8859068
 0.94642985 0.94642985]
tr_loss:[0.4469103  0.45228392 0.45229635 0.45228267 0.4308073  0.36685976
 0.4637021  0.45228267 0.4527703  0.4447744  0.4308074  0.4659935
 0.36685973 0.45227575 0.45228308 0.4308073  0.45228267 0.36685973
 0.4659935  0.44691038 0.45228267 0.36685973 0.45228267 0.44691038
 0.44691038 0.45228258 0.44691247 0.4659935  0.36685973 0.4308073
 0.45228267 0.36685976 0.45228267 0.44691038 0.36685973 0.4308074
 0.4659935  0.3669059  0.46599355 0.45228267 0.46599358 0.44691038
 0.44691038 0.45228013 0.45228267 0.4659935  0.36685973 0.44691044
 0.4659935  0.44691038]
tr_loss:[0.22132199 0.22139642 0.24013694 0.24013695 0.22446468 0.22372314
 0.24013695 0.23829241 0.2237241  0.22372317 0.22776029 0.24013701
 0.2401369  0.22776027 0.24064866 0.224436   0.2244647  0.2244649
 0.22137174 0.2213964  0.24013694 0.24064875 0.23481357 0.22446465
 0.2401369  0.22446463 0.21822798 0.22776048 0.22446468 0.22372317
 0.22776027 0.24013694 0.22776024 0.22776024 0.24013695 0.22372337
 0.22372313 0.22776023 0.24013695 0.22139645 0.22446463 0.22776027
 0.22446468 0.22139649 0.22372317 0.24013695 0.24000195 0.22776023
 0.23984084 0.22372317]
tr_loss:[0.07631525 0.12120757 0.07028864 0.08781326 0.08781318 0.08387817
 0.12120757 0.07097875 0.0838782  0.12120757 0.08827873 0.07510845
 0.07028864 0.07631525 0.07510845 0.0882787  0.12120757 0.12120756
 0.08781326 0.0702887  0.07028867 0.08781321 0.07028868 0.08781324
 0.08781321 0.12120756 0.07028864 0.08387818 0.08781321 0.07510848
 0.07028868 0.12121632 0.08781322 0.08781321 0.12120757 0.08781319
 0.12120757 0.08387817 0.08787094 0.07631524 0.08781324 0.08781322
 0.07028866 0.07631525 0.07446406 0.08781322 0.08781323 0.08781321
 0.08781321 0.12120755]
tr_loss:[0.01265472 0.02572894 0.02098769 0.02098769 0.01718577 0.01280716
 0.02098769 0.02098769 0.01265487 0.02572895 0.01280718 0.02098769
 0.05192506 0.05192506 0.05192507 0.01265472 0.02572894 0.02098768
 0.02098769 0.02149731 0.01280719 0.02098769 0.05192506 0.05192507
 0.02268898 0.01280716 0.02120021 0.02149729 0.02572894 0.02098768
 0.01280718 0.02120019 0.01280718 0.02098768 0.02268898 0.01280718
 0.01265471 0.02098768 0.02572894 0.01265472 0.01280716 0.01265471
 0.02572894 0.02119922 0.01719046 0.01265472 0.02572894 0.05192507
 0.01280719 0.01280717]
tr_loss:[0.02610275 0.0165733  0.01384768 0.02582555 0.01384767 0.01384767
 0.00762765 0.00762765 0.01580204 0.01384768 0.01384767 0.02610204
 0.02610204 0.01574879 0.01384767 0.02610204 0.00857523 0.01384767
 0.03859868 0.01384767 0.00762765 0.00762764 0.01384767 0.02610205
 0.01384768 0.01384772 0.03859868 0.0165733  0.01653096 0.02610204
 0.01384768 0.01223723 0.00857523 0.01384767 0.00762765 0.00857523
 0.01384767 0.01384768 0.01384767 0.00857522 0.02610204 0.03859869
 0.02610204 0.03859868 0.01574879 0.00857525 0.03859868 0.01580204
 0.00857523 0.02610205]
tr_loss:[0.02086074 0.01331112 0.02086073 0.00615713 0.01466481 0.02086073
 0.00615714 0.01554935 0.01409458 0.01331112 0.01331112 0.0070166
 0.00701661 0.01331112 0.03034971 0.01331348 0.02086072 0.01331112
 0.00615715 0.01331112 0.01331232 0.01331113 0.00676166 0.00615714
 0.01331112 0.01331112 0.02086073 0.01331112 0.01331112 0.01435723
 0.02086075 0.02086073 0.00615714 0.01435725 0.0061572  0.01331112
 0.0070166  0.03034971 0.01331112 0.01554935 0.01435725 0.01331112
 0.02086073 0.03034971 0.01331112 0.0070166  0.02086073 0.01331112
 0.01331113 0.0070166 ]
tr_loss:[0.01517926 0.00477296 0.0144832  0.01517926 0.01448321 0.01517926
 0.00760379 0.01520387 0.01517926 0.01618223 0.01517926 0.00477297
 0.0134392  0.01517925 0.01448321 0.01347844 0.02837891 0.01517926
 0.0134392  0.01577877 0.00760379 0.01618223 0.0134392  0.0076038
 0.01618215 0.01517926 0.00760379 0.01517926 0.00477296 0.02837891
 0.03283906 0.01517926 0.00477297 0.01518047 0.0076038  0.00477297
 0.00760379 0.01448321 0.02837891 0.00477295 0.01448321 0.02837891
 0.00760379 0.00760379 0.02837891 0.01517926 0.01517926 0.01517926
 0.00728206 0.02837891]
tr_loss:[0.0106956  0.0106956  0.01467171 0.0106956  0.01587805 0.00484661
 0.02849209 0.00715958 0.01587806 0.01069559 0.01069578 0.01587805
 0.0106956  0.00484661 0.01587806 0.01396551 0.01587805 0.00484662
 0.01396551 0.0106956  0.01587806 0.00715958 0.01587806 0.02849209
 0.0106956  0.0106956  0.01587806 0.00715958 0.00484661 0.0106956
 0.01587806 0.00716869 0.00715959 0.01587805 0.01587806 0.02849209
 0.01587805 0.00484662 0.02849209 0.00715958 0.02849209 0.01587806
 0.01587805 0.00715958 0.01210239 0.01587805 0.01600497 0.01600497
 0.0284921  0.01587805]
tr_loss:[0.01024678 0.01029722 0.00493403 0.01214592 0.00493402 0.00491439
 0.01029722 0.00493403 0.03017149 0.01426862 0.00465788 0.0301715
 0.00465789 0.0301715  0.00465788 0.0301715  0.01426863 0.01426863
 0.01426862 0.03017151 0.00493402 0.01426863 0.01426862 0.01426862
 0.00493403 0.00465788 0.01029723 0.01426863 0.01426863 0.00465787
 0.01426862 0.00493402 0.00493487 0.01426862 0.01426863 0.01426863
 0.0301715  0.01029723 0.01029723 0.01169783 0.01426863 0.00465789
 0.00493402 0.01029723 0.01029723 0.00465787 0.01169783 0.01426862
 0.01029723 0.01426862]
tr_loss:[0.00301067 0.013291   0.01053881 0.01053881 0.0324943  0.0324943
 0.01053881 0.01053881 0.01065361 0.00382021 0.01065316 0.03249429
 0.013291   0.00382022 0.0324943  0.01053881 0.00382022 0.01053881
 0.00382022 0.00984701 0.01053881 0.013291   0.01054043 0.01053881
 0.00853438 0.01053881 0.00301067 0.013291   0.009847   0.009847
 0.01053881 0.0038202  0.0105389  0.01053881 0.00857025 0.01053881
 0.0324943  0.01335408 0.01053881 0.00984669 0.0324943  0.0324943
 0.01053881 0.013291   0.00644481 0.0038202  0.0038202  0.00857026
 0.01329099 0.00381992]
tr_loss:[0.02473443 0.00758748 0.03480851 0.00758748 0.02473443 0.00483744
 0.00447537 0.00447537 0.02473443 0.00483745 0.00483518 0.02473443
 0.00447537 0.00258654 0.00483745 0.00758748 0.00447537 0.00447537
 0.00258654 0.03480851 0.00258654 0.00483745 0.00254057 0.00447537
 0.00758748 0.00483745 0.00483745 0.00483745 0.00483745 0.00476179
 0.00483745 0.00758748 0.0025998  0.00701294 0.00632257 0.00632222
 0.00701645 0.00701632 0.00758748 0.00483745 0.00701632 0.00483745
 0.00483745 0.00758748 0.00483741 0.03480851 0.00258655 0.00258655
 0.00483745 0.03480851]
tr_loss:[0.00369085 0.00369084 0.00369085 0.01018945 0.00369084 0.00287989
 0.02986712 0.00287989 0.00287988 0.00369085 0.00369084 0.00369084
 0.00369084 0.00737932 0.0013951  0.00737789 0.00287988 0.00287988
 0.02986711 0.00816059 0.00369084 0.03658117 0.00815608 0.01018981
 0.03658117 0.00369094 0.00737931 0.00369085 0.01018981 0.00369084
 0.00068539 0.03658117 0.00369084 0.01018982 0.03658118 0.00369085
 0.00287987 0.00369084 0.00369085 0.00369085 0.00815607 0.00440744
 0.00737932 0.00369085 0.00287988 0.00287989 0.00369084 0.00369084
 0.0298671  0.00440744]
tr_loss:[0.00645948 0.03465966 0.00459258 0.03465966 0.00646409 0.02376239
 0.00459259 0.02376239 0.00142937 0.00646409 0.00459258 0.00646409
 0.00631263 0.00459259 0.00459259 0.00631264 0.00646409 0.00459258
 0.00631263 0.00459259 0.02376239 0.00459259 0.00254934 0.02376238
 0.00631263 0.00184621 0.02376238 0.02376238 0.02376239 0.00631263
 0.00459258 0.00459259 0.00459258 0.00459258 0.03462749 0.00631263
 0.00631263 0.03465966 0.02376239 0.00772753 0.00142937 0.00459258
 0.00459258 0.00631263 0.00804495 0.03465966 0.00459258 0.00804495
 0.00459259 0.00142935]
tr_loss:[0.00498506 0.00748005 0.00498546 0.03197503 0.00748004 0.03197503
 0.00748004 0.01767124 0.00748097 0.00180276 0.00938358 0.03197502
 0.00748005 0.01767124 0.01767124 0.00941608 0.00180276 0.00748005
 0.00930889 0.00748004 0.00748005 0.00180276 0.00748005 0.00748004
 0.00748005 0.00180275 0.00748005 0.00180275 0.00748004 0.00941609
 0.00180276 0.00748005 0.00748005 0.03195066 0.00180276 0.00748018
 0.00498545 0.00180276 0.00941609 0.00495312 0.00748004 0.01767124
 0.00498546 0.00748004 0.03197502 0.00180276 0.0074801  0.00748004
 0.00498546 0.01767123]
tr_loss:[0.00204022 0.00926248 0.00926248 0.02846419 0.02846418 0.00926248
 0.00926248 0.00926248 0.00960683 0.00926248 0.0092625  0.01344552
 0.00470517 0.00926248 0.00926248 0.01344552 0.00982597 0.01031425
 0.00960683 0.00926248 0.01031425 0.00926248 0.00926248 0.00204022
 0.01344552 0.00960013 0.00926248 0.00204021 0.02846419 0.01344552
 0.00926248 0.02846418 0.00204022 0.00926248 0.01344553 0.00926248
 0.01031426 0.00960683 0.00926248 0.00960683 0.00204021 0.00926248
 0.00204021 0.00204021 0.00926247 0.00204022 0.00926248 0.01344552
 0.01031426 0.02846419]
tr_loss:[0.01196499 0.0090645  0.00973164 0.00471052 0.00973164 0.02529359
 0.00968498 0.00968498 0.00973164 0.02529359 0.00471054 0.00968497
 0.00968498 0.02529359 0.00968498 0.00471052 0.002287   0.00968498
 0.01196499 0.01196493 0.00228712 0.00968497 0.01196499 0.00968498
 0.01196499 0.00471053 0.00228713 0.00968497 0.00968498 0.00471053
 0.00471053 0.00228712 0.00228712 0.00906449 0.00968498 0.0090645
 0.00228712 0.02529359 0.00968498 0.00471052 0.00968497 0.01196499
 0.01196499 0.02529359 0.00968497 0.00973164 0.01196499 0.00228712
 0.01196499 0.00843173]
tr_loss:[0.01317438 0.02402204 0.00511784 0.01317438 0.00511784 0.02402204
 0.0086684  0.00252923 0.00866838 0.00477013 0.0086684  0.0086684
 0.02402204 0.0086684  0.00866838 0.00511783 0.02402204 0.02402204
 0.02402205 0.00795241 0.0086684  0.00757567 0.01317438 0.0086684
 0.0086684  0.00795241 0.00252923 0.00511784 0.00511783 0.00252923
 0.0086684  0.00252923 0.00511783 0.0086684  0.02402205 0.00795241
 0.00866839 0.01317438 0.0086684  0.00870659 0.0086684  0.00252923
 0.00252923 0.02402205 0.01317438 0.0086684  0.00866839 0.01317509
 0.00252923 0.01317438]
tr_loss:[0.00775416 0.00692948 0.0030508  0.00692947 0.00692948 0.00737797
 0.00321452 0.00737797 0.00692948 0.00737798 0.0030508  0.02276199
 0.01810021 0.00684028 0.00590956 0.00692947 0.01810021 0.01810021
 0.0030508  0.00692947 0.0030508  0.00719217 0.02276199 0.00692947
 0.00692948 0.00692947 0.02276199 0.01805104 0.02275747 0.00590956
 0.00590956 0.01810021 0.01810021 0.0030508  0.0077543  0.00311524
 0.01810022 0.00692948 0.00692947 0.00692948 0.00692948 0.00692948
 0.00737797 0.0030508  0.0030508  0.00590956 0.00737797 0.02276199
 0.00692823 0.00718684]
tr_loss:[0.02286552 0.00525975 0.0068014  0.00525974 0.02286552 0.00525975
 0.02286551 0.00525974 0.02286551 0.01996021 0.00739603 0.00238951
 0.00238951 0.02286551 0.00739603 0.00739603 0.00724825 0.0199602
 0.0023895  0.02286552 0.00724825 0.00724825 0.00525974 0.00238951
 0.00525974 0.00531872 0.01996021 0.02286552 0.00525975 0.00525974
 0.00525975 0.00739603 0.00525975 0.00525975 0.02286552 0.02286551
 0.02286552 0.0229328  0.00724826 0.00238951 0.00525974 0.00525974
 0.00525974 0.00516238 0.00739603 0.00516238 0.00525974 0.0068014
 0.02286551 0.01996021]
tr_loss:[0.00668175 0.00668175 0.02050557 0.00219921 0.00828388 0.00554615
 0.00219922 0.00554615 0.02050557 0.01827195 0.00685506 0.00794862
 0.01828441 0.00554615 0.0182587  0.00554615 0.00641984 0.00668175
 0.00685506 0.00554615 0.01827195 0.00579544 0.00668175 0.00828368
 0.00668175 0.00554615 0.00219921 0.002207   0.00554614 0.00554615
 0.00554615 0.00554615 0.00554615 0.02050557 0.00685506 0.00554615
 0.01827195 0.00219919 0.02058061 0.02050557 0.00683013 0.00668175
 0.00554615 0.01827195 0.00219922 0.00685506 0.00668171 0.02050557
 0.00685506 0.00554615]
tr_loss:[0.02014502 0.01680809 0.00244745 0.00244745 0.0065836  0.0086891
 0.00244745 0.01680808 0.00868911 0.01680817 0.00314212 0.01680808
 0.00658468 0.0068206  0.00682059 0.01152007 0.0065836  0.0066661
 0.01680808 0.0065836  0.00244744 0.01680809 0.00662619 0.00244745
 0.0065836  0.01680808 0.00244745 0.0086887  0.01680809 0.00244745
 0.01680886 0.0065836  0.0068206  0.00941133 0.0065836  0.00244745
 0.00659561 0.0065836  0.00682059 0.00682059 0.00244745 0.00951115
 0.0065836  0.0068206  0.0065836  0.02014502 0.01680809 0.01680807
 0.02014497 0.0065836 ]
tr_loss:[0.00726348 0.01023955 0.00939599 0.00726348 0.00782088 0.01398076
 0.00726349 0.00249662 0.00726348 0.0072635  0.00782088 0.01024149
 0.00820358 0.0102429  0.01966976 0.01966976 0.01966975 0.00726427
 0.00726349 0.00939143 0.00726349 0.00726348 0.00782088 0.01023955
 0.00782089 0.00726348 0.00726348 0.01398076 0.00782088 0.00464982
 0.00782088 0.00782088 0.00726348 0.00726348 0.01398077 0.00726348
 0.01966976 0.00726368 0.00726348 0.00726349 0.00782088 0.01398077
 0.00249662 0.00726349 0.01024195 0.01023956 0.00782087 0.01398076
 0.0072694  0.00939599]
tr_loss:[0.0055407  0.01615477 0.00836105 0.01615477 0.01615478 0.01825854
 0.0055407  0.01825854 0.00160605 0.00689249 0.00689249 0.0055407
 0.00160605 0.01615477 0.0055407  0.01825854 0.00689248 0.0055407
 0.01615477 0.00160605 0.0026749  0.00691918 0.0055407  0.00689249
 0.01615477 0.00689249 0.00554071 0.00689249 0.0055407  0.0055407
 0.00160605 0.0055407  0.00812791 0.00689249 0.00689264 0.00691918
 0.0055407  0.0055407  0.0055407  0.0055407  0.00689248 0.01615477
 0.00554093 0.00836105 0.00836105 0.01825854 0.00159312 0.0055407
 0.00836105 0.00554071]
tr_loss:[0.00485246 0.00668458 0.00454013 0.00454013 0.00454013 0.00668459
 0.02010844 0.00454013 0.01814505 0.00454013 0.02010843 0.00668458
 0.00454013 0.00454015 0.00454013 0.00124931 0.00713356 0.00203424
 0.00454013 0.00713356 0.02010843 0.00454013 0.00668458 0.01856965
 0.00485246 0.02456269 0.00203415 0.00454013 0.02010843 0.01814505
 0.00454013 0.00454013 0.0065468  0.00454013 0.02010843 0.00203414
 0.00668459 0.02010843 0.00689385 0.00668458 0.00668459 0.00668458
 0.00454013 0.00203414 0.00203414 0.00203415 0.00454013 0.00668458
 0.00485246 0.00454015]
tr_loss:[0.00485552 0.00537667 0.00485552 0.00591765 0.00485552 0.01679714
 0.0167658  0.0224034  0.00271874 0.00485552 0.00485552 0.01676581
 0.00537667 0.02240339 0.00469312 0.00271475 0.00537667 0.02240339
 0.00664482 0.00485552 0.02240339 0.00469313 0.00485552 0.01676581
 0.00537667 0.00537667 0.00485552 0.02240339 0.01676581 0.00271874
 0.0167658  0.00271875 0.00485552 0.01676581 0.00485552 0.00537667
 0.01676581 0.0066448  0.00271875 0.00469313 0.00664481 0.00485552
 0.00271874 0.00485552 0.00271875 0.02240339 0.0167658  0.00537667
 0.00271874 0.0167658 ]
tr_loss:[0.01160995 0.00642029 0.00642029 0.00642029 0.02254651 0.0225465
 0.00642029 0.00357367 0.00642029 0.00642029 0.0225465  0.00638272
 0.00651562 0.00668645 0.01160995 0.01160995 0.00642029 0.00642029
 0.01160995 0.00358236 0.00204379 0.01160995 0.0225465  0.01160995
 0.00204379 0.00204379 0.01160995 0.00357367 0.0020438  0.00642029
 0.01160995 0.00638272 0.01160995 0.00684932 0.01160995 0.00204443
 0.00642029 0.00651562 0.01160995 0.0064203  0.00357368 0.00638267
 0.00357367 0.00642029 0.0064203  0.0225465  0.00642029 0.01160293
 0.00357367 0.02254649]
tr_loss:[0.00199975 0.00433678 0.02235542 0.00199975 0.00855962 0.00860606
 0.00860607 0.00860607 0.00868747 0.00860607 0.00868747 0.00199975
 0.00199975 0.0223552  0.00433781 0.00868747 0.00199975 0.00433678
 0.0055242  0.00872704 0.00868748 0.00860606 0.00868747 0.00868748
 0.00433678 0.00860606 0.00860606 0.02235541 0.00860607 0.00433678
 0.00847859 0.00868748 0.00862489 0.00199975 0.00433678 0.00199975
 0.00868748 0.00199976 0.00840734 0.00843664 0.00199975 0.00860607
 0.00843664 0.00843664 0.00868748 0.00433678 0.0051243  0.00199975
 0.02235541 0.00860538]
tr_loss:[0.00819311 0.00902717 0.0050075  0.00819308 0.00819308 0.00164883
 0.00902717 0.00903858 0.0050075  0.02288192 0.02288193 0.00819308
 0.00183867 0.0050075  0.00819308 0.0050075  0.00902717 0.00500389
 0.00902717 0.00819308 0.00800504 0.02288193 0.00819308 0.0090272
 0.00902717 0.02288193 0.00902717 0.00183867 0.02288193 0.0050075
 0.00819308 0.02288192 0.00902717 0.00902717 0.00819308 0.00183867
 0.00902717 0.02288193 0.0050075  0.00819308 0.0050075  0.00819308
 0.0050075  0.00902717 0.00912822 0.00582371 0.00902717 0.00570133
 0.02288192 0.00183867]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4700 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4701, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4701 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4702, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4702 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4703, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4703 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4704, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4704 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4705, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4705 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4706, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4706 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4707, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4707 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4708, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4708 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4709, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4709 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4710, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4710 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4711, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4711 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4712, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4712 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4713, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4713 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4714, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4714 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4715, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4715 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4716, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4716 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4717, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4717 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4718, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4718 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4719, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4719 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4720, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4720 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4721, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4721 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4722, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4722 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4723, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4723 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4724, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4724 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4725, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4725 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4726, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4726 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4727, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4727 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4728, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4728 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4729, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4729 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4730, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4730 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4731, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4731 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4732, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4732 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4733, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4733 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4734, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4734 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4735, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4735 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4736, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4736 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4737, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4737 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4738, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4738 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4739, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4739 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4740, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4740 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4741, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4741 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4742, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4742 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4743, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4743 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4744, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4744 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4745, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4745 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4746, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4746 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4747, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4747 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4748, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4748 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4749, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4749 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4750, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4750 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4751, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4751 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4752, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4752 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4753, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4753 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4754, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4754 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4755, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4755 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4756, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4756 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4757, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4757 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4758, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4758 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4759, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4759 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4760, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4760 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4761, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4761 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4762, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4762 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4763, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4763 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4764, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4764 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4765, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4765 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4766, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4766 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4767, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4767 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4768, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4768 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4769, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4769 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4770, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4770 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4771, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4771 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4772, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4772 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4773, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4773 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4774, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4774 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4775, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4775 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4776, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4776 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4777, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4777 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4778, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4778 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4779, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4779 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4780, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4780 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4781, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4781 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4782, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4782 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4783, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4783 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4784, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4784 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4785, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4785 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4786, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4786 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4787, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4787 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4788, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4788 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4789, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4789 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4790, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4790 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4791, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4791 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4792, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4792 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4793, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4793 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4794, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4794 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4795, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4795 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4796, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4796 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4797, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4797 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4798, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4798 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4799, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4799 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4800, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-4700
text_input.shape
(4800, 14400)
learning_input_tmp.shape
(4800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4800, 80)
learning_output.shape
(750, 80)
Model: "sequential_97"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_97 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1873244 1.1873243 1.1945326 1.1945326 1.1602592 1.2442234 1.2378321
 1.1868999 1.1602592 1.1945325 1.2378299 1.1869    1.1945325 1.2369385
 1.1602592 1.1770856 1.180883  1.1945326 1.1602595 1.1602592 1.1873244
 1.1873226 1.1670959 1.2442234 1.1602592 1.2442234 1.1602592 1.2395099
 1.2442234 1.2378299 1.1868999 1.1869001 1.23783   1.2442235 1.1602592
 1.1945326 1.2378304 1.1569483 1.1642458 1.1868999 1.1873243 1.1873244
 1.1636845 1.2442234 1.2362616 1.1869001 1.2442234 1.23783   1.2378299
 1.2442234]
tr_loss:[0.6747521  0.6865826  0.6874034  0.67475414 0.6875707  0.6875707
 0.70798254 0.6874118  0.674754   0.674754   0.7079831  0.7079831
 0.6874114  0.693202   0.6932019  0.68757075 0.6718205  0.6875707
 0.6724167  0.66832536 0.674754   0.693202   0.70787203 0.7234191
 0.6874035  0.7262505  0.7262551  0.6874035  0.6932019  0.6874034
 0.70363253 0.69320184 0.72625035 0.6723417  0.6747408  0.6874034
 0.6747541  0.72625035 0.674754   0.6875707  0.674754   0.6932019
 0.6874034  0.6932044  0.67475367 0.7079831  0.6747576  0.68740416
 0.72625035 0.693202  ]
tr_loss:[0.3343506  0.32804406 0.31979093 0.3343506  0.31310502 0.3343506
 0.31979096 0.31355646 0.319791   0.31971043 0.33435062 0.31355235
 0.3343506  0.3135565  0.33191395 0.319791   0.3197104  0.3343506
 0.31865063 0.31971043 0.3343506  0.31310496 0.3343506  0.3186506
 0.33435056 0.319791   0.319791   0.33435056 0.3197909  0.3197104
 0.33435062 0.31356174 0.3343506  0.3197104  0.31971058 0.32010645
 0.31865066 0.3343506  0.32776946 0.3197104  0.31355643 0.3197104
 0.3186506  0.3135565  0.3135565  0.33435062 0.31310496 0.31310496
 0.3343506  0.3135565 ]
tr_loss:[0.17821494 0.16993889 0.1699388  0.16064486 0.17821495 0.16466877
 0.17370892 0.17821494 0.17370892 0.16064486 0.17821507 0.16064484
 0.17370892 0.17824452 0.1834946  0.16370067 0.17821577 0.1646537
 0.1646537  0.17370895 0.16993889 0.17821494 0.16993886 0.16993888
 0.16064486 0.16465372 0.17821494 0.16993888 0.18092023 0.18218118
 0.16064486 0.16993886 0.16465372 0.17821684 0.16064486 0.16993889
 0.16781338 0.16781339 0.1646537  0.16781339 0.16781338 0.17821494
 0.16781338 0.16993883 0.1737089  0.17370892 0.1646537  0.16993888
 0.17821498 0.16064486]
tr_loss:[0.11339302 0.11339302 0.12011866 0.16236112 0.12533587 0.12075713
 0.12994896 0.16236112 0.11339302 0.12075713 0.12075713 0.12075713
 0.16236112 0.12075713 0.12994893 0.16236112 0.12075713 0.12075713
 0.11817379 0.12075713 0.12075713 0.11817379 0.12011866 0.11817379
 0.16067393 0.12764001 0.11817379 0.11984894 0.12075712 0.11817379
 0.12994897 0.12075713 0.12075713 0.16236112 0.12011866 0.11817379
 0.12075713 0.11966284 0.11817379 0.12994897 0.12011866 0.11339305
 0.12075713 0.12994897 0.16236112 0.12075713 0.12075713 0.12764004
 0.16236112 0.11817378]
tr_loss:[0.11380716 0.10902183 0.1595603  0.11380716 0.11385667 0.10544816
 0.11714248 0.15953936 0.11380716 0.10902184 0.11380801 0.10819139
 0.15953937 0.11380716 0.11380716 0.15953934 0.11702058 0.10902183
 0.11732926 0.10902183 0.10544815 0.11702073 0.11702073 0.15953934
 0.15953934 0.10902183 0.10544817 0.11702073 0.10819139 0.11702073
 0.11380716 0.10902183 0.11380716 0.10819139 0.10819139 0.10544815
 0.11702073 0.11385536 0.10544815 0.15953934 0.10819139 0.11702073
 0.15953936 0.10902183 0.15953931 0.11779163 0.11380716 0.10543969
 0.15953934 0.10819139]
tr_loss:[0.10691303 0.10428002 0.11939748 0.10691303 0.10428001 0.10613172
 0.15236163 0.12086193 0.10885737 0.10691303 0.10613172 0.15236166
 0.116675   0.11548871 0.12086165 0.12086165 0.12086165 0.10838275
 0.15236163 0.10691303 0.10613173 0.10613173 0.10428002 0.10885737
 0.10885737 0.11548872 0.15236163 0.11548871 0.10885735 0.12086165
 0.12086166 0.10613172 0.1061317  0.10428001 0.10691303 0.12086167
 0.12086165 0.15236163 0.10613172 0.15236163 0.10428002 0.12086165
 0.10885736 0.15236163 0.12086165 0.10428002 0.12086165 0.10691303
 0.12086163 0.10885737]
tr_loss:[0.12431653 0.10473096 0.10901079 0.11700654 0.10664542 0.12446375
 0.11613323 0.11972066 0.15401843 0.11700664 0.1243166  0.12113418
 0.12113418 0.10473096 0.12113418 0.10664544 0.10664542 0.1540184
 0.11613321 0.12431657 0.1243166  0.12113418 0.1243166  0.10473096
 0.1243166  0.15401843 0.11311758 0.11311756 0.10473096 0.10901079
 0.10473096 0.10473096 0.12431411 0.10664544 0.12431657 0.1131176
 0.1540184  0.15405688 0.1540184  0.1540184  0.12431659 0.1243166
 0.12431659 0.10901079 0.12113418 0.12427361 0.10664542 0.11311758
 0.1540184  0.10473096]
tr_loss:[0.10356128 0.15201482 0.15201482 0.11702256 0.1135728  0.10666446
 0.15201482 0.10356128 0.11702256 0.10356128 0.11702256 0.11702256
 0.10356127 0.10666448 0.10666449 0.15201482 0.10478687 0.11702256
 0.10356128 0.10496376 0.10666448 0.10478686 0.10478686 0.11702256
 0.10356126 0.11702256 0.11703856 0.11702323 0.10496378 0.10478687
 0.10478687 0.15201482 0.15201482 0.15201482 0.10356128 0.10356127
 0.10496378 0.15201482 0.11702256 0.10496378 0.15201482 0.11702256
 0.10478687 0.11598249 0.10666449 0.10356126 0.15201482 0.10478687
 0.10496378 0.10666449]
tr_loss:[0.10141418 0.10942449 0.10141418 0.11107612 0.10320978 0.11095037
 0.1057533  0.10942449 0.1543208  0.1030421  0.1030421  0.10942449
 0.15432079 0.11153831 0.10320978 0.1110761  0.10320978 0.10141418
 0.10320978 0.10942449 0.10942449 0.10141418 0.10942449 0.1030421
 0.10942449 0.10942449 0.11107606 0.10141418 0.10942449 0.10141418
 0.10942449 0.15432079 0.10942449 0.1030421  0.11107612 0.11107612
 0.10320683 0.15432079 0.1030421  0.10141418 0.1110761  0.1543208
 0.10320978 0.10942449 0.10942449 0.10942449 0.10942449 0.10320978
 0.10942452 0.1030421 ]
tr_loss:[0.10886188 0.10886188 0.14778647 0.09378625 0.09378624 0.14778647
 0.10874297 0.10140173 0.09703615 0.09378625 0.09378626 0.09777899
 0.10140175 0.0978661  0.09815975 0.14778647 0.09815975 0.09777899
 0.09777899 0.09777899 0.09378625 0.09815975 0.09777899 0.09378625
 0.09815925 0.09778166 0.10140173 0.0937861  0.10140173 0.1088619
 0.09815976 0.09816124 0.09378625 0.09789325 0.09777899 0.09830384
 0.09777899 0.14778647 0.10552976 0.09815975 0.10552977 0.10140173
 0.14778647 0.10140175 0.09378622 0.09777899 0.10140173 0.1088619
 0.10140175 0.10479665]
tr_loss:[0.07529183 0.08249746 0.07854996 0.06945376 0.07855007 0.1220845
 0.12208452 0.07854996 0.07529183 0.07854996 0.07854997 0.07435349
 0.08248855 0.07435349 0.07435348 0.07435348 0.07529183 0.08249645
 0.07435349 0.07855432 0.07854996 0.07435351 0.08116955 0.06945377
 0.07854997 0.08249748 0.07854994 0.08154703 0.07854997 0.07393702
 0.07435368 0.07854996 0.07435349 0.0739717  0.08009119 0.06945377
 0.12208452 0.07435349 0.06945376 0.07529183 0.07435349 0.07435398
 0.07529183 0.08249748 0.07435348 0.07435349 0.07529183 0.07854997
 0.08249746 0.07854996]
tr_loss:[0.0664463  0.05383988 0.05383987 0.06644631 0.05952748 0.10924409
 0.05926619 0.0583326  0.0611473  0.05953316 0.05926623 0.05832752
 0.05952748 0.05952747 0.05832752 0.05926623 0.05952749 0.10924409
 0.05926622 0.05383987 0.05926623 0.05383987 0.05952749 0.10925178
 0.10924409 0.05383987 0.05394085 0.05832752 0.0582498  0.0664463
 0.05832752 0.05952747 0.05832752 0.05383987 0.05383987 0.05952748
 0.0611473  0.05383987 0.05952747 0.05952747 0.05832752 0.10924409
 0.05383987 0.05923772 0.06644629 0.05952747 0.05952748 0.10924409
 0.05944068 0.05383987]
tr_loss:[0.06391703 0.05377168 0.05778726 0.05795122 0.06391703 0.05778728
 0.05377167 0.0537366  0.05669793 0.06391703 0.05804283 0.05620157
 0.10783841 0.06391703 0.05658046 0.05795122 0.05795122 0.0562002
 0.05795121 0.06391703 0.05795122 0.06391704 0.05620157 0.10783841
 0.05377166 0.05795114 0.05377167 0.05620157 0.05795122 0.06391703
 0.05795122 0.05377168 0.05801082 0.05377167 0.05377169 0.06391703
 0.05794655 0.06391703 0.05795122 0.05795086 0.0565813  0.05514011
 0.05795122 0.05795122 0.05794947 0.05620157 0.05620158 0.06391703
 0.06391703 0.06391703]
tr_loss:[0.10460573 0.05785634 0.10460565 0.05220275 0.05400457 0.05220274
 0.05220275 0.05400457 0.05703066 0.05785634 0.05315953 0.05220275
 0.05665027 0.05785636 0.06017425 0.06017425 0.05785635 0.05785634
 0.06017425 0.05220275 0.05785634 0.05315952 0.05665094 0.06017421
 0.10460575 0.05703066 0.05785636 0.05315952 0.05785634 0.05785635
 0.06017425 0.06017424 0.05400457 0.05678548 0.05678549 0.05400457
 0.05785636 0.05220642 0.05315952 0.05390329 0.10460572 0.05785635
 0.05785636 0.06017424 0.10460573 0.10460572 0.06017423 0.05400457
 0.05400457 0.05220275]
tr_loss:[0.05812745 0.0609897  0.05876265 0.06098969 0.0609897  0.05876265
 0.05876265 0.05876265 0.05876266 0.05404101 0.10511769 0.05165864
 0.10511769 0.05812747 0.05404101 0.05410699 0.1051177  0.05404101
 0.0609897  0.05876265 0.05410699 0.05410699 0.05165869 0.05876462
 0.05165865 0.05165864 0.10511769 0.05165864 0.10511769 0.10511769
 0.05410699 0.05876265 0.05876265 0.05173779 0.05404101 0.05165864
 0.05404101 0.10511769 0.05820381 0.05876265 0.05920513 0.05165865
 0.10511769 0.05165864 0.05404101 0.05876264 0.10511769 0.05876266
 0.05879126 0.10511769]
tr_loss:[0.05920488 0.05241423 0.06108641 0.05920488 0.05358034 0.05358034
 0.05414797 0.05241423 0.05414797 0.05414797 0.05949365 0.06108641
 0.05920487 0.05578829 0.05920487 0.05241423 0.0610864  0.05920488
 0.10509391 0.10529462 0.05920488 0.06057423 0.06108641 0.06108641
 0.10509388 0.05920488 0.05414797 0.05354012 0.05925515 0.05241423
 0.10509391 0.05920487 0.05920488 0.05920487 0.05414797 0.05414797
 0.05358034 0.0597768  0.05920487 0.05920488 0.05357936 0.05920491
 0.05241487 0.05414797 0.0610864  0.06108641 0.05920487 0.10509388
 0.05414797 0.1050939 ]
tr_loss:[0.0539114  0.10348096 0.06210531 0.10347269 0.10347269 0.05940328
 0.0539114  0.10347271 0.06035398 0.06035398 0.05861115 0.0539114
 0.05864703 0.05364972 0.10347271 0.05364972 0.05261365 0.05261366
 0.06035398 0.06035396 0.05861115 0.05364972 0.06035397 0.05364972
 0.05390406 0.05699699 0.05261366 0.05261366 0.05364972 0.05261365
 0.06035398 0.06030336 0.05861114 0.06035399 0.05861114 0.10347271
 0.05364972 0.06210531 0.06035397 0.05364972 0.10347271 0.05364972
 0.05861115 0.0539114  0.05364972 0.06114417 0.05261365 0.10347269
 0.05261365 0.06210531]
tr_loss:[0.10208566 0.06310157 0.05423255 0.05494825 0.06378902 0.05278108
 0.06238407 0.10208566 0.05612174 0.05612176 0.05278111 0.06238408
 0.06238408 0.05494864 0.0527812  0.10208566 0.05612174 0.06238407
 0.05278109 0.05494864 0.10208566 0.05423255 0.06310047 0.06310047
 0.05423255 0.05612174 0.05612174 0.05423255 0.06238407 0.06238407
 0.10208566 0.06238407 0.05278109 0.05422992 0.05423255 0.0527811
 0.05612174 0.05278109 0.05494864 0.05278064 0.05494864 0.05423255
 0.05612176 0.05423255 0.05423255 0.05612174 0.05278108 0.05278109
 0.05278109 0.05423255]
tr_loss:[0.06343704 0.10149195 0.05302865 0.05532414 0.05315738 0.05444177
 0.06333313 0.05444177 0.06333313 0.06428672 0.10149197 0.10149197
 0.06333313 0.10149197 0.06333312 0.05315739 0.05532414 0.0531574
 0.05495774 0.05444177 0.10158511 0.0627352  0.06333313 0.05444177
 0.06333312 0.05495774 0.0627352  0.05495774 0.05444177 0.05495774
 0.05532414 0.05444177 0.05532414 0.05495796 0.05532414 0.05444177
 0.10149195 0.06333325 0.06333312 0.10149195 0.05962024 0.05966927
 0.05942894 0.06343704 0.05315738 0.06333312 0.05495774 0.06333313
 0.06333311 0.10149286]
tr_loss:[0.06107219 0.10138033 0.05546185 0.05359415 0.05546184 0.05593673
 0.10138035 0.10138035 0.10138035 0.05546184 0.05235459 0.05362062
 0.10138035 0.05255749 0.05362062 0.05359415 0.05362062 0.10138035
 0.05362062 0.06107221 0.05701518 0.05255749 0.06107526 0.0610722
 0.05546185 0.05362062 0.05362062 0.06109575 0.05359415 0.0550127
 0.05546185 0.0610722  0.05255749 0.06107219 0.05546185 0.10138033
 0.05359415 0.06107221 0.05546184 0.05255751 0.05345679 0.06107285
 0.05362062 0.0610722  0.05362062 0.05362062 0.05255749 0.10138035
 0.10138035 0.10136243]
tr_loss:[0.05203449 0.05742636 0.05739481 0.05203449 0.1022769  0.05820519
 0.05203449 0.05742637 0.05224159 0.1022769  0.05838331 0.05203449
 0.05203449 0.05820519 0.05742345 0.05827935 0.05820519 0.05820519
 0.05820519 0.05320965 0.05892096 0.05203449 0.05224158 0.05820519
 0.05224159 0.10227688 0.05224159 0.10227688 0.05820519 0.05224159
 0.05820519 0.10227688 0.05320965 0.05892095 0.05224158 0.05224156
 0.05820519 0.05892096 0.05224158 0.05203448 0.05820519 0.05742636
 0.05224159 0.102277   0.05320965 0.05203449 0.05320964 0.05820519
 0.05820519 0.1022769 ]
tr_loss:[0.06118061 0.05528861 0.05528856 0.05615551 0.06118063 0.06118061
 0.06118061 0.05652434 0.05181082 0.06118061 0.053797   0.053797
 0.05528856 0.05528857 0.053797   0.06118063 0.05181082 0.05528856
 0.05528856 0.05528866 0.05528856 0.10463417 0.053797   0.05379713
 0.05181082 0.05233204 0.05528856 0.05181082 0.06118063 0.05233205
 0.053797   0.05233205 0.05528855 0.05181082 0.06118063 0.05181082
 0.10463417 0.10463415 0.05233206 0.05233205 0.06118061 0.05181081
 0.05621077 0.05565754 0.05652434 0.05233205 0.05528856 0.05528858
 0.10463415 0.10463415]
tr_loss:[0.05381811 0.10626726 0.10626726 0.05225055 0.05418799 0.05229456
 0.05381814 0.05381811 0.0529031  0.05464629 0.05290187 0.0558735
 0.05381811 0.05229456 0.05464629 0.10626727 0.06311972 0.06311971
 0.05381811 0.05381811 0.05381851 0.05381811 0.05464629 0.10626727
 0.05229456 0.05229457 0.05381812 0.06311972 0.06311971 0.05381811
 0.05464859 0.05381811 0.06311972 0.05464629 0.06311971 0.0529031
 0.05381811 0.05464629 0.05464673 0.06311972 0.05229456 0.05464629
 0.0558735  0.05464629 0.10626727 0.06311971 0.05381811 0.05464629
 0.0552998  0.05381811]
tr_loss:[0.06160558 0.05610217 0.0541104  0.0541104  0.06160558 0.0545569
 0.05136682 0.0545569  0.05457297 0.05403886 0.05412884 0.10537434
 0.05403886 0.05344532 0.0541104  0.0541104  0.05411074 0.05403886
 0.0541104  0.0545569  0.06160558 0.05610216 0.0545569  0.05647567
 0.0541104  0.05403886 0.0541104  0.0541104  0.0545569  0.0541104
 0.05136682 0.0541104  0.05457297 0.10537434 0.10537434 0.10537434
 0.0541104  0.05411003 0.0545569  0.05403887 0.06160559 0.0541104
 0.05403887 0.05136682 0.0541104  0.10537434 0.05403886 0.05136683
 0.0541104  0.0541104 ]
tr_loss:[0.05392518 0.05392518 0.05392518 0.05420335 0.05452821 0.05452821
 0.05420335 0.05551889 0.05987567 0.10392928 0.05420334 0.05987567
 0.10392928 0.10392927 0.05420335 0.05452821 0.05721914 0.05452821
 0.05420335 0.05392518 0.05452821 0.10392928 0.05392518 0.05987566
 0.05453507 0.05987565 0.10392928 0.10392928 0.05420334 0.05987566
 0.05420334 0.05987569 0.05452821 0.05420334 0.05452821 0.05041358
 0.05987567 0.05041465 0.05721914 0.059876   0.0546138  0.05704681
 0.05392518 0.10321255 0.05452821 0.05420336 0.05041466 0.05041466
 0.05420335 0.05987567]
tr_loss:[0.05723555 0.05723555 0.05575076 0.10190009 0.05334212 0.05259718
 0.10190009 0.05790899 0.05575078 0.05790854 0.10190009 0.0501437
 0.0501437  0.05790897 0.05575076 0.10190009 0.0501437  0.05575076
 0.05723485 0.0501437  0.0501437  0.05334212 0.10190009 0.05723555
 0.0525212  0.05706139 0.05334212 0.05723555 0.0501437  0.05575076
 0.05575075 0.05575076 0.0501437  0.05723555 0.05723555 0.05334212
 0.0501437  0.05575076 0.05790899 0.05299624 0.05334212 0.05014371
 0.05575076 0.05575076 0.10190009 0.05014371 0.05334212 0.05334212
 0.05334211 0.05575076]
tr_loss:[0.05227568 0.05593229 0.04998043 0.10088579 0.05593202 0.05227568
 0.05593202 0.05593203 0.05227568 0.05593202 0.05593202 0.05227607
 0.10088579 0.05227568 0.05192429 0.05192429 0.05593202 0.05038328
 0.05227568 0.05192429 0.05593203 0.05038328 0.05192428 0.05593774
 0.05192428 0.05227568 0.05192428 0.05740571 0.10088579 0.05594082
 0.10088579 0.10088579 0.05285589 0.05594081 0.05038328 0.05594081
 0.05227572 0.05593202 0.05038328 0.0574057  0.05275612 0.05721289
 0.05227568 0.05192428 0.05038328 0.05192429 0.05216775 0.05594082
 0.05192428 0.05038328]
tr_loss:[0.04939692 0.04853546 0.04939692 0.04939692 0.05293072 0.04854073
 0.04939692 0.05293072 0.09930144 0.05293072 0.04939692 0.04853546
 0.05462793 0.05407939 0.05016566 0.04853426 0.04939692 0.05293072
 0.05293072 0.09930144 0.04853546 0.05293072 0.05462793 0.05293072
 0.05293072 0.05462793 0.09930144 0.05016566 0.05293072 0.05014335
 0.09930146 0.05462794 0.09930144 0.04939693 0.05407939 0.05293072
 0.05462793 0.04853546 0.05293072 0.05293072 0.04939692 0.04853546
 0.09930144 0.04853546 0.05293072 0.05462793 0.09930146 0.09930146
 0.05016566 0.05462794]
tr_loss:[0.04277319 0.03480422 0.0356135  0.03480422 0.03635667 0.03480422
 0.0356135  0.03635668 0.03480423 0.08673743 0.04277321 0.03480422
 0.03480423 0.04277315 0.03635667 0.04277321 0.03480422 0.03635668
 0.03635667 0.04277321 0.0356135  0.03635668 0.03480422 0.03635668
 0.03480421 0.03480422 0.08673726 0.03480422 0.08673747 0.03480421
 0.03480421 0.03241246 0.0356135  0.03480422 0.08673746 0.04277319
 0.03480422 0.08673747 0.0356135  0.04277319 0.03241246 0.03480421
 0.0356135  0.03480422 0.0356135  0.04277321 0.03486974 0.03635667
 0.03480421 0.03561349]
text_input.shape
(4800, 14400)
learning_input_tmp.shape
(4800, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4800, 80)
learning_output.shape
(750, 80)
Model: "sequential_98"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_98 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.2284949 1.2236633 1.2310747 1.2310748 1.2339385 1.2310748 1.2169892
 1.227508  1.228495  1.2281954 1.228495  1.2339385 1.2236693 1.2280344
 1.228495  1.2284949 1.2236633 1.2169892 1.228495  1.2284949 1.2280003
 1.2284949 1.23408   1.2297053 1.2339385 1.220549  1.2169892 1.2237024
 1.236126  1.2236693 1.2360709 1.228495  1.2284952 1.2284949 1.2237024
 1.2280003 1.2310747 1.2281061 1.2169892 1.2284949 1.2236961 1.2284949
 1.236126  1.2284949 1.2361253 1.2280002 1.2361257 1.2237024 1.228495
 1.2284348]
tr_loss:[0.8070547  0.81257296 0.81257296 0.81257284 0.8321249  0.81257284
 0.85232985 0.7863916  0.8070547  0.81257284 0.8210602  0.8532362
 0.791258   0.82106    0.8210602  0.82106006 0.81257284 0.82106
 0.8070547  0.8532363  0.8070547  0.8109152  0.8355549  0.8321692
 0.82106006 0.8532364  0.79197377 0.8210602  0.8316172  0.81257296
 0.81091535 0.81257284 0.8210602  0.8070547  0.8070547  0.8210393
 0.81256735 0.8070547  0.81257284 0.81091535 0.7863916  0.8189565
 0.8070547  0.82106006 0.82106006 0.8109164  0.8316172  0.82106006
 0.8070547  0.82106006]
tr_loss:[0.45115146 0.4465924  0.44659233 0.44893503 0.45052618 0.45339522
 0.45339528 0.453389   0.45052618 0.5072281  0.45115146 0.45115146
 0.5072281  0.45339522 0.45052624 0.45115313 0.44893494 0.45052618
 0.44659224 0.44659227 0.45339528 0.44893503 0.5072281  0.44659227
 0.44893503 0.443309   0.45052624 0.44893503 0.44659224 0.44893503
 0.507228   0.4504934  0.45339566 0.44659233 0.45052624 0.45339528
 0.44659224 0.44893503 0.45051557 0.44659227 0.44659227 0.44710293
 0.45052618 0.4520236  0.45115152 0.44409505 0.5072281  0.5072281
 0.45052618 0.44893503]
tr_loss:[0.24874444 0.25059813 0.2542893  0.29518494 0.2542893  0.25403756
 0.2542893  0.29518494 0.2477756  0.25095764 0.24640429 0.25059813
 0.250931   0.25428933 0.25059813 0.25428915 0.2477756  0.29518494
 0.2951849  0.2542893  0.2477756  0.24640429 0.2542893  0.25171667
 0.24640432 0.24777564 0.2542893  0.2542893  0.24777564 0.25059813
 0.25093102 0.2951849  0.25093105 0.24777564 0.2542893  0.2477756
 0.25093108 0.24777564 0.24640429 0.24777563 0.2542893  0.24640432
 0.2477756  0.2542893  0.2477756  0.25093108 0.25093108 0.25501144
 0.24777563 0.25581193]
tr_loss:[0.14737831 0.16144425 0.1436822  0.16144422 0.13851085 0.15117797
 0.1473783  0.14339295 0.14339298 0.1870052  0.16101709 0.14339295
 0.13857901 0.1473783  0.16144422 0.15118016 0.16144387 0.14368218
 0.18700522 0.1436822  0.1436822  0.1870052  0.1436822  0.18700518
 0.14368221 0.16144425 0.13857903 0.16144422 0.14339295 0.1436822
 0.13857901 0.1473783  0.15117797 0.15117793 0.13857901 0.16144422
 0.14368221 0.18700518 0.15117796 0.1511774  0.13857901 0.15117793
 0.14737833 0.14339297 0.15117797 0.13857901 0.15117799 0.14368221
 0.14339292 0.14339295]
tr_loss:[0.08055882 0.08772626 0.08221832 0.06735499 0.09081597 0.08055878
 0.10843323 0.11484598 0.11484598 0.08055879 0.11484599 0.10843327
 0.10065468 0.11543026 0.06735498 0.09081588 0.08055879 0.08055882
 0.08055907 0.08772626 0.06735496 0.10843326 0.08221832 0.09081595
 0.10843325 0.06735499 0.08214948 0.09081595 0.08055881 0.11484597
 0.08055882 0.08221833 0.06735499 0.08055881 0.10843326 0.06735499
 0.08221833 0.06735528 0.08221833 0.10843326 0.10843326 0.10843325
 0.06735499 0.08055881 0.08059694 0.08221833 0.10843327 0.10843322
 0.10843325 0.10841632]
tr_loss:[0.06874844 0.06943677 0.02451342 0.06295905 0.04035208 0.05195897
 0.04035208 0.06943685 0.06943686 0.03798943 0.04872944 0.05195899
 0.06943685 0.03798958 0.06874846 0.06943683 0.06943684 0.06874846
 0.03798957 0.02451342 0.06943686 0.03984056 0.04035209 0.06874844
 0.04035209 0.06943686 0.06664719 0.03798957 0.02451342 0.06874844
 0.06874844 0.04035199 0.06943685 0.04035209 0.0588188  0.05195903
 0.06943686 0.06874846 0.04035209 0.04035208 0.03798958 0.02451343
 0.04878403 0.06943683 0.04035209 0.06935745 0.04035208 0.06943686
 0.03798957 0.03798958]
tr_loss:[0.00837096 0.02118019 0.01861377 0.02118019 0.0308476  0.02118019
 0.03084761 0.00837096 0.03084515 0.0186138  0.02914038 0.00837096
 0.02776026 0.0186138  0.00837099 0.0308476  0.04601518 0.02914039
 0.00837097 0.02118019 0.03927566 0.00837096 0.02914043 0.00837096
 0.04601284 0.02914041 0.01861377 0.00837096 0.0186138  0.02118019
 0.02116935 0.04601518 0.00837096 0.04601518 0.04560591 0.04601517
 0.03692834 0.03977543 0.00837096 0.0291404  0.02776026 0.04601516
 0.00837096 0.03084759 0.0186138  0.03692834 0.02115271 0.04601518
 0.00837096 0.0291404 ]
tr_loss:[0.00441781 0.01372557 0.0324611  0.00441781 0.00441781 0.03663649
 0.03663649 0.01338109 0.01691516 0.01691516 0.01338109 0.00441781
 0.00441781 0.0324611  0.01691517 0.01311821 0.0324611  0.01372557
 0.01372557 0.01337833 0.02508876 0.01338109 0.01971176 0.0324611
 0.00441781 0.03663648 0.03663649 0.0324611  0.01691514 0.0324611
 0.03663649 0.03663649 0.0132637  0.00443334 0.02751873 0.01691514
 0.03246107 0.01372557 0.01372557 0.00441781 0.00441781 0.01338109
 0.03663649 0.0324611  0.0324611  0.01338109 0.01691517 0.0324611
 0.01338109 0.01691514]
tr_loss:[0.01271413 0.02656127 0.01271411 0.02656127 0.00839353 0.01707043
 0.04784915 0.01373877 0.04784916 0.02094089 0.02656127 0.020318
 0.02656127 0.01707045 0.01271413 0.02656126 0.01373877 0.01271413
 0.02656127 0.01707045 0.02656127 0.01707043 0.01373877 0.01373877
 0.04784914 0.01271411 0.04784915 0.00839353 0.00839353 0.04784916
 0.01968999 0.02656024 0.01271411 0.01707045 0.01271411 0.04784914
 0.02656127 0.01271411 0.02656127 0.02656126 0.01706719 0.02030388
 0.01271411 0.01271411 0.02656127 0.02656118 0.01702795 0.02656127
 0.02656126 0.04784915]
tr_loss:[0.00940262 0.05362163 0.05362164 0.02676314 0.05362163 0.02253127
 0.05362163 0.0161904  0.02668377 0.05362164 0.02676313 0.05362164
 0.02676313 0.05362163 0.0161904  0.0130694  0.02676313 0.02676313
 0.02676314 0.02676314 0.05362163 0.02106474 0.01169606 0.02676313
 0.01469829 0.02676313 0.02676264 0.02676313 0.02106474 0.01169605
 0.02676313 0.01169606 0.0130694  0.01299301 0.02676313 0.01169606
 0.0161904  0.0161904  0.02106472 0.02676313 0.01169607 0.02676313
 0.0161904  0.05362164 0.02106475 0.02676313 0.05362163 0.01348769
 0.02676313 0.01619041]
tr_loss:[0.01277829 0.0499659  0.02092065 0.01529536 0.01277827 0.02807144
 0.04996591 0.02092066 0.00910468 0.02807144 0.02092065 0.00910468
 0.02807144 0.02807144 0.01529536 0.02092068 0.02807138 0.01529536
 0.02807144 0.01277829 0.04996591 0.01277827 0.02807144 0.02093117
 0.04996591 0.04996591 0.01277827 0.02473386 0.0499659  0.02805656
 0.02807144 0.02807144 0.0499659  0.02092066 0.00910468 0.01529536
 0.02092068 0.01529536 0.01529536 0.02807144 0.02807144 0.04996591
 0.04996591 0.01529536 0.01277829 0.02806943 0.00910468 0.04996591
 0.01181047 0.01277827]
tr_loss:[0.02743751 0.01376975 0.00715181 0.01376975 0.02049586 0.03084476
 0.0071518  0.02105664 0.0071518  0.03084475 0.04254559 0.02105666
 0.04254559 0.04254559 0.0071518  0.01376978 0.02105666 0.01519041
 0.03096566 0.0274375  0.01519041 0.01376978 0.0071518  0.03084186
 0.03084475 0.00715181 0.03084475 0.03084475 0.00715273 0.03084473
 0.02743751 0.00715181 0.01519023 0.01376978 0.00715181 0.01519042
 0.03084475 0.03084208 0.04254559 0.04254565 0.0186384  0.04254559
 0.03084475 0.03084475 0.01519042 0.0071518  0.02105664 0.03084475
 0.03084475 0.02704273]
tr_loss:[0.00706391 0.03376689 0.02187092 0.0154572  0.03360208 0.0154572
 0.00706391 0.03360208 0.03360209 0.02923129 0.03360209 0.03360208
 0.01545721 0.03376689 0.02187093 0.02767796 0.03360208 0.03360209
 0.00706391 0.03376689 0.0218709  0.03360208 0.00706391 0.02187092
 0.0340117  0.00706391 0.03360208 0.0337669  0.01613648 0.01545721
 0.01545718 0.0218709  0.03360208 0.00706391 0.01545721 0.03104671
 0.01613649 0.01545718 0.01545721 0.03376688 0.01545718 0.02922657
 0.03360209 0.0154572  0.0336021  0.03360208 0.01613649 0.03360208
 0.01545717 0.0218709 ]
tr_loss:[0.01681667 0.03521206 0.0285802  0.0074371  0.02722207 0.03176906
 0.0352121  0.03521195 0.03521209 0.02722206 0.00674329 0.01681668
 0.02722207 0.02222997 0.03015328 0.01681665 0.0285802  0.02722207
 0.02222848 0.01681668 0.01687345 0.0074371  0.0074371  0.01687345
 0.02722206 0.0074371  0.0352121  0.02722207 0.02222848 0.0074371
 0.01681716 0.02722207 0.01681664 0.02222848 0.01687345 0.0074371
 0.01681665 0.03521209 0.03176906 0.02722237 0.00761798 0.01681664
 0.0074371  0.02722207 0.0074371  0.03521209 0.0074371  0.01687345
 0.00743709 0.03015329]
tr_loss:[0.01726625 0.01726621 0.03535707 0.03535707 0.01654615 0.03535708
 0.02924494 0.0172662  0.03535707 0.01654615 0.03535708 0.03535707
 0.03535707 0.02355137 0.03535704 0.02953753 0.02355137 0.01726618
 0.01726618 0.03535708 0.0070658  0.0211482  0.01726622 0.02355137
 0.02776601 0.01654615 0.02924548 0.03535708 0.02355137 0.03526568
 0.01726618 0.0070658  0.0070658  0.01654615 0.0211482  0.0070658
 0.03535708 0.03535707 0.02355138 0.03535707 0.03535707 0.01726621
 0.02355118 0.01654615 0.01654615 0.02776601 0.01726621 0.02355138
 0.02114821 0.01726618]
tr_loss:[0.01369312 0.01706829 0.02847792 0.01358843 0.01706826 0.01706826
 0.00444152 0.02847792 0.01706828 0.0151975  0.03228896 0.00444152
 0.0151975  0.01369312 0.00444152 0.01369311 0.00444152 0.01426937
 0.03228998 0.0321003  0.00444152 0.03207585 0.02354766 0.02907706
 0.00444202 0.03228998 0.0284779  0.00444152 0.00444152 0.01519747
 0.01369312 0.0151975  0.02847792 0.01519748 0.01706828 0.01706827
 0.03228998 0.01369312 0.01706828 0.03238549 0.01519751 0.02354766
 0.03228997 0.03228997 0.03228997 0.03228997 0.03228998 0.02847791
 0.00444152 0.01369311]
tr_loss:[0.01385251 0.03075117 0.01485908 0.01220836 0.03493831 0.01485907
 0.00295615 0.01385251 0.03493909 0.01385251 0.01485911 0.01220836
 0.03075117 0.02472218 0.01385249 0.01385248 0.01375688 0.0138525
 0.00294977 0.00295616 0.00295615 0.03074922 0.01385251 0.01385251
 0.03075041 0.00295615 0.03493831 0.01220802 0.00295615 0.01220835
 0.03493831 0.03075117 0.00295615 0.03075117 0.0148591  0.00295616
 0.02472219 0.02472219 0.03075117 0.03075117 0.01485907 0.03075117
 0.03072966 0.01220836 0.0349383  0.03064109 0.01220836 0.03075078
 0.01385251 0.02905545]
tr_loss:[0.0212295  0.01846483 0.01603004 0.01603001 0.0233475  0.04047861
 0.04047861 0.03047899 0.01603003 0.0404786  0.0192805  0.01276554
 0.0233475  0.0233475  0.01603001 0.01276551 0.01276551 0.00368664
 0.01270509 0.01928053 0.01928051 0.02488775 0.01270503 0.03047899
 0.00368664 0.04047861 0.01602883 0.04047861 0.01276541 0.01276551
 0.01276551 0.00368665 0.01265844 0.00368664 0.03047899 0.01603004
 0.00368664 0.00368664 0.01846483 0.03047899 0.01276554 0.01270509
 0.01270509 0.00368664 0.01603004 0.01276554 0.03047899 0.01276551
 0.03047899 0.00368664]
tr_loss:[0.01409562 0.02238047 0.03011614 0.01409562 0.03011613 0.01858501
 0.00585448 0.00585448 0.03011614 0.01409562 0.01409562 0.04428923
 0.00585448 0.01409562 0.01342372 0.03011613 0.01700344 0.01700343
 0.01342373 0.00585448 0.03011614 0.04428914 0.00585448 0.03009874
 0.00585447 0.00585448 0.03011614 0.03011614 0.01409562 0.04428922
 0.01409562 0.01700343 0.03011615 0.03011614 0.04428923 0.01342373
 0.0134237  0.04428923 0.00585448 0.01342372 0.01409562 0.0134237
 0.03011615 0.01342373 0.04428923 0.01409562 0.03011614 0.01700346
 0.00585448 0.00585448]
tr_loss:[0.02920955 0.01400448 0.02920954 0.0140045  0.02920876 0.00661715
 0.02920955 0.02920955 0.01400447 0.0164284  0.04370339 0.02920141
 0.01431907 0.04370338 0.00661716 0.01431314 0.0140045  0.02311172
 0.02920955 0.01431907 0.04370338 0.04370338 0.0244429  0.01400447
 0.00661715 0.01400447 0.01642839 0.00661716 0.02920955 0.0140045
 0.02920956 0.02920955 0.02919712 0.01400447 0.02920955 0.00661716
 0.02169042 0.00661716 0.04370338 0.00661715 0.02160932 0.02920955
 0.00660234 0.04370337 0.02920955 0.0140045  0.01642842 0.04370339
 0.00661715 0.01431907]
tr_loss:[0.01306298 0.00535137 0.01306298 0.03698834 0.00535137 0.02802544
 0.02802544 0.03698832 0.01453904 0.01393986 0.03698832 0.01453903
 0.02802544 0.02802544 0.01306298 0.00535136 0.01453906 0.01393983
 0.00535137 0.01393984 0.02802544 0.01306298 0.03698834 0.00535137
 0.03698832 0.00535137 0.02802544 0.03698832 0.02802544 0.02802544
 0.02802544 0.02802544 0.02802544 0.01306298 0.01393984 0.0179884
 0.03698834 0.03698832 0.02742944 0.00535137 0.0185717  0.01453906
 0.01453906 0.02802544 0.01393986 0.02802544 0.03698834 0.0179884
 0.03698834 0.02802544]
tr_loss:[0.02258441 0.01333461 0.01563918 0.0211213  0.00541997 0.01443537
 0.01443535 0.02915414 0.01443535 0.02915414 0.01333461 0.02258441
 0.02514463 0.01333461 0.0225844  0.02915414 0.02258441 0.02030407
 0.02915414 0.01563937 0.02915415 0.00541997 0.01563919 0.01443537
 0.02117375 0.01563918 0.02915413 0.02258441 0.02258441 0.02335854
 0.02258441 0.01443535 0.02915415 0.02915414 0.01443537 0.00541997
 0.00541997 0.02335854 0.02915414 0.01333461 0.00541997 0.0225844
 0.00541997 0.02910934 0.00541997 0.02258441 0.01563919 0.01563916
 0.02335854 0.01333388]
tr_loss:[0.03435729 0.01336025 0.02106921 0.0343572  0.01772579 0.01234033
 0.03435729 0.03435729 0.03435729 0.01772375 0.0188852  0.03435729
 0.01772576 0.0273169  0.03435729 0.03435729 0.03435729 0.01877986
 0.02106921 0.0210692  0.03435729 0.03435729 0.0210692  0.01772579
 0.03435729 0.03435729 0.03435659 0.01234033 0.03435729 0.01888517
 0.01234033 0.02951354 0.0188852  0.0343573  0.01772569 0.01772579
 0.01772579 0.02106918 0.01772579 0.01888517 0.03435729 0.03435728
 0.02106916 0.03435729 0.02106921 0.03435729 0.02106921 0.02106919
 0.03435728 0.02106921]
tr_loss:[0.03190256 0.03190256 0.01538058 0.01639334 0.01525923 0.01612126
 0.03190256 0.01639332 0.02010231 0.02915611 0.0201023  0.0085216
 0.01612126 0.01525922 0.01525922 0.01639332 0.03190256 0.01639332
 0.01525342 0.0085216  0.02010231 0.03190256 0.01639332 0.01612126
 0.03190256 0.03190254 0.03190256 0.01525922 0.01525922 0.0085216
 0.02740494 0.0085216  0.02485233 0.01612126 0.01639334 0.01612126
 0.00852146 0.0085216  0.01612127 0.0085216  0.01527257 0.01525922
 0.02010232 0.03190256 0.01636487 0.02010229 0.01639335 0.00852159
 0.03190256 0.00852159]
tr_loss:[0.01302652 0.02687303 0.01764488 0.02276058 0.01347742 0.02687305
 0.01349025 0.01302649 0.01302649 0.02818647 0.01302652 0.01302652
 0.01349025 0.02182781 0.01302649 0.01349025 0.02687306 0.02818662
 0.01764486 0.01302649 0.01764486 0.02276058 0.01302649 0.02818662
 0.01302649 0.01764486 0.00571957 0.00571957 0.02818662 0.02818641
 0.02818662 0.02818661 0.02687304 0.02687303 0.02818662 0.01349025
 0.00571957 0.01764486 0.01302652 0.01302485 0.00571961 0.02276058
 0.02818662 0.02818662 0.02818662 0.02687305 0.00571957 0.00526417
 0.01764486 0.02182781]
tr_loss:[0.01231896 0.01293096 0.02677056 0.02125551 0.02677054 0.03716875
 0.01682134 0.02676789 0.01293096 0.01231896 0.02677056 0.03716874
 0.03716875 0.01682349 0.00530317 0.01682132 0.02677055 0.01668299
 0.01293096 0.01682134 0.01231893 0.01231896 0.03716874 0.01293096
 0.0159778  0.0204782  0.02319746 0.00530134 0.01293096 0.01680061
 0.03716874 0.02180587 0.01293096 0.02677056 0.01231893 0.00530317
 0.01231894 0.0204782  0.01682132 0.00530317 0.00530317 0.01293096
 0.02677056 0.02677056 0.01231881 0.00688522 0.03716805 0.02677056
 0.01682135 0.01231893]
tr_loss:[0.02274101 0.04135834 0.00483866 0.01253769 0.00483865 0.01253769
 0.04135834 0.01253769 0.02633043 0.01253769 0.01253769 0.0263217
 0.02633043 0.01569214 0.04135836 0.02633043 0.01569214 0.02085999
 0.04135834 0.04135835 0.01241013 0.04135835 0.02633043 0.00483866
 0.00491055 0.02233667 0.01253769 0.02624099 0.01253769 0.04811914
 0.01253769 0.02633039 0.04135834 0.01569211 0.01569211 0.01196688
 0.01569213 0.01241013 0.00483866 0.04141223 0.02633043 0.02633043
 0.02633044 0.04135836 0.02633043 0.00483866 0.02633043 0.02633043
 0.04135835 0.01241011]
tr_loss:[0.01208528 0.01306659 0.03887389 0.03887389 0.0268429  0.0268429
 0.01306659 0.01902457 0.02684281 0.0039129  0.0388739  0.0268429
 0.01208528 0.01902455 0.01306656 0.03887389 0.01306656 0.0039129
 0.03887388 0.0268429  0.03887389 0.0268429  0.0039129  0.0388739
 0.01208528 0.01306656 0.0268429  0.0268429  0.0268429  0.01208528
 0.01208528 0.0039129  0.01414523 0.03887389 0.0268429  0.0268429
 0.01208528 0.01306658 0.00391291 0.0268429  0.01306656 0.02105981
 0.0268429  0.0268429  0.0268429  0.0141452  0.01306658 0.0141452
 0.0268429  0.01837263]
tr_loss:[0.02797296 0.02797297 0.03215018 0.01197904 0.03215019 0.01418825
 0.01418827 0.01418827 0.01222821 0.00361571 0.01331587 0.01886741
 0.01331587 0.02275127 0.01222821 0.01331587 0.01418827 0.01222821
 0.02797297 0.0181743  0.03215018 0.01331585 0.00361571 0.02797297
 0.00361571 0.01418825 0.01222822 0.02797297 0.02797297 0.01418827
 0.00361571 0.01222821 0.02797297 0.00361571 0.01418827 0.01331587
 0.01418861 0.01222821 0.01222821 0.01222821 0.01886709 0.01222821
 0.02797297 0.01331587 0.01331585 0.02797297 0.00361571 0.01418824
 0.01222821 0.02796599]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4800 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4801, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4801 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4802, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4802 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4803, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4803 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4804, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4804 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4805, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4805 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4806, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4806 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4807, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4807 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4808, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4808 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4809, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4809 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4810, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4810 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4811, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4811 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4812, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4812 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4813, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4813 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4814, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4814 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4815, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4815 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4816, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4816 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4817, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4817 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4818, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4818 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4819, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4819 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4820, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4820 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4821, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4821 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4822, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4822 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4823, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4823 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4824, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4824 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4825, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4825 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4826, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4826 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4827, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4827 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4828, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4828 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4829, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4829 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4830, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4830 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4831, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4831 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4832, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4832 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4833, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4833 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4834, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4834 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4835, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4835 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4836, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4836 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4837, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4837 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4838, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4838 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4839, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4839 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4840, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4840 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4841, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4841 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4842, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4842 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4843, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4843 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4844, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4844 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4845, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4845 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4846, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4846 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4847, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4847 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4848, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4848 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4849, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4849 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4850, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4850 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4851, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4851 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4852, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4852 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4853, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4853 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4854, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4854 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4855, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4855 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4856, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4856 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4857, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4857 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4858, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4858 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4859, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4859 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4860, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4860 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4861, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4861 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4862, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4862 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4863, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4863 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4864, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4864 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4865, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4865 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4866, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4866 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4867, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4867 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4868, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4868 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4869, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4869 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4870, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4870 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4871, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4871 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4872, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4872 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4873, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4873 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4874, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4874 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4875, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4875 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4876, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4876 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4877, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4877 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4878, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4878 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4879, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4879 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4880, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4880 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4881, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4881 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4882, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4882 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4883, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4883 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4884, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4884 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4885, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4885 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4886, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4886 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4887, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4887 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4888, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4888 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4889, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4889 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4890, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4890 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4891, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4891 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4892, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4892 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4893, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4893 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4894, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4894 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4895, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4895 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4896, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4896 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4897, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4897 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4898, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4898 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4899, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4899 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4900, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-4800
text_input.shape
(4900, 14400)
learning_input_tmp.shape
(4900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4900, 80)
learning_output.shape
(750, 80)
Model: "sequential_99"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_99 (SimpleRNN)   (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.869976  1.8319333 1.8458269 1.7706487 1.8015652 1.833226  1.87099
 1.8015652 1.7706482 1.8319333 1.8015652 1.87099   1.8004119 1.8015308
 1.8319286 1.833226  1.833226  1.8319283 1.7706482 1.8709904 1.8709902
 1.8015652 1.7706482 1.7706478 1.8709902 1.8284019 1.8458271 1.8290489
 1.7706482 1.8015652 1.786267  1.87099   1.7689259 1.8319333 1.8709902
 1.7706482 1.8709902 1.8458267 1.87099   1.833087  1.8434544 1.8015652
 1.87099   1.8290489 1.8015649 1.8015652 1.7706482 1.8319336 1.8319333
 1.8332262]
tr_loss:[0.9949148  0.9191235  0.91912377 0.9252037  0.925974   0.9407193
 0.9407193  0.93182147 0.90901613 0.91912365 0.909016   0.99487674
 0.93182147 0.9949148  0.9259739  0.9259739  0.90901613 0.9252036
 0.91907775 0.925974   0.9407194  0.9949148  0.925974   0.93182147
 0.9259739  0.9407194  0.9191222  0.90901625 0.9406847  0.9949148
 0.9252037  0.9949148  0.9407193  0.94071925 0.925974   0.9407194
 0.92595387 0.9259741  0.9949148  0.9949148  0.9407193  0.9252057
 0.9259739  0.909016   0.9949148  0.925974   0.94071925 0.9949148
 0.9949148  0.90901625]
tr_loss:[0.5414445  0.5414445  0.5714079  0.59129995 0.56281245 0.56281245
 0.5780796  0.5628123  0.5628123  0.5527348  0.55332696 0.5628123
 0.5913536  0.55273485 0.571408   0.55273473 0.5533271  0.5780795
 0.54705054 0.5714079  0.5913537  0.55332696 0.5414445  0.553327
 0.571408   0.55273473 0.5780795  0.571408   0.55273485 0.571408
 0.55273485 0.55273473 0.56281245 0.571408   0.5912659  0.5913537
 0.5527348  0.5628124  0.55273473 0.571408   0.5780796  0.5913538
 0.571408   0.5780795  0.5628122  0.55273473 0.55273485 0.57800657
 0.55273473 0.5780796 ]
tr_loss:[0.27994195 0.28297216 0.27993196 0.27920276 0.27477518 0.276766
 0.27477518 0.27477515 0.28297213 0.26328135 0.27920276 0.27920276
 0.28297216 0.27920276 0.28297216 0.26328516 0.27994195 0.27994195
 0.2752343  0.28297216 0.27477512 0.27522507 0.2632852  0.27477512
 0.2798972  0.27477512 0.2747751  0.2752367  0.27920276 0.27477515
 0.2784238  0.27477494 0.28005433 0.27477512 0.2752343  0.27477515
 0.27477512 0.2632852  0.27523428 0.2752343  0.27477518 0.27523428
 0.2752343  0.29807752 0.27920276 0.27920276 0.27523428 0.2747752
 0.26328522 0.27523434]
tr_loss:[0.11369804 0.11456728 0.11456732 0.1079746  0.11456726 0.11456728
 0.11456732 0.10789857 0.14994493 0.11369804 0.13396612 0.11456728
 0.11369804 0.11456735 0.11369804 0.10789857 0.11545221 0.10835649
 0.14994495 0.14994493 0.10789856 0.11369804 0.1499449  0.10789857
 0.13396612 0.10789855 0.13396612 0.11456728 0.13396613 0.14994493
 0.13396612 0.11456732 0.11456873 0.10835654 0.11369804 0.10835651
 0.1499449  0.11369804 0.11545219 0.11456728 0.10835649 0.1145732
 0.11369805 0.11456728 0.10835651 0.1083565  0.14994492 0.10836396
 0.11369802 0.13396612]
tr_loss:[0.10845914 0.10845914 0.06318514 0.07988258 0.06373322 0.06577986
 0.07988258 0.06577991 0.06577992 0.06318515 0.06318515 0.06318516
 0.10845913 0.06318603 0.06373182 0.06577992 0.06184616 0.06577986
 0.06184615 0.06377637 0.06577987 0.06577991 0.06373182 0.06377637
 0.10845914 0.10845912 0.06377638 0.06184613 0.06377638 0.07988258
 0.06184616 0.06318516 0.06377637 0.10845914 0.10845914 0.06377638
 0.06377638 0.06377663 0.06318515 0.06413566 0.06373187 0.06184616
 0.06318514 0.06377638 0.06628148 0.06577991 0.10845914 0.07988258
 0.07988258 0.06381094]
tr_loss:[0.05079788 0.04651406 0.04651406 0.04651406 0.04405753 0.05079838
 0.04651406 0.09012319 0.04196854 0.04196854 0.04730788 0.04651406
 0.04110477 0.09012321 0.05079788 0.04405751 0.04730788 0.04196854
 0.04730189 0.09012319 0.04405321 0.04196854 0.04405753 0.04406765
 0.09012319 0.05079792 0.05079787 0.04730788 0.05079792 0.04651406
 0.09012318 0.0901232  0.04730786 0.04730783 0.04730788 0.09012354
 0.05079786 0.04110476 0.0901232  0.04196854 0.04651406 0.0901232
 0.04405752 0.04651406 0.04651406 0.0901232  0.09012318 0.04110478
 0.04196856 0.04110479]
tr_loss:[0.03264326 0.01815233 0.02576436 0.02255501 0.02576435 0.01805533
 0.01570056 0.06590901 0.01869906 0.01805534 0.01570056 0.01570056
 0.01867412 0.03264328 0.01869906 0.02576436 0.02255501 0.0257501
 0.022555   0.03264329 0.06590901 0.03264331 0.022555   0.02576436
 0.02255501 0.02576436 0.01805533 0.02576436 0.01869906 0.01570056
 0.02255501 0.01805532 0.03264327 0.0180553  0.03264329 0.02576424
 0.01570056 0.01869906 0.02576436 0.06590901 0.06590899 0.03264329
 0.01805531 0.022555   0.03264328 0.06590898 0.02255501 0.03264339
 0.01805531 0.01869906]
tr_loss:[0.01310524 0.00699453 0.00729017 0.00699453 0.00729017 0.00918291
 0.01445704 0.05511961 0.02164033 0.02157978 0.00918291 0.00699453
 0.01445704 0.00729018 0.00918291 0.00729018 0.00729052 0.02157979
 0.05511962 0.00699453 0.00918291 0.00729016 0.00918291 0.00729018
 0.00729017 0.01445704 0.0551196  0.02158239 0.05511961 0.00729018
 0.00729018 0.05511962 0.00680237 0.01310525 0.02157978 0.00729017
 0.02157978 0.00926865 0.05511962 0.00729017 0.05511962 0.00699453
 0.00699454 0.01445705 0.01310525 0.00918291 0.0551196  0.00729016
 0.02157978 0.01310524]
tr_loss:[0.01829917 0.00532729 0.01078148 0.00693704 0.00530856 0.00694015
 0.007392   0.00532729 0.00694015 0.007392   0.01829915 0.00532731
 0.01829915 0.00532731 0.00532732 0.01194896 0.00694015 0.01194897
 0.007392   0.01829915 0.00694015 0.007392   0.01078149 0.01194897
 0.01194897 0.01829915 0.007392   0.00694015 0.01194896 0.01829916
 0.01829915 0.01078148 0.01185255 0.01194896 0.01831159 0.05355958
 0.01829915 0.00532729 0.01829915 0.01194897 0.01078149 0.01829916
 0.00694015 0.00532731 0.01829915 0.007392   0.00694015 0.00694015
 0.01829916 0.007392  ]
tr_loss:[0.00905443 0.05209472 0.00776366 0.00905443 0.00712318 0.0051926
 0.01324841 0.00845969 0.01324841 0.00340958 0.00519259 0.00712318
 0.00845968 0.05209472 0.00340958 0.00712318 0.0132484  0.00519259
 0.00712318 0.00905443 0.00519259 0.00340958 0.00905443 0.00340958
 0.0051926  0.0051926  0.00845969 0.0132484  0.01324841 0.0132484
 0.01229735 0.00845969 0.00845969 0.00712318 0.00340959 0.01324841
 0.00708949 0.00917862 0.05209472 0.0071232  0.00340958 0.00340959
 0.00905443 0.01324841 0.00845969 0.00845969 0.00845969 0.01324841
 0.01324841 0.00712318]
tr_loss:[0.00586147 0.00586147 0.004094   0.0046578  0.05239747 0.004094
 0.004094   0.00586147 0.00416719 0.00416719 0.00416138 0.00416718
 0.01010608 0.01010609 0.01342201 0.05239747 0.05270589 0.0046578
 0.0524     0.00586148 0.01010608 0.00586147 0.00416718 0.01010609
 0.00333328 0.00409399 0.01342201 0.0046578  0.00416717 0.01010609
 0.00409399 0.00409399 0.05239747 0.01010609 0.01010608 0.0046578
 0.05239747 0.01010608 0.004094   0.013422   0.00586147 0.00586147
 0.01010608 0.0046578  0.05239747 0.00409399 0.01010608 0.01342201
 0.00409398 0.01010609]
tr_loss:[0.01662642 0.0108063  0.00612929 0.05507172 0.00501003 0.00612929
 0.00755601 0.00755602 0.00501003 0.00612929 0.05507172 0.00284183
 0.00612929 0.00755601 0.0108063  0.00612929 0.01662642 0.00612929
 0.0108063  0.00501003 0.00755601 0.05507172 0.00501003 0.00612929
 0.01662642 0.00612929 0.00755601 0.00284183 0.00501003 0.05507172
 0.05497667 0.0108063  0.007556   0.00501003 0.0108063  0.0108063
 0.0108063  0.00612929 0.00501003 0.0108063  0.00501003 0.00501417
 0.0108063  0.00755602 0.01662641 0.01662642 0.01662642 0.00284182
 0.05507172 0.00501003]
tr_loss:[0.01570331 0.01567227 0.00227194 0.01676824 0.01136205 0.0157033
 0.01570331 0.01135583 0.00653469 0.00653469 0.00877333 0.01570329
 0.00876475 0.00876476 0.00227194 0.0157033  0.00227193 0.01135561
 0.01580179 0.00463344 0.05599449 0.01135561 0.01570329 0.00463344
 0.0113556  0.00876475 0.05599449 0.00463344 0.05599449 0.00463344
 0.00227194 0.05599449 0.00463344 0.01135561 0.00463344 0.0113556
 0.05599449 0.0157033  0.0157033  0.00653469 0.01135561 0.00876476
 0.01570019 0.05599449 0.00653469 0.0113556  0.00227194 0.00227194
 0.00653475 0.00227194]
tr_loss:[0.00475276 0.00475276 0.01074704 0.01074703 0.01074704 0.00161876
 0.01074704 0.05403434 0.01026608 0.05403434 0.05403434 0.01074704
 0.01026609 0.00460395 0.01074704 0.01568706 0.00619634 0.00475276
 0.01026609 0.00475276 0.0038932  0.00475276 0.0038932  0.00161876
 0.05403434 0.01074704 0.00161876 0.00161876 0.00161876 0.01074704
 0.00161876 0.00475276 0.01042694 0.01026607 0.0047527  0.00619634
 0.00619633 0.00161876 0.05403434 0.00475169 0.0038932  0.05403434
 0.05403434 0.0038932  0.00619633 0.01026608 0.01026608 0.01026609
 0.00619633 0.05403434]
tr_loss:[0.00854303 0.00854303 0.00802284 0.00303073 0.00303072 0.00358873
 0.00303072 0.00802284 0.00303243 0.00268471 0.00614167 0.00802284
 0.00854142 0.00358873 0.00268471 0.00358873 0.0026847  0.00513868
 0.00303072 0.00513868 0.00268471 0.00268472 0.05174527 0.00358873
 0.00513868 0.05174527 0.00268472 0.00513868 0.00854303 0.00854304
 0.00513868 0.00854304 0.00358873 0.00268471 0.00303072 0.00303073
 0.00303072 0.00854303 0.00802284 0.00303072 0.00802284 0.00358873
 0.00268471 0.00854303 0.00268471 0.00852676 0.00358873 0.00513868
 0.00513868 0.00513868]
tr_loss:[0.00953063 0.00953063 0.00953063 0.00841441 0.00634675 0.00634674
 0.00841441 0.0075006  0.00750065 0.00634674 0.00841441 0.00953063
 0.00108195 0.0514317  0.00634675 0.00841441 0.05143172 0.00750066
 0.00841442 0.00454735 0.00108195 0.00634674 0.00750066 0.00634675
 0.00325816 0.00750066 0.00953062 0.00841442 0.0095306  0.00749942
 0.00750066 0.00750066 0.00841442 0.00108217 0.00841442 0.0514317
 0.0514317  0.0084144  0.00841441 0.00953062 0.00953063 0.0514317
 0.00634675 0.00634675 0.00953063 0.00454735 0.00750066 0.00750066
 0.00841441 0.0514317 ]
tr_loss:[0.00085652 0.00832507 0.00832507 0.05202559 0.00543093 0.01044971
 0.00543054 0.01046368 0.00763216 0.00085652 0.01032669 0.01044962
 0.00832508 0.01044962 0.05202559 0.01016041 0.00832508 0.01044963
 0.01044962 0.00543054 0.05202559 0.01044962 0.00543054 0.01044962
 0.05202559 0.00085652 0.00763216 0.00085652 0.00543054 0.00543054
 0.05202559 0.00543054 0.01044963 0.01032669 0.05202559 0.00763416
 0.00832507 0.01044962 0.00763215 0.01032669 0.05202559 0.00085652
 0.01032669 0.05202559 0.05202559 0.0103267  0.01032667 0.00543131
 0.0103267  0.05202559]
tr_loss:[0.00927944 0.00927944 0.00513517 0.00078106 0.00823244 0.00078106
 0.00513517 0.00819513 0.05210791 0.00819513 0.00823239 0.05210791
 0.05210791 0.00927944 0.00078106 0.00928036 0.00078106 0.00819513
 0.01001097 0.01001096 0.00513517 0.01001097 0.00078106 0.01001097
 0.01001096 0.00823238 0.00823238 0.00819513 0.00927944 0.00078109
 0.00819513 0.00078106 0.00823238 0.00078106 0.00823238 0.00819512
 0.00823238 0.00513517 0.00823238 0.00823238 0.00927944 0.00819512
 0.00819512 0.00823318 0.05210791 0.00819512 0.00823238 0.05210791
 0.00823238 0.00819513]
tr_loss:[0.00722785 0.05166071 0.05166071 0.00722786 0.00678116 0.00678133
 0.00678117 0.00677102 0.00678116 0.00048606 0.00097496 0.00433479
 0.00433479 0.00048607 0.00856422 0.00929943 0.0085619  0.00856422
 0.00048607 0.00433479 0.00740228 0.00933802 0.00722786 0.00433479
 0.00933803 0.00048606 0.05166071 0.00496415 0.05166071 0.00933802
 0.00433479 0.00933802 0.00675496 0.00433479 0.05166071 0.00433479
 0.00933803 0.0067811  0.00678116 0.00433479 0.00933802 0.00722787
 0.00678117 0.00048607 0.00433479 0.00433479 0.00678116 0.00048606
 0.0516607  0.00722786]
tr_loss:[0.00468502 0.00073118 0.00629131 0.00629131 0.00954725 0.00685893
 0.00629131 0.00954725 0.00468502 0.00954725 0.00468502 0.00073353
 0.00954725 0.00954725 0.00468502 0.00629131 0.00954597 0.0511715
 0.00629131 0.00468502 0.0065518  0.00351825 0.00631317 0.00468502
 0.00954725 0.00073118 0.0511715  0.00629131 0.00629131 0.00629131
 0.00073118 0.00954725 0.00629131 0.00470998 0.00629131 0.00351694
 0.00468502 0.0062913  0.00663466 0.00351694 0.00468502 0.00468502
 0.00629131 0.00073118 0.05261913 0.00629131 0.0065518  0.00468456
 0.00954725 0.00351694]
tr_loss:[0.0046782  0.00329061 0.00599672 0.05150321 0.00329061 0.00599672
 0.01002072 0.00198867 0.00599672 0.00599672 0.00329061 0.01002071
 0.00329061 0.00599672 0.00329061 0.00198867 0.01002071 0.00329061
 0.0046782  0.05150281 0.00329265 0.05150281 0.00599672 0.00259101
 0.00599672 0.00599672 0.00259102 0.05150281 0.00259102 0.00198866
 0.00329061 0.00329154 0.0046782  0.0046782  0.00599672 0.00467821
 0.00857509 0.00329061 0.00259102 0.01002071 0.00180173 0.00259102
 0.0042728  0.05150281 0.00329073 0.00599672 0.05150281 0.01002072
 0.00599672 0.00599672]
tr_loss:[0.00409823 0.00680405 0.05287396 0.00680405 0.01086906 0.00410638
 0.00680405 0.00410638 0.00173619 0.00405673 0.00954444 0.00680405
 0.00173619 0.00409823 0.05287396 0.05287395 0.00409823 0.00680405
 0.01086906 0.00680405 0.00410641 0.01086906 0.00680405 0.00680405
 0.01087107 0.01086905 0.01086905 0.01086905 0.00398314 0.01086905
 0.00409823 0.00680405 0.01086905 0.00680405 0.00409823 0.01086905
 0.00410638 0.00405673 0.00680405 0.00173619 0.00405787 0.05287396
 0.01086905 0.05286868 0.00680405 0.00680404 0.00173619 0.00405673
 0.00409435 0.00173619]
tr_loss:[0.00403568 0.01027469 0.00403568 0.00765002 0.00457672 0.00457672
 0.00765002 0.05380776 0.05358012 0.0102747  0.05358011 0.00765002
 0.01116556 0.00165513 0.00508333 0.00508333 0.00165513 0.00165513
 0.00165513 0.00508334 0.01027469 0.00457672 0.05358012 0.00508334
 0.00457672 0.00457672 0.00508332 0.00165513 0.00403568 0.00165513
 0.00765002 0.00508338 0.0102747  0.01027469 0.01027469 0.00403568
 0.00765002 0.00508333 0.00457672 0.00457672 0.00508333 0.05358012
 0.00765002 0.00508334 0.00165513 0.00457672 0.0102747  0.00765002
 0.00508333 0.00508331]
tr_loss:[0.00705045 0.00366731 0.00705045 0.05260799 0.00366731 0.00705045
 0.00178454 0.00178452 0.00403795 0.00705045 0.0038266  0.0038266
 0.00403821 0.00366731 0.00403822 0.00853823 0.00705045 0.0038266
 0.00366503 0.0038266  0.00834992 0.00853824 0.00403822 0.00705045
 0.00853823 0.00403822 0.052608   0.00705045 0.00705044 0.00705045
 0.0038266  0.0038266  0.00403822 0.0038266  0.00366731 0.00366731
 0.00705045 0.00178452 0.00705045 0.00403821 0.0038266  0.00403822
 0.00705045 0.052608   0.00366731 0.00403822 0.00403583 0.00403822
 0.05260805 0.0038266 ]
tr_loss:[0.00548298 0.00316125 0.00548298 0.00272246 0.05130076 0.00150038
 0.00272245 0.00548298 0.00548298 0.00150037 0.00150037 0.00150037
 0.00316125 0.00483929 0.05130077 0.0081216  0.00483929 0.00812159
 0.00548298 0.00272237 0.00548298 0.05130077 0.00483929 0.00272246
 0.05130076 0.00271999 0.00548298 0.00272246 0.00150038 0.00272245
 0.05130076 0.00316128 0.00150038 0.00150037 0.00150038 0.05130076
 0.0058284  0.00548298 0.00272246 0.00548298 0.00548298 0.00483929
 0.00150038 0.00812159 0.00548298 0.00812159 0.00316125 0.05130076
 0.05130073 0.00548298]
tr_loss:[0.000367   0.00670086 0.00445976 0.000367   0.00462421 0.00462421
 0.00445977 0.05106004 0.05106004 0.00670086 0.00358707 0.00445976
 0.00934868 0.000367   0.00446034 0.00358707 0.05106004 0.05106005
 0.00462421 0.000367   0.000367   0.00669918 0.05106005 0.00445977
 0.00670086 0.00670086 0.00934868 0.000367   0.00358707 0.00462421
 0.00358707 0.00358707 0.05106004 0.00445981 0.05106004 0.00934868
 0.00445977 0.05106005 0.00670087 0.00445976 0.00445977 0.00670086
 0.00462421 0.00670086 0.05106004 0.000367   0.000367   0.05106004
 0.00445976 0.00445977]
tr_loss:[0.00614472 0.00424747 0.01037375 0.00430514 0.00424746 0.00824243
 0.00018111 0.00824243 0.00430514 0.00824243 0.05142118 0.01037374
 0.01037375 0.01037374 0.00430514 0.00824243 0.00824243 0.00018113
 0.05142118 0.05142118 0.00430514 0.05142118 0.01037375 0.00018092
 0.01037374 0.00430514 0.00824243 0.00018111 0.00614473 0.00018111
 0.00824243 0.00614472 0.00430514 0.00430514 0.00824243 0.00614472
 0.05142118 0.05142118 0.00424746 0.00614472 0.00424746 0.00430514
 0.00614473 0.01037375 0.00430514 0.0001811  0.00614473 0.00614473
 0.00430514 0.00824244]
tr_loss:[0.00015941 0.00015941 0.00856927 0.0513691  0.05136909 0.00799642
 0.0513691  0.00800582 0.0060431  0.00507069 0.00015941 0.00507068
 0.0040779  0.00507069 0.00507068 0.0513691  0.05136909 0.0040779
 0.00800584 0.00507069 0.00856927 0.00856927 0.00800577 0.00856927
 0.00015941 0.0513691  0.00507069 0.00800584 0.00856927 0.00507069
 0.0513691  0.05136909 0.00800584 0.00507069 0.00856927 0.0040779
 0.00800585 0.0513691  0.00507069 0.00800585 0.05136562 0.00507085
 0.00507068 0.05136909 0.0060431  0.0040779  0.00604311 0.0513691
 0.00015941 0.00604311]
tr_loss:[0.00578597 0.05121665 0.05121665 0.00707799 0.00707799 0.00368356
 0.05121665 0.00679555 0.00045299 0.00578596 0.05121385 0.00707799
 0.00368356 0.00679555 0.05121665 0.00045299 0.05121679 0.00368356
 0.00368356 0.00707795 0.00578596 0.05123067 0.00707799 0.00707769
 0.00578794 0.00045299 0.00518089 0.00578596 0.00578596 0.00707799
 0.00368356 0.00045299 0.05121665 0.05121665 0.00679555 0.05121665
 0.00578596 0.00045283 0.00578596 0.00679555 0.00679555 0.00045299
 0.00045299 0.00323988 0.00518005 0.05121665 0.00368356 0.05121665
 0.00045299 0.00707799]
text_input.shape
(4900, 14400)
learning_input_tmp.shape
(4900, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(4900, 80)
learning_output.shape
(750, 80)
Model: "sequential_100"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_100 (SimpleRNN)  (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.431967  1.4094836 1.4416487 1.4917139 1.410007  1.451658  1.4290891
 1.4094836 1.4319052 1.4917139 1.4416487 1.438945  1.4319671 1.438945
 1.4389441 1.4389461 1.4917139 1.4094834 1.438945  1.4094836 1.4416493
 1.451534  1.4416487 1.4319674 1.4094833 1.4416487 1.4386683 1.4319673
 1.4274924 1.438945  1.4290891 1.438945  1.4516299 1.4295449 1.4319673
 1.4388679 1.4416487 1.4416487 1.4917617 1.4290891 1.4290901 1.4416487
 1.4516518 1.4917138 1.4094847 1.429089  1.4290891 1.4917139 1.4290892
 1.4094834]
tr_loss:[0.85507905 0.88845026 0.8550789  0.8248636  0.855079   0.8291501
 0.8884503  0.8570469  0.8248636  0.88845026 0.88845026 0.8570469
 0.8570469  0.87963563 0.8550792  0.8291502  0.8228092  0.8570469
 0.8884503  0.87963474 0.82280934 0.88845026 0.8291504  0.8248636
 0.8228092  0.8291502  0.8248636  0.84079915 0.8248636  0.8796355
 0.8570469  0.8787411  0.88845026 0.8570469  0.8570469  0.8570469
 0.8570469  0.8550789  0.87963563 0.8550789  0.8248636  0.855079
 0.82486266 0.8228092  0.87963563 0.8248636  0.8291501  0.8570469
 0.82868654 0.8291503 ]
tr_loss:[0.354072   0.33972663 0.3540575  0.37304723 0.3410423  0.33972663
 0.34104225 0.37304726 0.37304726 0.35313278 0.3397266  0.35313278
 0.33972654 0.37304902 0.35407203 0.37304726 0.37304726 0.34498122
 0.34498125 0.33972657 0.34498125 0.35313278 0.33972657 0.34104222
 0.33972663 0.3397266  0.35313278 0.3449812  0.35313278 0.34104222
 0.4265348  0.4265348  0.34498125 0.37304726 0.34498125 0.33972657
 0.34498122 0.34983248 0.33972654 0.35407203 0.42653474 0.34498122
 0.33972657 0.34104225 0.34498137 0.34498122 0.3397266  0.42653465
 0.33972657 0.34718424]
tr_loss:[0.18858889 0.14128527 0.10758741 0.10602069 0.11652057 0.10602109
 0.14128527 0.18858887 0.14128527 0.1075874  0.11628483 0.18858886
 0.14128527 0.10758741 0.10758742 0.14128526 0.12051972 0.10758742
 0.12051971 0.11628483 0.10758746 0.11628487 0.10758741 0.14128526
 0.14128526 0.13129345 0.13129345 0.14128524 0.13141419 0.1205197
 0.14128523 0.10758741 0.14128527 0.11636861 0.10888871 0.12051971
 0.11628485 0.14128527 0.13129345 0.10760486 0.10758742 0.14128524
 0.13129345 0.10758741 0.10758741 0.14128527 0.11628483 0.11628485
 0.11628486 0.11628489]
tr_loss:[0.05420141 0.03342357 0.08846058 0.04232508 0.03342358 0.05420141
 0.04232508 0.05420141 0.04232507 0.05420141 0.04232507 0.04232508
 0.04232508 0.03024882 0.02773656 0.08846059 0.03574853 0.03024981
 0.04232508 0.02773656 0.03574855 0.04232508 0.03342357 0.02773657
 0.04232508 0.03342357 0.03024881 0.04232508 0.03024887 0.03045248
 0.04232508 0.03024881 0.03574855 0.03024882 0.03574854 0.02773657
 0.05420141 0.02773658 0.05420141 0.03024882 0.03024881 0.04243127
 0.03024882 0.04232507 0.05420141 0.08846058 0.03024882 0.03574853
 0.03344231 0.03024882]
tr_loss:[0.00597266 0.00597266 0.00866134 0.00479861 0.00597265 0.00866133
 0.01171559 0.00597266 0.01406675 0.00907524 0.00597265 0.00866134
 0.01020261 0.00597266 0.01406675 0.05516735 0.01171559 0.00866133
 0.01406675 0.00907524 0.05516737 0.01406675 0.00866134 0.00907524
 0.00907523 0.00597265 0.00907524 0.01171559 0.00866134 0.00597266
 0.00597266 0.00479861 0.01406676 0.00597266 0.00907524 0.05516737
 0.01171559 0.00866132 0.00564555 0.05516737 0.00597266 0.00479861
 0.01406675 0.00479861 0.01405624 0.00479861 0.00866139 0.05516737
 0.01171559 0.00479861]
tr_loss:[0.02455404 0.06283282 0.06283282 0.02219842 0.00615275 0.00615274
 0.02455404 0.02455404 0.01347301 0.01347301 0.01347301 0.00949343
 0.00615273 0.02219841 0.00615275 0.00949343 0.06283282 0.00949343
 0.06283282 0.02455405 0.01347301 0.02455404 0.01347301 0.00615276
 0.00859312 0.0221984  0.00859312 0.00859312 0.02455405 0.06283282
 0.02455404 0.00615275 0.02455403 0.00615275 0.06283282 0.06283282
 0.00949343 0.02219841 0.01347301 0.06283281 0.06283282 0.02455404
 0.01347301 0.00949235 0.02219843 0.06283282 0.00949343 0.02455404
 0.06283281 0.01347301]
tr_loss:[0.00968381 0.02412651 0.00919547 0.00919547 0.00549426 0.02412936
 0.00614843 0.02412936 0.00919547 0.00549426 0.00612591 0.02412936
 0.05497025 0.05497024 0.02412936 0.00614844 0.00900416 0.00964294
 0.00614844 0.05497023 0.00614844 0.00968381 0.00919547 0.05496342
 0.00968381 0.00919547 0.00614843 0.01813861 0.00549426 0.05497023
 0.00919547 0.01813882 0.00549425 0.02412936 0.00549425 0.00968381
 0.00549425 0.00614844 0.05497024 0.05497025 0.05497131 0.02412916
 0.00919547 0.0181386  0.05497024 0.02412936 0.05497024 0.00968381
 0.01813863 0.02412936]
tr_loss:[0.0161858  0.00369681 0.00449729 0.00352595 0.00369685 0.00449729
 0.04742109 0.00369685 0.00845042 0.00646532 0.04742109 0.01618595
 0.00352596 0.00646001 0.00369685 0.01618595 0.00449729 0.04742109
 0.04742109 0.01618404 0.00646532 0.01618596 0.00646532 0.04742109
 0.00352596 0.00646522 0.00449729 0.00369685 0.00845655 0.00845656
 0.00845657 0.00447036 0.00449729 0.00404195 0.00449729 0.00369685
 0.00646528 0.00352596 0.00845657 0.00646532 0.00352596 0.01618596
 0.00646532 0.04742109 0.00449729 0.00352595 0.00449729 0.00369685
 0.00449729 0.04742109]
tr_loss:[0.00272292 0.00532396 0.00532396 0.00971619 0.00783787 0.00971619
 0.00971619 0.00783787 0.00971619 0.00272291 0.00789943 0.00941676
 0.00971619 0.00532396 0.00783787 0.04435309 0.00261747 0.00971619
 0.00532396 0.00783787 0.00971618 0.00971619 0.00971619 0.04435309
 0.00971619 0.00783788 0.00532396 0.00941676 0.00272292 0.00971619
 0.00532396 0.00783788 0.00971618 0.00783787 0.00384311 0.04435309
 0.00971619 0.00971619 0.00941676 0.00941676 0.00783788 0.00272292
 0.00532396 0.00384311 0.00937239 0.00971619 0.00941677 0.00783788
 0.00971619 0.04435309]
tr_loss:[0.04517864 0.00875703 0.00801051 0.01231934 0.02223548 0.01005303
 0.01005302 0.00801051 0.00875703 0.01005328 0.00369562 0.01005301
 0.00369562 0.01005301 0.00875704 0.00801056 0.00801051 0.00875703
 0.00801051 0.00878255 0.00369562 0.01231934 0.00875703 0.04517864
 0.00801051 0.01005302 0.00369563 0.00801051 0.01989698 0.00369563
 0.04517864 0.01989698 0.01231934 0.00875703 0.00875703 0.00801051
 0.04517864 0.04517864 0.01989698 0.02014283 0.01231934 0.00875703
 0.04517864 0.00875703 0.01989698 0.01005303 0.00369562 0.00875703
 0.00875703 0.00875703]
tr_loss:[0.00707454 0.00707454 0.00707454 0.01024532 0.03770897 0.01873083
 0.01024532 0.03770898 0.00707455 0.002221   0.00707454 0.01019512
 0.01250269 0.00768026 0.00222101 0.01250269 0.01873083 0.00222101
 0.03770897 0.03770897 0.01024531 0.00768026 0.01024532 0.00222101
 0.00715338 0.00707455 0.0125027  0.03770897 0.00768026 0.00222101
 0.03770897 0.01873083 0.00222101 0.00768058 0.00707454 0.00768026
 0.00768026 0.00768026 0.03770896 0.00707454 0.00222101 0.01250483
 0.01024522 0.002221   0.01024532 0.00743042 0.03771142 0.01024531
 0.0125027  0.03770897]
tr_loss:[0.00977256 0.00977256 0.00977257 0.01674383 0.00820309 0.01505701
 0.00258897 0.02413529 0.01283304 0.01283304 0.01674383 0.01285745
 0.01505701 0.01674382 0.01674383 0.00977256 0.00258896 0.00820308
 0.00820308 0.00977687 0.02413294 0.00258897 0.02413529 0.02413528
 0.00977268 0.01674382 0.00258896 0.01505701 0.00820309 0.01505701
 0.01673695 0.01283304 0.00977256 0.01283304 0.02413528 0.00820309
 0.01674382 0.00820309 0.01505701 0.01283304 0.01505701 0.00820309
 0.01674382 0.00977257 0.00258896 0.00820308 0.01674382 0.00820309
 0.00820308 0.01674383]
tr_loss:[0.01136505 0.02799446 0.00982187 0.0035125  0.01253095 0.00351249
 0.00351249 0.00982187 0.0035125  0.00351249 0.02799448 0.02799447
 0.01136898 0.00982187 0.01253095 0.00351248 0.01136898 0.01253095
 0.00351249 0.00982187 0.01253095 0.00351249 0.00351249 0.02799448
 0.01253095 0.02799447 0.00982187 0.0035125  0.01011378 0.00982186
 0.0138154  0.00351249 0.00351248 0.00982187 0.0138154  0.01136898
 0.01136897 0.02799447 0.00902496 0.02799447 0.01136898 0.02752231
 0.01381524 0.02799447 0.01381539 0.0035125  0.02943804 0.01136897
 0.0138154  0.0138154 ]
tr_loss:[0.02957711 0.00880407 0.00581984 0.00769556 0.00649496 0.00769658
 0.02957712 0.00372129 0.00985945 0.00985946 0.00649497 0.0295771
 0.00769557 0.00646213 0.00987409 0.00581984 0.0037213  0.00985945
 0.00769556 0.00769557 0.00880407 0.00649496 0.0037213  0.0295771
 0.00985945 0.00649496 0.00985945 0.00581984 0.00581984 0.02957711
 0.00985946 0.02957711 0.00985946 0.00649496 0.0037213  0.00880405
 0.0295771  0.003721   0.006496   0.00581984 0.00880371 0.0295771
 0.0295771  0.00769557 0.00649497 0.00985946 0.00649497 0.00372129
 0.00581983 0.00372129]
tr_loss:[0.0107133  0.0107133  0.00353436 0.00745748 0.0107133  0.00558622
 0.00352937 0.00540767 0.00558622 0.00745748 0.00509911 0.00558622
 0.00509911 0.0107133  0.0107133  0.00352936 0.00509911 0.00745749
 0.0050991  0.00540766 0.00745748 0.00352936 0.00745748 0.0107133
 0.0107133  0.03173608 0.0107133  0.0107133  0.00352936 0.00558621
 0.00509911 0.00352936 0.00509911 0.00745748 0.0107133  0.00352936
 0.00745748 0.00540769 0.01071329 0.03176    0.00558622 0.0107133
 0.00745749 0.0050582  0.0107133  0.00540766 0.0107133  0.03173607
 0.0107133  0.00509911]
tr_loss:[0.00550353 0.01065463 0.00450969 0.00550353 0.01065462 0.01065463
 0.00550353 0.00550353 0.00450969 0.00450969 0.0065532  0.00550353
 0.0065532  0.01000792 0.0065532  0.00550353 0.03841211 0.01065462
 0.01000799 0.00450969 0.00450969 0.00450969 0.01000799 0.0065532
 0.03841212 0.00249438 0.00249453 0.010008   0.00550353 0.00249454
 0.01065462 0.01000799 0.03841211 0.01065462 0.00450969 0.01065752
 0.00450969 0.0045926  0.01065462 0.01000799 0.00249453 0.00249454
 0.00655321 0.00550353 0.03841212 0.00249454 0.01000799 0.03841212
 0.00249453 0.00550353]
tr_loss:[0.00537255 0.00268785 0.00470836 0.0104927  0.04190769 0.01044312
 0.0104927  0.01044249 0.01044249 0.00615965 0.04190769 0.00537253
 0.00524456 0.01046101 0.00470836 0.00615966 0.01044249 0.01049271
 0.00475019 0.00537253 0.04190769 0.00268785 0.00470836 0.00268785
 0.00615965 0.0104927  0.00615966 0.01044248 0.00470836 0.04190769
 0.00537253 0.00615966 0.01044249 0.01044249 0.01051511 0.01049271
 0.00470836 0.01044248 0.04190769 0.00268785 0.00268785 0.01044249
 0.01044248 0.00615964 0.01044248 0.01044249 0.00537253 0.00537253
 0.04190769 0.04190769]
tr_loss:[0.00985713 0.00391306 0.005376   0.00422048 0.005376   0.00422047
 0.00985713 0.00985713 0.00985713 0.00985713 0.00429744 0.00849209
 0.005376   0.00429744 0.00429744 0.04160932 0.00845661 0.00849209
 0.00331915 0.00422048 0.04160931 0.00422047 0.00543938 0.00849209
 0.00331917 0.00331915 0.00422047 0.00849209 0.00302473 0.00422047
 0.00849209 0.00422047 0.00331915 0.04160931 0.00422047 0.0033191
 0.0416237  0.00331915 0.00985713 0.04161853 0.005376   0.00985713
 0.00429744 0.00331915 0.00985713 0.00331915 0.00429744 0.00331915
 0.00849208 0.00849208]
tr_loss:[0.04053529 0.0039458  0.04053529 0.00473149 0.00473149 0.00323493
 0.0039458  0.00678868 0.0039458  0.01051418 0.0039458  0.00678868
 0.00394541 0.00617971 0.0039458  0.0039458  0.04053529 0.00678868
 0.00323493 0.00473166 0.00678868 0.0061797  0.00394408 0.01051418
 0.00473149 0.00323493 0.0039458  0.0039458  0.0039458  0.00323493
 0.00323494 0.00473149 0.00473149 0.00678868 0.0039458  0.00323494
 0.0061797  0.00617971 0.00323493 0.01051418 0.00678868 0.00323493
 0.0039458  0.00473149 0.0039458  0.0047315  0.00678868 0.00617971
 0.00323492 0.00614452]
tr_loss:[0.00589245 0.00520244 0.00425882 0.01121084 0.00520244 0.007959
 0.00520244 0.00425882 0.01121089 0.01121084 0.00589246 0.00520244
 0.00589244 0.007959   0.00520244 0.01121084 0.01121084 0.01121084
 0.00425882 0.03927026 0.00520244 0.03927026 0.03927026 0.00425882
 0.00325529 0.007959   0.03927026 0.00520244 0.00520244 0.00520244
 0.01121822 0.03927026 0.007959   0.01121084 0.01121084 0.00425882
 0.00589245 0.00520244 0.007959   0.007959   0.007959   0.03927026
 0.0032553  0.00589246 0.00425882 0.007959   0.00589246 0.03927057
 0.03927027 0.00325529]
tr_loss:[0.03343598 0.03343597 0.00424758 0.00424761 0.00529814 0.00563634
 0.0029744  0.00563634 0.00529814 0.00774675 0.00774675 0.00563634
 0.03343597 0.01012465 0.0029744  0.00568135 0.01012464 0.0029744
 0.03343596 0.00424758 0.00772036 0.00529814 0.01012464 0.0029744
 0.01012464 0.0029744  0.01012465 0.00297439 0.00529814 0.00774675
 0.00563634 0.00529814 0.00424758 0.00297439 0.00297439 0.03343596
 0.00563634 0.00424758 0.01012464 0.00774675 0.01012464 0.00746199
 0.00774675 0.01013874 0.00774675 0.0029744  0.01012463 0.03343596
 0.00774675 0.03343598]
tr_loss:[0.00501579 0.00753692 0.00268358 0.00529539 0.02305867 0.00740154
 0.02305866 0.00753692 0.0052986  0.0052986  0.00501579 0.00753693
 0.00529861 0.00529861 0.02305866 0.00529861 0.0050158  0.00740265
 0.00808331 0.00808332 0.00753692 0.00753692 0.00740265 0.0050158
 0.00753714 0.00808332 0.00808332 0.00268358 0.00753692 0.00753692
 0.00501579 0.00501579 0.00740265 0.00753692 0.00753692 0.00268359
 0.00753692 0.00740244 0.0050158  0.02283047 0.00529861 0.00268358
 0.00808331 0.00753692 0.00753693 0.00740265 0.00808332 0.00740262
 0.02305867 0.00753692]
tr_loss:[0.00622751 0.00408106 0.00802002 0.01917554 0.00889398 0.01428365
 0.00627457 0.00889878 0.01917557 0.00674077 0.0211551  0.00889398
 0.00889398 0.00889398 0.01917556 0.01428365 0.01917556 0.01428366
 0.00802002 0.01917555 0.00889398 0.00622751 0.00622751 0.01917555
 0.00622751 0.01428365 0.00674077 0.00408106 0.00622751 0.00802134
 0.01428365 0.00674076 0.00889398 0.00674077 0.00889398 0.00622751
 0.00622751 0.00622751 0.00622751 0.00622751 0.00408106 0.01917555
 0.01917556 0.00674077 0.01917556 0.01917556 0.00622751 0.01428682
 0.00408105 0.00408105]
tr_loss:[0.00587662 0.00882968 0.00713233 0.01562865 0.00587662 0.01825049
 0.0105593  0.00882968 0.01562866 0.00587663 0.00652234 0.00587778
 0.010822   0.00882968 0.00587669 0.01825048 0.00713238 0.00713233
 0.00713233 0.00587662 0.01825049 0.01082199 0.00587662 0.00587662
 0.01562867 0.0105593  0.01825049 0.01562866 0.0105593  0.00587663
 0.00713233 0.00713233 0.00713234 0.0156261  0.01082199 0.00882968
 0.01082199 0.0105593  0.01082222 0.01082199 0.01055934 0.01082199
 0.010822   0.00882968 0.0105593  0.00713233 0.01562866 0.00587662
 0.01055931 0.00713233]
tr_loss:[0.00269902 0.00500353 0.00758855 0.00538669 0.00619205 0.00269902
 0.00269902 0.00500353 0.00500353 0.00500353 0.01302172 0.00269902
 0.021507   0.0053867  0.00269902 0.01302171 0.00269902 0.00619205
 0.01207626 0.01301295 0.00619205 0.01302171 0.00535881 0.00619205
 0.01302171 0.00269902 0.01302172 0.00758961 0.00758845 0.00500353
 0.00269902 0.00269901 0.0053867  0.00538669 0.00619205 0.01302171
 0.00500353 0.0053867  0.01302172 0.01302172 0.01302175 0.00619205
 0.02150701 0.00500353 0.00619205 0.00269902 0.01304584 0.0053867
 0.0053867  0.0053867 ]
tr_loss:[0.00592842 0.00121542 0.00362462 0.00454675 0.00593068 0.03352361
 0.00592842 0.00454675 0.00639819 0.03352361 0.00679488 0.00592842
 0.00679488 0.03352362 0.00454675 0.00592842 0.00742085 0.00121543
 0.03352361 0.00679488 0.00679488 0.03352361 0.00742085 0.00592842
 0.03352361 0.00592842 0.03352362 0.03352362 0.00121289 0.00592842
 0.00121543 0.00679488 0.03352362 0.03352361 0.00592842 0.00121542
 0.00454675 0.00454675 0.00362462 0.00592842 0.03352362 0.00102785
 0.03352362 0.03352361 0.03352362 0.00362462 0.03352361 0.00592842
 0.00454675 0.03352361]
tr_loss:[0.0083185  0.0083185  0.00791625 0.0083185  0.00831852 0.00200393
 0.0083185  0.00403506 0.00403982 0.00564316 0.03285753 0.03285753
 0.03285753 0.0083185  0.0083185  0.00791625 0.00403982 0.00578195
 0.00578586 0.00791625 0.00200392 0.00578335 0.03285753 0.00403982
 0.0083185  0.00403982 0.00831849 0.0083185  0.0083185  0.03285753
 0.00403982 0.00564316 0.00200392 0.0083185  0.00403982 0.00200392
 0.0083185  0.00564316 0.03285753 0.00564316 0.03285753 0.00564316
 0.00200392 0.00564316 0.00578195 0.00578195 0.00403982 0.00564316
 0.00564316 0.03285752]
tr_loss:[0.00619884 0.00536291 0.00826404 0.00262889 0.00919452 0.00919452
 0.02666385 0.00826404 0.00826404 0.00262891 0.02666385 0.00536291
 0.00452968 0.00504701 0.00826404 0.00919452 0.00452968 0.02666385
 0.00619884 0.00262892 0.00826404 0.00919452 0.00826404 0.00262891
 0.00619884 0.00619884 0.00452968 0.00919452 0.00919452 0.00262892
 0.00452968 0.02666385 0.00536292 0.00262231 0.00256709 0.00114452
 0.00930649 0.00619884 0.02666385 0.00826404 0.02666366 0.00919452
 0.00619884 0.00826404 0.00262892 0.00617154 0.02666386 0.00262892
 0.00619884 0.00536301]
tr_loss:[0.01632554 0.00823501 0.00721452 0.00305769 0.00305769 0.00776785
 0.00584163 0.01632554 0.01632554 0.00721452 0.00584163 0.00584163
 0.00305769 0.00721452 0.01632554 0.01632554 0.00305743 0.00776785
 0.00776784 0.00823502 0.00823502 0.0082351  0.00305768 0.00721452
 0.00721452 0.01632553 0.00823501 0.00523776 0.00776591 0.00584163
 0.00776785 0.00523798 0.00523776 0.00523776 0.00665411 0.00523776
 0.00584163 0.00776784 0.00721452 0.01632554 0.00776784 0.00305769
 0.00776785 0.00823502 0.00584163 0.00584164 0.00721452 0.00584162
 0.00721452 0.00776785]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4900 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4901, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4901 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4902, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4902 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4903, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4903 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4904, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4904 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4905, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4905 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4906, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4906 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4907, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4907 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4908, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4908 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4909, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4909 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4910, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4910 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4911, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4911 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4912, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4912 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4913, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4913 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4914, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4914 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4915, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4915 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4916, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4916 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4917, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4917 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4918, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4918 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4919, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4919 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4920, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4920 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4921, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4921 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4922, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4922 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4923, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4923 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4924, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4924 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4925, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4925 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4926, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4926 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4927, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4927 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4928, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4928 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4929, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4929 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4930, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4930 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4931, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4931 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4932, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4932 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4933, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4933 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4934, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4934 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4935, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4935 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4936, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4936 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4937, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4937 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4938, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4938 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4939, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4939 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4940, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4940 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4941, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4941 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4942, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4942 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4943, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4943 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4944, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4944 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4945, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4945 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4946, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4946 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4947, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4947 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4948, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4948 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4949, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4949 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4950, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4950 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4951, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4951 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4952, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4952 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4953, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4953 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4954, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4954 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4955, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4955 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4956, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4956 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4957, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4957 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4958, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4958 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4959, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4959 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4960, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4960 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4961, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4961 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4962, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4962 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4963, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4963 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4964, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4964 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4965, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4965 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4966, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4966 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4967, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4967 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4968, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4968 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4969, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4969 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4970, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4970 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4971, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4971 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4972, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4972 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4973, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4973 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4974, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4974 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4975, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4975 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4976, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4976 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4977, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4977 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4978, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4978 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4979, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4979 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4980, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4980 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4981, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4981 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4982, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4982 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4983, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4983 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4984, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4984 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4985, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4985 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4986, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4986 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4987, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4987 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4988, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4988 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4989, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4989 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4990, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4990 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4991, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4991 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4992, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4992 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4993, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4993 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4994, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4994 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4995, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4995 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4996, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4996 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4997, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4997 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4998, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4998 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(4999, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 4999 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5000, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-4900
text_input.shape
(5000, 14400)
learning_input_tmp.shape
(5000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(5000, 80)
learning_output.shape
(750, 80)
Model: "sequential_101"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_101 (SimpleRNN)  (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1039108 1.0960066 1.1442358 1.1122143 1.0493362 1.1237504 1.1650498
 1.1209421 1.1237501 1.049351  1.1209427 1.1209427 1.049351  1.1650511
 1.1039116 1.0493509 1.1237501 1.1122152 1.0493511 1.1209427 1.0493507
 1.1442306 1.0960068 1.1122142 1.1209428 1.1650503 1.1039222 1.1237504
 1.1237485 1.1237501 1.1442306 1.0493507 1.1637356 1.1237502 1.103929
 1.1016855 1.1039108 1.1209427 1.1490784 1.1646601 1.1237501 1.1122129
 1.1237501 1.1122143 1.1650509 1.1122141 1.1122142 1.1237501 1.0493509
 1.1442306]
tr_loss:[0.7221328  0.7217258  0.7326888  0.81018865 0.7404123  0.74516356
 0.73485136 0.74041224 0.7557217  0.74041224 0.7217237  0.74041224
 0.7557217  0.74516803 0.75572175 0.72289455 0.73485124 0.74041224
 0.7217245  0.74041235 0.7403859  0.72172356 0.7326889  0.7348513
 0.7217237  0.73485124 0.7557216  0.74041235 0.8100982  0.7557217
 0.7451681  0.7471125  0.81018794 0.7451681  0.74516803 0.74516803
 0.7326888  0.81018865 0.8101888  0.7557217  0.72172356 0.7326897
 0.7221328  0.81018865 0.7451681  0.74516803 0.7557217  0.7348513
 0.81018865 0.7557217 ]
tr_loss:[0.42546225 0.42535084 0.46031508 0.4253509  0.43409786 0.40840062
 0.43409792 0.40840062 0.4340864  0.46031514 0.41163522 0.4156104
 0.42535096 0.41964778 0.42051372 0.46031514 0.41163516 0.41605538
 0.42051378 0.42051372 0.4253509  0.43409786 0.46031508 0.42535096
 0.43409792 0.42535082 0.4116351  0.43409786 0.43409792 0.42813724
 0.42051378 0.41163516 0.43409786 0.41113585 0.41964784 0.41964778
 0.43478522 0.42535096 0.41605535 0.4116353  0.41605538 0.42535084
 0.41163525 0.41964778 0.46031517 0.46031508 0.4253509  0.4160553
 0.42051372 0.40840062]
tr_loss:[0.2396956  0.22835545 0.23095636 0.21967837 0.22920728 0.23969564
 0.22349462 0.26014224 0.22349462 0.22924705 0.22349457 0.2536511
 0.2396956  0.22924705 0.21967831 0.26014218 0.21997836 0.22240464
 0.22240457 0.2518478  0.22835544 0.26014227 0.2224046  0.22240464
 0.22048113 0.2234946  0.26014224 0.21967836 0.2536511  0.253651
 0.25365114 0.22924706 0.22240452 0.22903554 0.22238807 0.22835545
 0.22349891 0.22349462 0.23969567 0.23969567 0.2283555  0.22835545
 0.22924718 0.22835541 0.26014224 0.22240739 0.21967828 0.25365114
 0.22349468 0.22349462]
tr_loss:[0.09894595 0.10107388 0.15169461 0.11166535 0.15169458 0.09778486
 0.09894594 0.09576669 0.11166533 0.09894593 0.15169457 0.11166535
 0.09229885 0.09301833 0.09778486 0.09894595 0.15169461 0.09576668
 0.09778832 0.10357262 0.11166533 0.11166535 0.09301834 0.15169463
 0.09778486 0.09576668 0.09301834 0.098946   0.15169461 0.11166533
 0.09894826 0.11166535 0.11166533 0.10357262 0.09894593 0.11166532
 0.09301835 0.15143341 0.09778486 0.09576669 0.09301834 0.09301833
 0.10357263 0.09301836 0.09894593 0.09778488 0.15169463 0.10357261
 0.09576671 0.11166532]
tr_loss:[0.10505132 0.10505132 0.0555537  0.06665438 0.06665437 0.06665437
 0.06492288 0.06665439 0.10505132 0.06055136 0.06492287 0.06492978
 0.06665439 0.06586287 0.06854157 0.06055024 0.06665438 0.06055024
 0.06665438 0.06055582 0.0569297  0.06853881 0.1050513  0.05692969
 0.05692969 0.05692969 0.0569297  0.05692969 0.06492288 0.06492984
 0.06854157 0.06492978 0.0555537  0.10505132 0.06492984 0.06492978
 0.1050513  0.06055024 0.06854156 0.06665438 0.06854156 0.06055024
 0.05555635 0.06665408 0.06665437 0.06055024 0.05692969 0.10505132
 0.06854156 0.05555369]
tr_loss:[0.05892178 0.05507657 0.05507657 0.07144563 0.05725961 0.1007565
 0.05583004 0.06282222 0.05507656 0.05892178 0.05892178 0.0628222
 0.05583004 0.0572596  0.06575596 0.05892178 0.05583004 0.06282221
 0.05892178 0.05507657 0.07144558 0.06575598 0.05892178 0.05725963
 0.10075654 0.05507656 0.07144558 0.06575598 0.05725961 0.07144566
 0.07144558 0.06575599 0.0572596  0.06282222 0.05507682 0.05583005
 0.07144557 0.06575564 0.06575598 0.05583005 0.05583004 0.07144558
 0.07144563 0.10075655 0.0558308  0.07144558 0.06282221 0.07144692
 0.10075655 0.05507656]
tr_loss:[0.05759532 0.05882103 0.0542359  0.09923847 0.05882103 0.09923847
 0.05423588 0.05423591 0.05793049 0.05793052 0.05362193 0.05759532
 0.05759531 0.05423589 0.0710063  0.09923847 0.05423608 0.0710063
 0.05362192 0.0710063  0.06150088 0.05759528 0.09923847 0.09923842
 0.06150085 0.07100635 0.09923842 0.05423589 0.05882103 0.05423588
 0.06150089 0.05759512 0.05882103 0.05759531 0.09923842 0.06150088
 0.0710063  0.0542359  0.05362192 0.05882103 0.05882104 0.05882105
 0.07098377 0.06150089 0.09923842 0.05793051 0.07100635 0.09923847
 0.05759531 0.05362192]
tr_loss:[0.07133328 0.06140371 0.06140371 0.10196837 0.06360451 0.06360451
 0.06399752 0.06040964 0.06399752 0.06360451 0.06040958 0.0713331
 0.06140371 0.07133324 0.10196837 0.06302813 0.05824531 0.05824531
 0.10196842 0.06399754 0.06399753 0.06140371 0.0584961  0.06140371
 0.06399754 0.10196837 0.10196837 0.06399752 0.10196842 0.07133329
 0.06040964 0.05849457 0.06399876 0.06140373 0.0584961  0.06360451
 0.06399754 0.06360451 0.06040965 0.06360451 0.07133327 0.05849611
 0.0636045  0.06399754 0.06399753 0.05849611 0.06399753 0.06040964
 0.10196843 0.06399754]
tr_loss:[0.0990351  0.05770204 0.05635757 0.05635758 0.06609932 0.05639146
 0.05749589 0.05323927 0.09903506 0.09903511 0.05617546 0.05617546
 0.06609938 0.09903511 0.05770207 0.0574959  0.05770205 0.0990351
 0.0990351  0.05770205 0.05635757 0.0574959  0.05770204 0.05770205
 0.0574959  0.0574959  0.05617546 0.05318189 0.06609938 0.06609939
 0.05599863 0.05635757 0.05617546 0.05770203 0.09903506 0.05617546
 0.05323928 0.05770205 0.09903506 0.05635757 0.05770206 0.05374252
 0.06609933 0.06609933 0.09903506 0.06608951 0.09887837 0.05323927
 0.05323928 0.05635757]
tr_loss:[0.05943326 0.05038376 0.05097854 0.05038386 0.05850202 0.05850202
 0.05850207 0.1002906  0.05340809 0.05591887 0.10029066 0.05038561
 0.05340813 0.05038375 0.05393844 0.05591887 0.05097856 0.10029064
 0.05393844 0.05340809 0.10028986 0.05038375 0.05943327 0.05340809
 0.05038376 0.05591887 0.05591887 0.05340809 0.05038376 0.0559081
 0.05038375 0.05038374 0.05591887 0.05850201 0.05393844 0.05943326
 0.05340809 0.10029066 0.05340808 0.05097856 0.05943326 0.05393844
 0.05393844 0.05850201 0.05393844 0.05340808 0.05097855 0.05038375
 0.10029064 0.05097854]
tr_loss:[0.05861231 0.0676263  0.05391855 0.05697254 0.05391856 0.05200759
 0.05391856 0.05944859 0.0520076  0.06847695 0.05792025 0.05792025
 0.0520076  0.05944892 0.05792025 0.10587635 0.07167144 0.06847695
 0.06847695 0.0520076  0.06847695 0.05391855 0.05391855 0.05944859
 0.05695202 0.05391855 0.05695202 0.10587633 0.10587635 0.05944862
 0.06847695 0.05695202 0.06847695 0.05695202 0.05944859 0.05391856
 0.05861234 0.10587636 0.05391855 0.10588823 0.10587635 0.05944859
 0.05861231 0.10587635 0.05391855 0.05861231 0.05200759 0.06847695
 0.05944859 0.05391855]
tr_loss:[0.05759785 0.0603011  0.05759709 0.05450277 0.0603011  0.0603011
 0.0523072  0.0523072  0.05230721 0.10529846 0.1052985  0.0523072
 0.06915818 0.0603011  0.06915818 0.05837207 0.06030277 0.05837161
 0.05450278 0.06915816 0.05759709 0.05450277 0.10529848 0.05837161
 0.0523072  0.05759709 0.10530195 0.06030186 0.05837161 0.1052985
 0.05759709 0.06026428 0.0523072  0.10529848 0.05837161 0.1052985
 0.06915818 0.0603011  0.0603011  0.0603011  0.10529844 0.05955579
 0.0523072  0.05230721 0.05759709 0.05759709 0.06915818 0.05450277
 0.0575971  0.06915819]
tr_loss:[0.05526466 0.05526466 0.05802161 0.05720159 0.05080594 0.05802162
 0.05080593 0.06319173 0.05082515 0.09867204 0.09867204 0.05802161
 0.06319173 0.06319173 0.05865673 0.05865673 0.05080594 0.05865673
 0.05720159 0.05802161 0.05802161 0.06319173 0.05203622 0.05080593
 0.09858973 0.06318853 0.05080593 0.05526466 0.05162815 0.05865673
 0.05080593 0.05526466 0.09958814 0.06319172 0.09867199 0.05080594
 0.05203623 0.05526466 0.09867203 0.05203621 0.05526466 0.05720159
 0.05720159 0.05203623 0.05080594 0.05865673 0.05802161 0.05080593
 0.05203623 0.05720159]
tr_loss:[0.05806053 0.05443861 0.05408896 0.05796308 0.05905069 0.05408894
 0.05082619 0.05796308 0.05108818 0.0508262  0.05806054 0.05108817
 0.05806053 0.05796308 0.05408895 0.0508262  0.05796308 0.05408895
 0.05905069 0.05796308 0.05905069 0.05796302 0.05905069 0.05524548
 0.05408896 0.05905074 0.05369635 0.09009405 0.05524548 0.05082619
 0.05408894 0.0508262  0.05905069 0.0508262  0.090094   0.05905069
 0.05408895 0.05108817 0.05905069 0.05905069 0.05806054 0.05408896
 0.05408894 0.05905069 0.05108819 0.09009404 0.0508262  0.09009406
 0.05796308 0.05408895]
tr_loss:[0.05907761 0.08394061 0.05290382 0.06104727 0.08394067 0.05590697
 0.05514492 0.05907761 0.05437881 0.05907762 0.05437881 0.05290382
 0.05437881 0.05546072 0.05437881 0.05590699 0.06104722 0.05590697
 0.05907761 0.06104722 0.05290382 0.05907762 0.05514492 0.05866693
 0.05907762 0.06104723 0.06104722 0.05590697 0.05907762 0.06104571
 0.05437881 0.0543788  0.05590697 0.08394067 0.05873723 0.0590726
 0.08394067 0.05590697 0.05907761 0.05873722 0.06104722 0.05290382
 0.05590697 0.0543788  0.05590697 0.05437882 0.06104722 0.05290383
 0.05873721 0.06104722]
tr_loss:[0.05907514 0.0575536  0.05987694 0.05987694 0.08161877 0.05907513
 0.05987694 0.06346281 0.08161873 0.06346281 0.05987694 0.05907513
 0.05723367 0.05754926 0.08161873 0.05907514 0.0575536  0.05519658
 0.05907514 0.05519656 0.0575536  0.0575536  0.05519658 0.05482091
 0.08161877 0.05519656 0.08161873 0.06346286 0.08161877 0.08161534
 0.0548209  0.05723367 0.08161872 0.06346281 0.05987694 0.06346281
 0.0590185  0.05907513 0.05723121 0.05755359 0.05519656 0.0634628
 0.05907513 0.05907514 0.05907514 0.05723367 0.05987694 0.06346281
 0.06346279 0.05987694]
tr_loss:[0.06347153 0.05941806 0.05651746 0.05734922 0.07880588 0.05430501
 0.0568528  0.0568528  0.054305   0.07880588 0.0634716  0.0568528
 0.05430501 0.05941802 0.054305   0.05941805 0.05640306 0.06347155
 0.07880588 0.05941806 0.05734922 0.05651745 0.05734922 0.05430501
 0.06347156 0.0634716  0.05941806 0.05430501 0.05941805 0.054305
 0.05430501 0.05651744 0.05734922 0.05651744 0.05651744 0.07886326
 0.05941806 0.05651744 0.07880582 0.05734922 0.05734922 0.06347155
 0.07880586 0.05941806 0.05651744 0.05941805 0.07880583 0.05941806
 0.05429904 0.057128  ]
tr_loss:[0.08079535 0.05268533 0.05984405 0.08042933 0.059844   0.05984405
 0.05466774 0.05604494 0.08042933 0.08042928 0.05466774 0.05466774
 0.08043045 0.05984405 0.05268534 0.05896482 0.05604495 0.05604496
 0.05199736 0.08042934 0.05604496 0.05466774 0.08042928 0.059844
 0.05604494 0.08042933 0.05984401 0.08042934 0.05466774 0.05604494
 0.05466774 0.05604494 0.05896524 0.08042933 0.05466774 0.05199736
 0.05604495 0.05464055 0.08042934 0.08042933 0.05199736 0.05896524
 0.059844   0.05199736 0.05604494 0.05268534 0.05604495 0.05199737
 0.05268534 0.05199736]
tr_loss:[0.0790915  0.05790709 0.05301944 0.05301943 0.05812629 0.05651923
 0.05301943 0.0790915  0.05164557 0.05651924 0.0581263  0.06293203
 0.07909156 0.07909156 0.05812631 0.05790718 0.06293204 0.0579071
 0.05164557 0.07909156 0.05812631 0.07909151 0.05301936 0.07909156
 0.0579071  0.05572927 0.06293203 0.05572926 0.05812629 0.0579071
 0.06293203 0.05790709 0.05819188 0.05302089 0.05301943 0.06293203
 0.0579071  0.06293203 0.05651924 0.06293204 0.05164558 0.05164557
 0.05812635 0.06293202 0.05164558 0.05164558 0.05164558 0.07909151
 0.06293203 0.07909156]
tr_loss:[0.05801026 0.05194129 0.05656341 0.06502638 0.07828536 0.05377606
 0.06502637 0.05932643 0.05145001 0.05145002 0.05377606 0.05145001
 0.06502637 0.05377605 0.05730571 0.05801026 0.05144994 0.0593272
 0.07828541 0.05932643 0.05145002 0.05145002 0.05932644 0.05377605
 0.05730567 0.05377605 0.05145001 0.05932643 0.06502296 0.05815244
 0.05377605 0.05656341 0.05730566 0.05145001 0.05730567 0.053776
 0.05656341 0.05656341 0.05801025 0.05730567 0.05730567 0.0782854
 0.0782854  0.06502637 0.05730566 0.06502637 0.05145003 0.07828541
 0.05377605 0.05932643]
tr_loss:[0.05610858 0.05610858 0.05610858 0.05610858 0.05483083 0.05470286
 0.05610858 0.05169583 0.05470286 0.05486185 0.05807557 0.05169583
 0.0830552  0.06266314 0.05807557 0.06266312 0.05169582 0.0830552
 0.06266312 0.05470286 0.05483083 0.05807557 0.06266313 0.05470286
 0.05610858 0.05483083 0.05483083 0.06266315 0.05169582 0.04973563
 0.0517035  0.05610858 0.04973562 0.05470286 0.05470286 0.0830552
 0.05470289 0.0830552  0.05610858 0.05807555 0.06266315 0.05470286
 0.05610858 0.05470286 0.0830552  0.04973563 0.05807557 0.06266314
 0.04973563 0.04973562]
tr_loss:[0.05736454 0.04834466 0.05437232 0.05736453 0.05736454 0.04834457
 0.04874583 0.04874583 0.04834466 0.05170067 0.04874583 0.05216715
 0.05170075 0.04874583 0.05216715 0.04835861 0.08629642 0.04834466
 0.04834466 0.04834466 0.05170068 0.05736454 0.04834466 0.05437232
 0.05170068 0.04874583 0.05736454 0.08629648 0.05383341 0.05383343
 0.08629648 0.05736454 0.0538334  0.05437232 0.05170068 0.08629642
 0.08629647 0.08629648 0.05170067 0.04834466 0.05261589 0.05383341
 0.04834466 0.08629648 0.04874583 0.05170067 0.04834466 0.05383341
 0.05736453 0.05216715]
tr_loss:[0.08269858 0.05113906 0.04309432 0.04599139 0.04309432 0.04309432
 0.04548792 0.04599139 0.04309432 0.08269853 0.04309432 0.04548792
 0.04548792 0.04599139 0.04401582 0.04309432 0.04401582 0.05113906
 0.04309432 0.04393737 0.05113905 0.04548792 0.04401581 0.04599139
 0.04857591 0.04308787 0.08269858 0.0439678  0.04857686 0.05113906
 0.04396781 0.04309432 0.04309433 0.04857596 0.04309431 0.08265065
 0.04548792 0.04599139 0.04309432 0.0439678  0.04599139 0.04401581
 0.04548792 0.04539293 0.04599139 0.04309432 0.04548966 0.04396779
 0.08269857 0.04599139]
tr_loss:[0.0188473  0.02955819 0.01737671 0.01394191 0.02955819 0.0295582
 0.0188473  0.01561725 0.057608   0.01736613 0.01394191 0.01736613
 0.01561725 0.01801138 0.02955819 0.01561726 0.01736613 0.01644296
 0.01561725 0.01884729 0.01644297 0.02955819 0.02955819 0.057608
 0.01644297 0.05760803 0.01884728 0.01644296 0.01801139 0.01884777
 0.01884734 0.01801138 0.01644297 0.01736614 0.01644296 0.02955819
 0.02955819 0.01736614 0.01394191 0.01644297 0.01394192 0.01884729
 0.01564742 0.01646314 0.057608   0.01736614 0.0188473  0.0295582
 0.0188473  0.01394191]
tr_loss:[0.00672573 0.00333904 0.00606236 0.00434719 0.0439515  0.00333905
 0.00434718 0.01505812 0.00346188 0.00671054 0.01505813 0.00606236
 0.01505813 0.04395152 0.003332   0.00606236 0.00672573 0.00380094
 0.00380094 0.00672573 0.00443947 0.01505813 0.00672573 0.0043491
 0.00346189 0.0437809  0.01505812 0.00346188 0.00672573 0.00346188
 0.00606236 0.01505812 0.00672573 0.00606236 0.00346188 0.00346189
 0.0439515  0.00434719 0.00346188 0.00333904 0.00380094 0.0439515
 0.00606236 0.00380095 0.00346188 0.00606236 0.00434718 0.04395151
 0.00434719 0.01505814]
tr_loss:[0.0012045  0.01121601 0.04216184 0.00411982 0.00411982 0.00411982
 0.00060022 0.00060022 0.011216   0.00411982 0.01121601 0.01121601
 0.04216184 0.00432079 0.00433356 0.00383724 0.00060022 0.00411982
 0.00590158 0.00432079 0.00432079 0.04216184 0.00412625 0.00412099
 0.00441045 0.00432079 0.00411982 0.011216   0.0012045  0.00432078
 0.00383724 0.00060022 0.00411982 0.00060022 0.0012045  0.011216
 0.04216126 0.00411982 0.00411982 0.00411982 0.04216185 0.011216
 0.0012045  0.00590158 0.04216184 0.00412001 0.00411982 0.00590159
 0.00383724 0.00590158]
tr_loss:[0.00091206 0.00091206 0.00106093 0.00106094 0.00423266 0.0390521
 0.0055093  0.00731906 0.00091207 0.00812693 0.00765598 0.00423266
 0.00091206 0.00423266 0.0390521  0.00091207 0.00765597 0.0390521
 0.00765597 0.00812693 0.0390521  0.00423266 0.00423266 0.00812747
 0.0010609  0.0390521  0.00106093 0.00765597 0.00423266 0.0390521
 0.00106094 0.00423266 0.00840711 0.00731902 0.00091206 0.00091207
 0.00765597 0.00765598 0.00423266 0.00106094 0.00091206 0.0055093
 0.00812693 0.00812693 0.00731906 0.00423266 0.00765597 0.00091206
 0.00731883 0.0390521 ]
tr_loss:[0.01210255 0.00661741 0.00978326 0.01210255 0.00661681 0.03324323
 0.00661681 0.00248943 0.00782004 0.00248943 0.00248943 0.00574808
 0.00274962 0.00661681 0.00661681 0.00274963 0.00574807 0.00274963
 0.00978327 0.00274962 0.00661681 0.00658836 0.00661681 0.00247126
 0.00248943 0.00782004 0.00782004 0.00574807 0.00661681 0.03324329
 0.00978327 0.0332433  0.00661681 0.01210255 0.0332433  0.00248943
 0.00274963 0.00782004 0.00978321 0.00978325 0.00248943 0.00978328
 0.00782004 0.03324329 0.00248943 0.00978327 0.00673427 0.03324329
 0.00274962 0.00626858]
tr_loss:[0.01460459 0.00452734 0.01460459 0.00452734 0.00452734 0.01115272
 0.01460459 0.00717048 0.00407896 0.00708719 0.02531212 0.02531211
 0.01460469 0.00717048 0.01115272 0.00957513 0.01460458 0.00717045
 0.00717048 0.00452734 0.00717048 0.02531213 0.01460458 0.00717048
 0.00452733 0.02531211 0.00407897 0.02531212 0.01460459 0.00452734
 0.00717048 0.00942193 0.00919015 0.00407897 0.00407897 0.00452733
 0.00407897 0.02531212 0.01115272 0.01114386 0.02531212 0.02531212
 0.01115272 0.01115272 0.00919015 0.02531212 0.01105978 0.00407897
 0.00452734 0.00452733]
text_input.shape
(5000, 14400)
learning_input_tmp.shape
(5000, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(5000, 80)
learning_output.shape
(750, 80)
Model: "sequential_102"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_102 (SimpleRNN)  (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.4576674 1.4334043 1.4559318 1.4274411 1.4329134 1.4193313 1.4274412
 1.4334043 1.4559362 1.4334043 1.3790951 1.4192588 1.4641885 1.432919
 1.4334043 1.4334043 1.4641883 1.4190102 1.4274411 1.4330013 1.4559314
 1.464192  1.4301687 1.4600418 1.4641883 1.4329128 1.427441  1.4329134
 1.4192588 1.3790972 1.4600418 1.3790972 1.4641883 1.3790903 1.4600418
 1.4559903 1.3790976 1.4641883 1.4192585 1.4600418 1.4329134 1.4600418
 1.4274412 1.4334043 1.3790973 1.4600418 1.4274412 1.4328874 1.4192587
 1.4192588]
tr_loss:[0.68864894 0.72065514 0.6817347  0.66458386 0.6900346  0.71931285
 0.7193128  0.6894798  0.68173456 0.71931285 0.6703409  0.6703409
 0.6817347  0.71931285 0.688649   0.6645838  0.661054   0.6619867
 0.7193129  0.71931285 0.6886481  0.661054   0.7137306  0.6817347
 0.6610541  0.68864894 0.6886489  0.66106576 0.688649   0.670341
 0.71931285 0.68141496 0.6610541  0.6886489  0.6703899  0.688649
 0.68369794 0.6703409  0.6646134  0.6817347  0.6610543  0.6836979
 0.68173474 0.6886676  0.68369794 0.661054   0.664584   0.68369794
 0.683698   0.688649  ]
tr_loss:[0.35853234 0.3620769  0.35721293 0.38819093 0.36207688 0.3626193
 0.3585763  0.35722303 0.35721293 0.382947   0.3620769  0.3486913
 0.3486913  0.38294703 0.38902265 0.3620769  0.38902265 0.35853234
 0.38902265 0.3486913  0.38902262 0.35853234 0.38294703 0.38294703
 0.3866673  0.38294703 0.3620769  0.38902265 0.36286587 0.38902265
 0.35853234 0.34888142 0.38294703 0.34869128 0.36261934 0.34852618
 0.35721293 0.35721296 0.3866673  0.35721293 0.3866673  0.34869128
 0.35849628 0.3572129  0.34868562 0.38294703 0.34869128 0.35721293
 0.35721287 0.3486913 ]
tr_loss:[0.14465949 0.1597071  0.17652991 0.1579419  0.1847896  0.14465947
 0.17652991 0.1579419  0.16027045 0.19622831 0.18479273 0.1962283
 0.15441106 0.16027045 0.154411   0.18479271 0.18479271 0.1847927
 0.15794191 0.18479273 0.17652993 0.1597071  0.18479273 0.15794337
 0.1579419  0.18479273 0.15794188 0.1765299  0.18479273 0.16027047
 0.17652991 0.1597071  0.17652991 0.154411   0.14465949 0.18479273
 0.1962283  0.15970711 0.17652991 0.196229   0.1579421  0.16027045
 0.14465949 0.15794191 0.1962283  0.14465949 0.17652993 0.1597071
 0.19622827 0.18477651]
tr_loss:[0.03633829 0.04390256 0.04667159 0.03527903 0.04667159 0.04667157
 0.03633829 0.03480554 0.03480554 0.03527903 0.03633829 0.03480554
 0.04390256 0.07164045 0.07164045 0.03430427 0.04677724 0.03633829
 0.04667158 0.03480554 0.03480554 0.03527903 0.04667158 0.03527902
 0.03430427 0.03690284 0.03480554 0.03480554 0.03690283 0.03690284
 0.03527903 0.03690284 0.03527903 0.03527902 0.04390256 0.03480554
 0.07164044 0.03445657 0.03690284 0.04390256 0.03430428 0.04667158
 0.03690284 0.04662342 0.03690284 0.03527903 0.03430427 0.03527902
 0.0363383  0.03430428]
tr_loss:[0.04670846 0.01063488 0.0076852  0.04670845 0.01063477 0.01063488
 0.00813275 0.04670846 0.04670846 0.01302612 0.01063484 0.04670849
 0.01063488 0.01302612 0.0076852  0.04670845 0.04670846 0.02110383
 0.00643541 0.01063488 0.01302598 0.02110421 0.00813275 0.0211042
 0.00813275 0.00643541 0.04670846 0.04670846 0.02110418 0.01063487
 0.01063488 0.00643541 0.01302614 0.00643541 0.04690419 0.0076852
 0.00643541 0.00643541 0.00765382 0.02110419 0.01302612 0.0211042
 0.04670803 0.04670846 0.00681872 0.02110421 0.0076852  0.01063488
 0.0076852  0.00643541]
tr_loss:[0.00892846 0.01524533 0.00879056 0.00684984 0.00923754 0.01524534
 0.02280536 0.00879058 0.01524536 0.00879058 0.05092707 0.05092707
 0.00892871 0.02280536 0.00879058 0.00684984 0.00597609 0.00879058
 0.00923754 0.00892871 0.00879058 0.00892871 0.00923754 0.0089287
 0.0089287  0.01524533 0.05097566 0.0089287  0.00879056 0.00923754
 0.0089287  0.02280536 0.02280535 0.00892871 0.00597609 0.05092707
 0.00684985 0.00597608 0.02280536 0.00879058 0.05092707 0.0089287
 0.0089287  0.01524536 0.00879058 0.02280536 0.00923754 0.00684985
 0.05092706 0.05092707]
tr_loss:[0.05074582 0.01791341 0.00561849 0.01070858 0.00674112 0.00561848
 0.01791342 0.00614959 0.00674112 0.00673969 0.05074582 0.0061496
 0.01791341 0.01791329 0.01070858 0.01070857 0.00674112 0.05074582
 0.00562484 0.00381847 0.00381847 0.00561849 0.01070856 0.01070856
 0.00561847 0.05074582 0.01791342 0.05074582 0.00381847 0.00561816
 0.0071573  0.05074582 0.00674112 0.00561847 0.05074582 0.0061496
 0.00381847 0.01790985 0.00381848 0.00381847 0.01791342 0.00674112
 0.05074582 0.00674112 0.01070856 0.00381847 0.01070858 0.01791342
 0.01791342 0.00381847]
tr_loss:[0.04961376 0.04961376 0.01287682 0.00521554 0.01287682 0.00521555
 0.00974061 0.00521556 0.01287682 0.00546633 0.00388306 0.00490111
 0.00295989 0.00974061 0.01287683 0.00295989 0.00546665 0.04961377
 0.00490111 0.00974061 0.00521554 0.00295989 0.00295989 0.04961376
 0.00388306 0.00476368 0.00974062 0.00974061 0.00521556 0.01287682
 0.00974061 0.00490111 0.00521555 0.00560519 0.00295989 0.00490111
 0.00974061 0.00295989 0.00974061 0.00546633 0.0134667  0.00974061
 0.04961377 0.00295988 0.00490111 0.00962483 0.00521555 0.00388306
 0.04961376 0.00546633]
tr_loss:[0.00361173 0.00629795 0.01167122 0.00416986 0.00416986 0.0036185
 0.04894992 0.0116712  0.01167121 0.04894812 0.00416986 0.01338978
 0.0086312  0.00416986 0.00754255 0.0036185  0.01167122 0.00861462
 0.01167121 0.00416921 0.00629795 0.00629795 0.00861462 0.0036185
 0.01339016 0.00754255 0.04894814 0.00629795 0.01167122 0.0036185
 0.04894813 0.00361851 0.00861462 0.0036185  0.01167122 0.00754255
 0.00754255 0.01167121 0.01338978 0.00861462 0.00861462 0.01167121
 0.00629795 0.01338978 0.00416986 0.00861462 0.0036185  0.00861462
 0.0116712  0.00629795]
tr_loss:[0.01532441 0.04802671 0.01532431 0.01532431 0.0074249  0.01070325
 0.01070325 0.0074249  0.01070326 0.00434372 0.0074249  0.00469459
 0.01070325 0.01627512 0.01532431 0.01070325 0.00434371 0.04802672
 0.01532432 0.01540799 0.01092985 0.01092985 0.00469457 0.01070325
 0.04802671 0.00467783 0.00434371 0.00469459 0.00434371 0.01092985
 0.0074249  0.01070325 0.00469457 0.0099944  0.01532431 0.0074249
 0.00434372 0.01092985 0.0074249  0.0074249  0.0099944  0.01092985
 0.04802671 0.04802671 0.0074249  0.04802671 0.0074249  0.00434372
 0.00469459 0.01092985]
tr_loss:[0.01202964 0.04627845 0.01202964 0.00806364 0.00953724 0.04627844
 0.0053816  0.00806364 0.0095372  0.00806364 0.00538162 0.04627845
 0.00631978 0.0095372  0.01684541 0.0095372  0.0095372  0.04627845
 0.04627845 0.04627845 0.00806364 0.00953718 0.00483659 0.01202964
 0.00806364 0.00538162 0.00806364 0.01684541 0.00806364 0.00806364
 0.01202964 0.00806364 0.00483658 0.01114763 0.00483659 0.00538162
 0.00483654 0.0095372  0.00538162 0.0095372  0.01684542 0.04627844
 0.00806368 0.00483658 0.0095372  0.0095372  0.04627845 0.00483658
 0.0053648  0.00806364]
tr_loss:[0.04273611 0.00854572 0.01799356 0.01148932 0.04273609 0.01799356
 0.00841408 0.00607883 0.0123242  0.01799356 0.01148931 0.00607881
 0.01231145 0.01799356 0.00607884 0.01801222 0.01799357 0.00523038
 0.04273609 0.00607883 0.00522746 0.04273609 0.01799356 0.00841408
 0.00841408 0.00703902 0.0085553  0.00607882 0.00519407 0.00607881
 0.00607881 0.0052304  0.01799356 0.00607883 0.01799356 0.01232421
 0.00607881 0.00523038 0.01799356 0.01232421 0.00841408 0.00607881
 0.04273609 0.01232421 0.01799357 0.01232421 0.0060788  0.00841408
 0.01799356 0.04273609]
tr_loss:[0.00530158 0.00993788 0.01021128 0.01570034 0.03824443 0.00473132
 0.00473132 0.00931728 0.00500802 0.00473132 0.00993788 0.00746648
 0.00746648 0.00993788 0.01021128 0.00931727 0.00993788 0.00993788
 0.00931728 0.01570034 0.00993788 0.0157005  0.00993788 0.00530158
 0.03824476 0.00473131 0.01570034 0.00473132 0.00993788 0.03824443
 0.03824444 0.00473132 0.01021128 0.00993788 0.00798818 0.03824442
 0.01021128 0.03824442 0.03824441 0.00530157 0.00746648 0.00993788
 0.03824442 0.01021128 0.00530157 0.00746648 0.03824442 0.01021128
 0.01021114 0.00473126]
tr_loss:[0.01445734 0.03288488 0.01189869 0.00832645 0.00832645 0.00832646
 0.01189869 0.01189858 0.03288489 0.00614033 0.00529942 0.00614031
 0.00832645 0.00832645 0.00614033 0.00529942 0.01445511 0.00529942
 0.00846414 0.00529942 0.03288489 0.01189869 0.01445508 0.00529942
 0.0072299  0.00569968 0.0072299  0.03288488 0.00529942 0.01445508
 0.01189869 0.00614032 0.00614033 0.00614032 0.00614033 0.00832645
 0.01445508 0.0072299  0.00722989 0.00529942 0.00614033 0.0072299
 0.00529942 0.01445508 0.00614033 0.0072299  0.00529942 0.00832645
 0.00529942 0.00529942]
tr_loss:[0.00626451 0.01125492 0.00448782 0.0050437  0.01125078 0.0050437
 0.00724188 0.01125492 0.01125492 0.01404297 0.03725891 0.01404625
 0.01404297 0.00724191 0.00655518 0.00626648 0.00626452 0.01125492
 0.0050437  0.01125492 0.00724189 0.03725891 0.03725891 0.01404297
 0.01405589 0.00626451 0.01125492 0.00626451 0.01125492 0.00656802
 0.00626451 0.00626451 0.03725892 0.01125492 0.01404297 0.00626451
 0.0050437  0.00626451 0.01125492 0.01404297 0.00656802 0.03725891
 0.00626451 0.01125492 0.00626451 0.00626451 0.01125491 0.03725892
 0.01125491 0.03725892]
tr_loss:[0.00560927 0.01564381 0.00561717 0.00467537 0.01584101 0.01564377
 0.01564377 0.04122185 0.00627469 0.01564377 0.04148351 0.04122186
 0.00842492 0.04122185 0.00561717 0.01564377 0.00842494 0.00842493
 0.04122186 0.00459872 0.00768899 0.00561717 0.00768899 0.04122185
 0.00627469 0.0046875  0.00375649 0.00561565 0.00768899 0.00768899
 0.00842492 0.00768899 0.00627469 0.00842494 0.00627469 0.00768899
 0.00627469 0.00561717 0.01564378 0.00375649 0.04122185 0.00627469
 0.00768899 0.00627469 0.04122185 0.00842494 0.00768899 0.04122185
 0.04122186 0.00561717]
tr_loss:[0.0064333  0.00657768 0.00504434 0.00661435 0.04066877 0.01429642
 0.00504435 0.01790884 0.00661435 0.00504435 0.04066877 0.00898896
 0.00468862 0.01790883 0.00661435 0.04066877 0.04066877 0.04066876
 0.00472606 0.00898894 0.00898895 0.04066876 0.00472606 0.00662453
 0.00662453 0.00543134 0.04066877 0.00662453 0.00898895 0.00468862
 0.00662453 0.00472606 0.04066876 0.01792689 0.00661435 0.00468862
 0.00898894 0.00472606 0.01790883 0.01790884 0.00662453 0.00468862
 0.04066876 0.00504435 0.00661435 0.00898896 0.04065934 0.00898896
 0.00504434 0.00661293]
tr_loss:[0.00656706 0.0375606  0.0186992  0.00474138 0.00852889 0.00474138
 0.0375606  0.00656706 0.00852892 0.00656707 0.00697652 0.00474137
 0.00852889 0.00421229 0.00421229 0.00474136 0.00474138 0.0186992
 0.00474138 0.00421229 0.00841911 0.00697652 0.00852891 0.00783951
 0.0186992  0.00474138 0.00697652 0.00474137 0.00421229 0.00421229
 0.00697652 0.0186992  0.00421229 0.00852889 0.00474137 0.00474138
 0.00474138 0.00421229 0.00690027 0.00474138 0.00421229 0.0186992
 0.00697604 0.0375606  0.0375606  0.00852889 0.00697652 0.00421229
 0.00421219 0.00783951]
tr_loss:[0.00430535 0.01753883 0.00711072 0.00718983 0.00430534 0.00490376
 0.00711072 0.01753883 0.00718983 0.01753882 0.00674988 0.00490376
 0.00627472 0.00674988 0.00674988 0.00711072 0.00814621 0.00490376
 0.01753883 0.00430534 0.03608655 0.03608834 0.00410237 0.00490376
 0.00814621 0.00814621 0.00711072 0.00430534 0.00674988 0.03608834
 0.00718981 0.00490376 0.00490376 0.00490376 0.00429269 0.00430535
 0.00718982 0.00814621 0.01757189 0.00430535 0.00430534 0.01753884
 0.00718981 0.03608833 0.00718981 0.00430534 0.00718981 0.03608833
 0.00814621 0.00490376]
tr_loss:[0.00722273 0.00694715 0.00354588 0.00541699 0.00722273 0.01467311
 0.03572423 0.00722273 0.00354588 0.00722274 0.00594415 0.01467311
 0.00594415 0.00594415 0.00354588 0.00594415 0.03572423 0.00722274
 0.03572423 0.00694715 0.0146731  0.00594415 0.00694715 0.00722273
 0.005417   0.01467311 0.00722273 0.00722274 0.00694715 0.0146741
 0.01467311 0.00354588 0.00618776 0.00594415 0.00722273 0.00541699
 0.00541701 0.01467311 0.03572424 0.00722274 0.005417   0.00594415
 0.005417   0.00618776 0.00354588 0.00694715 0.03572425 0.00594415
 0.00354589 0.00541701]
tr_loss:[0.00610239 0.01095474 0.00555411 0.00610239 0.01099756 0.00555411
 0.03743175 0.00683851 0.01095474 0.00610239 0.00555411 0.00683851
 0.00683851 0.00393352 0.01094032 0.00498262 0.00498262 0.01263004
 0.00555411 0.01095474 0.01263004 0.00610239 0.00610239 0.00683851
 0.0049826  0.01263004 0.00393352 0.01263004 0.00683851 0.01095474
 0.03743175 0.00683851 0.01095474 0.00393352 0.00683851 0.00393352
 0.00393352 0.00393352 0.00555411 0.00498262 0.00610239 0.03743176
 0.01263004 0.01263004 0.01095473 0.00498262 0.01095474 0.00498261
 0.00393352 0.01263004]
tr_loss:[0.00410961 0.00666311 0.00666322 0.00527172 0.0062438  0.00527172
 0.04107639 0.00527173 0.04107638 0.0051563  0.01305422 0.04107641
 0.00527172 0.0062438  0.0062438  0.00515631 0.00410961 0.00707939
 0.0062438  0.0062438  0.00413686 0.00666338 0.0410764  0.0410764
 0.0410764  0.00666311 0.00410961 0.04107638 0.0041096  0.0062438
 0.00527173 0.00410961 0.00410979 0.00666311 0.04108797 0.0051563
 0.00410965 0.01214968 0.00666311 0.0410764  0.00410961 0.01214968
 0.0121842  0.0121842  0.00666311 0.0410764  0.00515632 0.0062438
 0.0410764  0.0410764 ]
tr_loss:[0.00512705 0.01013762 0.00374589 0.00374589 0.00374589 0.01260268
 0.01013763 0.00512707 0.01260268 0.00374589 0.00543374 0.00512707
 0.00585081 0.01260268 0.01260268 0.00512707 0.01260268 0.03681221
 0.01260268 0.01013762 0.00585117 0.00635381 0.0368122  0.0368122
 0.00512706 0.00512706 0.00512706 0.00512717 0.01260332 0.00635381
 0.00635417 0.00374589 0.00635381 0.00635381 0.01013762 0.00585117
 0.03949688 0.00475813 0.00499801 0.00454202 0.00585118 0.00585117
 0.01260268 0.01013762 0.00635381 0.0368122  0.00585117 0.00512707
 0.01260268 0.00499802]
tr_loss:[0.00735023 0.00359439 0.01396145 0.00359415 0.00578253 0.03298392
 0.01396146 0.01396146 0.00658175 0.00359415 0.00735023 0.00578253
 0.00359416 0.00735023 0.00578253 0.01396146 0.00735023 0.01399016
 0.00538232 0.00735023 0.00658175 0.00359415 0.00538232 0.00735023
 0.00658175 0.00359416 0.00538232 0.01396905 0.00578253 0.00552091
 0.00578253 0.00658175 0.00735139 0.00552092 0.00359416 0.00735023
 0.00359518 0.00578253 0.00359416 0.0073502  0.00578253 0.03298394
 0.00577796 0.01396146 0.00658175 0.03298394 0.00538232 0.00552077
 0.01396146 0.00551456]
tr_loss:[0.00519631 0.00380225 0.00689874 0.00380225 0.00704654 0.00650863
 0.00650866 0.00519631 0.00591944 0.03361425 0.00704654 0.00704654
 0.00519631 0.00704654 0.00610824 0.0157584  0.00704654 0.00610824
 0.03361424 0.00591945 0.00704654 0.00610824 0.03361425 0.03361426
 0.00632834 0.00704654 0.00704654 0.00380225 0.00704654 0.0157584
 0.00650865 0.00380225 0.00650864 0.00519631 0.00704654 0.03361425
 0.00380225 0.00591944 0.01575841 0.00610824 0.00704654 0.00650866
 0.00380225 0.00380225 0.00380225 0.00380225 0.01575841 0.00610824
 0.00704654 0.00519631]
tr_loss:[0.0072104  0.03464845 0.0066799  0.00611704 0.0072104  0.00457556
 0.00392548 0.00611704 0.00540294 0.00457555 0.00540294 0.00721041
 0.01620181 0.00457555 0.00392548 0.00392548 0.00721039 0.03464844
 0.00611704 0.03464846 0.00721039 0.03464845 0.0066799  0.01620181
 0.00721039 0.00721041 0.00611704 0.0066799  0.00721041 0.00611704
 0.00611704 0.00455543 0.00439575 0.00392548 0.01620181 0.00611692
 0.03465842 0.03464844 0.0066799  0.0066799  0.00611704 0.0072104
 0.03464846 0.00611704 0.0066799  0.03464829 0.00721039 0.00721039
 0.00721038 0.01620181]
tr_loss:[0.00612172 0.00602361 0.00408794 0.00602358 0.01541516 0.01541516
 0.01541516 0.00463519 0.00560805 0.01565192 0.00602361 0.00408794
 0.03269481 0.00730549 0.03255852 0.03255852 0.03255852 0.01541515
 0.00560805 0.01541516 0.00602361 0.01541516 0.00463519 0.03255852
 0.00730547 0.01541516 0.00560806 0.00463519 0.00730548 0.00730058
 0.00408794 0.00730548 0.0154153  0.03255852 0.00463519 0.03255849
 0.00408794 0.00560805 0.03255853 0.03255852 0.03255851 0.00730548
 0.00560805 0.00408779 0.00602361 0.01541516 0.00606183 0.00730547
 0.00602361 0.00560805]
tr_loss:[0.01474832 0.00522083 0.00522236 0.00666859 0.00879472 0.00522235
 0.01474832 0.02609859 0.00498361 0.00666858 0.01474832 0.00498361
 0.00522235 0.00498361 0.00677993 0.02609859 0.00522235 0.01474832
 0.00763457 0.00763457 0.00763457 0.00763457 0.00677993 0.00498361
 0.00879471 0.00666858 0.00666858 0.00677993 0.00763455 0.00677993
 0.01474832 0.02609859 0.00879472 0.00522236 0.02609859 0.00522235
 0.00522236 0.01474832 0.00763456 0.00879472 0.02609859 0.00879472
 0.00763456 0.00666858 0.00763457 0.00763456 0.00666858 0.0147498
 0.01474836 0.00677993]
tr_loss:[0.01389427 0.00527265 0.0103651  0.01389427 0.00527266 0.00706628
 0.00690236 0.00548095 0.00548096 0.00706628 0.01389427 0.01389427
 0.02494728 0.00690236 0.00690236 0.00527265 0.00706629 0.00690236
 0.0068878  0.0068878  0.0068878  0.0103651  0.01389427 0.00548095
 0.00690236 0.00527265 0.00690236 0.01036511 0.0068878  0.02494741
 0.00690236 0.01051426 0.02494729 0.02494728 0.01389427 0.0103651
 0.02494729 0.00527266 0.00690236 0.00690236 0.0070667  0.0103651
 0.00690236 0.01389427 0.02494912 0.02494729 0.00548095 0.02494728
 0.01036514 0.00688781]
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5000 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5001, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5001 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5002, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5002 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5003, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5003 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5004, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5004 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5005, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5005 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5006, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5006 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5007, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5007 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5008, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5008 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5009, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5009 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5010, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5010 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5011, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5011 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5012, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5012 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5013, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5013 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5014, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5014 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5015, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5015 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5016, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5016 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5017, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5017 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5018, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5018 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5019, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5019 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5020, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5020 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5021, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5021 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5022, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5022 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5023, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5023 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5024, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5024 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5025, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5025 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5026, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5026 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5027, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5027 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5028, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5028 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5029, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5029 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5030, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5030 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5031, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5031 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5032, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5032 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5033, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5033 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5034, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5034 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5035, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5035 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5036, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5036 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5037, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5037 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5038, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5038 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5039, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5039 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5040, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5040 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5041, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5041 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5042, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5042 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5043, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5043 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5044, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5044 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5045, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5045 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5046, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5046 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5047, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5047 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5048, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5048 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5049, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5049 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5050, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5050 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5051, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5051 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5052, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5052 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5053, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5053 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5054, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5054 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5055, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5055 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5056, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5056 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5057, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5057 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5058, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5058 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5059, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5059 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5060, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5060 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5061, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5061 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5062, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5062 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5063, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5063 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5064, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5064 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5065, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5065 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5066, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5066 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5067, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5067 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5068, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5068 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5069, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5069 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5070, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5070 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5071, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5071 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5072, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5072 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5073, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5073 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5074, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5074 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5075, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5075 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5076, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5076 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5077, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5077 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5078, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5078 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5079, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5079 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5080, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5080 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5081, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5081 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5082, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5082 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5083, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5083 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5084, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5084 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5085, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5085 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5086, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5086 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5087, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5087 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5088, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5088 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5089, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5089 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5090, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5090 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5091, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5091 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5092, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5092 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5093, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5093 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5094, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5094 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5095, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5095 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5096, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5096 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5097, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5097 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5098, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5098 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5099, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_foward
tdd_renew_learning_input
foward_input.shape
(14400,)
(180, 80)
(179, 80)
(14320,)
./out_learn 0.9 5099 3 50.0 >> scr_output_learn.txt
tdd_renew_foward
learning_input.shape
(5100, 14400)
learning_input.shape[1]
2
(180, 80)
foward_input.shape
(14400,)
(180, 80)
foward_input_tmp.shape
(179, 80)
(14400,)
tdd_learn
tdd_learn0-5000
text_input.shape
(5100, 14400)
learning_input_tmp.shape
(5100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(5100, 80)
learning_output.shape
(750, 80)
Model: "sequential_103"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_103 (SimpleRNN)  (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.1558439 1.2342921 1.1822822 1.1822822 1.193125  1.193125  1.1846267
 1.1558439 1.2220842 1.1551993 1.1905432 1.1558437 1.1558437 1.1931251
 1.1846253 1.155844  1.155844  1.1905432 1.1905432 1.1737058 1.1905432
 1.1846263 1.2342921 1.1695669 1.1931251 1.222084  1.1846267 1.1846267
 1.2220831 1.1846267 1.193125  1.1695676 1.2220842 1.222084  1.1846266
 1.234292  1.1846266 1.222084  1.1905432 1.1695664 1.1822822 1.2342923
 1.1695654 1.222084  1.1905432 1.222077  1.193125  1.1695664 1.1822822
 1.155844 ]
tr_loss:[0.7487199  0.71979725 0.6956386  0.71979725 0.7613085  0.7491802
 0.7512499  0.7613085  0.7441782  0.6969897  0.7441782  0.74251485
 0.7512775  0.74918026 0.74918    0.74918044 0.74417824 0.7491802
 0.71979743 0.76130867 0.7425149  0.7613086  0.75127804 0.71979725
 0.75127804 0.7197973  0.7512781  0.75127804 0.74817276 0.76130843
 0.74259174 0.78118074 0.78118074 0.6969898  0.7491802  0.75127804
 0.7441782  0.6969897  0.7610154  0.7440843  0.7512762  0.71979725
 0.7425149  0.71979725 0.7441782  0.71979725 0.6970011  0.76130855
 0.7425149  0.78118074]
tr_loss:[0.41126567 0.42396078 0.41460365 0.47329885 0.40342093 0.40342098
 0.40599132 0.41240492 0.42396078 0.42396078 0.40342093 0.40266022
 0.41240492 0.41341108 0.4112657  0.41126567 0.41156045 0.4112657
 0.4034191  0.41341442 0.41341048 0.41156036 0.41240492 0.4134144
 0.41156045 0.41240492 0.42396078 0.42396075 0.4134144  0.4112657
 0.40599138 0.4034513  0.42396075 0.4112657  0.41341442 0.41240495
 0.40599138 0.41240495 0.4134144  0.41156045 0.4134144  0.4112657
 0.41126576 0.40599403 0.41126567 0.4112657  0.42448968 0.40599138
 0.41240495 0.40342098]
tr_loss:[0.25970644 0.18814224 0.25970644 0.190521   0.190521   0.19052099
 0.18814045 0.20627613 0.19459951 0.204156   0.18849978 0.19459951
 0.18814042 0.18814233 0.18814223 0.20627613 0.19459951 0.18849953
 0.25970644 0.19052099 0.18849948 0.20627618 0.18814045 0.20627935
 0.20627613 0.18814042 0.18814228 0.1881423  0.20415604 0.19459951
 0.1946204  0.20415863 0.1881487  0.20627613 0.18814048 0.19052102
 0.18814225 0.18814042 0.19459952 0.20627613 0.20415604 0.1884995
 0.20415601 0.19052099 0.25970644 0.18814227 0.18814114 0.18814221
 0.18849948 0.18814042]
tr_loss:[0.07062481 0.07000891 0.08176462 0.07561048 0.06890637 0.06890638
 0.07062481 0.07000296 0.08193697 0.07000296 0.07561048 0.07000297
 0.07062481 0.13565853 0.13565855 0.08193694 0.070003   0.07062481
 0.069683   0.07561048 0.08176462 0.06968301 0.07564105 0.069683
 0.13565856 0.07866136 0.06968297 0.0817646  0.07817576 0.0817646
 0.06968298 0.08193696 0.0706289  0.08176462 0.08193696 0.07000296
 0.07062481 0.08176459 0.08193696 0.08193697 0.07000296 0.07062487
 0.0817646  0.069683   0.06890637 0.07561048 0.07561047 0.08193678
 0.07561247 0.07561047]
tr_loss:[0.04127374 0.02026491 0.02299884 0.02556326 0.0297219  0.02076272
 0.02299743 0.02590726 0.02026491 0.02076272 0.02319619 0.02556322
 0.0297219  0.02556326 0.04079684 0.0229974  0.04079684 0.02535031
 0.02026491 0.04079685 0.02972191 0.0231962  0.02556326 0.02299742
 0.02026491 0.02026491 0.0207627  0.04079685 0.02076272 0.04079684
 0.0231962  0.02076272 0.02026492 0.0207627  0.02076119 0.07323517
 0.02026492 0.02026491 0.02556326 0.02972149 0.07323517 0.04079686
 0.02556326 0.02026492 0.02319619 0.0229974  0.02076271 0.02299739
 0.0207627  0.02299741]
tr_loss:[0.01358171 0.01906128 0.0334315  0.01283982 0.01906128 0.03343149
 0.01556133 0.01906128 0.01556136 0.01357225 0.02557738 0.0334315
 0.03343149 0.01357223 0.0334315  0.02557738 0.03343149 0.01283982
 0.01556137 0.01283982 0.06333213 0.01542606 0.01283982 0.01556137
 0.01357224 0.01283982 0.03343149 0.03343149 0.02543965 0.01357223
 0.03343149 0.01906128 0.02557738 0.06333214 0.03343149 0.01556137
 0.01283982 0.02557737 0.01357224 0.01398776 0.01283982 0.02557738
 0.01556136 0.01906128 0.01283982 0.01906128 0.01556133 0.0252801
 0.06333213 0.01306534]
tr_loss:[0.02783223 0.02783224 0.0309494  0.01877286 0.06416914 0.01394932
 0.06416913 0.01645019 0.01319868 0.01465619 0.0164502  0.01465622
 0.01319869 0.01877286 0.06416914 0.01394932 0.01319868 0.03094937
 0.01394932 0.01394932 0.01394932 0.03094939 0.02783223 0.03093469
 0.0187534  0.01644785 0.01319869 0.01877286 0.01645016 0.01319869
 0.0164502  0.06416913 0.01465621 0.01465621 0.01877286 0.01465621
 0.0164502  0.03094939 0.01394932 0.02783223 0.01465619 0.0308012
 0.02783223 0.06416913 0.01877286 0.02783223 0.0146562  0.0131983
 0.0309494  0.03094938]
tr_loss:[0.01427888 0.01427885 0.01427888 0.01140512 0.01773189 0.0315068
 0.01773189 0.01773189 0.01234272 0.01424728 0.01773178 0.02715423
 0.02715423 0.01773189 0.01398973 0.0315068  0.01234272 0.01234273
 0.01234273 0.01234272 0.01234272 0.01427885 0.01140512 0.0315068
 0.02715423 0.03150678 0.0626433  0.01234273 0.01140512 0.01427888
 0.01424483 0.01427885 0.01140512 0.01140512 0.01427888 0.01463664
 0.01427885 0.06264329 0.01234272 0.02715423 0.02715423 0.01140512
 0.01234273 0.01140512 0.0315068  0.01463664 0.0315054  0.01427885
 0.01427885 0.0315068 ]
tr_loss:[0.01317891 0.00915948 0.00915949 0.00915945 0.03336738 0.03336739
 0.0121994  0.0121994  0.01478462 0.02646621 0.03336739 0.01478192
 0.00915949 0.01317891 0.01219935 0.0121994  0.01735586 0.01735586
 0.00915949 0.0121994  0.00915949 0.01317891 0.01219941 0.01317892
 0.02646621 0.01317892 0.02646621 0.02646621 0.01735586 0.01317891
 0.01219942 0.01735586 0.0131788  0.01478459 0.0121994  0.03336721
 0.0121994  0.01317891 0.01478459 0.03336739 0.00915948 0.02578774
 0.0121994  0.06153123 0.00909635 0.01735586 0.01478462 0.03336739
 0.01478462 0.02646611]
tr_loss:[0.06140631 0.03505924 0.01562802 0.01758616 0.06140631 0.01279058
 0.01758616 0.01260144 0.00823851 0.03505924 0.01758616 0.06140631
 0.02651358 0.01279058 0.01263894 0.01758616 0.01260144 0.03505924
 0.01562804 0.00823851 0.00823851 0.01279058 0.01758616 0.01279058
 0.00823851 0.03505927 0.01562804 0.03505924 0.01260145 0.06140631
 0.03505924 0.01562805 0.01260144 0.01757383 0.06140631 0.01758616
 0.01260144 0.00823851 0.01260144 0.01562804 0.01758616 0.01758616
 0.01260144 0.02651358 0.0127906  0.02651358 0.01562805 0.01279058
 0.01279058 0.01758616]
tr_loss:[0.06151747 0.0079426  0.01780221 0.01780221 0.01275734 0.06151747
 0.06151747 0.00794258 0.03593826 0.01780221 0.01290026 0.02670548
 0.00794227 0.01275735 0.01613523 0.01780221 0.0079426  0.03593826
 0.02670548 0.01275735 0.06151747 0.01290025 0.01780221 0.01780221
 0.01275732 0.01613526 0.02670548 0.0079426  0.0079426  0.0079426
 0.01780221 0.01290026 0.01290026 0.01613526 0.01275735 0.01780221
 0.01780221 0.0079426  0.01723796 0.01613527 0.00794381 0.01780221
 0.03593826 0.03593827 0.01275735 0.01287877 0.02663925 0.01275735
 0.01613527 0.01779732]
tr_loss:[0.02683788 0.02683783 0.02683788 0.01637396 0.01277045 0.01791524
 0.00783399 0.02683788 0.01303699 0.01637392 0.0616018  0.02683788
 0.00783399 0.01791524 0.02683788 0.0616018  0.01637395 0.01304837
 0.01277047 0.01277047 0.03633005 0.01304836 0.01277046 0.01637396
 0.01277045 0.01308152 0.01791523 0.01277046 0.03502078 0.01637395
 0.00783399 0.01277047 0.02683521 0.00783397 0.02683788 0.0616018
 0.01297261 0.01304836 0.01277046 0.0616018  0.03633005 0.02683788
 0.03633005 0.03633005 0.02683788 0.02683788 0.01637366 0.01637394
 0.01791524 0.01277047]
tr_loss:[0.00781885 0.02688735 0.01791557 0.06161106 0.00781885 0.00781885
 0.06161105 0.02688735 0.02688735 0.01791557 0.06161106 0.03631591
 0.01637001 0.0112763  0.03631591 0.02688735 0.01276962 0.00781885
 0.01304673 0.00781885 0.01791557 0.01791557 0.01276963 0.02688735
 0.01276961 0.01636997 0.01276963 0.02688735 0.02688735 0.01791557
 0.06161105 0.06161105 0.01791557 0.02688735 0.03631591 0.00781894
 0.02688735 0.03631593 0.01276962 0.01276962 0.01304518 0.01304519
 0.06161105 0.01782253 0.01304518 0.01276962 0.01276962 0.00781885
 0.01276964 0.01637006]
tr_loss:[0.0127557  0.01293524 0.01293523 0.01275571 0.03601467 0.0127557
 0.06156458 0.01619533 0.03601468 0.01783605 0.0127557  0.0127557
 0.03601467 0.00786322 0.0127557  0.0127557  0.00786322 0.01619537
 0.0127557  0.02686878 0.02688219 0.01293523 0.01293524 0.02688219
 0.03601468 0.01293524 0.00786322 0.06156458 0.0127557  0.00786322
 0.03601467 0.03601467 0.02688219 0.02688219 0.02688219 0.01293523
 0.01619533 0.01619534 0.00691524 0.01783605 0.02688219 0.01783605
 0.01783605 0.01783605 0.01619533 0.01619537 0.06156458 0.0127557
 0.02688219 0.03601468]
tr_loss:[0.0176533  0.0176533  0.0176533  0.06147161 0.01267935 0.0176533
 0.01577501 0.03527455 0.02684418 0.00802412 0.01267934 0.03527454
 0.01573573 0.01577501 0.01765329 0.01267747 0.03527454 0.01267934
 0.01275376 0.02684418 0.0176533  0.01577496 0.01267934 0.00801952
 0.02652757 0.01267935 0.0176533  0.00802412 0.00802412 0.01267936
 0.0176533  0.00802412 0.01275374 0.02684418 0.00802412 0.01267934
 0.06147161 0.00802412 0.01275374 0.03527454 0.0176533  0.03527454
 0.01275374 0.03527877 0.00802412 0.01577497 0.01267935 0.01275375
 0.02684418 0.03527454]
tr_loss:[0.01288715 0.01511617 0.01288714 0.03401016 0.01231739 0.01288714
 0.01288714 0.01288714 0.01231739 0.00844683 0.0151162  0.00844683
 0.06144774 0.01511617 0.01288714 0.01741907 0.02690149 0.03401017
 0.06144774 0.03401016 0.03401017 0.01288714 0.02683499 0.02690149
 0.01741907 0.01741907 0.01231737 0.01741907 0.01199462 0.02690149
 0.00844683 0.02690148 0.01741857 0.02690148 0.00844683 0.01288714
 0.02690148 0.02690149 0.01224131 0.01511618 0.01288714 0.01741907
 0.00844683 0.01741907 0.01741907 0.06144774 0.06144773 0.06144773
 0.02690149 0.02690146]
tr_loss:[0.0617042  0.00829769 0.03264846 0.01209797 0.01332203 0.01332213
 0.02726509 0.01209796 0.01332213 0.01209797 0.00934164 0.00921338
 0.02726509 0.02726509 0.01453991 0.03264842 0.0617042  0.01734733
 0.01453993 0.01209797 0.01453993 0.00921338 0.01332215 0.03264846
 0.03264846 0.01209797 0.02726509 0.01453993 0.02726509 0.03264846
 0.02110362 0.00921338 0.01734365 0.01209797 0.01734733 0.03264846
 0.01209797 0.01734733 0.01209797 0.01209796 0.03264846 0.00921338
 0.03264846 0.0617042  0.03264846 0.00921338 0.02726509 0.01454464
 0.01332215 0.03264846]
tr_loss:[0.01044439 0.01761201 0.01421254 0.0104444  0.03144419 0.01615144
 0.03144456 0.02810919 0.01426243 0.01421252 0.01220843 0.01761201
 0.06240509 0.02810924 0.01421254 0.01761201 0.02810924 0.03134472
 0.01761198 0.06240507 0.01220842 0.01421254 0.01421252 0.03144456
 0.02810924 0.03144456 0.01220842 0.01044436 0.01421252 0.02740631
 0.01761201 0.01426246 0.02810924 0.01426246 0.01761201 0.01761201
 0.02810899 0.01761201 0.01421254 0.01761201 0.01426246 0.03144456
 0.02810924 0.01421253 0.0281087  0.02810924 0.01421252 0.01761201
 0.0104444  0.01761201]
tr_loss:[0.01420234 0.01426234 0.03141123 0.06238834 0.03141124 0.06238834
 0.01420235 0.01221274 0.06238834 0.01426172 0.01041893 0.01166097
 0.01221274 0.01426174 0.03141124 0.06238834 0.01420235 0.01220029
 0.01420235 0.01420235 0.03141124 0.02813009 0.01426174 0.01420235
 0.01041892 0.01426174 0.03141124 0.01426172 0.01041892 0.03141124
 0.01761901 0.01221274 0.01426171 0.01426174 0.01426171 0.01041892
 0.01221274 0.01420234 0.02813009 0.01420235 0.01221238 0.01761902
 0.01041892 0.01041892 0.02813009 0.01426172 0.01426174 0.01426174
 0.01426174 0.01420234]
tr_loss:[0.02751026 0.00948654 0.00948654 0.03214159 0.00948654 0.03214158
 0.01739372 0.01351736 0.03214158 0.00948654 0.01439695 0.00948654
 0.01215313 0.01439698 0.01209121 0.03214158 0.01739372 0.00948654
 0.01439698 0.02750756 0.01209121 0.01739372 0.02751026 0.02751026
 0.01351736 0.01439698 0.00948654 0.01739372 0.01739372 0.00948654
 0.03214158 0.0120912  0.01739372 0.01351736 0.03214159 0.01439697
 0.06182516 0.06182516 0.01439695 0.03144737 0.0120912  0.01351737
 0.00948654 0.01348138 0.03214159 0.01351736 0.02751026 0.01739372
 0.00948654 0.02751027]
tr_loss:[0.00861936 0.01220382 0.01736429 0.01484252 0.01484253 0.01220382
 0.00861936 0.02700779 0.0148425  0.01736429 0.01484253 0.0333255
 0.01296749 0.01736429 0.00886284 0.00861936 0.01220383 0.0148425
 0.06144177 0.02703785 0.01220436 0.01736429 0.02703785 0.0333255
 0.0333255  0.02703775 0.01220384 0.00861936 0.00861936 0.0333255
 0.01220382 0.0122104  0.01296749 0.01280651 0.01414351 0.00861936
 0.0333255  0.02703785 0.01220383 0.0333255  0.01296749 0.00861936
 0.01736429 0.01713725 0.02703785 0.03332499 0.01736429 0.0148082
 0.06144177 0.06144177]
tr_loss:[0.01747298 0.03417021 0.00823173 0.02691499 0.00816733 0.01240553
 0.06136522 0.03417021 0.03417021 0.01747298 0.01240553 0.01240555
 0.01691166 0.01240555 0.01240553 0.01278332 0.06136521 0.01747298
 0.00823175 0.01747298 0.0341702  0.01525268 0.01525271 0.01525271
 0.01525267 0.06136522 0.01240554 0.03417021 0.03417021 0.01278335
 0.01747291 0.06136522 0.01278335 0.02691499 0.01278334 0.06136521
 0.01525268 0.02200043 0.03417021 0.01240554 0.01240553 0.01525268
 0.01240553 0.01277751 0.03572651 0.02691499 0.00823174 0.01240555
 0.0174728  0.01240553]
tr_loss:[0.01275039 0.015341   0.01245693 0.00815775 0.06134756 0.02690719
 0.02690719 0.01275038 0.00815775 0.01245694 0.01750515 0.01534099
 0.02690719 0.01534099 0.01750515 0.01245694 0.01275038 0.0343241
 0.0343241  0.01534099 0.02690117 0.06134756 0.06134756 0.02690719
 0.01275038 0.06134756 0.06134756 0.00815775 0.00815775 0.00815775
 0.00815775 0.01534101 0.00815775 0.00815896 0.01275038 0.02690719
 0.01245694 0.02690719 0.02690719 0.01245886 0.01244688 0.06134756
 0.06134756 0.01275038 0.01750515 0.01275038 0.01245693 0.01750515
 0.06134756 0.01245693]
tr_loss:[0.00815248 0.01273734 0.0342736  0.00815248 0.01748985 0.02691065
 0.00816972 0.01532448 0.0175018  0.01245183 0.02691066 0.01532445
 0.0175018  0.02691066 0.01532445 0.00815248 0.0342736  0.01532446
 0.06131974 0.0175018  0.0342736  0.01281505 0.01245182 0.01273736
 0.01532449 0.02691066 0.06131973 0.01532448 0.02691066 0.02691066
 0.01532449 0.0342736  0.02691066 0.0342736  0.01245182 0.01273735
 0.00815248 0.00815248 0.01273734 0.00815257 0.01245182 0.01532448
 0.01245182 0.01273736 0.0175018  0.02691066 0.00815248 0.01273736
 0.02691065 0.02676401]
tr_loss:[0.03384804 0.03384831 0.01234816 0.01743846 0.03384804 0.03384804
 0.01743846 0.03384805 0.01276801 0.01512132 0.012768   0.01276801
 0.01276801 0.02694305 0.01743846 0.01743846 0.012768   0.00827183
 0.03384804 0.02694305 0.01743846 0.01276799 0.00827183 0.03384804
 0.0127663  0.01234814 0.03384805 0.03384804 0.02694305 0.01234814
 0.01512132 0.00827183 0.06128519 0.01234826 0.03384804 0.03384804
 0.012768   0.06128519 0.01234816 0.01743846 0.00827183 0.06128519
 0.01234814 0.02694305 0.01743846 0.03384801 0.01512129 0.01743846
 0.01276756 0.01234814]
tr_loss:[0.01214932 0.01466819 0.03281712 0.01214932 0.01281355 0.01297341
 0.0129734  0.01734842 0.01734842 0.00870031 0.02714528 0.01214933
 0.02714528 0.01466817 0.061336   0.01734842 0.02714528 0.01734709
 0.0146682  0.01734842 0.01214932 0.01214932 0.02714528 0.02714528
 0.00870031 0.01214932 0.01466819 0.02714528 0.03281712 0.01466554
 0.01734842 0.02714528 0.02714528 0.00870031 0.01297341 0.01214933
 0.0146682  0.01734842 0.01466817 0.00870031 0.01734842 0.01214927
 0.0087003  0.01297341 0.0146682  0.01297341 0.03281705 0.00870031
 0.01466817 0.01734843]
tr_loss:[0.01209495 0.03191777 0.01436592 0.03191878 0.01436595 0.01436592
 0.01209495 0.06154404 0.06154404 0.01740174 0.02754313 0.00927601
 0.00927601 0.00927601 0.01732411 0.00927601 0.01740174 0.01209495
 0.02754313 0.00927601 0.009276   0.03191877 0.01209496 0.02754313
 0.02754313 0.01209496 0.01436592 0.03191877 0.01436592 0.01209495
 0.01333998 0.01436595 0.02754313 0.01740174 0.03191877 0.06154405
 0.06154404 0.01333995 0.01204167 0.009276   0.00927601 0.00927601
 0.06154404 0.01333998 0.01740174 0.00927601 0.01436592 0.01740174
 0.03191877 0.06154404]
tr_loss:[0.0142893  0.02777698 0.01428928 0.01747536 0.01747536 0.01428928
 0.00954734 0.02777698 0.0142893  0.01428928 0.00954732 0.01352206
 0.01352206 0.00954734 0.01352206 0.01212341 0.02776321 0.01747536
 0.03156561 0.0142893  0.03157325 0.01747536 0.01352206 0.01352208
 0.01428928 0.03157326 0.01352206 0.01212341 0.01747536 0.01212341
 0.0142893  0.02777577 0.01744827 0.00954734 0.03157326 0.02777698
 0.01352206 0.01352206 0.01352206 0.01428936 0.01212341 0.03183851
 0.01352206 0.01747536 0.0142893  0.01428928 0.06163731 0.01747536
 0.02777698 0.01428928]
tr_loss:[0.00931268 0.03174798 0.00931268 0.01432665 0.01332529 0.03174798
 0.02762127 0.01210219 0.00931268 0.02762127 0.03174798 0.01432668
 0.02762127 0.01210217 0.00931268 0.01432665 0.01210217 0.02762127
 0.00931236 0.01742481 0.01210217 0.02762127 0.01332527 0.02762127
 0.02606986 0.03174798 0.03169352 0.06144177 0.031748   0.02762127
 0.01332529 0.01210217 0.01742481 0.031748   0.06144177 0.03174798
 0.01332527 0.01432642 0.00931268 0.01332527 0.01742481 0.01742481
 0.01332528 0.02762127 0.00931268 0.06144177 0.01210219 0.00931268
 0.01432665 0.03174797]
text_input.shape
(5100, 14400)
learning_input_tmp.shape
(5100, 180, 80)
learning_input.shape
(750, 180, 80)
learning_output_tmp.shape
(5100, 80)
learning_output.shape
(750, 80)
Model: "sequential_104"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 simple_rnn_104 (SimpleRNN)  (None, 80)                12880     
                                                                 
=================================================================
Total params: 12,880
Trainable params: 12,880
Non-trainable params: 0
_________________________________________________________________
tr_loss:[1.3943386 1.4083995 1.413232  1.3984454 1.350462  1.416028  1.4160887
 1.4160182 1.4160184 1.4007151 1.3984454 1.3998234 1.4160184 1.4132327
 1.350462  1.3984454 1.381513  1.3984454 1.4131467 1.4132318 1.4132318
 1.4160182 1.4132318 1.4084766 1.3984454 1.3984454 1.4132318 1.4007151
 1.4132307 1.400715  1.3943384 1.3792851 1.3984454 1.3792851 1.3792919
 1.3984452 1.4160182 1.4160182 1.3792851 1.3984448 1.4132318 1.4084766
 1.3792851 1.4132318 1.400715  1.3792851 1.4084766 1.3792851 1.3504618
 1.4131984]
tr_loss:[0.7770039  0.7831777  0.80767155 0.8209879  0.79840624 0.80767155
 0.820988   0.7984501  0.79555863 0.7984501  0.7955587  0.79866207
 0.7770039  0.7966099  0.80767155 0.8003866  0.81001985 0.7770039
 0.79817057 0.8076714  0.7962444  0.8100201  0.8136427  0.777003
 0.81001985 0.8209879  0.8076714  0.820988   0.79845005 0.80767137
 0.7770039  0.80767155 0.80767155 0.783179   0.80767155 0.7966099
 0.7966099  0.79660994 0.8209878  0.7955587  0.820988   0.8209879
 0.7966099  0.8209879  0.7770039  0.80767155 0.7955587  0.783179
 0.820988   0.777004  ]
tr_loss:[0.47618192 0.44421586 0.40326127 0.48502198 0.40326127 0.48502192
 0.40326127 0.43951234 0.42448014 0.43951234 0.43951234 0.44421586
 0.45704278 0.43951234 0.45704278 0.43951234 0.43951234 0.4761819
 0.45704538 0.4850219  0.44421592 0.4761819  0.43254232 0.4761819
 0.4556655  0.44421586 0.43254226 0.47618192 0.42449155 0.44421586
 0.40326127 0.43951154 0.43254226 0.40326127 0.40326127 0.40326124
 0.4566196  0.42448014 0.43951234 0.4761819  0.43254226 0.42405748
 0.44421703 0.47618198 0.43951234 0.42448005 0.43254232 0.40327263
 0.44421592 0.43254226]
tr_loss:[0.30238524 0.25324884 0.25957847 0.26450774 0.25957844 0.25957283
 0.2645077  0.32750645 0.26450777 0.2595784  0.25957844 0.25324887
 0.24256404 0.26406202 0.25324887 0.30238518 0.2532488  0.264062
 0.242564   0.32750642 0.26406384 0.2595784  0.2595784  0.30238524
 0.25324887 0.2844685  0.264062   0.30238518 0.24326034 0.25957823
 0.2645077  0.25983796 0.26451603 0.2532161  0.30238524 0.30238518
 0.2532488  0.25324878 0.28446847 0.2645077  0.25324875 0.24256405
 0.25324884 0.32750645 0.30238524 0.26406202 0.24256405 0.26450777
 0.32750645 0.26834053]
tr_loss:[0.18305722 0.18827648 0.18862486 0.22034824 0.18704213 0.18751058
 0.22057846 0.1870421  0.18751054 0.18704215 0.18305719 0.18827648
 0.2205784  0.20605712 0.1830572  0.20605715 0.24098437 0.18862487
 0.24098437 0.18704212 0.18751054 0.18827648 0.24098437 0.18862489
 0.18880814 0.18862489 0.18862489 0.22057843 0.18827645 0.18758836
 0.18704212 0.20605707 0.20605715 0.22057846 0.18862489 0.1875106
 0.1870421  0.20605715 0.22057846 0.24098437 0.18827648 0.20605159
 0.18751054 0.20605712 0.20605707 0.1870421  0.20605712 0.18305722
 0.1870421  0.1870421 ]
tr_loss:[0.11939032 0.12120173 0.12120171 0.11372401 0.11372399 0.11372473
 0.14423874 0.14423874 0.15395999 0.18817824 0.1197532  0.14423874
 0.11745717 0.1183534  0.14423874 0.11939027 0.18817826 0.1197625
 0.15395999 0.1193902  0.11939026 0.15395889 0.12120171 0.1197532
 0.14423873 0.14423701 0.11939032 0.11939027 0.11939031 0.12120172
 0.1197532  0.12120171 0.15395999 0.11745717 0.12120172 0.15395997
 0.14423868 0.12120171 0.12120172 0.12120172 0.14423874 0.14423871
 0.14423871 0.11745717 0.1197532  0.11745715 0.11372397 0.11939031
 0.11372399 0.11745717]
tr_loss:[0.04657129 0.04657129 0.05298536 0.11845355 0.05335184 0.04775185
 0.05417446 0.05417445 0.05346184 0.04775186 0.08697247 0.04657129
 0.0720553  0.05417446 0.08697248 0.04775183 0.07205535 0.07205535
 0.05340526 0.0543227  0.04775182 0.05417457 0.08697248 0.05298537
 0.04775184 0.05335184 0.05335183 0.04775182 0.04657129 0.05417451
 0.08697249 0.04657128 0.05298535 0.05417446 0.04715076 0.07205534
 0.04657129 0.05335183 0.07205531 0.11845355 0.05335184 0.11845354
 0.05298537 0.04775183 0.0720553  0.05335183 0.08697247 0.05335184
 0.05417445 0.05335183]
tr_loss:[0.05879401 0.08401464 0.02552876 0.05782338 0.05879399 0.02785035
 0.02785035 0.02552876 0.02120104 0.0406434  0.04064336 0.02552876
 0.08401464 0.02992989 0.05879401 0.03029206 0.02785035 0.01956272
 0.02552877 0.0195627  0.05879401 0.02785035 0.02120104 0.02989435
 0.02989434 0.0195627  0.02120104 0.058794   0.058794   0.02122411
 0.02785035 0.02120104 0.02153357 0.02989434 0.02120103 0.04064336
 0.04064336 0.02989435 0.02989434 0.02785035 0.02785035 0.02120104
 0.05879399 0.02785035 0.02552876 0.02989434 0.02120103 0.058794
 0.02120104 0.058794  ]
tr_loss:[0.01719586 0.02782004 0.02783553 0.02578681 0.02578681 0.03763326
 0.05557008 0.05555388 0.08072723 0.02578681 0.03763329 0.05555388
 0.05555389 0.03763326 0.0376333  0.02306639 0.02306776 0.02306639
 0.05555389 0.02578681 0.02578681 0.01719586 0.02782004 0.05555388
 0.02578681 0.01936797 0.02306639 0.02414922 0.02306639 0.01936797
 0.01719586 0.02782004 0.02306641 0.02578681 0.01719586 0.02799349
 0.01719588 0.01936797 0.02782004 0.05555388 0.08072723 0.02782004
 0.05555389 0.0376333  0.02306641 0.01937419 0.01936797 0.08072721
 0.0807272  0.02306639]
tr_loss:[0.05293553 0.05293553 0.07929163 0.02148065 0.03578044 0.02624238
 0.02148064 0.02624238 0.0529366  0.07929164 0.02449461 0.05293553
 0.0244945  0.02167531 0.01878038 0.0244945  0.01878039 0.05293553
 0.02624238 0.01878039 0.01878039 0.0244945  0.07929163 0.01593747
 0.02148063 0.05293553 0.03578052 0.01878039 0.01593748 0.01878039
 0.02148064 0.01878039 0.0244945  0.02261117 0.02148064 0.01878039
 0.0244945  0.01593749 0.01593751 0.07929164 0.0244945  0.02148065
 0.03578056 0.03578052 0.02624238 0.01593749 0.02148063 0.0244945
 0.07929164 0.05293553]
tr_loss:[0.01099352 0.01626403 0.04223366 0.02812707 0.04223366 0.02812707
 0.01099352 0.04223366 0.07257275 0.01884135 0.01884136 0.02054903
 0.04223367 0.04223366 0.02812703 0.01626403 0.04223366 0.01884135
 0.01099352 0.01509165 0.02054903 0.07257275 0.04218664 0.07257275
 0.02054903 0.04223366 0.01884135 0.01099351 0.02812674 0.02812703
 0.02812703 0.02812707 0.02658145 0.02054903 0.01627467 0.02054903
 0.01509167 0.01884135 0.02054903 0.01099352 0.01509167 0.04223367
 0.02810588 0.04223366 0.01626403 0.01099352 0.01626403 0.01884135
 0.01884135 0.01509167]
tr_loss:[0.01654728 0.00994711 0.05880831 0.00564679 0.00994712 0.00616268
 0.00994711 0.00606309 0.01654667 0.01654728 0.01629733 0.05880831
 0.01654728 0.00606309 0.00606308 0.01201537 0.00606307 0.00606309
 0.01969777 0.01629733 0.05880831 0.01653214 0.00994711 0.01629732
 0.00616266 0.00606309 0.00994711 0.05880831 0.00616268 0.01969777
 0.01201536 0.01654728 0.01201538 0.01201538 0.00616268 0.00606309
 0.01201538 0.00994711 0.00606309 0.00606309 0.00606291 0.01969778
 0.05880832 0.01654728 0.01201537 0.01654728 0.01201538 0.01629733
 0.01201537 0.01201536]
tr_loss:[0.01364889 0.05949323 0.01473415 0.0107519  0.03282907 0.03282908
 0.05949323 0.01108873 0.00786186 0.03282907 0.00786189 0.01473415
 0.03282907 0.01108873 0.05949323 0.01364887 0.00786189 0.01108873
 0.03283578 0.01075188 0.01473415 0.01364889 0.02382578 0.02382578
 0.01108873 0.02382578 0.02382578 0.01075188 0.02382578 0.01108873
 0.01075188 0.03282907 0.03282907 0.05949323 0.01108873 0.00786189
 0.01473415 0.02382578 0.02382578 0.01473415 0.01068718 0.03282907
 0.01473398 0.00786189 0.0107519  0.01075188 0.00914353 0.03282907
 0.01473415 0.03285163]
tr_loss:[0.01640769 0.01640772 0.01228842 0.03661365 0.02611251 0.01711886
 0.01228842 0.00741377 0.03661365 0.01228842 0.06116346 0.03661365
 0.01228843 0.01280656 0.02611252 0.00741379 0.01658005 0.03661365
 0.06116346 0.02611251 0.00741387 0.06116346 0.03661365 0.01711885
 0.01640767 0.02611251 0.01711885 0.01276608 0.01280657 0.02611252
 0.03661365 0.00741379 0.01640768 0.06116346 0.01280656 0.00741379
 0.03661365 0.01640772 0.01280656 0.01280655 0.01711886 0.01228842
 0.01280689 0.02611251 0.01280758 0.03661365 0.02611252 0.00741379
 0.03661365 0.01228843]
tr_loss:[0.01347423 0.02682002 0.01728983 0.01728981 0.02682002 0.01273406
 0.02682002 0.00736971 0.01273407 0.02682002 0.01791058 0.01347423
 0.01273406 0.01728984 0.01347423 0.00736971 0.0172898  0.06177542
 0.03779691 0.01791058 0.01791058 0.01728984 0.02682002 0.02682002
 0.02682002 0.01273406 0.01728984 0.00736971 0.01273406 0.0172898
 0.01347423 0.01347423 0.01791058 0.01347424 0.01728983 0.00736971
 0.01728983 0.03779688 0.01765266 0.0172898  0.01728984 0.03779688
 0.01791058 0.01791058 0.0166079  0.02681887 0.02682002 0.02682002
 0.0073697  0.01789607]
tr_loss:[0.02199307 0.01822519 0.03826503 0.02709257 0.02709257 0.01373844
 0.01822515 0.01822519 0.00735794 0.01291552 0.01763754 0.01373846
 0.02706292 0.01311552 0.06202707 0.01373845 0.01822519 0.01021058
 0.06202706 0.01373844 0.01764048 0.03826502 0.01373844 0.01291552
 0.01764048 0.03826504 0.03826503 0.00735794 0.00735794 0.01822519
 0.0073579  0.01764048 0.01291552 0.03826502 0.00735794 0.01291553
 0.01291552 0.03826502 0.01373846 0.01373846 0.01764052 0.01764048
 0.02709257 0.01764048 0.01373844 0.01373846 0.02709257 0.01764048
 0.02709256 0.06202708]
tr_loss:[0.02720642 0.00734485 0.01385447 0.01299535 0.01780013 0.01836316
 0.03847406 0.00734484 0.00734485 0.02714026 0.01385479 0.01836242
 0.06213705 0.01385447 0.01385447 0.01836316 0.01299498 0.01836316
 0.01780016 0.06213704 0.01385446 0.03847406 0.01299532 0.01385445
 0.01836316 0.01780016 0.01836316 0.01836316 0.01299534 0.01780016
 0.01836316 0.00734485 0.03847406 0.01780016 0.00734484 0.01299534
 0.02720643 0.01385446 0.03847406 0.01299534 0.01385447 0.03847406
 0.01834815 0.00734484 0.01385446 0.06213704 0.03847406 0.02720643
 0.01780014 0.02720643]
tr_loss:[0.01390159 0.0139016  0.01841892 0.01841891 0.01390168 0.01390159
 0.02724511 0.01815465 0.01787455 0.06217692 0.02724511 0.01302701
 0.00732422 0.02724511 0.01841891 0.0184131  0.01302701 0.03856401
 0.01841892 0.00732422 0.02724511 0.02724511 0.00732422 0.01302701
 0.00732422 0.02724511 0.06217692 0.01390159 0.0272317  0.03856402
 0.06217692 0.03856491 0.01300104 0.00732422 0.0139016  0.01787457
 0.06217692 0.01787457 0.01302701 0.01841892 0.01390159 0.01787455
 0.01787457 0.01302702 0.01787454 0.01841891 0.01302701 0.01710944
 0.02724511 0.03856402]
tr_loss:[0.02723646 0.03858444 0.0184256  0.0072283  0.01790211 0.00635939
 0.00729232 0.02723636 0.00729232 0.0184256  0.0184256  0.01390759
 0.02723646 0.00729232 0.0184256  0.01785924 0.01790212 0.02723646
 0.00729232 0.0184256  0.01790212 0.03858834 0.0184256  0.00729232
 0.03858489 0.01390757 0.02723646 0.01390757 0.01790212 0.01390757
 0.01785867 0.00729232 0.0184256  0.00729232 0.01390758 0.04008804
 0.06217145 0.02723646 0.0184256  0.00729232 0.00729351 0.00729232
 0.01790212 0.0130295  0.01302951 0.01302949 0.01790208 0.06217145
 0.0184256  0.0184256 ]
tr_loss:[0.0130085  0.01388092 0.01789767 0.01839339 0.01789694 0.06212686
 0.00724423 0.03855184 0.03855184 0.06212686 0.0138809  0.03855184
 0.01789695 0.01789695 0.00724423 0.03855184 0.01388092 0.01300843
 0.0138809  0.0138809  0.00724423 0.01789695 0.03855184 0.02718728
 0.0130085  0.06212686 0.01300851 0.00724423 0.01839339 0.03855184
 0.01789699 0.01789699 0.02718728 0.01300851 0.01789695 0.02718461
 0.02718728 0.01300851 0.06212686 0.06212686 0.01300851 0.06212686
 0.01839339 0.03855184 0.02718728 0.02718728 0.0138809  0.03855205
 0.02718728 0.01388091]
tr_loss:[0.03846216 0.01381741 0.01381713 0.02708882 0.02708882 0.06203489
 0.01296071 0.03846215 0.03846215 0.0138174  0.02708882 0.03846215
 0.0138174  0.01381741 0.06203489 0.03846214 0.01785998 0.01296072
 0.01285147 0.0071701  0.02708882 0.03846381 0.01296071 0.03846214
 0.01831729 0.01831729 0.01785993 0.06203489 0.0071701  0.02708882
 0.01381741 0.02694262 0.01296071 0.00717009 0.02708882 0.01296071
 0.01831729 0.01381838 0.02708882 0.0071701  0.00717009 0.03899618
 0.0071701  0.00717009 0.01831729 0.01831729 0.00717009 0.01831729
 0.03846215 0.01296071]
tr_loss:[0.01817717 0.01817717 0.01286906 0.03829307 0.02691464 0.03829307
 0.01778165 0.01817717 0.01778163 0.0128737  0.03829307 0.0128737
 0.01370027 0.01778164 0.01817717 0.01287369 0.02691464 0.01778162
 0.01287369 0.01817717 0.01287369 0.01817717 0.01287368 0.06187158
 0.02691464 0.01370023 0.03829306 0.01778166 0.03829306 0.03829307
 0.02691464 0.01817717 0.00705054 0.01368959 0.0128737  0.01287369
 0.01370027 0.0128737  0.01817717 0.02691464 0.0128737  0.01778166
 0.01287369 0.01370027 0.01817717 0.00705053 0.01817717 0.03829306
 0.03829308 0.06187158]
tr_loss:[0.01349496 0.00685004 0.01349496 0.01349496 0.01793154 0.02661125
 0.0176406  0.01793154 0.01349498 0.03799924 0.03799924 0.06158974
 0.01349496 0.01272229 0.01349498 0.01272229 0.00708555 0.06158974
 0.06158974 0.01793154 0.02661125 0.01349497 0.0176406  0.01272229
 0.01793154 0.01349497 0.01793154 0.03799924 0.0176406  0.01764057
 0.01349496 0.00685004 0.03799924 0.01349496 0.02661125 0.01342215
 0.0127223  0.01349498 0.01793154 0.06158974 0.01259177 0.0127223
 0.00686652 0.0127223  0.01764062 0.0127223  0.01782998 0.00685004
 0.01764057 0.01793153]
tr_loss:[0.01748504 0.01748531 0.01245003 0.03748423 0.01748319 0.01245002
 0.06108334 0.03748422 0.03747675 0.03748422 0.01748531 0.00648324
 0.01245004 0.00648748 0.02605287 0.01312299 0.01748531 0.01312298
 0.06108334 0.03748422 0.00648748 0.00648748 0.01312298 0.01748531
 0.00648748 0.01245003 0.02605286 0.01748531 0.01312299 0.03748422
 0.01312299 0.03748424 0.03748422 0.00648748 0.03748428 0.01739061
 0.06108334 0.01748521 0.00648746 0.01739064 0.06108334 0.02605287
 0.01312298 0.01312298 0.00648748 0.01245004 0.00648748 0.06108334
 0.01312299 0.03748422]
tr_loss:[0.06008117 0.01603276 0.01693673 0.02488475 0.00573955 0.03653815
 0.03653815 0.01658986 0.01693678 0.01658986 0.01693676 0.01693675
 0.00573955 0.01658986 0.01304741 0.01693678 0.00573955 0.03653815
 0.01658986 0.00573955 0.02488475 0.02488475 0.00573955 0.01191646
 0.01191509 0.03653815 0.01191647 0.00573955 0.01693651 0.01191645
 0.03653815 0.02488475 0.0123827  0.02488475 0.01191645 0.01693678
 0.01238269 0.01602895 0.01693673 0.01191647 0.02488475 0.01238269
 0.0123827  0.03653815 0.02488475 0.01693674 0.01238119 0.01191645
 0.01693675 0.01191645]
tr_loss:[0.01487715 0.02235944 0.02235944 0.0351489  0.01098087 0.01636161
 0.02235943 0.01098086 0.00417232 0.00417231 0.01101102 0.01636161
 0.02235943 0.05821032 0.01098087 0.00417232 0.01636159 0.01101102
 0.01636157 0.0351489  0.01487715 0.02235832 0.01101102 0.03514889
 0.0351489  0.00417232 0.00417231 0.01098086 0.01101103 0.02235944
 0.03511507 0.0351489  0.00417232 0.01487715 0.00417232 0.00417231
 0.01636164 0.01098087 0.02100281 0.05821032 0.01636161 0.01098086
 0.05821032 0.01636161 0.05821032 0.01101102 0.0351489  0.02235944
 0.02235944 0.03514891]
tr_loss:[0.01789292 0.03559664 0.01076607 0.00183388 0.00183388 0.03559664
 0.0131394  0.01789292 0.03559663 0.00999338 0.00999338 0.01076608
 0.01076609 0.03559664 0.01076607 0.03559664 0.03559664 0.00999338
 0.0131394  0.01768703 0.00999339 0.0131394  0.01789291 0.03559664
 0.01789291 0.00999338 0.00183388 0.00183388 0.00999338 0.05639548
 0.00968968 0.00183388 0.00999338 0.03559664 0.01076608 0.01789291
 0.03559664 0.01768867 0.03559663 0.01768868 0.01412863 0.03559664
 0.00183388 0.00183388 0.0131394  0.01076607 0.01988586 0.05639549
 0.0131394  0.03559664]
tr_loss:[0.01248959 0.0228052  0.01396198 0.0149189  0.00220648 0.0149189
 0.05820988 0.00220649 0.03987929 0.02280519 0.00220648 0.01396196
 0.01608874 0.05820988 0.03998067 0.00220648 0.05820988 0.01248957
 0.01608874 0.00220648 0.01608874 0.01608874 0.00220662 0.0149189
 0.03998067 0.01531207 0.01608874 0.02280522 0.02280522 0.03998067
 0.01396198 0.01396196 0.02280519 0.00220649 0.00220649 0.00220648
 0.05820988 0.02280522 0.01608874 0.0149189  0.01396196 0.01608874
 0.0149189  0.01248959 0.02280517 0.00220649 0.01608874 0.05820988
 0.01608874 0.01148868]
tr_loss:[0.02277591 0.0139506  0.0227759  0.05820021 0.01395058 0.02277592
 0.01395058 0.00220677 0.01608987 0.01234036 0.01608992 0.01247876
 0.03111619 0.02277593 0.00220677 0.0139506  0.03994973 0.01395058
 0.00220677 0.01573882 0.03994926 0.01608992 0.03994948 0.02277591
 0.01491166 0.01247876 0.02277591 0.00220677 0.00220674 0.01608992
 0.0149117  0.00220677 0.00220677 0.02277594 0.00220677 0.0149117
 0.00220677 0.01246169 0.03994972 0.01608992 0.01608992 0.00220677
 0.0139506  0.0139506  0.02277591 0.01247876 0.02277596 0.0149117
 0.05820021 0.01484628]
tr_loss:[0.01746319 0.01746912 0.0174686  0.01746912 0.01746912 0.01316394
 0.01010649 0.01811878 0.05642513 0.01316394 0.01316394 0.05642514
 0.01316394 0.01746912 0.00169528 0.01811878 0.00169528 0.01097048
 0.01316394 0.0359473  0.03591567 0.01746912 0.0359473  0.01097048
 0.01811883 0.01010649 0.01746889 0.01746912 0.01811878 0.01316394
 0.01010649 0.0181188  0.01097048 0.01811881 0.01316394 0.05642514
 0.0174691  0.0359473  0.01097047 0.01097048 0.01097048 0.01316394
 0.01097046 0.01811878 0.01811879 0.01316394 0.01010649 0.05642513
 0.01811881 0.01811883]
